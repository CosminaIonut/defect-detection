Epoch 1/20
 73/122 [================>.............] - ETA: 0s - loss: 0.4063 - mae: 0.0741 - mse: 0.0147
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184326-e5id3ily\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 7ms/step - loss: 0.3038 - mae: 0.0611 - mse: 0.0098 - val_loss: 0.0990 - val_mae: 0.0421 - val_mse: 0.0025 - lr: 0.0773
Epoch 2/20
 78/122 [==================>...........] - ETA: 0s - loss: 0.0594 - mae: 0.0416 - mse: 0.0025
122/122 [==============================] - 1s 7ms/step - loss: 0.0470 - mae: 0.0414 - mse: 0.0024 - val_loss: 0.0185 - val_mae: 0.0413 - val_mse: 0.0024 - lr: 0.0773
Epoch 3/20
122/122 [==============================] - 1s 6ms/step - loss: 0.0108 - mae: 0.0404 - mse: 0.0023 - val_loss: 0.0063 - val_mae: 0.0401 - val_mse: 0.0022 - lr: 0.0773
Epoch 4/20
 76/122 [=================>............] - ETA: 0s - loss: 0.0053 - mae: 0.0392 - mse: 0.0021
122/122 [==============================] - 1s 6ms/step - loss: 0.0049 - mae: 0.0395 - mse: 0.0022 - val_loss: 0.0041 - val_mae: 0.0394 - val_mse: 0.0021 - lr: 0.0773
Epoch 5/20
 66/122 [===============>..............] - ETA: 0s - loss: 0.0038 - mae: 0.0392 - mse: 0.0021
122/122 [==============================] - 1s 6ms/step - loss: 0.0037 - mae: 0.0390 - mse: 0.0021 - val_loss: 0.0034 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0773
Epoch 6/20
 74/122 [=================>............] - ETA: 0s - loss: 0.0033 - mae: 0.0386 - mse: 0.0020
122/122 [==============================] - 1s 6ms/step - loss: 0.0032 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.0031 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0773
Epoch 7/20
 71/122 [================>.............] - ETA: 0s - loss: 0.0030 - mae: 0.0385 - mse: 0.0020
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.03863098472356796.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184326-e5id3ily\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184326-e5id3ily\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 6ms/step - loss: 0.0029 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0029 - val_mae: 0.0389 - val_mse: 0.0020 - lr: 0.0773
Epoch 8/20
 75/122 [=================>............] - ETA: 0s - loss: 0.0028 - mae: 0.0385 - mse: 0.0020
122/122 [==============================] - 1s 6ms/step - loss: 0.0028 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0028 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0386
Epoch 9/20
122/122 [==============================] - 1s 6ms/step - loss: 0.0027 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0386
Epoch 10/20
 75/122 [=================>............] - ETA: 0s - loss: 0.0027 - mae: 0.0383 - mse: 0.0020
122/122 [==============================] - 1s 6ms/step - loss: 0.0026 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0386
Epoch 11/20
 85/122 [===================>..........] - ETA: 0s - loss: 0.0026 - mae: 0.0380 - mse: 0.0020
122/122 [==============================] - 1s 7ms/step - loss: 0.0026 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0386
Epoch 12/20
 96/122 [======================>.......] - ETA: 0s - loss: 0.0025 - mae: 0.0382 - mse: 0.0020
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.01931549236178398.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184326-e5id3ily\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 9ms/step - loss: 0.0025 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0025 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0386
Epoch 13/20
 82/122 [===================>..........] - ETA: 0s - loss: 0.0025 - mae: 0.0379 - mse: 0.0019
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184326-e5id3ily\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 6ms/step - loss: 0.0025 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0025 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0193
Epoch 14/20
 78/122 [==================>...........] - ETA: 0s - loss: 0.0025 - mae: 0.0381 - mse: 0.0020
122/122 [==============================] - 1s 6ms/step - loss: 0.0025 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0025 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0193
Epoch 15/20
 76/122 [=================>............] - ETA: 0s - loss: 0.0025 - mae: 0.0383 - mse: 0.0020
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00965774618089199.
122/122 [==============================] - 1s 6ms/step - loss: 0.0025 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0025 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0193
Epoch 16/20
 78/122 [==================>...........] - ETA: 0s - loss: 0.0024 - mae: 0.0382 - mse: 0.0020
122/122 [==============================] - 1s 7ms/step - loss: 0.0024 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0025 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0097
Epoch 17/20
 78/122 [==================>...........] - ETA: 0s - loss: 0.0024 - mae: 0.0378 - mse: 0.0019
122/122 [==============================] - 1s 6ms/step - loss: 0.0024 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0024 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0097
Epoch 18/20
 76/122 [=================>............] - ETA: 0s - loss: 0.0024 - mae: 0.0380 - mse: 0.0020
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.004828873090445995.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184326-e5id3ily\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 6ms/step - loss: 0.0024 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0024 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0097
Epoch 19/20
 77/122 [=================>............] - ETA: 0s - loss: 0.0024 - mae: 0.0381 - mse: 0.0020
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184326-e5id3ily\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 7ms/step - loss: 0.0024 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0024 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0048
Epoch 20/20
 79/122 [==================>...........] - ETA: 0s - loss: 0.0024 - mae: 0.0379 - mse: 0.0019
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0005s vs `on_train_batch_end` time: 0.0008s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0002s vs `on_train_batch_end` time: 0.0007s). Check your callbacks.
122/122 [==============================] - 1s 7ms/step - loss: 0.0024 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0024 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0048
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.07726197244303395_30_32_20epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
162/162 [==============================] - 1s 2ms/step - loss: 0.2380 - mae: 0.0676 - mse: 0.0083 - val_loss: 0.0521 - val_mae: 0.0512 - val_mse: 0.0036 - lr: 0.0773
Epoch 2/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0213 - mae: 0.0510 - mse: 0.0035 - val_loss: 0.0074 - val_mae: 0.0506 - val_mse: 0.0034 - lr: 0.0773
Epoch 3/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0050 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0039 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0773
Epoch 4/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0773
Epoch 5/20
155/162 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.03863098472356796.
162/162 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0773
Epoch 6/20
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0386
Epoch 7/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0386
Epoch 8/20
128/162 [======================>.......] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.01931549236178398.
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0386
Epoch 9/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0193
Epoch 10/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0193
Epoch 11/20
159/162 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00965774618089199.
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0193
Epoch 12/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0097
Epoch 13/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0097
Epoch 14/20
149/162 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.004828873090445995.
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0097
Epoch 15/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0048
Epoch 16/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0048
Epoch 17/20
 85/162 [==============>...............] - ETA: 0s - loss: 0.0033 - mae: 0.0501 - mse: 0.0033
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0024144365452229977.
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0048
Epoch 18/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0024
Epoch 19/20
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0024
Epoch 20/20
118/162 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0508 - mse: 0.0034
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0012072182726114988.
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0024
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.07726197244303395_30_32_20epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
122/122 [==============================] - 0s 2ms/step - loss: 0.3067 - mae: 0.0454 - mse: 0.0034 - val_loss: 0.0995 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0773
Epoch 2/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0455 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0160 - val_mae: 0.0382 - val_mse: 0.0019 - lr: 0.0773
Epoch 3/20
122/122 [==============================] - 0s 962us/step - loss: 0.0083 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0041 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0773
Epoch 4/20
 82/122 [===================>..........] - ETA: 0s - loss: 0.0032 - mae: 0.0381 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.03863098472356796.
122/122 [==============================] - 1s 6ms/step - loss: 0.0029 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0773
Epoch 5/20
 78/122 [==================>...........] - ETA: 0s - loss: 0.0022 - mae: 0.0381 - mse: 0.0019
122/122 [==============================] - 1s 6ms/step - loss: 0.0022 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0386
Epoch 6/20
110/122 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0379 - mse: 0.0019
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184326-e5id3ily\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 10ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0386
Epoch 7/20
 81/122 [==================>...........] - ETA: 0s - loss: 0.0020 - mae: 0.0378 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.01931549236178398.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184326-e5id3ily\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 6ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0386
Epoch 8/20
122/122 [==============================] - 1s 6ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0193
Epoch 9/20
 71/122 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.0019
122/122 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0193
Epoch 10/20
 71/122 [================>.............] - ETA: 0s - loss: 0.0020 - mae: 0.0388 - mse: 0.0020
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00965774618089199.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184326-e5id3ily\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0193
Epoch 11/20
 77/122 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
122/122 [==============================] - 2s 13ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0097
Epoch 12/20
 76/122 [=================>............] - ETA: 0s - loss: 0.0020 - mae: 0.0382 - mse: 0.0019
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184326-e5id3ily\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 9ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0097
Epoch 13/20
 67/122 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.004828873090445995.
122/122 [==============================] - 1s 7ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0097
Epoch 14/20
 68/122 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
122/122 [==============================] - 1s 7ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0048
Epoch 15/20
 80/122 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
122/122 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0048
Epoch 16/20
 79/122 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0024144365452229977.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184326-e5id3ily\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0048
Epoch 17/20
 71/122 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0373 - mse: 0.0019
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184326-e5id3ily\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0024
Epoch 18/20
122/122 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0024
Epoch 19/20
 78/122 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0374 - mse: 0.0019
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0012072182726114988.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184326-e5id3ily\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0024
Epoch 20/20
 80/122 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184326-e5id3ily\files\model-best)... Done. 0.0s
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0009s). Check your callbacks.
122/122 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0012
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.07726197244303395_30_32_20epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
122/122 [==============================] - 0s 2ms/step - loss: 0.2851 - mae: 0.0406 - mse: 0.0023 - val_loss: 0.0926 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0773
Epoch 2/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0422 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0148 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0773
Epoch 3/20
122/122 [==============================] - 0s 975us/step - loss: 0.0076 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0038 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0773
Epoch 4/20
 82/122 [===================>..........] - ETA: 0s - loss: 0.0030 - mae: 0.0382 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.03863098472356796.
122/122 [==============================] - 0s 1ms/step - loss: 0.0027 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0773
Epoch 5/20
122/122 [==============================] - 0s 985us/step - loss: 0.0021 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0386
Epoch 6/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0386
Epoch 7/20
 85/122 [===================>..........] - ETA: 0s - loss: 0.0020 - mae: 0.0379 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.01931549236178398.
122/122 [==============================] - 0s 979us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0386
Epoch 8/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0193
Epoch 9/20
 85/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
122/122 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0193
Epoch 10/20
 78/122 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00965774618089199.
122/122 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0193
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184326-e5id3ily\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0193
122/122 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0193
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184326-e5id3ily\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0193
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184326-e5id3ily\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0193
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184326-e5id3ily\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0193
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184326-e5id3ily\files\model-best)... Done. 0.0s
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0024144365452229977. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0193
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0024144365452229977. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0193
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184326-e5id3ily\files\model-best)... Done. 0.0s
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0024144365452229977. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0193
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0024144365452229977. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0193
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0012072182726114988. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0193
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0012072182726114988. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0193
Epoch 5/20ReduceLROnPlateau reducing learning rate to 0.0024144365452229977.N-20HN_sgd_0.07726197244303395_30_32_20epochs/model_4.h583 - val_mse: 0.0019 - lr: 0.0193
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0048
Epoch 17/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0024
Epoch 18/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0024
Epoch 19/20
 81/122 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.0019
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0012072182726114988.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0024
Epoch 20/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0012
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.07726197244303395_30_32_20epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
122/122 [==============================] - 0s 2ms/step - loss: 0.2812 - mae: 0.0545 - mse: 0.0056 - val_loss: 0.0908 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0773
Epoch 2/20
122/122 [==============================] - 0s 999us/step - loss: 0.0415 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0148 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0773
Epoch 3/20
122/122 [==============================] - 0s 956us/step - loss: 0.0077 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0039 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0773
Epoch 4/20
 83/122 [===================>..........] - ETA: 0s - loss: 0.0030 - mae: 0.0378 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.03863098472356796.
122/122 [==============================] - 0s 1ms/step - loss: 0.0028 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0773
Epoch 5/20ReduceLROnPlateau reducing learning rate to 0.0024144365452229977.N-20HN_sgd_0.07726197244303395_30_32_20epochs/model_4.h583 - val_mse: 0.0019 - lr: 0.0193
122/122 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0386
Epoch 6/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0386
Epoch 7/20
 86/122 [====================>.........] - ETA: 0s - loss: 0.0020 - mae: 0.0379 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.01931549236178398.
122/122 [==============================] - 0s 977us/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0386
Epoch 8/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0193
Epoch 9/20
122/122 [==============================] - 0s 994us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0193
Epoch 10/20
 61/122 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00965774618089199.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0193
Epoch 11/20
122/122 [==============================] - 0s 997us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0097
Epoch 12/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0097
Epoch 13/20
 84/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.004828873090445995.
122/122 [==============================] - 0s 992us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0097
Epoch 14/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0048
Epoch 15/20
122/122 [==============================] - 0s 976us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0048
Epoch 16/20
 81/122 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0024144365452229977.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0048
Epoch 17/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0024
Epoch 18/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0024
Epoch 19/20
 83/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0012072182726114988.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0024
Epoch 20/20
122/122 [==============================] - 0s 997us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0012
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.07726197244303395_30_32_20epochs/model_7.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
122/122 [==============================] - 0s 2ms/step - loss: 0.3003 - mae: 0.0534 - mse: 0.0062 - val_loss: 0.0977 - val_mae: 0.0395 - val_mse: 0.0021 - lr: 0.0773
Epoch 2/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0455 - mae: 0.0392 - mse: 0.0021 - val_loss: 0.0170 - val_mae: 0.0397 - val_mse: 0.0022 - lr: 0.0773
Epoch 3/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0093 - mae: 0.0388 - mse: 0.0020 - val_loss: 0.0051 - val_mae: 0.0393 - val_mse: 0.0021 - lr: 0.0773
Epoch 4/20
 87/122 [====================>.........] - ETA: 0s - loss: 0.0041 - mae: 0.0388 - mse: 0.0020
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.03863098472356796.
122/122 [==============================] - 0s 960us/step - loss: 0.0038 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0031 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0773
Epoch 5/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0028 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0386
Epoch 6/20
122/122 [==============================] - 0s 994us/step - loss: 0.0026 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0386
Epoch 7/20
122/122 [==============================] - 0s 1000us/step - loss: 0.0025 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0024 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0386
Epoch 8/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0386
Epoch 9/20
 85/122 [===================>..........] - ETA: 0s - loss: 0.0023 - mae: 0.0380 - mse: 0.0019
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.01931549236178398.
122/122 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0386
Epoch 10/20
122/122 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0193
Epoch 11/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0193
Epoch 12/20
 82/122 [===================>..........] - ETA: 0s - loss: 0.0022 - mae: 0.0382 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00965774618089199.
122/122 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0193
Epoch 13/20
122/122 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0097
Epoch 14/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0097
Epoch 15/20
 83/122 [===================>..........] - ETA: 0s - loss: 0.0021 - mae: 0.0381 - mse: 0.0019
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.004828873090445995.
122/122 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0097
Epoch 16/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0048
Epoch 17/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0048
Epoch 18/20
 82/122 [===================>..........] - ETA: 0s - loss: 0.0021 - mae: 0.0380 - mse: 0.0019
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0024144365452229977.
122/122 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0048
Epoch 19/20
122/122 [==============================] - 0s 987us/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0024
Epoch 20/20
122/122 [==============================] - 0s 999us/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0024
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.07726197244303395_30_32_20epochs/model_8.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
122/122 [==============================] - 0s 2ms/step - loss: 0.3051 - mae: 0.0800 - mse: 0.0153 - val_loss: 0.0981 - val_mae: 0.0437 - val_mse: 0.0028 - lr: 0.0773
Epoch 2/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0462 - mae: 0.0423 - mse: 0.0026 - val_loss: 0.0178 - val_mae: 0.0418 - val_mse: 0.0025 - lr: 0.0773
Epoch 3/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0100 - mae: 0.0409 - mse: 0.0024 - val_loss: 0.0057 - val_mae: 0.0406 - val_mse: 0.0023 - lr: 0.0773
Epoch 4/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0043 - mae: 0.0399 - mse: 0.0022 - val_loss: 0.0035 - val_mae: 0.0402 - val_mse: 0.0023 - lr: 0.0773
Epoch 5/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0031 - mae: 0.0394 - mse: 0.0021 - val_loss: 0.0029 - val_mae: 0.0396 - val_mse: 0.0022 - lr: 0.0773
Epoch 6/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0027 - mae: 0.0390 - mse: 0.0021 - val_loss: 0.0026 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0773
Epoch 7/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.0025 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0773
Epoch 8/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0024 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0773
Epoch 9/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0773
Epoch 10/20
 81/122 [==================>...........] - ETA: 0s - loss: 0.0022 - mae: 0.0385 - mse: 0.0020
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.03863098472356796.
122/122 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0773
Epoch 11/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0386
Epoch 12/20
122/122 [==============================] - 0s 987us/step - loss: 0.0021 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0386
Epoch 13/20
 86/122 [====================>.........] - ETA: 0s - loss: 0.0021 - mae: 0.0377 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.01931549236178398.
122/122 [==============================] - 0s 999us/step - loss: 0.0021 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0386
Epoch 14/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0193
Epoch 15/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0193
Epoch 16/20
 82/122 [===================>..........] - ETA: 0s - loss: 0.0021 - mae: 0.0384 - mse: 0.0020
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00965774618089199.
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0193
Epoch 17/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0097
Epoch 18/20
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0097
Epoch 19/20
 73/122 [================>.............] - ETA: 0s - loss: 0.0020 - mae: 0.0374 - mse: 0.0019
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.004828873090445995.
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0097
Epoch 20/20
122/122 [==============================] - 0s 981us/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0048
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.07726197244303395_30_32_20epochs/model_9.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0009s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0004s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.