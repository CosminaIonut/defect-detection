wandb: WARNING The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0033s). Check your callbacks.
Epoch 1/20
229/243 [===========================>..] - ETA: 0s - loss: 0.0175 - mae: 0.0456 - mse: 0.0039
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_125130-p2weyvfa\files\model-best)... Done. 0.0s
243/243 [==============================] - 3s 8ms/step - loss: 0.0166 - mae: 0.0451 - mse: 0.0038 - val_loss: 0.0020 - val_mae: 0.0362 - val_mse: 0.0018 - lr: 0.0997
Epoch 2/20
208/243 [========================>.....] - ETA: 0s - loss: 0.0022 - mae: 0.0369 - mse: 0.0019
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.049845680594444275.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_125130-p2weyvfa\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 7ms/step - loss: 0.0021 - mae: 0.0367 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0352 - val_mse: 0.0017 - lr: 0.0997
Epoch 3/20
215/243 [=========================>....] - ETA: 0s - loss: 0.0018 - mae: 0.0335 - mse: 0.0016
243/243 [==============================] - 2s 6ms/step - loss: 0.0018 - mae: 0.0335 - mse: 0.0016 - val_loss: 0.0016 - val_mae: 0.0323 - val_mse: 0.0015 - lr: 0.0498
Epoch 4/20
222/243 [==========================>...] - ETA: 0s - loss: 0.0017 - mae: 0.0312 - mse: 0.0014
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.024922840297222137.
243/243 [==============================] - 1s 2ms/step - loss: 0.0017 - mae: 0.0314 - mse: 0.0015 - val_loss: 0.0021 - val_mae: 0.0357 - val_mse: 0.0018 - lr: 0.0498
Epoch 5/20
235/243 [============================>.] - ETA: 0s - loss: 0.0015 - mae: 0.0290 - mse: 0.0013
243/243 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0290 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0274 - val_mse: 0.0012 - lr: 0.0249
Epoch 6/20
218/243 [=========================>....] - ETA: 0s - loss: 0.0014 - mae: 0.0272 - mse: 0.0012
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.012461420148611069.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_125130-p2weyvfa\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0272 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0271 - val_mse: 0.0012 - lr: 0.0249
Epoch 7/20
230/243 [===========================>..] - ETA: 0s - loss: 0.0013 - mae: 0.0255 - mse: 0.0011
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.006230710074305534.
243/243 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0254 - mse: 0.0011 - val_loss: 0.0014 - val_mae: 0.0281 - val_mse: 0.0012 - lr: 0.0125
Epoch 8/20
229/243 [===========================>..] - ETA: 0s - loss: 0.0012 - mae: 0.0244 - mse: 9.8785e-04
243/243 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0245 - mse: 9.9532e-04 - val_loss: 0.0012 - val_mae: 0.0245 - val_mse: 9.7548e-04 - lr: 0.0062
Epoch 9/20
237/243 [============================>.] - ETA: 0s - loss: 0.0011 - mae: 0.0242 - mse: 9.7026e-04
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.003115355037152767.
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0243 - mse: 9.7404e-04 - val_loss: 0.0012 - val_mae: 0.0258 - val_mse: 0.0010 - lr: 0.0062
Epoch 10/20
213/243 [=========================>....] - ETA: 0s - loss: 0.0011 - mae: 0.0237 - mse: 9.3987e-04
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0015576775185763836.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_125130-p2weyvfa\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 6ms/step - loss: 0.0011 - mae: 0.0237 - mse: 9.4029e-04 - val_loss: 0.0011 - val_mae: 0.0243 - val_mse: 9.6521e-04 - lr: 0.0031
Epoch 11/20
229/243 [===========================>..] - ETA: 0s - loss: 0.0011 - mae: 0.0238 - mse: 9.4094e-04
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0007788387592881918.
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0237 - mse: 9.3554e-04 - val_loss: 0.0011 - val_mae: 0.0245 - val_mse: 9.7916e-04 - lr: 0.0016
Epoch 12/20
213/243 [=========================>....] - ETA: 0s - loss: 0.0011 - mae: 0.0234 - mse: 9.1952e-04
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0003894193796440959.
243/243 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0235 - mse: 9.2455e-04 - val_loss: 0.0011 - val_mae: 0.0244 - val_mse: 9.6682e-04 - lr: 7.7884e-04
Epoch 13/20
225/243 [==========================>...] - ETA: 0s - loss: 0.0011 - mae: 0.0233 - mse: 9.0846e-04
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00019470968982204795.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_125130-p2weyvfa\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0234 - mse: 9.1644e-04 - val_loss: 0.0011 - val_mae: 0.0241 - val_mse: 9.5114e-04 - lr: 3.8942e-04
Epoch 14/20
219/243 [==========================>...] - ETA: 0s - loss: 0.0011 - mae: 0.0234 - mse: 9.1621e-04
Epoch 14: ReduceLROnPlateau reducing learning rate to 9.735484491102397e-05.
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0234 - mse: 9.1827e-04 - val_loss: 0.0011 - val_mae: 0.0241 - val_mse: 9.5079e-04 - lr: 1.9471e-04
Epoch 15/20
217/243 [=========================>....] - ETA: 0s - loss: 0.0011 - mae: 0.0234 - mse: 9.1904e-04
Epoch 15: ReduceLROnPlateau reducing learning rate to 4.867742245551199e-05.
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0233 - mse: 9.1581e-04 - val_loss: 0.0011 - val_mae: 0.0241 - val_mse: 9.5057e-04 - lr: 9.7355e-05
Epoch 16/20
219/243 [==========================>...] - ETA: 0s - loss: 0.0011 - mae: 0.0234 - mse: 9.1650e-04
Epoch 16: ReduceLROnPlateau reducing learning rate to 2.4338711227755994e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_125130-p2weyvfa\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 8ms/step - loss: 0.0011 - mae: 0.0233 - mse: 9.1538e-04 - val_loss: 0.0011 - val_mae: 0.0241 - val_mse: 9.5001e-04 - lr: 4.8677e-05
Epoch 17/20
222/243 [==========================>...] - ETA: 0s - loss: 0.0011 - mae: 0.0234 - mse: 9.1624e-04
Epoch 17: ReduceLROnPlateau reducing learning rate to 1.2169355613877997e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_125130-p2weyvfa\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0233 - mse: 9.1478e-04 - val_loss: 0.0011 - val_mae: 0.0241 - val_mse: 9.4997e-04 - lr: 2.4339e-05
Epoch 18/20
224/243 [==========================>...] - ETA: 0s - loss: 0.0011 - mae: 0.0232 - mse: 9.0823e-04
Epoch 18: ReduceLROnPlateau reducing learning rate to 1e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_125130-p2weyvfa\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0233 - mse: 9.1426e-04 - val_loss: 0.0011 - val_mae: 0.0241 - val_mse: 9.5003e-04 - lr: 1.2169e-05
Epoch 19/20
206/243 [========================>.....] - ETA: 0s - loss: 0.0011 - mae: 0.0234 - mse: 9.2142e-04
243/243 [==============================] - 1s 6ms/step - loss: 0.0011 - mae: 0.0233 - mse: 9.1451e-04 - val_loss: 0.0011 - val_mae: 0.0241 - val_mse: 9.5005e-04 - lr: 1.0000e-05
Epoch 20/20
243/243 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0233 - mse: 9.1453e-04 - val_loss: 0.0011 - val_mae: 0.0241 - val_mse: 9.5007e-04 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_adam_0.09969135756709652LR_[30]HN_16BS_1P_val_mseM_20epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
323/323 [==============================] - 2s 3ms/step - loss: 0.0120 - mae: 0.0528 - mse: 0.0040 - val_loss: 0.0035 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0997
Epoch 2/20
322/323 [============================>.] - ETA: 0s - loss: 0.0035 - mae: 0.0508 - mse: 0.0034
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.049845680594444275.
323/323 [==============================] - 1s 2ms/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0506 - val_mse: 0.0035 - lr: 0.0997
Epoch 3/20
317/323 [============================>.] - ETA: 0s - loss: 0.0035 - mae: 0.0508 - mse: 0.0034
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.024922840297222137.
323/323 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - lr: 0.0498
Epoch 4/20
297/323 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.012461420148611069.
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0249
Epoch 5/20
292/323 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.006230710074305534.
323/323 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0125
Epoch 6/20
300/323 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.003115355037152767.
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0062
Epoch 7/20
309/323 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0508 - mse: 0.0034
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0015576775185763836.
323/323 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0031
Epoch 8/20
294/323 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0007788387592881918.
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0016
Epoch 9/20
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 7.7884e-04
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003894193796440959.
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 7.7884e-04
Epoch 10/20
283/323 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0508 - mse: 0.0034
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00019470968982204795.
323/323 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.8942e-04
Epoch 11/20
310/323 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 11: ReduceLROnPlateau reducing learning rate to 9.735484491102397e-05.
323/323 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.9471e-04
Epoch 12/20
288/323 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034
Epoch 12: ReduceLROnPlateau reducing learning rate to 4.867742245551199e-05.
323/323 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 9.7355e-05
Epoch 13/20
310/323 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 13: ReduceLROnPlateau reducing learning rate to 2.4338711227755994e-05.
323/323 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 4.8677e-05
Epoch 14/20
323/323 [==============================] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.2169355613877997e-05.
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 2.4339e-05
Epoch 15/20
299/323 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.
323/323 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.2169e-05
Epoch 16/20
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 17/20
 27/323 [=>............................] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 19/20
266/323 [=======================>......] - ETA: 0s - loss: 0.0034 - mae: 0.0509 - mse: 0.0034
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0393 - val_mse: 0.0021 - lr: 0.0997e-05
243/243 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0125e-05
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0016e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.9471e-04
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.4339e-05
185/243 [=====================>........] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.4339e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
 52/243 [=====>........................] - ETA: 0s - loss: 0.0025 - mae: 0.0400 - mse: 0.00210019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
241/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
233/243 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
243/243 [==============================] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
222/243 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
148/243 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
148/243 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
243/243 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
243/243 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0395 - val_mse: 0.0021 - lr: 0.0498e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0062e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.7884e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 9.7355e-05
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.2169e-05
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.2169e-05
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.2169e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0021s vs `on_train_batch_end` time: 0.0033s). Check your callbacks.
228/243 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.2169e-05
219/243 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.2169e-05
229/243 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.2169e-05
219/243 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.2169e-05
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0132 - mae: 0.0401 - mse: 0.0023 - val_loss: 0.0021 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0997e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0249e-05
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0031e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.8942e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.8677e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
223/243 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
243/243 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 0.0249e-05
139/243 [================>.............] - ETA: 0s - loss: 0.0013 - mae: 0.0259 - mse: 0.0011        al_loss: 0.0021 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 0.0249e-05
222/243 [==========================>...] - ETA: 0s - loss: 0.0013 - mae: 0.0259 - mse: 0.0011        al_loss: 0.0021 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 0.0249e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0246 - mse: 9.7739e-04 - val_loss: 0.0012 - val_mae: 0.0249 - val_mse: 0.0010 - lr: 0.0016
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0243 - mse: 9.5957e-04 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 2.4339e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0243 - mse: 9.5957e-04 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 2.4339e-05
238/243 [============================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0343 - mse: 0.00175957e-04 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 2.4339e-05
236/243 [============================>.] - ETA: 0s - loss: 0.0015 - mae: 0.0302 - mse: 0.0013         - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 2.4339e-05
233/243 [===========================>..] - ETA: 0s - loss: 0.0014 - mae: 0.0296 - mse: 0.0013         - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 2.4339e-05
222/243 [==========================>...] - ETA: 0s - loss: 0.0014 - mae: 0.0297 - mse: 0.0013         - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 2.4339e-05
213/243 [=========================>....] - ETA: 0s - loss: 0.0014 - mae: 0.0297 - mse: 0.0013         - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 2.4339e-05
243/243 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0297 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0298 - val_mse: 0.0013 - lr: 1.0000e-05e-05
243/243 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0297 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0298 - val_mse: 0.0013 - lr: 1.0000e-05e-05