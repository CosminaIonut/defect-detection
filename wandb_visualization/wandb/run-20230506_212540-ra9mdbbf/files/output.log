(5161, 8)
(2212, 8)
Epoch 1/20
WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
wandb: WARNING The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.




323/323 [==============================] - ETA: 0s - loss: 0.0065 - mae: 0.0634 - mse: 0.0065 - root_mean_squared_error: 0.0807
323/323 [==============================] - 18s 41ms/step - loss: 0.0065 - mae: 0.0634 - mse: 0.0065 - root_mean_squared_error: 0.0807 - val_loss: 0.0073 - val_mae: 0.0698 - val_mse: 0.0073 - val_root_mean_squared_error: 0.0853 - lr: 0.0244
Epoch 2/20



323/323 [==============================] - ETA: 0s - loss: 0.0041 - mae: 0.0540 - mse: 0.0041 - root_mean_squared_error: 0.0642
323/323 [==============================] - 13s 41ms/step - loss: 0.0041 - mae: 0.0540 - mse: 0.0041 - root_mean_squared_error: 0.0642 - val_loss: 0.0038 - val_mae: 0.0521 - val_mse: 0.0038 - val_root_mean_squared_error: 0.0615 - lr: 0.0244
Epoch 3/20



323/323 [==============================] - ETA: 0s - loss: 0.0039 - mae: 0.0527 - mse: 0.0039 - root_mean_squared_error: 0.0621
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.012176580727100372.
323/323 [==============================] - 11s 34ms/step - loss: 0.0039 - mae: 0.0527 - mse: 0.0039 - root_mean_squared_error: 0.0621 - val_loss: 0.0075 - val_mae: 0.0706 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 0.0244
Epoch 4/20






322/323 [============================>.] - ETA: 0s - loss: 0.0035 - mae: 0.0509 - mse: 0.0035 - root_mean_squared_error: 0.0591
323/323 [==============================] - 13s 42ms/step - loss: 0.0035 - mae: 0.0509 - mse: 0.0035 - root_mean_squared_error: 0.0591 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0586 - lr: 0.0122
Epoch 5/20



323/323 [==============================] - ETA: 0s - loss: 0.0035 - mae: 0.0510 - mse: 0.0035 - root_mean_squared_error: 0.0590
323/323 [==============================] - 13s 41ms/step - loss: 0.0035 - mae: 0.0510 - mse: 0.0035 - root_mean_squared_error: 0.0590 - val_loss: 0.0033 - val_mae: 0.0504 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0576 - lr: 0.0122
Epoch 6/20



323/323 [==============================] - ETA: 0s - loss: 0.0035 - mae: 0.0509 - mse: 0.0035 - root_mean_squared_error: 0.0588
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.006088290363550186.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230506_212540-ra9mdbbf\files\model-best)... Done. 0.0s
323/323 [==============================] - 13s 41ms/step - loss: 0.0035 - mae: 0.0509 - mse: 0.0035 - root_mean_squared_error: 0.0588 - val_loss: 0.0033 - val_mae: 0.0504 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0574 - lr: 0.0122
Epoch 7/20



322/323 [============================>.] - ETA: 0s - loss: 0.0033 - mae: 0.0504 - mse: 0.0033 - root_mean_squared_error: 0.0577
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.003044145181775093.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230506_212540-ra9mdbbf\files\model-best)... Done. 0.0s
323/323 [==============================] - 14s 42ms/step - loss: 0.0033 - mae: 0.0504 - mse: 0.0033 - root_mean_squared_error: 0.0577 - val_loss: 0.0032 - val_mae: 0.0498 - val_mse: 0.0032 - val_root_mean_squared_error: 0.0568 - lr: 0.0061
Epoch 8/20




323/323 [==============================] - ETA: 0s - loss: 0.0033 - mae: 0.0502 - mse: 0.0033 - root_mean_squared_error: 0.0573
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0015220725908875465.
323/323 [==============================] - 11s 35ms/step - loss: 0.0033 - mae: 0.0502 - mse: 0.0033 - root_mean_squared_error: 0.0573 - val_loss: 0.0032 - val_mae: 0.0498 - val_mse: 0.0032 - val_root_mean_squared_error: 0.0569 - lr: 0.0030
Epoch 9/20




323/323 [==============================] - ETA: 0s - loss: 0.0033 - mae: 0.0502 - mse: 0.0033 - root_mean_squared_error: 0.0572
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0007610362954437733.
323/323 [==============================] - 12s 36ms/step - loss: 0.0033 - mae: 0.0502 - mse: 0.0033 - root_mean_squared_error: 0.0572 - val_loss: 0.0033 - val_mae: 0.0502 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0571 - lr: 0.0015
Epoch 10/20





322/323 [============================>.] - ETA: 0s - loss: 0.0033 - mae: 0.0501 - mse: 0.0033 - root_mean_squared_error: 0.0571
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00038051814772188663.
323/323 [==============================] - 11s 33ms/step - loss: 0.0033 - mae: 0.0501 - mse: 0.0033 - root_mean_squared_error: 0.0571 - val_loss: 0.0032 - val_mae: 0.0497 - val_mse: 0.0032 - val_root_mean_squared_error: 0.0569 - lr: 7.6104e-04
Epoch 11/20



323/323 [==============================] - ETA: 0s - loss: 0.0033 - mae: 0.0500 - mse: 0.0033 - root_mean_squared_error: 0.0571
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00019025907386094332.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230506_212540-ra9mdbbf\files\model-best)... Done. 0.0s
323/323 [==============================] - 10s 32ms/step - loss: 0.0033 - mae: 0.0500 - mse: 0.0033 - root_mean_squared_error: 0.0571 - val_loss: 0.0032 - val_mae: 0.0499 - val_mse: 0.0032 - val_root_mean_squared_error: 0.0568 - lr: 3.8052e-04
Epoch 12/20


322/323 [============================>.] - ETA: 0s - loss: 0.0033 - mae: 0.0500 - mse: 0.0033 - root_mean_squared_error: 0.0571
Epoch 12: ReduceLROnPlateau reducing learning rate to 9.512953693047166e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230506_212540-ra9mdbbf\files\model-best)... Done. 0.0s
323/323 [==============================] - 10s 31ms/step - loss: 0.0033 - mae: 0.0500 - mse: 0.0033 - root_mean_squared_error: 0.0571 - val_loss: 0.0032 - val_mae: 0.0498 - val_mse: 0.0032 - val_root_mean_squared_error: 0.0568 - lr: 1.9026e-04
Epoch 13/20


323/323 [==============================] - ETA: 0s - loss: 0.0033 - mae: 0.0500 - mse: 0.0033 - root_mean_squared_error: 0.0571
Epoch 13: ReduceLROnPlateau reducing learning rate to 4.756476846523583e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230506_212540-ra9mdbbf\files\model-best)... Done. 0.0s
323/323 [==============================] - 10s 30ms/step - loss: 0.0033 - mae: 0.0500 - mse: 0.0033 - root_mean_squared_error: 0.0571 - val_loss: 0.0032 - val_mae: 0.0498 - val_mse: 0.0032 - val_root_mean_squared_error: 0.0568 - lr: 9.5130e-05
Epoch 14/20


323/323 [==============================] - ETA: 0s - loss: 0.0033 - mae: 0.0500 - mse: 0.0033 - root_mean_squared_error: 0.0570
Epoch 14: ReduceLROnPlateau reducing learning rate to 2.3782384232617915e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230506_212540-ra9mdbbf\files\model-best)... Done. 0.0s
323/323 [==============================] - 10s 30ms/step - loss: 0.0033 - mae: 0.0500 - mse: 0.0033 - root_mean_squared_error: 0.0570 - val_loss: 0.0032 - val_mae: 0.0498 - val_mse: 0.0032 - val_root_mean_squared_error: 0.0568 - lr: 4.7565e-05
Epoch 15/20


322/323 [============================>.] - ETA: 0s - loss: 0.0033 - mae: 0.0500 - mse: 0.0033 - root_mean_squared_error: 0.0570
Epoch 15: ReduceLROnPlateau reducing learning rate to 1.1891192116308957e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230506_212540-ra9mdbbf\files\model-best)... Done. 0.0s
323/323 [==============================] - 9s 29ms/step - loss: 0.0033 - mae: 0.0500 - mse: 0.0033 - root_mean_squared_error: 0.0570 - val_loss: 0.0032 - val_mae: 0.0498 - val_mse: 0.0032 - val_root_mean_squared_error: 0.0568 - lr: 2.3782e-05
Epoch 16/20


323/323 [==============================] - ETA: 0s - loss: 0.0033 - mae: 0.0500 - mse: 0.0033 - root_mean_squared_error: 0.0570
Epoch 16: ReduceLROnPlateau reducing learning rate to 1e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230506_212540-ra9mdbbf\files\model-best)... Done. 0.0s
323/323 [==============================] - 10s 32ms/step - loss: 0.0033 - mae: 0.0500 - mse: 0.0033 - root_mean_squared_error: 0.0570 - val_loss: 0.0032 - val_mae: 0.0498 - val_mse: 0.0032 - val_root_mean_squared_error: 0.0568 - lr: 1.1891e-05
Epoch 17/20


323/323 [==============================] - 9s 28ms/step - loss: 0.0033 - mae: 0.0500 - mse: 0.0033 - root_mean_squared_error: 0.0570 - val_loss: 0.0032 - val_mae: 0.0498 - val_mse: 0.0032 - val_root_mean_squared_error: 0.0568 - lr: 1.0000e-05
Epoch 18/20



322/323 [============================>.] - ETA: 0s - loss: 0.0033 - mae: 0.0500 - mse: 0.0033 - root_mean_squared_error: 0.0570
323/323 [==============================] - 10s 30ms/step - loss: 0.0033 - mae: 0.0500 - mse: 0.0033 - root_mean_squared_error: 0.0570 - val_loss: 0.0032 - val_mae: 0.0498 - val_mse: 0.0032 - val_root_mean_squared_error: 0.0568 - lr: 1.0000e-05
Epoch 19/20


323/323 [==============================] - 8s 26ms/step - loss: 0.0033 - mae: 0.0500 - mse: 0.0033 - root_mean_squared_error: 0.0570 - val_loss: 0.0032 - val_mae: 0.0498 - val_mse: 0.0032 - val_root_mean_squared_error: 0.0568 - lr: 1.0000e-05
Epoch 20/20


323/323 [==============================] - 8s 24ms/step - loss: 0.0033 - mae: 0.0500 - mse: 0.0033 - root_mean_squared_error: 0.0570 - val_loss: 0.0032 - val_mae: 0.0498 - val_mse: 0.0032 - val_root_mean_squared_error: 0.0568 - lr: 1.0000e-05
>Saved ../trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
(7716, 8)
(3307, 8)
Epoch 1/20
 20/483 [>.............................] - ETA: 11s - loss: 0.0294 - mae: 0.1121 - mse: 0.0294 - root_mean_squared_error: 0.1715






483/483 [==============================] - 13s 26ms/step - loss: 0.0101 - mae: 0.0823 - mse: 0.0101 - root_mean_squared_error: 0.1006 - val_loss: 0.0121 - val_mae: 0.0902 - val_mse: 0.0121 - val_root_mean_squared_error: 0.1099 - lr: 0.0244
Epoch 2/20




483/483 [==============================] - 12s 25ms/step - loss: 0.0082 - mae: 0.0775 - mse: 0.0082 - root_mean_squared_error: 0.0907 - val_loss: 0.0118 - val_mae: 0.0894 - val_mse: 0.0118 - val_root_mean_squared_error: 0.1085 - lr: 0.0244
Epoch 3/20





483/483 [==============================] - 12s 25ms/step - loss: 0.0080 - mae: 0.0765 - mse: 0.0080 - root_mean_squared_error: 0.0893 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 0.0244
Epoch 4/20





483/483 [==============================] - ETA: 0s - loss: 0.0079 - mae: 0.0765 - mse: 0.0079 - root_mean_squared_error: 0.0890
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.012176580727100372.
483/483 [==============================] - 12s 24ms/step - loss: 0.0079 - mae: 0.0765 - mse: 0.0079 - root_mean_squared_error: 0.0890 - val_loss: 0.0089 - val_mae: 0.0803 - val_mse: 0.0089 - val_root_mean_squared_error: 0.0945 - lr: 0.0244
Epoch 5/20





483/483 [==============================] - ETA: 0s - loss: 0.0077 - mae: 0.0757 - mse: 0.0077 - root_mean_squared_error: 0.0880
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.006088290363550186.
483/483 [==============================] - 12s 25ms/step - loss: 0.0077 - mae: 0.0757 - mse: 0.0077 - root_mean_squared_error: 0.0880 - val_loss: 0.0077 - val_mae: 0.0763 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0880 - lr: 0.0122
Epoch 6/20





481/483 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0875
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.003044145181775093.
483/483 [==============================] - 12s 24ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0875 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0876 - lr: 0.0061
Epoch 7/20





483/483 [==============================] - ETA: 0s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0015220725908875465.
483/483 [==============================] - 12s 24ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0079 - val_mae: 0.0768 - val_mse: 0.0079 - val_root_mean_squared_error: 0.0887 - lr: 0.0030
Epoch 8/20





481/483 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0754 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0007610362954437733.
483/483 [==============================] - 12s 24ms/step - loss: 0.0076 - mae: 0.0754 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 0.0015
Epoch 9/20





481/483 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0871
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00038051814772188663.
483/483 [==============================] - 12s 24ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0761 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0875 - lr: 7.6104e-04
Epoch 10/20
178/483 [==========>...................] - ETA: 6s - loss: 0.0077 - mae: 0.0758 - mse: 0.0077 - root_mean_squared_error: 0.0877
271/483 [===============>..............] - ETA: 4s - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0871
364/483 [=====================>........] - ETA: 2s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870
453/483 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0873
483/483 [==============================] - ETA: 0s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0871
 85/483 [====>.........................] - ETA: 8s - loss: 0.0078 - mae: 0.0763 - mse: 0.0078 - root_mean_squared_error: 0.0884 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 3.8052e-04
177/483 [=========>....................] - ETA: 6s - loss: 0.0078 - mae: 0.0761 - mse: 0.0078 - root_mean_squared_error: 0.0882 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 3.8052e-04
273/483 [===============>..............] - ETA: 4s - loss: 0.0077 - mae: 0.0755 - mse: 0.0077 - root_mean_squared_error: 0.0875 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 3.8052e-04
362/483 [=====================>........] - ETA: 2s - loss: 0.0076 - mae: 0.0751 - mse: 0.0076 - root_mean_squared_error: 0.0870 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 3.8052e-04
455/483 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0751 - mse: 0.0076 - root_mean_squared_error: 0.0870 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 3.8052e-04
 16/483 [..............................] - ETA: 10s - loss: 0.0082 - mae: 0.0789 - mse: 0.0082 - root_mean_squared_error: 0.0904.0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.9026e-04
109/483 [=====>........................] - ETA: 8s - loss: 0.0074 - mae: 0.0745 - mse: 0.0074 - root_mean_squared_error: 0.0862 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.9026e-04
202/483 [===========>..................] - ETA: 6s - loss: 0.0075 - mae: 0.0747 - mse: 0.0075 - root_mean_squared_error: 0.0864 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.9026e-04
295/483 [=================>............] - ETA: 4s - loss: 0.0075 - mae: 0.0750 - mse: 0.0075 - root_mean_squared_error: 0.0867 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.9026e-04
364/483 [=====================>........] - ETA: 2s - loss: 0.0075 - mae: 0.0751 - mse: 0.0075 - root_mean_squared_error: 0.0868 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.9026e-04
457/483 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0751 - mse: 0.0076 - root_mean_squared_error: 0.0869 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.9026e-04
 13/483 [..............................] - ETA: 10s - loss: 0.0082 - mae: 0.0797 - mse: 0.0082 - root_mean_squared_error: 0.0907.0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 9.5130e-05
100/483 [=====>........................] - ETA: 9s - loss: 0.0079 - mae: 0.0774 - mse: 0.0079 - root_mean_squared_error: 0.0888 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 9.5130e-05
193/483 [==========>...................] - ETA: 6s - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0881 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 9.5130e-05
286/483 [================>.............] - ETA: 4s - loss: 0.0077 - mae: 0.0757 - mse: 0.0077 - root_mean_squared_error: 0.0875 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 9.5130e-05
378/483 [======================>.......] - ETA: 2s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0874 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 9.5130e-05
468/483 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0871 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 9.5130e-05
 28/483 [>.............................] - ETA: 10s - loss: 0.0075 - mae: 0.0747 - mse: 0.0075 - root_mean_squared_error: 0.0866.0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 4.7565e-05
118/483 [======>.......................] - ETA: 8s - loss: 0.0076 - mae: 0.0749 - mse: 0.0076 - root_mean_squared_error: 0.0871 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 4.7565e-05
197/483 [===========>..................] - ETA: 6s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0871 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 4.7565e-05
287/483 [================>.............] - ETA: 4s - loss: 0.0076 - mae: 0.0751 - mse: 0.0076 - root_mean_squared_error: 0.0870 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 4.7565e-05
377/483 [======================>.......] - ETA: 2s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0871 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 4.7565e-05
446/483 [==========================>...] - ETA: 0s - loss: 0.0076 - mae: 0.0754 - mse: 0.0076 - root_mean_squared_error: 0.0872 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 4.7565e-05
 10/483 [..............................] - ETA: 10s - loss: 0.0076 - mae: 0.0746 - mse: 0.0076 - root_mean_squared_error: 0.0873.0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 2.3782e-05
 99/483 [=====>........................] - ETA: 8s - loss: 0.0074 - mae: 0.0739 - mse: 0.0074 - root_mean_squared_error: 0.0860 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 2.3782e-05
180/483 [==========>...................] - ETA: 7s - loss: 0.0075 - mae: 0.0745 - mse: 0.0075 - root_mean_squared_error: 0.0864 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 2.3782e-05
259/483 [===============>..............] - ETA: 5s - loss: 0.0075 - mae: 0.0745 - mse: 0.0075 - root_mean_squared_error: 0.0864 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 2.3782e-05
349/483 [====================>.........] - ETA: 3s - loss: 0.0075 - mae: 0.0749 - mse: 0.0075 - root_mean_squared_error: 0.0867 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 2.3782e-05
442/483 [==========================>...] - ETA: 0s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 .0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 2.3782e-05
  1/483 [..............................] - ETA: 10s - loss: 0.0096 - mae: 0.0867 - mse: 0.0096 - root_mean_squared_error: 0.0980.0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.1891e-05
 93/483 [====>.........................] - ETA: 8s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.1891e-05
186/483 [==========>...................] - ETA: 6s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.1891e-05
247/483 [==============>...............] - ETA: 5s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.1891e-05
325/483 [===================>..........] - ETA: 3s - loss: 0.0076 - mae: 0.0751 - mse: 0.0076 - root_mean_squared_error: 0.0871 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.1891e-05
406/483 [========================>.....] - ETA: 1s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0873 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.1891e-05
483/483 [==============================] - ETA: 0s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.1891e-05
 58/483 [==>...........................] - ETA: 9s - loss: 0.0077 - mae: 0.0756 - mse: 0.0077 - root_mean_squared_error: 0.0878 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
154/483 [========>.....................] - ETA: 7s - loss: 0.0077 - mae: 0.0755 - mse: 0.0077 - root_mean_squared_error: 0.0876 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
244/483 [==============>...............] - ETA: 5s - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0872 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
322/483 [===================>..........] - ETA: 3s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0869 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
410/483 [========================>.....] - ETA: 1s - loss: 0.0075 - mae: 0.0748 - mse: 0.0075 - root_mean_squared_error: 0.0866 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
481/483 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
 61/483 [==>...........................] - ETA: 9s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0870 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
154/483 [========>.....................] - ETA: 7s - loss: 0.0076 - mae: 0.0758 - mse: 0.0076 - root_mean_squared_error: 0.0873 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
223/483 [============>.................] - ETA: 5s - loss: 0.0075 - mae: 0.0748 - mse: 0.0075 - root_mean_squared_error: 0.0864 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
302/483 [=================>............] - ETA: 4s - loss: 0.0075 - mae: 0.0751 - mse: 0.0075 - root_mean_squared_error: 0.0867 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
380/483 [======================>.......] - ETA: 2s - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0871 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
466/483 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
482/483 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0871 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
 96/483 [====>.........................] - ETA: 10s - loss: 0.0073 - mae: 0.0736 - mse: 0.0073 - root_mean_squared_error: 0.0855.0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
178/483 [==========>...................] - ETA: 7s - loss: 0.0074 - mae: 0.0740 - mse: 0.0074 - root_mean_squared_error: 0.0858 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
268/483 [===============>..............] - ETA: 5s - loss: 0.0074 - mae: 0.0741 - mse: 0.0074 - root_mean_squared_error: 0.0859 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
360/483 [=====================>........] - ETA: 2s - loss: 0.0075 - mae: 0.0745 - mse: 0.0075 - root_mean_squared_error: 0.0864 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
449/483 [==========================>...] - ETA: 0s - loss: 0.0076 - mae: 0.0751 - mse: 0.0076 - root_mean_squared_error: 0.0869 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
  3/483 [..............................] - ETA: 12s - loss: 0.0080 - mae: 0.0794 - mse: 0.0080 - root_mean_squared_error: 0.0896.0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
 59/483 [==>...........................] - ETA: 11s - loss: 0.0077 - mae: 0.0762 - mse: 0.0077 - root_mean_squared_error: 0.0878.0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
139/483 [=======>......................] - ETA: 9s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0873 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
229/483 [=============>................] - ETA: 6s - loss: 0.0078 - mae: 0.0763 - mse: 0.0078 - root_mean_squared_error: 0.0882 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
322/483 [===================>..........] - ETA: 3s - loss: 0.0077 - mae: 0.0757 - mse: 0.0077 - root_mean_squared_error: 0.0877 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
415/483 [========================>.....] - ETA: 1s - loss: 0.0076 - mae: 0.0751 - mse: 0.0076 - root_mean_squared_error: 0.0870 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
481/483 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 .0870 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_2.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00019025907386094332.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00019025907386094332.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00019025907386094332.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00019025907386094332.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00019025907386094332.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00019025907386094332.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00019025907386094332.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_3.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
>Saved ../trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
>Saved ../trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00038051814772188663.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00038051814772188663.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00038051814772188663.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00038051814772188663.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00038051814772188663.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00038051814772188663.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_4.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
>Saved ../trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_5.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
>Saved ../trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
>Saved ../trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00038051814772188663.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00038051814772188663.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00038051814772188663.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00038051814772188663.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00038051814772188663.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00038051814772188663.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00038051814772188663.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_6.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
>Saved ../trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
>Saved ../trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20duceLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 0.003044145181775093.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 0.003044145181775093.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 0.003044145181775093.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 0.003044145181775093.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 0.003044145181775093.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 0.003044145181775093.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 0.003044145181775093.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 0.003044145181775093.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 0.003044145181775093.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 0.003044145181775093.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 0.003044145181775093.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 0.003044145181775093.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 0.003044145181775093.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 0.003044145181775093.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 0.003044145181775093.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 0.003044145181775093.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 0.003044145181775093.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 0.003044145181775093.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 0.003044145181775093.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 0.003044145181775093.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_7.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0007610362954437733.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_8.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
>Saved ../trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.012176580727100372.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006088290363550186.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.003044145181775093.61029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0015220725908875465.1029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.0007610362954437733.029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 0.00038051814772188663.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 0.00019025907386094332.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 9.512953693047166e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 4.756476846523583e-05..29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 2.3782384232617915e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1.1891192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.192116308957e-05.29885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_9.h5 val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
>Saved ../trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_10.h5val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
>Saved ../trained_models/RNN/models_segments_overlap-rnn_rmsprop_0.024353161029885984LR_[10]HL2DU_16BS_1P_val_lossM_20epochs/model_10.h5val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05