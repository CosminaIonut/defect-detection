
wandb: WARNING The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
Epoch 1/30
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230428_204224-1qjfhh5x\files\model-best)... Done. 0.0s
17/17 [==============================] - 6s 87ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0266
Epoch 2/30
14/17 [=======================>......] - ETA: 0s - loss: 0.0044 - mae: 0.0540 - mse: 0.0044 - root_mean_squared_error: 0.0661
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.013304593972861767.
17/17 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0266
Epoch 3/30
14/17 [=======================>......] - ETA: 0s - loss: 0.0044 - mae: 0.0539 - mse: 0.0044 - root_mean_squared_error: 0.0660
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.006652296986430883.
17/17 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0133
Epoch 4/30
15/17 [=========================>....] - ETA: 0s - loss: 0.0044 - mae: 0.0541 - mse: 0.0044 - root_mean_squared_error: 0.0662
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0033261484932154417.
17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0067
Epoch 5/30
17/17 [==============================] - ETA: 0s - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0016630742466077209.
17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0033
Epoch 6/30
16/17 [===========================>..] - ETA: 0s - loss: 0.0044 - mae: 0.0543 - mse: 0.0044 - root_mean_squared_error: 0.0663
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0008315371233038604.
17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0017
Epoch 7/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0038 - mae: 0.0501 - mse: 0.0038 - root_mean_squared_error: 0.0620
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0004157685616519302.
17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 8.3154e-04
Epoch 8/30
16/17 [===========================>..] - ETA: 0s - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002078842808259651.
17/17 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 4.1577e-04
Epoch 9/30
17/17 [==============================] - ETA: 0s - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010394214041298255.
17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 2.0788e-04
Epoch 10/30
16/17 [===========================>..] - ETA: 0s - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663
Epoch 10: ReduceLROnPlateau reducing learning rate to 5.197107020649128e-05.
17/17 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.0394e-04
Epoch 11/30
17/17 [==============================] - ETA: 0s - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663
Epoch 11: ReduceLROnPlateau reducing learning rate to 2.598553510324564e-05.
17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 5.1971e-05
Epoch 12/30
16/17 [===========================>..] - ETA: 0s - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.299276755162282e-05.
17/17 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 2.5986e-05
Epoch 13/30
15/17 [=========================>....] - ETA: 0s - loss: 0.0044 - mae: 0.0539 - mse: 0.0044 - root_mean_squared_error: 0.0660
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.2993e-05
Epoch 14/30
17/17 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.0000e-05
Epoch 15/30
17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.0000e-05
Epoch 16/30
17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.0000e-05
Epoch 17/30
17/17 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.0000e-05
Epoch 18/30
17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.0000e-05
Epoch 19/30
17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.0000e-05
Epoch 20/30
17/17 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.0000e-05
Epoch 21/30
17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.0000e-05
Epoch 22/30
17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.0000e-05
Epoch 23/30
17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.0000e-05
Epoch 24/30
17/17 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.0000e-05
Epoch 25/30
17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.0000e-05
Epoch 26/30
17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.0000e-05
Epoch 27/30
17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.0000e-05
Epoch 28/30
17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.0000e-05
Epoch 29/30
17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.0000e-05
Epoch 30/30
17/17 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.0000e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn_sgd_0.026609187435857096LR_[24]CHN_20CNNI_232BS_40DU_1P_val_lossM_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
Epoch 1/30
23/23 [==============================] - 1s 15ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.0266
Epoch 2/30
15/23 [==================>...........] - ETA: 0s - loss: 0.0340 - mae: 0.1750 - mse: 0.0340 - root_mean_squared_error: 0.1843
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.013304593972861767.
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.0266
Epoch 3/30
15/23 [==================>...........] - ETA: 0s - loss: 0.0343 - mae: 0.1758 - mse: 0.0343 - root_mean_squared_error: 0.1852
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.006652296986430883.
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.0133
Epoch 4/30
14/23 [=================>............] - ETA: 0s - loss: 0.0339 - mae: 0.1748 - mse: 0.0339 - root_mean_squared_error: 0.1842
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0033261484932154417.
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.0067
Epoch 5/30
15/23 [==================>...........] - ETA: 0s - loss: 0.0342 - mae: 0.1758 - mse: 0.0342 - root_mean_squared_error: 0.1850
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0016630742466077209.
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.0033
Epoch 6/30
14/23 [=================>............] - ETA: 0s - loss: 0.0342 - mae: 0.1754 - mse: 0.0342 - root_mean_squared_error: 0.1848
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0008315371233038604.
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.0017
Epoch 7/30
15/23 [==================>...........] - ETA: 0s - loss: 0.0343 - mae: 0.1758 - mse: 0.0343 - root_mean_squared_error: 0.1853
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0004157685616519302.
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 8.3154e-04
Epoch 8/30
14/23 [=================>............] - ETA: 0s - loss: 0.0338 - mae: 0.1747 - mse: 0.0338 - root_mean_squared_error: 0.1840
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002078842808259651.
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 4.1577e-04
Epoch 9/30
15/23 [==================>...........] - ETA: 0s - loss: 0.0339 - mae: 0.1749 - mse: 0.0339 - root_mean_squared_error: 0.1842
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010394214041298255.
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 2.0788e-04
Epoch 10/30
15/23 [==================>...........] - ETA: 0s - loss: 0.0341 - mae: 0.1755 - mse: 0.0341 - root_mean_squared_error: 0.1848
Epoch 10: ReduceLROnPlateau reducing learning rate to 5.197107020649128e-05.
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 1.0394e-04
Epoch 11/30
15/23 [==================>...........] - ETA: 0s - loss: 0.0340 - mae: 0.1748 - mse: 0.0340 - root_mean_squared_error: 0.1843
Epoch 11: ReduceLROnPlateau reducing learning rate to 2.598553510324564e-05.
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 5.1971e-05
Epoch 12/30
14/23 [=================>............] - ETA: 0s - loss: 0.0341 - mae: 0.1754 - mse: 0.0341 - root_mean_squared_error: 0.1847
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.299276755162282e-05.
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 2.5986e-05
Epoch 13/30
14/23 [=================>............] - ETA: 0s - loss: 0.0343 - mae: 0.1758 - mse: 0.0343 - root_mean_squared_error: 0.1852
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
23/23 [==============================] - 0s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 1.2993e-05
Epoch 14/30
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 1.0000e-05
Epoch 15/30
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 1.0000e-05
Epoch 16/30
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 1.0000e-05
Epoch 17/30
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 1.0000e-05
Epoch 18/30
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 1.0000e-05
Epoch 19/30
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 1.0000e-05
Epoch 20/30
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 1.0000e-05
Epoch 21/30
23/23 [==============================] - 0s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 1.0000e-05
Epoch 22/30
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 1.0000e-05
Epoch 23/30
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 1.0000e-05
Epoch 24/30
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 1.0000e-05
Epoch 25/30
23/23 [==============================] - 0s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 1.0000e-05
Epoch 26/30
23/23 [==============================] - 0s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 1.0000e-05
Epoch 27/30
 1/23 [>.............................] - ETA: 0s - loss: 0.0365 - mae: 0.1815 - mse: 0.0365 - root_mean_squared_error: 0.1910
23/23 [==============================] - 0s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 1.0000e-05
Epoch 30/30
23/23 [==============================] - 0s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 1.0000e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn_sgd_0.026609187435857096LR_[24]CHN_20CNNI_232BS_40DU_1P_val_lossM_30epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
Epoch 1/30
17/17 [==============================] - 1s 15ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.0266
Epoch 2/30
12/17 [====================>.........] - ETA: 0s - loss: 0.0921 - mae: 0.3003 - mse: 0.0921 - root_mean_squared_error: 0.3035
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.013304593972861767.
17/17 [==============================] - 0s 8ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.0266
Epoch 3/30
11/17 [==================>...........] - ETA: 0s - loss: 0.0920 - mae: 0.3002 - mse: 0.0920 - root_mean_squared_error: 0.3034
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.006652296986430883.
17/17 [==============================] - 0s 9ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.0133
Epoch 4/30
12/17 [====================>.........] - ETA: 0s - loss: 0.0917 - mae: 0.2996 - mse: 0.0917 - root_mean_squared_error: 0.3028
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0033261484932154417.
17/17 [==============================] - 0s 8ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.0067
Epoch 5/30
17/17 [==============================] - 0s 8ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 4.1577e-04
Epoch 9/30
11/17 [==================>...........] - ETA: 0s - loss: 0.0914 - mae: 0.2992 - mse: 0.0914 - root_mean_squared_error: 0.3024
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010394214041298255.
17/17 [==============================] - 0s 8ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 2.0788e-04
Epoch 10/30
11/17 [==================>...........] - ETA: 0s - loss: 0.0910 - mae: 0.2985 - mse: 0.0910 - root_mean_squared_error: 0.3017
Epoch 10: ReduceLROnPlateau reducing learning rate to 5.197107020649128e-05.
17/17 [==============================] - 0s 9ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 1.0394e-04
Epoch 11/30
11/17 [==================>...........] - ETA: 0s - loss: 0.0917 - mae: 0.2997 - mse: 0.0917 - root_mean_squared_error: 0.3028
Epoch 11: ReduceLROnPlateau reducing learning rate to 2.598553510324564e-05.
17/17 [==============================] - 0s 8ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 5.1971e-05
Epoch 12/30
11/17 [==================>...........] - ETA: 0s - loss: 0.0920 - mae: 0.3001 - mse: 0.0920 - root_mean_squared_error: 0.3032
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.299276755162282e-05.
17/17 [==============================] - 0s 8ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 2.5986e-05
Epoch 13/30
12/17 [====================>.........] - ETA: 0s - loss: 0.0920 - mae: 0.3002 - mse: 0.0920 - root_mean_squared_error: 0.3034
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
17/17 [==============================] - 0s 9ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 1.2993e-05
Epoch 14/30
17/17 [==============================] - 0s 8ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 1.0000e-05
Epoch 15/30
17/17 [==============================] - 0s 8ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 1.0000e-05
Epoch 16/30
17/17 [==============================] - 0s 8ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 1.0000e-05
Epoch 17/30
17/17 [==============================] - 0s 9ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 1.0000e-05
Epoch 18/30
17/17 [==============================] - 0s 8ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 1.0000e-05
Epoch 19/30
11/17 [==================>...........] - ETA: 0s - loss: 0.0919 - mae: 0.3000 - mse: 0.0919 - root_mean_squared_error: 0.3032
17/17 [==============================] - 0s 8ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 1.0000e-05
Epoch 21/30
17/17 [==============================] - 0s 8ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 1.0000e-05
Epoch 22/30
17/17 [==============================] - 0s 8ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 1.0000e-05
Epoch 23/30
17/17 [==============================] - 0s 8ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 1.0000e-05
Epoch 24/30
17/17 [==============================] - 0s 8ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 1.0000e-05
Epoch 25/30
17/17 [==============================] - 0s 9ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 1.0000e-05
Epoch 26/30
17/17 [==============================] - 0s 8ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 1.0000e-05
Epoch 27/30
17/17 [==============================] - 0s 8ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 1.0000e-05
Epoch 28/30
17/17 [==============================] - 0s 8ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 1.0000e-05
Epoch 29/30
17/17 [==============================] - 0s 8ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 1.0000e-05
Epoch 30/30
17/17 [==============================] - 0s 8ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 1.0000e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn_sgd_0.026609187435857096LR_[24]CHN_20CNNI_232BS_40DU_1P_val_lossM_30epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
12/17 [====================>.........] - ETA: 0s - loss: 0.1622 - mae: 0.4004 - mse: 0.1622 - root_mean_squared_error: 0.40283030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 1.0000e-05
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0033261484932154417.
17/17 [==============================] - 0s 8ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.0067
Epoch 5/30
10/17 [================>.............] - ETA: 0s - loss: 0.1618 - mae: 0.3999 - mse: 0.1618 - root_mean_squared_error: 0.4022
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0016630742466077209.
17/17 [==============================] - 0s 8ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.0033
Epoch 6/30
12/17 [====================>.........] - ETA: 0s - loss: 0.1614 - mae: 0.3993 - mse: 0.1614 - root_mean_squared_error: 0.4017
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0008315371233038604.
17/17 [==============================] - 0s 9ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.0017
Epoch 7/30
12/17 [====================>.........] - ETA: 0s - loss: 0.1617 - mae: 0.3997 - mse: 0.1617 - root_mean_squared_error: 0.4021
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0004157685616519302.
17/17 [==============================] - 0s 8ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 8.3154e-04
Epoch 8/30
11/17 [==================>...........] - ETA: 0s - loss: 0.1616 - mae: 0.3996 - mse: 0.1616 - root_mean_squared_error: 0.4020
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002078842808259651.
17/17 [==============================] - 0s 8ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 4.1577e-04
Epoch 9/30
12/17 [====================>.........] - ETA: 0s - loss: 0.1612 - mae: 0.3991 - mse: 0.1612 - root_mean_squared_error: 0.4015
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010394214041298255.
17/17 [==============================] - 0s 9ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 2.0788e-04
Epoch 10/30
11/17 [==================>...........] - ETA: 0s - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022
Epoch 10: ReduceLROnPlateau reducing learning rate to 5.197107020649128e-05.
17/17 [==============================] - 0s 9ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 1.0394e-04
Epoch 11/30
 1/17 [>.............................] - ETA: 0s - loss: 0.1638 - mae: 0.4022 - mse: 0.1638 - root_mean_squared_error: 0.4047
17/17 [==============================] - 0s 8ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 2.5986e-05
Epoch 13/30
12/17 [====================>.........] - ETA: 0s - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4023
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
17/17 [==============================] - 0s 8ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 1.2993e-05
Epoch 14/30
17/17 [==============================] - 0s 9ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 1.0000e-05
Epoch 15/30
17/17 [==============================] - 0s 8ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 1.0000e-05
Epoch 16/30
17/17 [==============================] - 0s 7ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 1.0000e-05
Epoch 17/30
17/17 [==============================] - 0s 8ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 1.0000e-05
Epoch 18/30
17/17 [==============================] - 0s 7ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 1.0000e-05
Epoch 19/30
17/17 [==============================] - 0s 8ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 1.0000e-05
Epoch 20/30
17/17 [==============================] - 0s 8ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 1.0000e-05
Epoch 21/30
17/17 [==============================] - 0s 8ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 1.0000e-05
Epoch 22/30
 1/17 [>.............................] - ETA: 0s - loss: 0.1638 - mae: 0.4025 - mse: 0.1638 - root_mean_squared_error: 0.4047
17/17 [==============================] - 0s 8ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 2.5986e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0038s vs `on_train_batch_end` time: 0.0039s). Check your callbacks.
17/17 [==============================] - 0s 8ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 1.0000e-05
Epoch 29/30
17/17 [==============================] - 0s 8ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 1.0000e-05
Epoch 30/30
17/17 [==============================] - 0s 8ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 1.0000e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn_sgd_0.026609187435857096LR_[24]CHN_20CNNI_232BS_40DU_1P_val_lossM_30epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
Epoch 1/30
10/17 [================>.............] - ETA: 0s - loss: 0.2512 - mae: 0.4993 - mse: 0.2512 - root_mean_squared_error: 0.5012
11/17 [==================>...........] - ETA: 0s - loss: 0.2518 - mae: 0.4999 - mse: 0.2518 - root_mean_squared_error: 0.50184022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 1.0000e-05
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002078842808259651.
17/17 [==============================] - 0s 9ms/step - loss: 0.2517 - mae: 0.4998 - mse: 0.2517 - root_mean_squared_error: 0.5017 - val_loss: 0.2524 - val_mae: 0.5004 - val_mse: 0.2524 - val_root_mean_squared_error: 0.5024 - lr: 4.1577e-04
Epoch 9/30
17/17 [==============================] - ETA: 0s - loss: 0.2517 - mae: 0.4998 - mse: 0.2517 - root_mean_squared_error: 0.5017
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010394214041298255.
17/17 [==============================] - 0s 11ms/step - loss: 0.2517 - mae: 0.4998 - mse: 0.2517 - root_mean_squared_error: 0.5017 - val_loss: 0.2524 - val_mae: 0.5004 - val_mse: 0.2524 - val_root_mean_squared_error: 0.5024 - lr: 2.0788e-04
Epoch 10/30
11/17 [==================>...........] - ETA: 0s - loss: 0.2521 - mae: 0.5002 - mse: 0.2521 - root_mean_squared_error: 0.5021
Epoch 10: ReduceLROnPlateau reducing learning rate to 5.197107020649128e-05.
17/17 [==============================] - 0s 9ms/step - loss: 0.2517 - mae: 0.4998 - mse: 0.2517 - root_mean_squared_error: 0.5017 - val_loss: 0.2524 - val_mae: 0.5004 - val_mse: 0.2524 - val_root_mean_squared_error: 0.5024 - lr: 1.0394e-04
Epoch 11/30
11/17 [==================>...........] - ETA: 0s - loss: 0.2516 - mae: 0.4997 - mse: 0.2516 - root_mean_squared_error: 0.5016
Epoch 11: ReduceLROnPlateau reducing learning rate to 2.598553510324564e-05.
17/17 [==============================] - 0s 8ms/step - loss: 0.2517 - mae: 0.4998 - mse: 0.2517 - root_mean_squared_error: 0.5017 - val_loss: 0.2524 - val_mae: 0.5004 - val_mse: 0.2524 - val_root_mean_squared_error: 0.5024 - lr: 5.1971e-05
Epoch 12/30
11/17 [==================>...........] - ETA: 0s - loss: 0.2517 - mae: 0.4998 - mse: 0.2517 - root_mean_squared_error: 0.5017
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.299276755162282e-05.
17/17 [==============================] - 0s 8ms/step - loss: 0.2517 - mae: 0.4998 - mse: 0.2517 - root_mean_squared_error: 0.5017 - val_loss: 0.2524 - val_mae: 0.5004 - val_mse: 0.2524 - val_root_mean_squared_error: 0.5024 - lr: 2.5986e-05
Epoch 13/30
12/17 [====================>.........] - ETA: 0s - loss: 0.2510 - mae: 0.4991 - mse: 0.2510 - root_mean_squared_error: 0.5010
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
17/17 [==============================] - 0s 9ms/step - loss: 0.2517 - mae: 0.4998 - mse: 0.2517 - root_mean_squared_error: 0.5017 - val_loss: 0.2524 - val_mae: 0.5004 - val_mse: 0.2524 - val_root_mean_squared_error: 0.5024 - lr: 1.2993e-05
Epoch 14/30
11/17 [==================>...........] - ETA: 0s - loss: 0.2515 - mae: 0.4996 - mse: 0.2515 - root_mean_squared_error: 0.5015
17/17 [==============================] - 0s 8ms/step - loss: 0.2517 - mae: 0.4998 - mse: 0.2517 - root_mean_squared_error: 0.5017 - val_loss: 0.2524 - val_mae: 0.5004 - val_mse: 0.2524 - val_root_mean_squared_error: 0.5024 - lr: 1.0000e-05
Epoch 20/30
17/17 [==============================] - 0s 8ms/step - loss: 0.2517 - mae: 0.4998 - mse: 0.2517 - root_mean_squared_error: 0.5017 - val_loss: 0.2524 - val_mae: 0.5004 - val_mse: 0.2524 - val_root_mean_squared_error: 0.5024 - lr: 1.0000e-05
Epoch 21/30
17/17 [==============================] - 0s 8ms/step - loss: 0.2517 - mae: 0.4998 - mse: 0.2517 - root_mean_squared_error: 0.5017 - val_loss: 0.2524 - val_mae: 0.5004 - val_mse: 0.2524 - val_root_mean_squared_error: 0.5024 - lr: 1.0000e-05
Epoch 22/30
17/17 [==============================] - 0s 9ms/step - loss: 0.2517 - mae: 0.4998 - mse: 0.2517 - root_mean_squared_error: 0.5017 - val_loss: 0.2524 - val_mae: 0.5004 - val_mse: 0.2524 - val_root_mean_squared_error: 0.5024 - lr: 1.0000e-05
Epoch 23/30
17/17 [==============================] - 0s 8ms/step - loss: 0.2517 - mae: 0.4998 - mse: 0.2517 - root_mean_squared_error: 0.5017 - val_loss: 0.2524 - val_mae: 0.5004 - val_mse: 0.2524 - val_root_mean_squared_error: 0.5024 - lr: 1.0000e-05
Epoch 24/30
17/17 [==============================] - 0s 9ms/step - loss: 0.2517 - mae: 0.4998 - mse: 0.2517 - root_mean_squared_error: 0.5017 - val_loss: 0.2524 - val_mae: 0.5004 - val_mse: 0.2524 - val_root_mean_squared_error: 0.5024 - lr: 1.0000e-05
Epoch 25/30
17/17 [==============================] - 0s 8ms/step - loss: 0.2517 - mae: 0.4998 - mse: 0.2517 - root_mean_squared_error: 0.5017 - val_loss: 0.2524 - val_mae: 0.5004 - val_mse: 0.2524 - val_root_mean_squared_error: 0.5024 - lr: 1.0000e-05
Epoch 26/30
17/17 [==============================] - 0s 8ms/step - loss: 0.2517 - mae: 0.4998 - mse: 0.2517 - root_mean_squared_error: 0.5017 - val_loss: 0.2524 - val_mae: 0.5004 - val_mse: 0.2524 - val_root_mean_squared_error: 0.5024 - lr: 1.0000e-05
Epoch 27/30
17/17 [==============================] - 0s 8ms/step - loss: 0.2517 - mae: 0.4998 - mse: 0.2517 - root_mean_squared_error: 0.5017 - val_loss: 0.2524 - val_mae: 0.5004 - val_mse: 0.2524 - val_root_mean_squared_error: 0.5024 - lr: 1.0000e-05
Epoch 28/30
17/17 [==============================] - 0s 8ms/step - loss: 0.2517 - mae: 0.4998 - mse: 0.2517 - root_mean_squared_error: 0.5017 - val_loss: 0.2524 - val_mae: 0.5004 - val_mse: 0.2524 - val_root_mean_squared_error: 0.5024 - lr: 1.0000e-05
Epoch 29/30
 1/17 [>.............................] - ETA: 0s - loss: 0.2481 - mae: 0.4961 - mse: 0.2481 - root_mean_squared_error: 0.4981
17/17 [==============================] - 0s 9ms/step - loss: 0.3617 - mae: 0.5998 - mse: 0.3617 - root_mean_squared_error: 0.6014 - val_loss: 0.3625 - val_mae: 0.6004 - val_mse: 0.3625 - val_root_mean_squared_error: 0.6021 - lr: 0.0133e-05
Epoch 4/30
11/17 [==================>...........] - ETA: 0s - loss: 0.3624 - mae: 0.6004 - mse: 0.3624 - root_mean_squared_error: 0.6020
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0033261484932154417.
17/17 [==============================] - 0s 8ms/step - loss: 0.3617 - mae: 0.5998 - mse: 0.3617 - root_mean_squared_error: 0.6014 - val_loss: 0.3625 - val_mae: 0.6004 - val_mse: 0.3625 - val_root_mean_squared_error: 0.6021 - lr: 0.0067
Epoch 5/30
11/17 [==================>...........] - ETA: 0s - loss: 0.3610 - mae: 0.5993 - mse: 0.3610 - root_mean_squared_error: 0.6008
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0016630742466077209.
17/17 [==============================] - 0s 9ms/step - loss: 0.3617 - mae: 0.5998 - mse: 0.3617 - root_mean_squared_error: 0.6014 - val_loss: 0.3625 - val_mae: 0.6004 - val_mse: 0.3625 - val_root_mean_squared_error: 0.6021 - lr: 0.0033
Epoch 6/30
11/17 [==================>...........] - ETA: 0s - loss: 0.3621 - mae: 0.6002 - mse: 0.3621 - root_mean_squared_error: 0.6017
11/17 [==================>...........] - ETA: 0s - loss: 0.3618 - mae: 0.5999 - mse: 0.3618 - root_mean_squared_error: 0.60156014 - val_loss: 0.3625 - val_mae: 0.6004 - val_mse: 0.3625 - val_root_mean_squared_error: 0.6021 - lr: 0.0133e-05
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.299276755162282e-05.
17/17 [==============================] - 0s 8ms/step - loss: 0.3617 - mae: 0.5998 - mse: 0.3617 - root_mean_squared_error: 0.6014 - val_loss: 0.3625 - val_mae: 0.6004 - val_mse: 0.3625 - val_root_mean_squared_error: 0.6021 - lr: 2.5986e-05
Epoch 13/30
12/17 [====================>.........] - ETA: 0s - loss: 0.3607 - mae: 0.5990 - mse: 0.3607 - root_mean_squared_error: 0.6006
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
17/17 [==============================] - 0s 9ms/step - loss: 0.3617 - mae: 0.5998 - mse: 0.3617 - root_mean_squared_error: 0.6014 - val_loss: 0.3625 - val_mae: 0.6004 - val_mse: 0.3625 - val_root_mean_squared_error: 0.6021 - lr: 1.2993e-05
Epoch 14/30
17/17 [==============================] - 0s 8ms/step - loss: 0.3617 - mae: 0.5998 - mse: 0.3617 - root_mean_squared_error: 0.6014 - val_loss: 0.3625 - val_mae: 0.6004 - val_mse: 0.3625 - val_root_mean_squared_error: 0.6021 - lr: 1.0000e-05
Epoch 15/30
17/17 [==============================] - 0s 11ms/step - loss: 0.3617 - mae: 0.5998 - mse: 0.3617 - root_mean_squared_error: 0.6014 - val_loss: 0.3625 - val_mae: 0.6004 - val_mse: 0.3625 - val_root_mean_squared_error: 0.6021 - lr: 1.0000e-05
Epoch 16/30
17/17 [==============================] - 0s 8ms/step - loss: 0.3617 - mae: 0.5998 - mse: 0.3617 - root_mean_squared_error: 0.6014 - val_loss: 0.3625 - val_mae: 0.6004 - val_mse: 0.3625 - val_root_mean_squared_error: 0.6021 - lr: 1.0000e-05
Epoch 17/30
17/17 [==============================] - 0s 8ms/step - loss: 0.3617 - mae: 0.5998 - mse: 0.3617 - root_mean_squared_error: 0.6014 - val_loss: 0.3625 - val_mae: 0.6004 - val_mse: 0.3625 - val_root_mean_squared_error: 0.6021 - lr: 1.0000e-05
Epoch 18/30
17/17 [==============================] - 0s 8ms/step - loss: 0.3617 - mae: 0.5998 - mse: 0.3617 - root_mean_squared_error: 0.6014 - val_loss: 0.3625 - val_mae: 0.6004 - val_mse: 0.3625 - val_root_mean_squared_error: 0.6021 - lr: 1.0000e-05
Epoch 19/30
17/17 [==============================] - 0s 8ms/step - loss: 0.3617 - mae: 0.5998 - mse: 0.3617 - root_mean_squared_error: 0.6014 - val_loss: 0.3625 - val_mae: 0.6004 - val_mse: 0.3625 - val_root_mean_squared_error: 0.6021 - lr: 1.0000e-05
Epoch 20/30
13/17 [=====================>........] - ETA: 0s - loss: 0.3610 - mae: 0.5992 - mse: 0.3610 - root_mean_squared_error: 0.6008
17/17 [==============================] - 0s 8ms/step - loss: 0.3617 - mae: 0.5998 - mse: 0.3617 - root_mean_squared_error: 0.6014 - val_loss: 0.3625 - val_mae: 0.6004 - val_mse: 0.3625 - val_root_mean_squared_error: 0.6021 - lr: 1.0000e-05
Epoch 28/30
17/17 [==============================] - 0s 8ms/step - loss: 0.3617 - mae: 0.5998 - mse: 0.3617 - root_mean_squared_error: 0.6014 - val_loss: 0.3625 - val_mae: 0.6004 - val_mse: 0.3625 - val_root_mean_squared_error: 0.6021 - lr: 1.0000e-05
Epoch 29/30
17/17 [==============================] - 0s 8ms/step - loss: 0.3617 - mae: 0.5998 - mse: 0.3617 - root_mean_squared_error: 0.6014 - val_loss: 0.3625 - val_mae: 0.6004 - val_mse: 0.3625 - val_root_mean_squared_error: 0.6021 - lr: 1.0000e-05
Epoch 30/30
17/17 [==============================] - 0s 8ms/step - loss: 0.3617 - mae: 0.5998 - mse: 0.3617 - root_mean_squared_error: 0.6014 - val_loss: 0.3625 - val_mae: 0.6004 - val_mse: 0.3625 - val_root_mean_squared_error: 0.6021 - lr: 1.0000e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn_sgd_0.026609187435857096LR_[24]CHN_20CNNI_232BS_40DU_1P_val_lossM_30epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
Epoch 1/30
17/17 [==============================] - 0s 9ms/step - loss: 0.4917 - mae: 0.6998 - mse: 0.4917 - root_mean_squared_error: 0.7012 - val_loss: 0.4926 - val_mae: 0.7004 - val_mse: 0.4926 - val_root_mean_squared_error: 0.7018 - lr: 8.3154e-04
Epoch 8/30
11/17 [==================>...........] - ETA: 0s - loss: 0.4910 - mae: 0.6994 - mse: 0.4910 - root_mean_squared_error: 0.7007
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002078842808259651.
17/17 [==============================] - 0s 9ms/step - loss: 0.4917 - mae: 0.6998 - mse: 0.4917 - root_mean_squared_error: 0.7012 - val_loss: 0.4926 - val_mae: 0.7004 - val_mse: 0.4926 - val_root_mean_squared_error: 0.7018 - lr: 4.1577e-04
Epoch 9/30
11/17 [==================>...........] - ETA: 0s - loss: 0.4909 - mae: 0.6993 - mse: 0.4909 - root_mean_squared_error: 0.7007
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010394214041298255.
17/17 [==============================] - 0s 8ms/step - loss: 0.4917 - mae: 0.6998 - mse: 0.4917 - root_mean_squared_error: 0.7012 - val_loss: 0.4926 - val_mae: 0.7004 - val_mse: 0.4926 - val_root_mean_squared_error: 0.7018 - lr: 2.0788e-04
Epoch 10/30
11/17 [==================>...........] - ETA: 0s - loss: 0.4914 - mae: 0.6996 - mse: 0.4914 - root_mean_squared_error: 0.7010
Epoch 10: ReduceLROnPlateau reducing learning rate to 5.197107020649128e-05.
17/17 [==============================] - 0s 9ms/step - loss: 0.4917 - mae: 0.6998 - mse: 0.4917 - root_mean_squared_error: 0.7012 - val_loss: 0.4926 - val_mae: 0.7004 - val_mse: 0.4926 - val_root_mean_squared_error: 0.7018 - lr: 1.0394e-04
Epoch 11/30
11/17 [==================>...........] - ETA: 0s - loss: 0.4911 - mae: 0.6994 - mse: 0.4911 - root_mean_squared_error: 0.7008
Epoch 11: ReduceLROnPlateau reducing learning rate to 2.598553510324564e-05.
17/17 [==============================] - 0s 8ms/step - loss: 0.4917 - mae: 0.6998 - mse: 0.4917 - root_mean_squared_error: 0.7012 - val_loss: 0.4926 - val_mae: 0.7004 - val_mse: 0.4926 - val_root_mean_squared_error: 0.7018 - lr: 5.1971e-05
Epoch 12/30
11/17 [==================>...........] - ETA: 0s - loss: 0.4926 - mae: 0.7005 - mse: 0.4926 - root_mean_squared_error: 0.7019
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.299276755162282e-05.
17/17 [==============================] - 0s 9ms/step - loss: 0.4917 - mae: 0.6998 - mse: 0.4917 - root_mean_squared_error: 0.7012 - val_loss: 0.4926 - val_mae: 0.7004 - val_mse: 0.4926 - val_root_mean_squared_error: 0.7018 - lr: 2.5986e-05
Epoch 13/30
11/17 [==================>...........] - ETA: 0s - loss: 0.4922 - mae: 0.7002 - mse: 0.4922 - root_mean_squared_error: 0.7016
17/17 [==============================] - 0s 8ms/step - loss: 0.4917 - mae: 0.6998 - mse: 0.4917 - root_mean_squared_error: 0.7012 - val_loss: 0.4926 - val_mae: 0.7004 - val_mse: 0.4926 - val_root_mean_squared_error: 0.7018 - lr: 1.0000e-05
Epoch 19/30
17/17 [==============================] - 0s 8ms/step - loss: 0.4917 - mae: 0.6998 - mse: 0.4917 - root_mean_squared_error: 0.7012 - val_loss: 0.4926 - val_mae: 0.7004 - val_mse: 0.4926 - val_root_mean_squared_error: 0.7018 - lr: 1.0000e-05
Epoch 20/30
17/17 [==============================] - 0s 8ms/step - loss: 0.4917 - mae: 0.6998 - mse: 0.4917 - root_mean_squared_error: 0.7012 - val_loss: 0.4926 - val_mae: 0.7004 - val_mse: 0.4926 - val_root_mean_squared_error: 0.7018 - lr: 1.0000e-05
Epoch 21/30
17/17 [==============================] - 0s 8ms/step - loss: 0.4917 - mae: 0.6998 - mse: 0.4917 - root_mean_squared_error: 0.7012 - val_loss: 0.4926 - val_mae: 0.7004 - val_mse: 0.4926 - val_root_mean_squared_error: 0.7018 - lr: 1.0000e-05
Epoch 22/30
17/17 [==============================] - 0s 9ms/step - loss: 0.4917 - mae: 0.6998 - mse: 0.4917 - root_mean_squared_error: 0.7012 - val_loss: 0.4926 - val_mae: 0.7004 - val_mse: 0.4926 - val_root_mean_squared_error: 0.7018 - lr: 1.0000e-05
Epoch 23/30
17/17 [==============================] - 0s 8ms/step - loss: 0.4917 - mae: 0.6998 - mse: 0.4917 - root_mean_squared_error: 0.7012 - val_loss: 0.4926 - val_mae: 0.7004 - val_mse: 0.4926 - val_root_mean_squared_error: 0.7018 - lr: 1.0000e-05
Epoch 24/30
17/17 [==============================] - 0s 9ms/step - loss: 0.4917 - mae: 0.6998 - mse: 0.4917 - root_mean_squared_error: 0.7012 - val_loss: 0.4926 - val_mae: 0.7004 - val_mse: 0.4926 - val_root_mean_squared_error: 0.7018 - lr: 1.0000e-05
Epoch 25/30
17/17 [==============================] - 0s 8ms/step - loss: 0.4917 - mae: 0.6998 - mse: 0.4917 - root_mean_squared_error: 0.7012 - val_loss: 0.4926 - val_mae: 0.7004 - val_mse: 0.4926 - val_root_mean_squared_error: 0.7018 - lr: 1.0000e-05
Epoch 26/30
17/17 [==============================] - 0s 9ms/step - loss: 0.4917 - mae: 0.6998 - mse: 0.4917 - root_mean_squared_error: 0.7012 - val_loss: 0.4926 - val_mae: 0.7004 - val_mse: 0.4926 - val_root_mean_squared_error: 0.7018 - lr: 1.0000e-05
Epoch 27/30
11/17 [==================>...........] - ETA: 0s - loss: 0.4917 - mae: 0.6999 - mse: 0.4917 - root_mean_squared_error: 0.7012
17/17 [==============================] - 0s 8ms/step - loss: 0.4917 - mae: 0.6998 - mse: 0.4917 - root_mean_squared_error: 0.7012 - val_loss: 0.4926 - val_mae: 0.7004 - val_mse: 0.4926 - val_root_mean_squared_error: 0.7018 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0034s vs `on_train_batch_end` time: 0.0035s). Check your callbacks.
12/17 [====================>.........] - ETA: 0s - loss: 0.6421 - mae: 0.8001 - mse: 0.6421 - root_mean_squared_error: 0.80137012 - val_loss: 0.4926 - val_mae: 0.7004 - val_mse: 0.4926 - val_root_mean_squared_error: 0.7018 - lr: 1.0000e-05
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.006652296986430883.
17/17 [==============================] - 0s 9ms/step - loss: 0.6416 - mae: 0.7998 - mse: 0.6416 - root_mean_squared_error: 0.8010 - val_loss: 0.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 0.0133
Epoch 4/30
11/17 [==================>...........] - ETA: 0s - loss: 0.6402 - mae: 0.7989 - mse: 0.6402 - root_mean_squared_error: 0.8001
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0033261484932154417.
17/17 [==============================] - 0s 8ms/step - loss: 0.6416 - mae: 0.7998 - mse: 0.6416 - root_mean_squared_error: 0.8010 - val_loss: 0.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 0.0067
Epoch 5/30
 1/17 [>.............................] - ETA: 0s - loss: 0.6474 - mae: 0.8033 - mse: 0.6474 - root_mean_squared_error: 0.8046
17/17 [==============================] - 0s 8ms/step - loss: 0.6416 - mae: 0.7998 - mse: 0.6416 - root_mean_squared_error: 0.8010 - val_loss: 0.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 5.1971e-05
Epoch 12/30
12/17 [====================>.........] - ETA: 0s - loss: 0.6418 - mae: 0.8000 - mse: 0.6418 - root_mean_squared_error: 0.8012
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.299276755162282e-05.
17/17 [==============================] - 0s 9ms/step - loss: 0.6416 - mae: 0.7998 - mse: 0.6416 - root_mean_squared_error: 0.8010 - val_loss: 0.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 2.5986e-05
Epoch 13/30
11/17 [==================>...........] - ETA: 0s - loss: 0.6408 - mae: 0.7993 - mse: 0.6408 - root_mean_squared_error: 0.8005
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
17/17 [==============================] - 0s 8ms/step - loss: 0.6416 - mae: 0.7998 - mse: 0.6416 - root_mean_squared_error: 0.8010 - val_loss: 0.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2993e-05
Epoch 14/30
17/17 [==============================] - 0s 9ms/step - loss: 0.6416 - mae: 0.7998 - mse: 0.6416 - root_mean_squared_error: 0.8010 - val_loss: 0.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.0000e-05
Epoch 15/30
17/17 [==============================] - 0s 8ms/step - loss: 0.6416 - mae: 0.7998 - mse: 0.6416 - root_mean_squared_error: 0.8010 - val_loss: 0.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.0000e-05
Epoch 16/30
17/17 [==============================] - 0s 7ms/step - loss: 0.6416 - mae: 0.7998 - mse: 0.6416 - root_mean_squared_error: 0.8010 - val_loss: 0.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.0000e-05
Epoch 17/30
17/17 [==============================] - 0s 7ms/step - loss: 0.6416 - mae: 0.7998 - mse: 0.6416 - root_mean_squared_error: 0.8010 - val_loss: 0.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.0000e-05
Epoch 18/30
17/17 [==============================] - 0s 7ms/step - loss: 0.6416 - mae: 0.7998 - mse: 0.6416 - root_mean_squared_error: 0.8010 - val_loss: 0.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.0000e-05
Epoch 19/30
13/17 [=====================>........] - ETA: 0s - loss: 0.6418 - mae: 0.7999 - mse: 0.6418 - root_mean_squared_error: 0.8011
17/17 [==============================] - 0s 8ms/step - loss: 0.6416 - mae: 0.7998 - mse: 0.6416 - root_mean_squared_error: 0.8010 - val_loss: 0.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.0000e-05
Epoch 27/30
17/17 [==============================] - 0s 8ms/step - loss: 0.6416 - mae: 0.7998 - mse: 0.6416 - root_mean_squared_error: 0.8010 - val_loss: 0.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.0000e-05
Epoch 28/30
17/17 [==============================] - 0s 8ms/step - loss: 0.6416 - mae: 0.7998 - mse: 0.6416 - root_mean_squared_error: 0.8010 - val_loss: 0.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.0000e-05
Epoch 29/30
17/17 [==============================] - 0s 9ms/step - loss: 0.6416 - mae: 0.7998 - mse: 0.6416 - root_mean_squared_error: 0.8010 - val_loss: 0.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.0000e-05
Epoch 30/30
17/17 [==============================] - 0s 8ms/step - loss: 0.6416 - mae: 0.7998 - mse: 0.6416 - root_mean_squared_error: 0.8010 - val_loss: 0.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.0000e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn_sgd_0.026609187435857096LR_[24]CHN_20CNNI_232BS_40DU_1P_val_lossM_30epochs/model_8.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
Epoch 1/30
11/17 [==================>...........] - ETA: 0s - loss: 0.8102 - mae: 0.8990 - mse: 0.8102 - root_mean_squared_error: 0.90018010 - val_loss: 0.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.0000e-05
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0004157685616519302.
17/17 [==============================] - 0s 9ms/step - loss: 0.8116 - mae: 0.8998 - mse: 0.8116 - root_mean_squared_error: 0.9009 - val_loss: 0.8127 - val_mae: 0.9004 - val_mse: 0.8127 - val_root_mean_squared_error: 0.9015 - lr: 8.3154e-04
Epoch 8/30
11/17 [==================>...........] - ETA: 0s - loss: 0.8120 - mae: 0.9001 - mse: 0.8120 - root_mean_squared_error: 0.9011
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002078842808259651.
17/17 [==============================] - 0s 8ms/step - loss: 0.8116 - mae: 0.8998 - mse: 0.8116 - root_mean_squared_error: 0.9009 - val_loss: 0.8127 - val_mae: 0.9004 - val_mse: 0.8127 - val_root_mean_squared_error: 0.9015 - lr: 4.1577e-04
Epoch 9/30
11/17 [==================>...........] - ETA: 0s - loss: 0.8119 - mae: 0.9000 - mse: 0.8119 - root_mean_squared_error: 0.9010
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010394214041298255.
17/17 [==============================] - 0s 11ms/step - loss: 0.8116 - mae: 0.8998 - mse: 0.8116 - root_mean_squared_error: 0.9009 - val_loss: 0.8127 - val_mae: 0.9004 - val_mse: 0.8127 - val_root_mean_squared_error: 0.9015 - lr: 2.0788e-04
Epoch 10/30
12/17 [====================>.........] - ETA: 0s - loss: 0.8112 - mae: 0.8996 - mse: 0.8112 - root_mean_squared_error: 0.9007
Epoch 10: ReduceLROnPlateau reducing learning rate to 5.197107020649128e-05.
17/17 [==============================] - 0s 8ms/step - loss: 0.8116 - mae: 0.8998 - mse: 0.8116 - root_mean_squared_error: 0.9009 - val_loss: 0.8127 - val_mae: 0.9004 - val_mse: 0.8127 - val_root_mean_squared_error: 0.9015 - lr: 1.0394e-04
Epoch 11/30
12/17 [====================>.........] - ETA: 0s - loss: 0.8122 - mae: 0.9002 - mse: 0.8122 - root_mean_squared_error: 0.9012
Epoch 11: ReduceLROnPlateau reducing learning rate to 2.598553510324564e-05.
17/17 [==============================] - 0s 8ms/step - loss: 0.8116 - mae: 0.8998 - mse: 0.8116 - root_mean_squared_error: 0.9009 - val_loss: 0.8127 - val_mae: 0.9004 - val_mse: 0.8127 - val_root_mean_squared_error: 0.9015 - lr: 5.1971e-05
Epoch 12/30
11/17 [==================>...........] - ETA: 0s - loss: 0.8107 - mae: 0.8993 - mse: 0.8107 - root_mean_squared_error: 0.9004
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.299276755162282e-05.
17/17 [==============================] - 0s 8ms/step - loss: 0.8116 - mae: 0.8998 - mse: 0.8116 - root_mean_squared_error: 0.9009 - val_loss: 0.8127 - val_mae: 0.9004 - val_mse: 0.8127 - val_root_mean_squared_error: 0.9015 - lr: 2.5986e-05
Epoch 13/30
17/17 [==============================] - 0s 8ms/step - loss: 0.8116 - mae: 0.8998 - mse: 0.8116 - root_mean_squared_error: 0.9009 - val_loss: 0.8127 - val_mae: 0.9004 - val_mse: 0.8127 - val_root_mean_squared_error: 0.9015 - lr: 1.0000e-05
Epoch 18/30
17/17 [==============================] - 0s 8ms/step - loss: 0.8116 - mae: 0.8998 - mse: 0.8116 - root_mean_squared_error: 0.9009 - val_loss: 0.8127 - val_mae: 0.9004 - val_mse: 0.8127 - val_root_mean_squared_error: 0.9015 - lr: 1.0000e-05
Epoch 19/30
17/17 [==============================] - 0s 8ms/step - loss: 0.8116 - mae: 0.8998 - mse: 0.8116 - root_mean_squared_error: 0.9009 - val_loss: 0.8127 - val_mae: 0.9004 - val_mse: 0.8127 - val_root_mean_squared_error: 0.9015 - lr: 1.0000e-05
Epoch 20/30
17/17 [==============================] - 0s 8ms/step - loss: 0.8116 - mae: 0.8998 - mse: 0.8116 - root_mean_squared_error: 0.9009 - val_loss: 0.8127 - val_mae: 0.9004 - val_mse: 0.8127 - val_root_mean_squared_error: 0.9015 - lr: 1.0000e-05
Epoch 21/30
17/17 [==============================] - 0s 8ms/step - loss: 0.8116 - mae: 0.8998 - mse: 0.8116 - root_mean_squared_error: 0.9009 - val_loss: 0.8127 - val_mae: 0.9004 - val_mse: 0.8127 - val_root_mean_squared_error: 0.9015 - lr: 1.0000e-05
Epoch 22/30
17/17 [==============================] - 0s 8ms/step - loss: 0.8116 - mae: 0.8998 - mse: 0.8116 - root_mean_squared_error: 0.9009 - val_loss: 0.8127 - val_mae: 0.9004 - val_mse: 0.8127 - val_root_mean_squared_error: 0.9015 - lr: 1.0000e-05
Epoch 23/30
17/17 [==============================] - 0s 8ms/step - loss: 0.8116 - mae: 0.8998 - mse: 0.8116 - root_mean_squared_error: 0.9009 - val_loss: 0.8127 - val_mae: 0.9004 - val_mse: 0.8127 - val_root_mean_squared_error: 0.9015 - lr: 1.0000e-05
Epoch 24/30
17/17 [==============================] - 0s 8ms/step - loss: 0.8116 - mae: 0.8998 - mse: 0.8116 - root_mean_squared_error: 0.9009 - val_loss: 0.8127 - val_mae: 0.9004 - val_mse: 0.8127 - val_root_mean_squared_error: 0.9015 - lr: 1.0000e-05
Epoch 25/30
17/17 [==============================] - 0s 8ms/step - loss: 0.8116 - mae: 0.8998 - mse: 0.8116 - root_mean_squared_error: 0.9009 - val_loss: 0.8127 - val_mae: 0.9004 - val_mse: 0.8127 - val_root_mean_squared_error: 0.9015 - lr: 1.0000e-05
Epoch 26/30
17/17 [==============================] - 0s 8ms/step - loss: 0.8116 - mae: 0.8998 - mse: 0.8116 - root_mean_squared_error: 0.9009 - val_loss: 0.8127 - val_mae: 0.9004 - val_mse: 0.8127 - val_root_mean_squared_error: 0.9015 - lr: 1.0000e-05
Epoch 27/30
11/17 [==================>...........] - ETA: 0s - loss: 0.8100 - mae: 0.8990 - mse: 0.8100 - root_mean_squared_error: 0.9000
17/17 [==============================] - 0s 8ms/step - loss: 0.8116 - mae: 0.8998 - mse: 0.8116 - root_mean_squared_error: 0.9009 - val_loss: 0.8127 - val_mae: 0.9004 - val_mse: 0.8127 - val_root_mean_squared_error: 0.9015 - lr: 1.0000e-05
17/17 [==============================] - 0s 8ms/step - loss: 0.8116 - mae: 0.8998 - mse: 0.8116 - root_mean_squared_error: 0.9009 - val_loss: 0.8127 - val_mae: 0.9004 - val_mse: 0.8127 - val_root_mean_squared_error: 0.9015 - lr: 1.0000e-05