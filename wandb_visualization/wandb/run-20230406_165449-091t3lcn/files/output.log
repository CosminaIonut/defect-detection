Y [[0.396]
 [0.314]
 [0.326]
 ...
 [0.32 ]
 [0.374]
 [0.386]]
X [[0.01118243 0.01738499 0.01228667 ... 0.00130245 0.01862108 0.01527098]
 [0.02270906 0.0097482  0.02967412 ... 0.03415757 0.01340192 0.0044837 ]
 [0.01650482 0.00882636 0.0223758  ... 0.02595569 0.00470275 0.00906345]
 ...
 [0.00079213 0.00058654 0.0009241  ... 0.00101096 0.00056759 0.00053519]
 [0.00334416 0.00371257 0.0040112  ... 0.00257067 0.00239752 0.00563637]
 [0.00320211 0.00400127 0.00362818 ... 0.00174091 0.00353137 0.00485635]]
Epoch 1/100
74/86 [========================>.....] - ETA: 0s - loss: 2.6534 - mae: 0.0673 - mse: 0.0165
86/86 [==============================] - 2s 18ms/step - loss: 2.3168 - mae: 0.0657 - mse: 0.0149 - val_loss: 0.0491 - val_mae: 0.0327 - val_mse: 0.0016 - lr: 0.0100
Epoch 2/100
71/86 [=======================>......] - ETA: 0s - loss: 0.0459 - mae: 0.0508 - mse: 0.0092
86/86 [==============================] - 2s 19ms/step - loss: 0.0500 - mae: 0.0589 - mse: 0.0110 - val_loss: 0.0300 - val_mae: 0.0430 - val_mse: 0.0027 - lr: 0.0100
Epoch 3/100
86/86 [==============================] - 0s 4ms/step - loss: 0.0345 - mae: 0.0365 - mse: 0.0024 - val_loss: 0.0343 - val_mae: 0.0279 - val_mse: 0.0011 - lr: 0.0100
Epoch 4/100
86/86 [==============================] - 0s 3ms/step - loss: 0.0354 - mae: 0.0299 - mse: 0.0014 - val_loss: 0.0382 - val_mae: 0.0387 - val_mse: 0.0022 - lr: 0.0100
Epoch 5/100
86/86 [==============================] - 0s 3ms/step - loss: 0.0350 - mae: 0.0270 - mse: 0.0010 - val_loss: 0.0349 - val_mae: 0.0267 - val_mse: 9.5880e-04 - lr: 0.0100
Epoch 6/100
86/86 [==============================] - 0s 3ms/step - loss: 0.0350 - mae: 0.0259 - mse: 9.3457e-04 - val_loss: 0.0349 - val_mae: 0.0257 - val_mse: 8.6738e-04 - lr: 0.0100
Epoch 7/100
86/86 [==============================] - 0s 3ms/step - loss: 0.0349 - mae: 0.0259 - mse: 9.2684e-04 - val_loss: 0.0360 - val_mae: 0.0312 - val_mse: 0.0014 - lr: 0.0100
Epoch 8/100
82/86 [===========================>..] - ETA: 0s - loss: 0.0350 - mae: 0.0264 - mse: 9.8313e-04
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.
86/86 [==============================] - 1s 7ms/step - loss: 0.0350 - mae: 0.0263 - mse: 9.7612e-04 - val_loss: 0.0353 - val_mae: 0.0307 - val_mse: 0.0014 - lr: 0.0100
Epoch 9/100
77/86 [=========================>....] - ETA: 0s - loss: 0.0070 - mae: 0.0251 - mse: 8.5471e-04
86/86 [==============================] - 2s 19ms/step - loss: 0.0073 - mae: 0.0249 - mse: 8.4689e-04 - val_loss: 0.0085 - val_mae: 0.0286 - val_mse: 0.0012 - lr: 0.0050
Epoch 10/100
86/86 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0251 - mse: 8.4945e-04 - val_loss: 0.0094 - val_mae: 0.0259 - val_mse: 8.8986e-04 - lr: 0.0050
Epoch 11/100
77/86 [=========================>....] - ETA: 0s - loss: 0.0092 - mae: 0.0248 - mse: 8.3422e-04
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.
86/86 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0251 - mse: 8.5159e-04 - val_loss: 0.0093 - val_mae: 0.0266 - val_mse: 9.8456e-04 - lr: 0.0050
Epoch 12/100
75/86 [=========================>....] - ETA: 0s - loss: 0.0023 - mae: 0.0249 - mse: 8.3315e-04
86/86 [==============================] - 2s 18ms/step - loss: 0.0024 - mae: 0.0249 - mse: 8.3599e-04 - val_loss: 0.0028 - val_mae: 0.0257 - val_mse: 8.6891e-04 - lr: 0.0025
Epoch 13/100
86/86 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0248 - mse: 8.2816e-04 - val_loss: 0.0029 - val_mae: 0.0257 - val_mse: 8.6758e-04 - lr: 0.0025
Epoch 14/100
68/86 [======================>.......] - ETA: 0s - loss: 0.0029 - mae: 0.0250 - mse: 8.3975e-04
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.
86/86 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0249 - mse: 8.3007e-04 - val_loss: 0.0030 - val_mae: 0.0257 - val_mse: 8.6893e-04 - lr: 0.0025
Epoch 15/100
78/86 [==========================>...] - ETA: 0s - loss: 0.0012 - mae: 0.0247 - mse: 8.2211e-04
86/86 [==============================] - 1s 15ms/step - loss: 0.0012 - mae: 0.0248 - mse: 8.2461e-04 - val_loss: 0.0015 - val_mae: 0.0262 - val_mse: 9.1659e-04 - lr: 0.0012
Epoch 16/100
74/86 [========================>.....] - ETA: 0s - loss: 0.0013 - mae: 0.0248 - mse: 8.2794e-04
86/86 [==============================] - 2s 18ms/step - loss: 0.0013 - mae: 0.0248 - mse: 8.2387e-04 - val_loss: 0.0014 - val_mae: 0.0257 - val_mse: 8.8014e-04 - lr: 0.0012
Epoch 17/100
63/86 [====================>.........] - ETA: 0s - loss: 0.0013 - mae: 0.0245 - mse: 8.0734e-04
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\wandb\run-20230406_165449-091t3lcn\files\model-best)... Done. 0.0s
86/86 [==============================] - 2s 18ms/step - loss: 0.0013 - mae: 0.0248 - mse: 8.2380e-04 - val_loss: 0.0014 - val_mae: 0.0257 - val_mse: 8.6527e-04 - lr: 0.0012
Epoch 18/100
76/86 [=========================>....] - ETA: 0s - loss: 9.2495e-04 - mae: 0.0249 - mse: 8.2779e-04
86/86 [==============================] - 1s 16ms/step - loss: 9.2231e-04 - mae: 0.0248 - mse: 8.2119e-04 - val_loss: 9.9470e-04 - val_mae: 0.0257 - val_mse: 8.6910e-04 - lr: 6.2500e-04
Epoch 19/100
86/86 [==============================] - 0s 5ms/step - loss: 9.5338e-04 - mae: 0.0248 - mse: 8.2242e-04 - val_loss: 9.9852e-04 - val_mae: 0.0257 - val_mse: 8.6797e-04 - lr: 6.2500e-04
Epoch 20/100
66/86 [======================>.......] - ETA: 0s - loss: 9.5062e-04 - mae: 0.0246 - mse: 8.1962e-04
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.
86/86 [==============================] - 0s 3ms/step - loss: 9.5219e-04 - mae: 0.0247 - mse: 8.2125e-04 - val_loss: 9.9687e-04 - val_mae: 0.0257 - val_mse: 8.6692e-04 - lr: 6.2500e-04
Epoch 21/100
72/86 [========================>.....] - ETA: 0s - loss: 8.4520e-04 - mae: 0.0248 - mse: 8.2218e-04
86/86 [==============================] - 2s 20ms/step - loss: 8.4453e-04 - mae: 0.0247 - mse: 8.2031e-04 - val_loss: 9.0168e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 3.1250e-04
Epoch 22/100
63/86 [====================>.........] - ETA: 0s - loss: 8.5380e-04 - mae: 0.0248 - mse: 8.2140e-04
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\wandb\run-20230406_165449-091t3lcn\files\model-best)... Done. 0.0s
86/86 [==============================] - 1s 17ms/step - loss: 8.5302e-04 - mae: 0.0247 - mse: 8.2057e-04 - val_loss: 8.9872e-04 - val_mae: 0.0256 - val_mse: 8.6589e-04 - lr: 3.1250e-04
Epoch 23/100
64/86 [=====================>........] - ETA: 0s - loss: 8.4613e-04 - mae: 0.0246 - mse: 8.1317e-04
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.
86/86 [==============================] - 1s 17ms/step - loss: 8.5157e-04 - mae: 0.0247 - mse: 8.1855e-04 - val_loss: 8.9845e-04 - val_mae: 0.0256 - val_mse: 8.6550e-04 - lr: 3.1250e-04
Epoch 24/100
72/86 [========================>.....] - ETA: 0s - loss: 8.1963e-04 - mae: 0.0246 - mse: 8.1395e-04
86/86 [==============================] - 2s 18ms/step - loss: 8.2569e-04 - mae: 0.0247 - mse: 8.1968e-04 - val_loss: 8.7516e-04 - val_mae: 0.0256 - val_mse: 8.6547e-04 - lr: 1.5625e-04
Epoch 25/100
68/86 [======================>.......] - ETA: 0s - loss: 8.3091e-04 - mae: 0.0247 - mse: 8.2283e-04
86/86 [==============================] - 2s 18ms/step - loss: 8.2783e-04 - mae: 0.0247 - mse: 8.1972e-04 - val_loss: 8.7359e-04 - val_mae: 0.0257 - val_mse: 8.6547e-04 - lr: 1.5625e-04
Epoch 26/100
70/86 [=======================>......] - ETA: 0s - loss: 8.2029e-04 - mae: 0.0246 - mse: 8.1209e-04
Epoch 26: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\wandb\run-20230406_165449-091t3lcn\files\model-best)... Done. 0.0s
86/86 [==============================] - 1s 16ms/step - loss: 8.2797e-04 - mae: 0.0247 - mse: 8.1977e-04 - val_loss: 8.7353e-04 - val_mae: 0.0257 - val_mse: 8.6523e-04 - lr: 1.5625e-04
Epoch 27/100
84/86 [============================>.] - ETA: 0s - loss: 8.1925e-04 - mae: 0.0247 - mse: 8.1768e-04
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\wandb\run-20230406_165449-091t3lcn\files\model-best)... Done. 0.0s
86/86 [==============================] - 2s 22ms/step - loss: 8.2071e-04 - mae: 0.0247 - mse: 8.1912e-04 - val_loss: 8.6797e-04 - val_mae: 0.0257 - val_mse: 8.6533e-04 - lr: 7.8125e-05
Epoch 28/100
70/86 [=======================>......] - ETA: 0s - loss: 8.1561e-04 - mae: 0.0246 - mse: 8.1356e-04
86/86 [==============================] - 2s 20ms/step - loss: 8.2163e-04 - mae: 0.0247 - mse: 8.1958e-04 - val_loss: 8.6732e-04 - val_mae: 0.0257 - val_mse: 8.6527e-04 - lr: 7.8125e-05
Epoch 29/100
69/86 [=======================>......] - ETA: 0s - loss: 8.1980e-04 - mae: 0.0247 - mse: 8.1776e-04
Epoch 29: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.
86/86 [==============================] - 0s 4ms/step - loss: 8.2152e-04 - mae: 0.0247 - mse: 8.1947e-04 - val_loss: 8.6785e-04 - val_mae: 0.0256 - val_mse: 8.6550e-04 - lr: 7.8125e-05
Epoch 30/100
76/86 [=========================>....] - ETA: 0s - loss: 8.1986e-04 - mae: 0.0247 - mse: 8.1943e-04
86/86 [==============================] - 1s 17ms/step - loss: 8.2006e-04 - mae: 0.0247 - mse: 8.1963e-04 - val_loss: 8.6588e-04 - val_mae: 0.0257 - val_mse: 8.6525e-04 - lr: 3.9062e-05
Epoch 31/100
86/86 [==============================] - 2s 19ms/step - loss: 8.1992e-04 - mae: 0.0247 - mse: 8.1942e-04 - val_loss: 8.6576e-04 - val_mae: 0.0257 - val_mse: 8.6526e-04 - lr: 3.9062e-05
Epoch 32/100
69/86 [=======================>......] - ETA: 0s - loss: 8.1764e-04 - mae: 0.0246 - mse: 8.1712e-04
Epoch 32: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\wandb\run-20230406_165449-091t3lcn\files\model-best)... Done. 0.0s
86/86 [==============================] - 2s 19ms/step - loss: 8.1987e-04 - mae: 0.0247 - mse: 8.1935e-04 - val_loss: 8.6574e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 3.9062e-05
Epoch 33/100
71/86 [=======================>......] - ETA: 0s - loss: 8.2262e-04 - mae: 0.0248 - mse: 8.2254e-04
86/86 [==============================] - 1s 16ms/step - loss: 8.1936e-04 - mae: 0.0247 - mse: 8.1927e-04 - val_loss: 8.6540e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 1.9531e-05
Epoch 34/100
80/86 [==========================>...] - ETA: 0s - loss: 8.1881e-04 - mae: 0.0247 - mse: 8.1870e-04
86/86 [==============================] - 1s 17ms/step - loss: 8.1942e-04 - mae: 0.0247 - mse: 8.1930e-04 - val_loss: 8.6536e-04 - val_mae: 0.0257 - val_mse: 8.6525e-04 - lr: 1.9531e-05
Epoch 35/100
79/86 [==========================>...] - ETA: 0s - loss: 8.2188e-04 - mae: 0.0248 - mse: 8.2176e-04
Epoch 35: ReduceLROnPlateau reducing learning rate to 1e-05.
86/86 [==============================] - 0s 4ms/step - loss: 8.1939e-04 - mae: 0.0247 - mse: 8.1927e-04 - val_loss: 8.6536e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 1.9531e-05
Epoch 36/100
67/86 [======================>.......] - ETA: 0s - loss: 8.0760e-04 - mae: 0.0245 - mse: 8.0757e-04
86/86 [==============================] - 2s 20ms/step - loss: 8.1928e-04 - mae: 0.0247 - mse: 8.1925e-04 - val_loss: 8.6528e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 1.0000e-05
Epoch 37/100
83/86 [===========================>..] - ETA: 0s - loss: 8.1669e-04 - mae: 0.0246 - mse: 8.1666e-04
86/86 [==============================] - 2s 20ms/step - loss: 8.1928e-04 - mae: 0.0247 - mse: 8.1925e-04 - val_loss: 8.6528e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 1.0000e-05
86/86 [==============================] - 0s 3ms/step - loss: 8.1929e-04 - mae: 0.0247 - mse: 8.1926e-04 - val_loss: 8.6529e-04 - val_mae: 0.0257 - val_mse: 8.6526e-04 - lr: 1.0000e-055
Epoch 40/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1929e-04 - mae: 0.0247 - mse: 8.1926e-04 - val_loss: 8.6528e-04 - val_mae: 0.0257 - val_mse: 8.6525e-04 - lr: 1.0000e-05
Epoch 41/100
86/86 [==============================] - 0s 4ms/step - loss: 8.1928e-04 - mae: 0.0247 - mse: 8.1925e-04 - val_loss: 8.6529e-04 - val_mae: 0.0257 - val_mse: 8.6526e-04 - lr: 1.0000e-05
Epoch 42/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1929e-04 - mae: 0.0247 - mse: 8.1926e-04 - val_loss: 8.6529e-04 - val_mae: 0.0257 - val_mse: 8.6526e-04 - lr: 1.0000e-055
Epoch 43/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1926e-04 - mae: 0.0247 - mse: 8.1923e-04 - val_loss: 8.6528e-04 - val_mae: 0.0257 - val_mse: 8.6525e-04 - lr: 1.0000e-05
Epoch 44/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1927e-04 - mae: 0.0247 - mse: 8.1924e-04 - val_loss: 8.6529e-04 - val_mae: 0.0257 - val_mse: 8.6526e-04 - lr: 1.0000e-05
Epoch 45/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1929e-04 - mae: 0.0247 - mse: 8.1926e-04 - val_loss: 8.6528e-04 - val_mae: 0.0257 - val_mse: 8.6525e-04 - lr: 1.0000e-05
Epoch 46/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1928e-04 - mae: 0.0247 - mse: 8.1925e-04 - val_loss: 8.6527e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 1.0000e-05
Epoch 47/100
74/86 [========================>.....] - ETA: 0s - loss: 8.1708e-04 - mae: 0.0246 - mse: 8.1706e-04
86/86 [==============================] - 1s 13ms/step - loss: 8.1926e-04 - mae: 0.0247 - mse: 8.1923e-04 - val_loss: 8.6527e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 1.0000e-05
Epoch 48/100
84/86 [============================>.] - ETA: 0s - loss: 8.1738e-04 - mae: 0.0247 - mse: 8.1735e-04
86/86 [==============================] - 1s 13ms/step - loss: 8.1926e-04 - mae: 0.0247 - mse: 8.1923e-04 - val_loss: 8.6527e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 1.0000e-05
86/86 [==============================] - 0s 3ms/step - loss: 8.1926e-04 - mae: 0.0247 - mse: 8.1923e-04 - val_loss: 8.6527e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 1.0000e-055
Epoch 56/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1928e-04 - mae: 0.0247 - mse: 8.1925e-04 - val_loss: 8.6528e-04 - val_mae: 0.0257 - val_mse: 8.6525e-04 - lr: 1.0000e-05
Epoch 57/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1926e-04 - mae: 0.0247 - mse: 8.1923e-04 - val_loss: 8.6529e-04 - val_mae: 0.0257 - val_mse: 8.6526e-04 - lr: 1.0000e-05
Epoch 58/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1930e-04 - mae: 0.0247 - mse: 8.1927e-04 - val_loss: 8.6529e-04 - val_mae: 0.0257 - val_mse: 8.6527e-04 - lr: 1.0000e-05
Epoch 59/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1927e-04 - mae: 0.0247 - mse: 8.1923e-04 - val_loss: 8.6528e-04 - val_mae: 0.0257 - val_mse: 8.6525e-04 - lr: 1.0000e-05
Epoch 60/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1927e-04 - mae: 0.0247 - mse: 8.1924e-04 - val_loss: 8.6527e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 1.0000e-05
Epoch 61/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1926e-04 - mae: 0.0247 - mse: 8.1923e-04 - val_loss: 8.6528e-04 - val_mae: 0.0257 - val_mse: 8.6525e-04 - lr: 1.0000e-05
Epoch 62/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1925e-04 - mae: 0.0247 - mse: 8.1922e-04 - val_loss: 8.6528e-04 - val_mae: 0.0257 - val_mse: 8.6525e-04 - lr: 1.0000e-05
Epoch 63/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1926e-04 - mae: 0.0247 - mse: 8.1923e-04 - val_loss: 8.6527e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 1.0000e-055
Epoch 64/100
86/86 [==============================] - 0s 4ms/step - loss: 8.1926e-04 - mae: 0.0247 - mse: 8.1924e-04 - val_loss: 8.6528e-04 - val_mae: 0.0257 - val_mse: 8.6525e-04 - lr: 1.0000e-05
Epoch 65/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1926e-04 - mae: 0.0247 - mse: 8.1923e-04 - val_loss: 8.6529e-04 - val_mae: 0.0257 - val_mse: 8.6526e-04 - lr: 1.0000e-05
Epoch 66/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1928e-04 - mae: 0.0247 - mse: 8.1925e-04 - val_loss: 8.6530e-04 - val_mae: 0.0257 - val_mse: 8.6527e-04 - lr: 1.0000e-05
Epoch 67/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1926e-04 - mae: 0.0247 - mse: 8.1923e-04 - val_loss: 8.6532e-04 - val_mae: 0.0257 - val_mse: 8.6529e-04 - lr: 1.0000e-05
Epoch 68/100
86/86 [==============================] - 0s 2ms/step - loss: 8.1928e-04 - mae: 0.0247 - mse: 8.1925e-04 - val_loss: 8.6533e-04 - val_mae: 0.0257 - val_mse: 8.6529e-04 - lr: 1.0000e-05
Epoch 69/100
86/86 [==============================] - 0s 2ms/step - loss: 8.1929e-04 - mae: 0.0247 - mse: 8.1925e-04 - val_loss: 8.6531e-04 - val_mae: 0.0257 - val_mse: 8.6528e-04 - lr: 1.0000e-05
Epoch 70/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1928e-04 - mae: 0.0247 - mse: 8.1925e-04 - val_loss: 8.6532e-04 - val_mae: 0.0257 - val_mse: 8.6529e-04 - lr: 1.0000e-05
Epoch 71/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1929e-04 - mae: 0.0247 - mse: 8.1926e-04 - val_loss: 8.6529e-04 - val_mae: 0.0257 - val_mse: 8.6526e-04 - lr: 1.0000e-05
Epoch 72/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1927e-04 - mae: 0.0247 - mse: 8.1924e-04 - val_loss: 8.6529e-04 - val_mae: 0.0257 - val_mse: 8.6526e-04 - lr: 1.0000e-05
Epoch 73/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1927e-04 - mae: 0.0247 - mse: 8.1924e-04 - val_loss: 8.6530e-04 - val_mae: 0.0257 - val_mse: 8.6527e-04 - lr: 1.0000e-05
Epoch 74/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1929e-04 - mae: 0.0247 - mse: 8.1926e-04 - val_loss: 8.6530e-04 - val_mae: 0.0257 - val_mse: 8.6527e-04 - lr: 1.0000e-05
Epoch 75/100
86/86 [==============================] - 0s 4ms/step - loss: 8.1928e-04 - mae: 0.0247 - mse: 8.1925e-04 - val_loss: 8.6530e-04 - val_mae: 0.0257 - val_mse: 8.6527e-04 - lr: 1.0000e-05
Epoch 76/100
86/86 [==============================] - 0s 4ms/step - loss: 8.1928e-04 - mae: 0.0247 - mse: 8.1925e-04 - val_loss: 8.6532e-04 - val_mae: 0.0257 - val_mse: 8.6529e-04 - lr: 1.0000e-05
Epoch 77/100
86/86 [==============================] - 0s 5ms/step - loss: 8.1929e-04 - mae: 0.0247 - mse: 8.1926e-04 - val_loss: 8.6531e-04 - val_mae: 0.0257 - val_mse: 8.6528e-04 - lr: 1.0000e-05
Epoch 78/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1929e-04 - mae: 0.0247 - mse: 8.1926e-04 - val_loss: 8.6530e-04 - val_mae: 0.0257 - val_mse: 8.6527e-04 - lr: 1.0000e-05
Epoch 79/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1928e-04 - mae: 0.0247 - mse: 8.1925e-04 - val_loss: 8.6530e-04 - val_mae: 0.0257 - val_mse: 8.6527e-04 - lr: 1.0000e-05
Epoch 80/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1927e-04 - mae: 0.0247 - mse: 8.1924e-04 - val_loss: 8.6532e-04 - val_mae: 0.0257 - val_mse: 8.6529e-04 - lr: 1.0000e-05
Epoch 81/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1929e-04 - mae: 0.0247 - mse: 8.1926e-04 - val_loss: 8.6532e-04 - val_mae: 0.0257 - val_mse: 8.6529e-04 - lr: 1.0000e-05
Epoch 82/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1929e-04 - mae: 0.0247 - mse: 8.1926e-04 - val_loss: 8.6532e-04 - val_mae: 0.0257 - val_mse: 8.6529e-04 - lr: 1.0000e-05
Epoch 83/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1928e-04 - mae: 0.0247 - mse: 8.1925e-04 - val_loss: 8.6531e-04 - val_mae: 0.0257 - val_mse: 8.6528e-04 - lr: 1.0000e-05
Epoch 84/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1931e-04 - mae: 0.0247 - mse: 8.1928e-04 - val_loss: 8.6530e-04 - val_mae: 0.0257 - val_mse: 8.6527e-04 - lr: 1.0000e-05
Epoch 85/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1926e-04 - mae: 0.0247 - mse: 8.1923e-04 - val_loss: 8.6529e-04 - val_mae: 0.0257 - val_mse: 8.6527e-04 - lr: 1.0000e-05
Epoch 86/100
86/86 [==============================] - 0s 4ms/step - loss: 8.1927e-04 - mae: 0.0247 - mse: 8.1924e-04 - val_loss: 8.6528e-04 - val_mae: 0.0257 - val_mse: 8.6525e-04 - lr: 1.0000e-05
Epoch 87/100
86/86 [==============================] - 0s 4ms/step - loss: 8.1927e-04 - mae: 0.0247 - mse: 8.1924e-04 - val_loss: 8.6528e-04 - val_mae: 0.0257 - val_mse: 8.6526e-04 - lr: 1.0000e-05
Epoch 88/100
86/86 [==============================] - 0s 4ms/step - loss: 8.1927e-04 - mae: 0.0247 - mse: 8.1924e-04 - val_loss: 8.6528e-04 - val_mae: 0.0257 - val_mse: 8.6525e-04 - lr: 1.0000e-05
Epoch 89/100
86/86 [==============================] - 0s 4ms/step - loss: 8.1926e-04 - mae: 0.0247 - mse: 8.1923e-04 - val_loss: 8.6530e-04 - val_mae: 0.0257 - val_mse: 8.6527e-04 - lr: 1.0000e-05
Epoch 90/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1927e-04 - mae: 0.0247 - mse: 8.1924e-04 - val_loss: 8.6530e-04 - val_mae: 0.0257 - val_mse: 8.6527e-04 - lr: 1.0000e-05
Epoch 91/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1928e-04 - mae: 0.0247 - mse: 8.1924e-04 - val_loss: 8.6531e-04 - val_mae: 0.0257 - val_mse: 8.6528e-04 - lr: 1.0000e-05
Epoch 92/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1931e-04 - mae: 0.0247 - mse: 8.1927e-04 - val_loss: 8.6530e-04 - val_mae: 0.0257 - val_mse: 8.6527e-04 - lr: 1.0000e-05
Epoch 93/100
86/86 [==============================] - 0s 4ms/step - loss: 8.1927e-04 - mae: 0.0247 - mse: 8.1924e-04 - val_loss: 8.6529e-04 - val_mae: 0.0257 - val_mse: 8.6526e-04 - lr: 1.0000e-05
Epoch 94/100
86/86 [==============================] - 0s 4ms/step - loss: 8.1926e-04 - mae: 0.0247 - mse: 8.1923e-04 - val_loss: 8.6528e-04 - val_mae: 0.0257 - val_mse: 8.6525e-04 - lr: 1.0000e-05
Epoch 95/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1927e-04 - mae: 0.0247 - mse: 8.1924e-04 - val_loss: 8.6528e-04 - val_mae: 0.0257 - val_mse: 8.6526e-04 - lr: 1.0000e-05
Epoch 96/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1927e-04 - mae: 0.0247 - mse: 8.1924e-04 - val_loss: 8.6529e-04 - val_mae: 0.0257 - val_mse: 8.6526e-04 - lr: 1.0000e-05
Epoch 97/100
86/86 [==============================] - 0s 3ms/step - loss: 8.1928e-04 - mae: 0.0247 - mse: 8.1925e-04 - val_loss: 8.6531e-04 - val_mae: 0.0257 - val_mse: 8.6528e-04 - lr: 1.0000e-05
Epoch 98/100
86/86 [==============================] - 0s 4ms/step - loss: 8.1927e-04 - mae: 0.0247 - mse: 8.1924e-04 - val_loss: 8.6530e-04 - val_mae: 0.0257 - val_mse: 8.6527e-04 - lr: 1.0000e-05
Epoch 99/100
86/86 [==============================] - 0s 4ms/step - loss: 8.1927e-04 - mae: 0.0247 - mse: 8.1924e-04 - val_loss: 8.6532e-04 - val_mae: 0.0257 - val_mse: 8.6528e-04 - lr: 1.0000e-05
Epoch 100/100
86/86 [==============================] - 0s 4ms/step - loss: 8.1928e-04 - mae: 0.0247 - mse: 8.1925e-04 - val_loss: 8.6531e-04 - val_mae: 0.0257 - val_mse: 8.6528e-04 - lr: 1.0000e-05
>Saved models_no_overlap_30.0_0.01epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])