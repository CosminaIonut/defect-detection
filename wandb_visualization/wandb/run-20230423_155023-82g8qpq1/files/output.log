Epoch 1/50
 1/18 [>.............................] - ETA: 3s - loss: 0.8543 - mae: 0.9233 - mse: 0.8543
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
18/18 [==============================] - 1s 45ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0026
Epoch 2/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0026
Epoch 3/50
18/18 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0026
Epoch 4/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0026
Epoch 5/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0026
Epoch 6/50
18/18 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0026
Epoch 7/50
18/18 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0026
Epoch 8/50
18/18 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0026
Epoch 9/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0026
Epoch 10/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0026
Epoch 11/50
18/18 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0026
Epoch 12/50
18/18 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0026
Epoch 13/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0026
Epoch 14/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0026
Epoch 15/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0026
Epoch 16/50
 1/18 [>.............................] - ETA: 0s - loss: 0.8572 - mae: 0.9249 - mse: 0.8572
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0012852302752435207.
18/18 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0026
Epoch 17/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0013
Epoch 18/50
18/18 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0013
Epoch 19/50
18/18 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0013
Epoch 20/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0013
Epoch 21/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0013
Epoch 22/50
18/18 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0013
Epoch 23/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0013
Epoch 24/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0013
Epoch 25/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0013
Epoch 26/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0013
Epoch 27/50
18/18 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0013
Epoch 28/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0013
Epoch 29/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0013
Epoch 30/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0013
Epoch 31/50
 1/18 [>.............................] - ETA: 0s - loss: 0.8617 - mae: 0.9272 - mse: 0.8617
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0006426151376217604.
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0013
Epoch 32/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.4262e-04
Epoch 33/50
18/18 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.4262e-04
Epoch 34/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.4262e-04
Epoch 35/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.4262e-04
Epoch 36/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.4262e-04
Epoch 37/50
18/18 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.4262e-04
Epoch 38/50
18/18 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.4262e-04
Epoch 39/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.4262e-04
Epoch 40/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.4262e-04
Epoch 41/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.4262e-04
Epoch 42/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.4262e-04
Epoch 43/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.4262e-04
Epoch 44/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.4262e-04
Epoch 45/50
18/18 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.4262e-04
Epoch 46/50
 1/18 [>.............................] - ETA: 0s - loss: 0.8692 - mae: 0.9313 - mse: 0.8692
Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0003213075688108802.
18/18 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.4262e-04
Epoch 47/50
18/18 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 3.2131e-04
Epoch 48/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 3.2131e-04
Epoch 49/50
18/18 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 3.2131e-04
Epoch 50/50
18/18 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 3.2131e-04
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.0025704605497257173LR_[35]CHN_100CNNI_224BS_15P_val_lossM_50epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/50
 1/24 [>.............................] - ETA: 5s - loss: 0.6524 - mae: 0.8055 - mse: 0.6524
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0007s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0007s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.00266
Epoch 2/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0026
Epoch 3/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0026
Epoch 4/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0026
Epoch 5/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0026
Epoch 6/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.00266
Epoch 7/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0026
Epoch 8/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0026
Epoch 9/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0026
Epoch 10/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0026
Epoch 11/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0026
Epoch 12/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0026
Epoch 13/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0026
Epoch 14/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0026
Epoch 15/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0026
Epoch 16/50
 1/24 [>.............................] - ETA: 0s - loss: 0.6452 - mae: 0.8011 - mse: 0.6452
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0012852302752435207.
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0026
Epoch 17/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0013
Epoch 18/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0013
Epoch 19/50
24/24 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0013
Epoch 20/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0013
Epoch 21/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0013
Epoch 22/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0013
Epoch 23/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0013
Epoch 24/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0013
Epoch 25/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0013
Epoch 26/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0013
Epoch 27/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0013
Epoch 28/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0013
Epoch 29/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0013
Epoch 30/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0013
Epoch 31/50
 1/24 [>.............................] - ETA: 0s - loss: 0.6409 - mae: 0.7984 - mse: 0.6409
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0006426151376217604.
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0013
Epoch 32/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 6.4262e-04
Epoch 33/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 6.4262e-04
Epoch 34/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 6.4262e-04
Epoch 35/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 6.4262e-04
Epoch 36/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 6.4262e-04
Epoch 37/50
24/24 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 6.4262e-04
Epoch 38/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 6.4262e-04
Epoch 39/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 6.4262e-04
Epoch 40/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 6.4262e-04
Epoch 41/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 6.4262e-04
Epoch 42/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 6.4262e-04
Epoch 43/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 6.4262e-04
Epoch 44/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 6.4262e-04
Epoch 45/50
24/24 [==============================] - 0s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 6.4262e-04
Epoch 46/50
 1/24 [>.............................] - ETA: 0s - loss: 0.6454 - mae: 0.8013 - mse: 0.6454
Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0003213075688108802.
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 6.4262e-04
Epoch 47/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 3.2131e-04
Epoch 48/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 3.2131e-04
Epoch 49/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 3.2131e-04
Epoch 50/50
24/24 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 3.2131e-04
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.0025704605497257173LR_[35]CHN_100CNNI_224BS_15P_val_lossM_50epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/50
 1/18 [>.............................] - ETA: 4s - loss: 0.4553 - mae: 0.6734 - mse: 0.4553
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_train_batch_end` time: 0.0027s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_train_batch_end` time: 0.0027s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
18/18 [==============================] - 1s 70ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0026
Epoch 2/50
18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0026
Epoch 3/50
18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0026
Epoch 4/50
18/18 [==============================] - 0s 7ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0026
Epoch 5/50
18/18 [==============================] - 0s 6ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0026
Epoch 6/50
18/18 [==============================] - 0s 7ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0026
Epoch 7/50
18/18 [==============================] - 0s 7ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0026
Epoch 8/50
18/18 [==============================] - 0s 8ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0026
Epoch 9/50
18/18 [==============================] - 0s 9ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0026
Epoch 10/50
18/18 [==============================] - 0s 9ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0026
Epoch 11/50
18/18 [==============================] - 0s 6ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0026
Epoch 12/50
18/18 [==============================] - 0s 6ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0026
Epoch 13/50
18/18 [==============================] - 0s 6ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0026
Epoch 14/50
18/18 [==============================] - 0s 6ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0026
Epoch 15/50
18/18 [==============================] - 0s 6ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0026
Epoch 16/50
 1/18 [>.............................] - ETA: 0s - loss: 0.4556 - mae: 0.6736 - mse: 0.4556
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0012852302752435207.
18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0026
Epoch 17/50
18/18 [==============================] - 0s 6ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0013
Epoch 18/50
18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0013
Epoch 19/50
18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0013
Epoch 20/50
18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0013
Epoch 21/50
18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0013
Epoch 22/50
18/18 [==============================] - 0s 6ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0013
Epoch 23/50
18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0013
Epoch 24/50
18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0013
Epoch 25/50
18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0013
Epoch 26/50
18/18 [==============================] - 0s 7ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0013
Epoch 27/50
18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0013
Epoch 28/50
18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0013
Epoch 29/50
18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0013
Epoch 30/50
18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0013
Epoch 31/50
 1/18 [>.............................] - ETA: 0s - loss: 0.4564 - mae: 0.6741 - mse: 0.4564
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0006426151376217604.
18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0013
Epoch 32/50
18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 6.4262e-04
Epoch 33/50
18/18 [==============================] - 0s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 6.4262e-04
Epoch 34/50
18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 6.4262e-04
Epoch 35/50
18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 6.4262e-04
Epoch 36/50
18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 6.4262e-04
Epoch 37/50
18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 6.4262e-04
Epoch 38/50
18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 6.4262e-04
Epoch 39/50
18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 6.4262e-04
Epoch 40/50
18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 6.4262e-04
Epoch 41/50
18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 6.4262e-04
Epoch 42/50
18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 6.4262e-04
Epoch 43/50
18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 6.4262e-04
Epoch 44/50
18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 6.4262e-04
Epoch 45/50
18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 6.4262e-04
Epoch 46/50
 1/18 [>.............................] - ETA: 0s - loss: 0.4522 - mae: 0.6710 - mse: 0.4522
Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0003213075688108802.
18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 6.4262e-04
Epoch 47/50
18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 3.2131e-04
Epoch 48/50
18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 3.2131e-04
Epoch 49/50
18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 3.2131e-04
Epoch 50/50
18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 3.2131e-04
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.0025704605497257173LR_[35]CHN_100CNNI_224BS_15P_val_lossM_50epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/50
 1/18 [>.............................] - ETA: 5s - loss: 0.3296 - mae: 0.5726 - mse: 0.3296
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
18/18 [==============================] - 1s 64ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0026
Epoch 2/50
18/18 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0026
Epoch 3/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0026
Epoch 4/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0026
Epoch 5/50
18/18 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0026
Epoch 6/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0026
Epoch 7/50
18/18 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0026
Epoch 8/50
18/18 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0026
Epoch 9/50
18/18 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0026
Epoch 10/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0026
Epoch 11/50
18/18 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0026
Epoch 12/50
18/18 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0026
Epoch 13/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0026
Epoch 14/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0026
Epoch 15/50
18/18 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0026
Epoch 16/50
 1/18 [>.............................] - ETA: 0s - loss: 0.3331 - mae: 0.5756 - mse: 0.3331
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0012852302752435207.
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0026
Epoch 17/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0013
Epoch 18/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0013
Epoch 19/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0013
Epoch 20/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0013
Epoch 21/50
18/18 [==============================] - 0s 6ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0013
Epoch 22/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0013
Epoch 23/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0013
Epoch 24/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0013
Epoch 25/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0013
Epoch 26/50
18/18 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0013
Epoch 27/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0013
Epoch 28/50
18/18 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0013
Epoch 29/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0013
Epoch 30/50
18/18 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0013
Epoch 31/50
 1/18 [>.............................] - ETA: 0s - loss: 0.3330 - mae: 0.5753 - mse: 0.3330
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0006426151376217604.
18/18 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0013
Epoch 32/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 6.4262e-04
Epoch 33/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 6.4262e-04
Epoch 34/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 6.4262e-04
Epoch 35/50
18/18 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 6.4262e-04
Epoch 36/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 6.4262e-04
Epoch 37/50
18/18 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 6.4262e-04
Epoch 38/50
18/18 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 6.4262e-04
Epoch 39/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 6.4262e-04
Epoch 40/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 6.4262e-04
Epoch 41/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 6.4262e-04
Epoch 42/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 6.4262e-04
Epoch 43/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 6.4262e-04
Epoch 44/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 6.4262e-04
Epoch 45/50
18/18 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 6.4262e-04
Epoch 46/50
 1/18 [>.............................] - ETA: 0s - loss: 0.3327 - mae: 0.5752 - mse: 0.3327
Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0003213075688108802.
18/18 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 6.4262e-04
Epoch 47/50
18/18 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 3.2131e-04
Epoch 48/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 3.2131e-04
Epoch 49/50
18/18 [==============================] - 0s 5ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 3.2131e-04
Epoch 50/50
18/18 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 3.2131e-04
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.0025704605497257173LR_[35]CHN_100CNNI_224BS_15P_val_lossM_50epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/50
 1/18 [>.............................] - ETA: 6s - loss: 0.2271 - mae: 0.4743 - mse: 0.2271
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
18/18 [==============================] - 2s 71ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0026
Epoch 2/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0026
Epoch 3/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0026
Epoch 4/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0026
Epoch 5/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0026
Epoch 6/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0026
Epoch 7/50
18/18 [==============================] - 0s 5ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0026
Epoch 8/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0026
Epoch 9/50
18/18 [==============================] - 0s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0026
Epoch 10/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0026
Epoch 11/50
18/18 [==============================] - 0s 5ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0026
Epoch 12/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0026
Epoch 13/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0026
Epoch 14/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0026
Epoch 15/50
18/18 [==============================] - 0s 5ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0026
Epoch 16/50
 1/18 [>.............................] - ETA: 0s - loss: 0.2252 - mae: 0.4725 - mse: 0.2252
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0012852302752435207.
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0026
Epoch 17/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0013
Epoch 18/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0013
Epoch 19/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0013
Epoch 20/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0013
Epoch 21/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0013
Epoch 22/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0013
Epoch 23/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0013
Epoch 24/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0013
Epoch 25/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0013
Epoch 26/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0013
Epoch 27/50
18/18 [==============================] - 0s 5ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0013
Epoch 28/50
18/18 [==============================] - 0s 5ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0013
Epoch 29/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0013
Epoch 30/50
18/18 [==============================] - 0s 5ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0013
Epoch 31/50
 1/18 [>.............................] - ETA: 0s - loss: 0.2280 - mae: 0.4755 - mse: 0.2280
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0006426151376217604.
18/18 [==============================] - 0s 5ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0013
Epoch 32/50
18/18 [==============================] - 0s 5ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 6.4262e-04
Epoch 33/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 6.4262e-04
Epoch 34/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 6.4262e-04
Epoch 35/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 6.4262e-04
Epoch 36/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 6.4262e-04
Epoch 37/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 6.4262e-04
Epoch 38/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 6.4262e-04
Epoch 39/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 6.4262e-04
Epoch 40/50
18/18 [==============================] - 0s 5ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 6.4262e-04
Epoch 41/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 6.4262e-04
Epoch 42/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 6.4262e-04
Epoch 43/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 6.4262e-04
Epoch 44/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 6.4262e-04
Epoch 45/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 6.4262e-04
Epoch 46/50
 1/18 [>.............................] - ETA: 0s - loss: 0.2204 - mae: 0.4677 - mse: 0.2204
Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0003213075688108802.
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 6.4262e-04
Epoch 47/50
18/18 [==============================] - 0s 5ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 3.2131e-04
Epoch 48/50
18/18 [==============================] - 0s 5ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 3.2131e-04
Epoch 49/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 3.2131e-04
Epoch 50/50
18/18 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 3.2131e-04
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.0025704605497257173LR_[35]CHN_100CNNI_224BS_15P_val_lossM_50epochs/model_5.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/50
 1/18 [>.............................] - ETA: 6s - loss: 0.1429 - mae: 0.3756 - mse: 0.1429
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
18/18 [==============================] - 0s -9291us/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0026
Epoch 2/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0026
Epoch 3/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0026
Epoch 4/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0026
Epoch 5/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0026
Epoch 6/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0026
Epoch 7/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0026
Epoch 8/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0026
Epoch 9/50
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0026
Epoch 10/50
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0026
Epoch 11/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0026
Epoch 12/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0026
Epoch 13/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0026
Epoch 14/50
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0026
Epoch 15/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0026
Epoch 16/50
 1/18 [>.............................] - ETA: 0s - loss: 0.1409 - mae: 0.3727 - mse: 0.1409
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0012852302752435207.
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0026
Epoch 17/50
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0013
Epoch 18/50
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0013
Epoch 19/50
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0013
Epoch 20/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0013
Epoch 21/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0013
Epoch 22/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0013
Epoch 23/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0013
Epoch 24/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0013
Epoch 25/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0013
Epoch 26/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0013
Epoch 27/50
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0013
Epoch 28/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0013
Epoch 29/50
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0013
Epoch 30/50
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0013
Epoch 31/50
 1/18 [>.............................] - ETA: 0s - loss: 0.1420 - mae: 0.3741 - mse: 0.1420
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0006426151376217604.
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0013
Epoch 32/50
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 6.4262e-04
Epoch 33/50
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 6.4262e-04
Epoch 34/50
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 6.4262e-04
Epoch 35/50
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 6.4262e-04
Epoch 36/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 6.4262e-04
Epoch 37/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 6.4262e-04
Epoch 38/50
18/18 [==============================] - 0s 2ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 6.4262e-04
Epoch 39/50
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 6.4262e-04
Epoch 40/50
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 6.4262e-04
Epoch 41/50
18/18 [==============================] - 0s 2ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 6.4262e-04
Epoch 42/50
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 6.4262e-04
Epoch 43/50
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 6.4262e-04
Epoch 44/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 6.4262e-04
Epoch 45/50
18/18 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 6.4262e-04
Epoch 46/50
 1/18 [>.............................] - ETA: 0s - loss: 0.1449 - mae: 0.3781 - mse: 0.1449
Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0003213075688108802.
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 6.4262e-04
Epoch 47/50
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 3.2131e-04
Epoch 48/50
18/18 [==============================] - 0s 2ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 3.2131e-04
Epoch 49/50
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 3.2131e-04
Epoch 50/50
18/18 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 3.2131e-04
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.0025704605497257173LR_[35]CHN_100CNNI_224BS_15P_val_lossM_50epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/50
 1/18 [>.............................] - ETA: 5s - loss: 0.0771 - mae: 0.2743 - mse: 0.0771
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
18/18 [==============================] - 1s 50ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0026
Epoch 2/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0026
Epoch 3/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0026
Epoch 4/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0026
Epoch 5/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0026
Epoch 6/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0026
Epoch 7/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0026
Epoch 8/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0026
Epoch 9/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0026
Epoch 10/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0026
Epoch 11/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0026
Epoch 12/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0026
Epoch 13/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0026
Epoch 14/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0026
Epoch 15/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0026
Epoch 16/50
 1/18 [>.............................] - ETA: 0s - loss: 0.0742 - mae: 0.2690 - mse: 0.0742
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0012852302752435207.
18/18 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0026
Epoch 17/50
18/18 [==============================] - 0s 2ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0013
Epoch 18/50
18/18 [==============================] - 0s 2ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0013
Epoch 19/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0013
Epoch 20/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0013
Epoch 21/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0013
Epoch 22/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0013
Epoch 23/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0013
Epoch 24/50
18/18 [==============================] - 0s 2ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0013
Epoch 25/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0013
Epoch 26/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0013
Epoch 27/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0013
Epoch 28/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0013
Epoch 29/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0013
Epoch 30/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0013
Epoch 31/50
 1/18 [>.............................] - ETA: 0s - loss: 0.0774 - mae: 0.2746 - mse: 0.0774
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0006426151376217604.
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0013
Epoch 32/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 6.4262e-04
Epoch 33/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 6.4262e-04
Epoch 34/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 6.4262e-04
Epoch 35/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 6.4262e-04
Epoch 36/50
18/18 [==============================] - 0s 5ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 6.4262e-04
Epoch 37/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 6.4262e-04
Epoch 38/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 6.4262e-04
Epoch 39/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 6.4262e-04
Epoch 40/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 6.4262e-04
Epoch 41/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 6.4262e-04
Epoch 42/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 6.4262e-04
Epoch 43/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 6.4262e-04
Epoch 44/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 6.4262e-04
Epoch 45/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 6.4262e-04
Epoch 46/50
 1/18 [>.............................] - ETA: 0s - loss: 0.0789 - mae: 0.2778 - mse: 0.0789
Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0003213075688108802.
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 6.4262e-04
Epoch 47/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 3.2131e-04
Epoch 48/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 3.2131e-04
Epoch 49/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 3.2131e-04
Epoch 50/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 3.2131e-04
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.0025704605497257173LR_[35]CHN_100CNNI_224BS_15P_val_lossM_50epochs/model_7.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/50
 1/18 [>.............................] - ETA: 4s - loss: 0.0332 - mae: 0.1770 - mse: 0.0332
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
18/18 [==============================] - 1s 52ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0026
Epoch 2/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0026
Epoch 3/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0026
Epoch 4/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0026
Epoch 5/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0026
Epoch 6/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0026
Epoch 7/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0026
Epoch 8/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0026
Epoch 9/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0026
Epoch 10/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0026
Epoch 11/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0026
Epoch 12/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0026
Epoch 13/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0026
Epoch 14/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0026
Epoch 15/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0026
Epoch 16/50
 1/18 [>.............................] - ETA: 0s - loss: 0.0324 - mae: 0.1750 - mse: 0.0324
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0012852302752435207.
18/18 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0026
Epoch 17/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0013
Epoch 18/50
18/18 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0013
Epoch 19/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0013
Epoch 20/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0013
Epoch 21/50
18/18 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0013
Epoch 22/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0013
Epoch 23/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0013
Epoch 24/50
18/18 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0013
Epoch 25/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0013
Epoch 26/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0013
Epoch 27/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0013
Epoch 28/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0013
Epoch 29/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0013
Epoch 30/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0013
Epoch 31/50
 1/18 [>.............................] - ETA: 0s - loss: 0.0325 - mae: 0.1754 - mse: 0.0325
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0006426151376217604.
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0013
Epoch 32/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 6.4262e-04
Epoch 33/50
18/18 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 6.4262e-04
Epoch 34/50
18/18 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 6.4262e-04
Epoch 35/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 6.4262e-04
Epoch 36/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 6.4262e-04
Epoch 37/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 6.4262e-04
Epoch 38/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 6.4262e-04
Epoch 39/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 6.4262e-04
Epoch 40/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 6.4262e-04
Epoch 41/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 6.4262e-04
Epoch 42/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 6.4262e-04
Epoch 43/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 6.4262e-04
Epoch 44/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 6.4262e-04
Epoch 45/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 6.4262e-04
Epoch 46/50
 1/18 [>.............................] - ETA: 0s - loss: 0.0325 - mae: 0.1751 - mse: 0.0325
Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0003213075688108802.
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 6.4262e-04
Epoch 47/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 3.2131e-04
Epoch 48/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 3.2131e-04
Epoch 49/50
18/18 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 3.2131e-04
Epoch 50/50
18/18 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 3.2131e-04
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.0025704605497257173LR_[35]CHN_100CNNI_224BS_15P_val_lossM_50epochs/model_8.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/50
 1/18 [>.............................] - ETA: 4s - loss: 0.0075 - mae: 0.0748 - mse: 0.0075
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
18/18 [==============================] - 2s 112ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0026
Epoch 2/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0026
Epoch 3/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0026
Epoch 4/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0026
Epoch 5/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0026
Epoch 6/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0026
Epoch 7/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0026
Epoch 8/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0026
Epoch 9/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0026
Epoch 10/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0026
Epoch 11/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0026
Epoch 12/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0026
Epoch 13/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0026
Epoch 14/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0026
Epoch 15/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0026
Epoch 16/50
 1/18 [>.............................] - ETA: 0s - loss: 0.0079 - mae: 0.0771 - mse: 0.0079
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0012852302752435207.
18/18 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0026
Epoch 17/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0013
Epoch 18/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0013
Epoch 19/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0013
Epoch 20/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0013
Epoch 21/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0013
Epoch 22/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0013
Epoch 23/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0013
Epoch 24/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0013
Epoch 25/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0013
Epoch 26/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0013
Epoch 27/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0013
Epoch 28/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0013
Epoch 29/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0013
Epoch 30/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0013
Epoch 31/50
 1/18 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0746 - mse: 0.0074
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0006426151376217604.
18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0013
Epoch 32/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 6.4262e-04
Epoch 33/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 6.4262e-04
Epoch 34/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 6.4262e-04
Epoch 35/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 6.4262e-04
Epoch 36/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 6.4262e-04
Epoch 37/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 6.4262e-04
Epoch 38/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 6.4262e-04
Epoch 39/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 6.4262e-04
Epoch 40/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 6.4262e-04
Epoch 41/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 6.4262e-04
Epoch 42/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 6.4262e-04
Epoch 43/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 6.4262e-04
Epoch 44/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 6.4262e-04
Epoch 45/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 6.4262e-04
Epoch 46/50
 1/18 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0768 - mse: 0.0077
Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0003213075688108802.
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 6.4262e-04
Epoch 47/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 3.2131e-04
Epoch 48/50
18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 3.2131e-04
Epoch 49/50
18/18 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 3.2131e-04
Epoch 50/50
18/18 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 3.2131e-04
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.0025704605497257173LR_[35]CHN_100CNNI_224BS_15P_val_lossM_50epochs/model_9.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])