Epoch 1/20
20/25 [=======================>......] - ETA: 0s - loss: 1.6358 - mae: 0.0699 - mse: 0.0132
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_205252-ta1tuw50\files\model-best)... Done. 0.0s
25/25 [==============================] - 2s 74ms/step - loss: 1.3989 - mae: 0.0643 - mse: 0.0112 - val_loss: 0.2324 - val_mae: 0.0534 - val_mse: 0.0043 - lr: 0.0719
Epoch 2/20
14/25 [===============>..............] - ETA: 0s - loss: 0.1197 - mae: 0.0428 - mse: 0.0026
25/25 [==============================] - 1s 60ms/step - loss: 0.0848 - mae: 0.0413 - mse: 0.0024 - val_loss: 0.0207 - val_mae: 0.0467 - val_mse: 0.0032 - lr: 0.0719
Epoch 3/20
13/25 [==============>...............] - ETA: 0s - loss: 0.0137 - mae: 0.0423 - mse: 0.0026
25/25 [==============================] - 2s 65ms/step - loss: 0.0120 - mae: 0.0495 - mse: 0.0037 - val_loss: 0.0047 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0719
Epoch 4/20
25/25 [==============================] - ETA: 0s - loss: 0.0037 - mae: 0.0384 - mse: 0.0020
25/25 [==============================] - 9s 394ms/step - loss: 0.0037 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0033 - val_mae: 0.0414 - val_mse: 0.0024 - lr: 0.0719
Epoch 5/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0412 - mse: 0.0024 - val_loss: 0.0037 - val_mae: 0.0440 - val_mse: 0.0028 - lr: 0.0719
Epoch 6/20
25/25 [==============================] - 0s 5ms/step - loss: 0.0122 - mae: 0.0647 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0909 - val_mse: 0.0102 - lr: 0.0719
Epoch 7/20
20/25 [=======================>......] - ETA: 0s - loss: 0.0068 - mae: 0.0451 - mse: 0.0030
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.03595076873898506.
25/25 [==============================] - 0s 5ms/step - loss: 0.0062 - mae: 0.0439 - mse: 0.0028 - val_loss: 0.0040 - val_mae: 0.0447 - val_mse: 0.0029 - lr: 0.0719
Epoch 8/20
14/25 [===============>..............] - ETA: 0s - loss: 0.0030 - mae: 0.0395 - mse: 0.0021
25/25 [==============================] - 2s 74ms/step - loss: 0.0028 - mae: 0.0388 - mse: 0.0021 - val_loss: 0.0024 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0360
Epoch 9/20
24/25 [===========================>..] - ETA: 0s - loss: 0.0023 - mae: 0.0380 - mse: 0.0019
25/25 [==============================] - 1s 62ms/step - loss: 0.0023 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0360
Epoch 10/20
25/25 [==============================] - 0s 8ms/step - loss: 0.0023 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0025 - val_mae: 0.0396 - val_mse: 0.0022 - lr: 0.0360
Epoch 11/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0025 - mae: 0.0396 - mse: 0.0022 - val_loss: 0.0023 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0360
Epoch 12/20
 1/25 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0399 - mse: 0.0021
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.01797538436949253.
25/25 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0409 - val_mse: 0.0024 - lr: 0.0360
Epoch 13/20
24/25 [===========================>..] - ETA: 0s - loss: 0.0023 - mae: 0.0386 - mse: 0.0020
25/25 [==============================] - 1s 60ms/step - loss: 0.0023 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0180
Epoch 14/20
25/25 [==============================] - 0s 7ms/step - loss: 0.0022 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0180
Epoch 15/20
13/25 [==============>...............] - ETA: 0s - loss: 0.0023 - mae: 0.0390 - mse: 0.0021
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.008987692184746265.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_205252-ta1tuw50\files\model-best)... Done. 0.0s
25/25 [==============================] - 1s 60ms/step - loss: 0.0023 - mae: 0.0389 - mse: 0.0021 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0180
Epoch 16/20
25/25 [==============================] - 0s 7ms/step - loss: 0.0021 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0090
Epoch 17/20
14/25 [===============>..............] - ETA: 0s - loss: 0.0023 - mae: 0.0391 - mse: 0.0021
25/25 [==============================] - 2s 68ms/step - loss: 0.0022 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0090
Epoch 18/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0090
Epoch 19/20
25/25 [==============================] - ETA: 0s - loss: 0.0021 - mae: 0.0381 - mse: 0.0020
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_train_batch_end` time: 0.0030s). Check your callbacks.
25/25 [==============================] - 1s 57ms/step - loss: 0.0021 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0090
Epoch 20/20
24/25 [===========================>..] - ETA: 0s - loss: 0.0022 - mae: 0.0384 - mse: 0.0020
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.004493846092373133.
25/25 [==============================] - 0s 8ms/step - loss: 0.0022 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0024 - val_mae: 0.0393 - val_mse: 0.0021 - lr: 0.0090
>Saved ../trained_models/models_segments_overlap_adam_0.07190154039379697LR_[32, 64, 128, 256]HN_160BS_3P_val_lossM_20epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
33/33 [==============================] - 1s 10ms/step - loss: 1.0817 - mae: 0.0614 - mse: 0.0068 - val_loss: 0.0975 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0719
Epoch 2/20
33/33 [==============================] - 0s 5ms/step - loss: 0.0331 - mae: 0.0525 - mse: 0.0038 - val_loss: 0.0078 - val_mae: 0.0547 - val_mse: 0.0042 - lr: 0.0719
Epoch 3/20
33/33 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0527 - mse: 0.0038 - val_loss: 0.0049 - val_mae: 0.0543 - val_mse: 0.0042 - lr: 0.0719
Epoch 4/20
33/33 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0531 - mse: 0.0039 - val_loss: 0.0042 - val_mae: 0.0513 - val_mse: 0.0036 - lr: 0.0719
Epoch 5/20
33/33 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0516 - mse: 0.0036 - val_loss: 0.0042 - val_mae: 0.0528 - val_mse: 0.0039 - lr: 0.0719
Epoch 6/20
33/33 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0512 - mse: 0.0035 - val_loss: 0.0042 - val_mae: 0.0545 - val_mse: 0.0042 - lr: 0.0719
Epoch 7/20
33/33 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0511 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0719
Epoch 8/20
33/33 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0510 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0719
Epoch 9/20
33/33 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0719
Epoch 10/20
33/33 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0719
Epoch 11/20
33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0719
Epoch 12/20
33/33 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0719
Epoch 13/20
25/33 [=====================>........] - ETA: 0s - loss: 0.0034 - mae: 0.0508 - mse: 0.0034
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.03595076873898506.
33/33 [==============================] - 0s 7ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0719
Epoch 14/20
33/33 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0360
Epoch 15/20
33/33 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0360
Epoch 16/20
28/33 [========================>.....] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.01797538436949253.
33/33 [==============================] - 0s 7ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0360
Epoch 17/20
33/33 [==============================] - 0s 7ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0180
Epoch 18/20
33/33 [==============================] - 0s 7ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0180
Epoch 19/20
25/33 [=====================>........] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.008987692184746265.
33/33 [==============================] - 0s 7ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0180
Epoch 20/20
33/33 [==============================] - 0s 7ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0090
>Saved ../trained_models/models_segments_overlap_adam_0.07190154039379697LR_[32, 64, 128, 256]HN_160BS_3P_val_lossM_20epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
25/25 [==============================] - 1s 13ms/step - loss: 1.3837 - mae: 0.0569 - mse: 0.0058 - val_loss: 0.2294 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0719
Epoch 2/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0827 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0188 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0719
Epoch 3/20
25/25 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0390 - mse: 0.0021 - val_loss: 0.0039 - val_mae: 0.0406 - val_mse: 0.0023 - lr: 0.0719
Epoch 4/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0028 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0719
Epoch 5/20
 1/25 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0365 - mse: 0.0018
25/25 [==============================] - 0s 5ms/step - loss: 0.0021 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.07199
Epoch 6/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0400 - val_mse: 0.0022 - lr: 0.0719
Epoch 7/20
25/25 [==============================] - 0s 5ms/step - loss: 0.0021 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0719
Epoch 8/20
19/25 [=====================>........] - ETA: 0s - loss: 0.0021 - mae: 0.0379 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.03595076873898506.
25/25 [==============================] - 0s 5ms/step - loss: 0.0021 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.07199
Epoch 9/20
21/25 [========================>.....] - ETA: 0s - loss: 0.0020 - mae: 0.0379 - mse: 0.0019
25/25 [==============================] - 1s 60ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0360
Epoch 10/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0360
Epoch 11/20
 1/25 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0020
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.01797538436949253.
25/25 [==============================] - 1s 60ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0360
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_205252-ta1tuw50\files\model-best)... Done. 0.0s
25/25 [==============================] - 1s 60ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0360
 1/25 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0365 - mse: 0.0018.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0360
 1/25 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0365 - mse: 0.0018.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0360
25/25 [==============================] - 1s 61ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0180
25/25 [==============================] - 1s 61ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0180
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0021s). Check your callbacks.
25/25 [==============================] - 0s 7ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.07190
Epoch 5/20
25/25 [==============================] - 0s 5ms/step - loss: 0.0021 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0719
Epoch 6/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0719
Epoch 7/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0021 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0719
Epoch 8/20
14/25 [===============>..............] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0020
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.03595076873898506.
25/25 [==============================] - 0s 7ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.07190
Epoch 9/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0360
Epoch 10/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0360
Epoch 11/20
25/25 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0360
Epoch 12/20
25/25 [==============================] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.01797538436949253.
25/25 [==============================] - 0s 7ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0360
Epoch 13/20
25/25 [==============================] - 0s 7ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0180
Epoch 14/20
25/25 [==============================] - 0s 7ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0180
Epoch 15/20
12/25 [=============>................] - ETA: 0s - loss: 0.0019 - mae: 0.0374 - mse: 0.0019
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.008987692184746265.
25/25 [==============================] - 0s 7ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0180
Epoch 16/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0090
Epoch 17/20
25/25 [==============================] - 0s 7ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0090
Epoch 18/20
13/25 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.004493846092373133.
25/25 [==============================] - 0s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0090
Epoch 19/20
 1/25 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0406 - mse: 0.0021
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0015s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0030s). Check your callbacks.
 1/25 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.0019.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0045
Epoch 20/20
25/25 [==============================] - 0s 7ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0045
>Saved ../trained_models/models_segments_overlap_adam_0.07190154039379697LR_[32, 64, 128, 256]HN_160BS_3P_val_lossM_20epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
25/25 [==============================] - 1s 10ms/step - loss: 1.3642 - mae: 0.0577 - mse: 0.0062 - val_loss: 0.2312 - val_mae: 0.0475 - val_mse: 0.0034 - lr: 0.0719
Epoch 2/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0829 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0190 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0719
Epoch 3/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0034 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0719
Epoch 4/20
25/25 [==============================] - 0s 5ms/step - loss: 0.0026 - mae: 0.0380 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0719
Epoch 5/20
25/25 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0719
Epoch 6/20
25/25 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0719
Epoch 7/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0719
Epoch 8/20
 1/25 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0410 - mse: 0.0021
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.03595076873898506.
25/25 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0719
Epoch 9/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0360
Epoch 10/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0360
Epoch 11/20
 1/25 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0374 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.01797538436949253.
25/25 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0360
Epoch 12/20
25/25 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0180
Epoch 13/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0180
Epoch 14/20
25/25 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0180
Epoch 15/20
 1/25 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.0019.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0045
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.008987692184746265.
25/25 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0180
Epoch 16/20
25/25 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0090
Epoch 17/20
25/25 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0090
Epoch 18/20
20/25 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0382 - mse: 0.0019
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.004493846092373133.
25/25 [==============================] - 0s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0090
Epoch 19/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0045
Epoch 20/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0045
>Saved ../trained_models/models_segments_overlap_adam_0.07190154039379697LR_[32, 64, 128, 256]HN_160BS_3P_val_lossM_20epochs/model_5.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
25/25 [==============================] - 1s 11ms/step - loss: 1.3534 - mae: 0.0550 - mse: 0.0050 - val_loss: 0.2256 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0719
Epoch 2/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0812 - mae: 0.0389 - mse: 0.0021 - val_loss: 0.0188 - val_mae: 0.0408 - val_mse: 0.0024 - lr: 0.0719
Epoch 3/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0037 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0719
Epoch 4/20
25/25 [==============================] - 0s 5ms/step - loss: 0.0026 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0719
Epoch 5/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0021 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0719
Epoch 6/20
25/25 [==============================] - 0s 7ms/step - loss: 0.0021 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0719
Epoch 7/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0021 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0719
Epoch 8/20
24/25 [===========================>..] - ETA: 0s - loss: 0.0020 - mae: 0.0379 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.03595076873898506.
25/25 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0719
Epoch 9/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0360
Epoch 10/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0360
Epoch 11/20
25/25 [==============================] - ETA: 0s - loss: 0.0020 - mae: 0.0379 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.01797538436949253.
25/25 [==============================] - 0s 6ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0360
Epoch 12/20
25/25 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0180
Epoch 13/20
25/25 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0180
Epoch 14/20
25/25 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0180
Epoch 15/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0180
Epoch 16/20
25/25 [==============================] - ETA: 0s - loss: 0.0020 - mae: 0.0380 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.008987692184746265.
25/25 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0180
Epoch 17/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0090
Epoch 18/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0090
Epoch 19/20
 1/25 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0370 - mse: 0.0018
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.004493846092373133.
25/25 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0090
Epoch 20/20
25/25 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0045
>Saved ../trained_models/models_segments_overlap_adam_0.07190154039379697LR_[32, 64, 128, 256]HN_160BS_3P_val_lossM_20epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
25/25 [==============================] - 1s 15ms/step - loss: 1.3718 - mae: 0.0591 - mse: 0.0065 - val_loss: 0.2269 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0719
Epoch 2/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0826 - mae: 0.0406 - mse: 0.0023 - val_loss: 0.0194 - val_mae: 0.0400 - val_mse: 0.0022 - lr: 0.0719
Epoch 3/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.0396 - mse: 0.0022 - val_loss: 0.0042 - val_mae: 0.0411 - val_mse: 0.0024 - lr: 0.0719
Epoch 4/20
25/25 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0389 - mse: 0.0021 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0719
Epoch 5/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0719
Epoch 6/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0021 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0395 - val_mse: 0.0022 - lr: 0.0719
Epoch 7/20
25/25 [==============================] - 0s 5ms/step - loss: 0.0021 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0719
Epoch 8/20
18/25 [====================>.........] - ETA: 0s - loss: 0.0020 - mae: 0.0380 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.03595076873898506.
25/25 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0719
Epoch 9/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0360
Epoch 10/20
25/25 [==============================] - 0s 7ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0360
Epoch 11/20
25/25 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0360
Epoch 12/20
15/25 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.01797538436949253.
25/25 [==============================] - 0s 7ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0360
Epoch 13/20
25/25 [==============================] - 0s 7ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0180
Epoch 14/20
25/25 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0180
Epoch 15/20
21/25 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.008987692184746265.
25/25 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0180
Epoch 16/20
25/25 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0090
Epoch 17/20
21/25 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
25/25 [==============================] - 1s 60ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0090
Epoch 18/20
16/25 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.004493846092373133.
25/25 [==============================] - 0s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0090
Epoch 19/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0045
Epoch 20/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0045
>Saved ../trained_models/models_segments_overlap_adam_0.07190154039379697LR_[32, 64, 128, 256]HN_160BS_3P_val_lossM_20epochs/model_7.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
25/25 [==============================] - 1s 11ms/step - loss: 1.3863 - mae: 0.0621 - mse: 0.0083 - val_loss: 0.2313 - val_mae: 0.0464 - val_mse: 0.0032 - lr: 0.0719
Epoch 2/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0837 - mae: 0.0412 - mse: 0.0024 - val_loss: 0.0196 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0719
Epoch 3/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0396 - mse: 0.0022 - val_loss: 0.0038 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0719
Epoch 4/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0446 - mse: 0.0029 - val_loss: 0.0044 - val_mae: 0.0467 - val_mse: 0.0032 - lr: 0.0719
Epoch 5/20
25/25 [==============================] - 0s 5ms/step - loss: 0.0028 - mae: 0.0397 - mse: 0.0022 - val_loss: 0.0029 - val_mae: 0.0407 - val_mse: 0.0023 - lr: 0.0719
Epoch 6/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0394 - mse: 0.0021 - val_loss: 0.0022 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0719
Epoch 7/20
25/25 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0421 - mse: 0.0026 - val_loss: 0.0026 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0719
Epoch 8/20
25/25 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0719
Epoch 9/20
 1/25 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0375 - mse: 0.0019
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.03595076873898506.
25/25 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0028 - val_mae: 0.0433 - val_mse: 0.0027 - lr: 0.0719
Epoch 10/20
25/25 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0360
Epoch 11/20
25/25 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0360
Epoch 12/20
25/25 [==============================] - 0s 3ms/step - loss: 0.0021 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0029 - val_mae: 0.0445 - val_mse: 0.0029 - lr: 0.0360
Epoch 13/20
 1/25 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0463 - mse: 0.0031
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.01797538436949253.
25/25 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0401 - mse: 0.0022 - val_loss: 0.0023 - val_mae: 0.0399 - val_mse: 0.0022 - lr: 0.0360
Epoch 14/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0180
Epoch 15/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0180
Epoch 16/20
25/25 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0180
Epoch 17/20
25/25 [==============================] - 0s 7ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0180
Epoch 18/20
12/25 [=============>................] - ETA: 0s - loss: 0.0020 - mae: 0.0380 - mse: 0.0019
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.008987692184746265.
25/25 [==============================] - 0s 5ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0180
Epoch 19/20
25/25 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0090
Epoch 20/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0090
>Saved ../trained_models/models_segments_overlap_adam_0.07190154039379697LR_[32, 64, 128, 256]HN_160BS_3P_val_lossM_20epochs/model_8.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
25/25 [==============================] - 1s 12ms/step - loss: 1.4098 - mae: 0.0647 - mse: 0.0111 - val_loss: 0.2342 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0719
Epoch 2/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0847 - mae: 0.0389 - mse: 0.0021 - val_loss: 0.0242 - val_mae: 0.0690 - val_mse: 0.0067 - lr: 0.0719
Epoch 3/20
25/25 [==============================] - 0s 8ms/step - loss: 0.0150 - mae: 0.0548 - mse: 0.0045 - val_loss: 0.0067 - val_mae: 0.0488 - val_mse: 0.0036 - lr: 0.0719
Epoch 4/20
25/25 [==============================] - 0s 8ms/step - loss: 0.0086 - mae: 0.0545 - mse: 0.0045 - val_loss: 0.0039 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0719
Epoch 5/20
25/25 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0480 - mse: 0.0035 - val_loss: 0.0048 - val_mae: 0.0443 - val_mse: 0.0029 - lr: 0.0719
Epoch 6/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0394 - mse: 0.0021 - val_loss: 0.0027 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0719
Epoch 7/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0026 - mae: 0.0390 - mse: 0.0021 - val_loss: 0.0032 - val_mae: 0.0425 - val_mse: 0.0026 - lr: 0.0719
Epoch 8/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0586 - mse: 0.0051 - val_loss: 0.0038 - val_mae: 0.0390 - val_mse: 0.0020 - lr: 0.0719
Epoch 9/20
10/25 [===========>..................] - ETA: 0s - loss: 0.0034 - mae: 0.0394 - mse: 0.0021
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.03595076873898506.
25/25 [==============================] - 0s 8ms/step - loss: 0.0032 - mae: 0.0397 - mse: 0.0022 - val_loss: 0.0062 - val_mae: 0.0628 - val_mse: 0.0057 - lr: 0.0719
Epoch 10/20
25/25 [==============================] - 0s 7ms/step - loss: 0.0034 - mae: 0.0425 - mse: 0.0026 - val_loss: 0.0027 - val_mae: 0.0394 - val_mse: 0.0021 - lr: 0.0360
Epoch 11/20
25/25 [==============================] - 0s 7ms/step - loss: 0.0025 - mae: 0.0393 - mse: 0.0021 - val_loss: 0.0023 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0360
Epoch 12/20
25/25 [==============================] - 0s 3ms/step - loss: 0.0022 - mae: 0.0382 - mse: 0.0019 - val_loss: 0.0030 - val_mae: 0.0424 - val_mse: 0.0026 - lr: 0.0360
Epoch 13/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0025 - mae: 0.0401 - mse: 0.0023 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0360
Epoch 14/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0360
Epoch 15/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0022 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.0032 - val_mae: 0.0455 - val_mse: 0.0031 - lr: 0.0360
Epoch 16/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0424 - mse: 0.0026 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0360
Epoch 17/20
 1/25 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0384 - mse: 0.0020
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.01797538436949253.
25/25 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0390 - val_mse: 0.0020 - lr: 0.0360
Epoch 18/20
25/25 [==============================] - 0s 6ms/step - loss: 0.0022 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0180
Epoch 19/20
25/25 [==============================] - 0s 4ms/step - loss: 0.0022 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0396 - val_mse: 0.0022 - lr: 0.0180
Epoch 20/20
19/25 [=====================>........] - ETA: 0s - loss: 0.0023 - mae: 0.0390 - mse: 0.0021
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.008987692184746265.
25/25 [==============================] - 0s 5ms/step - loss: 0.0022 - mae: 0.0389 - mse: 0.0021 - val_loss: 0.0021 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0180
>Saved ../trained_models/models_segments_overlap_adam_0.07190154039379697LR_[32, 64, 128, 256]HN_160BS_3P_val_lossM_20epochs/model_9.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
25/25 [==============================] - 1s 60ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0090