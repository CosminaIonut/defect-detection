Epoch 1/20
160/162 [============================>.] - ETA: 0s - loss: 0.2542 - mae: 0.0740 - mse: 0.0138
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.
162/162 [==============================] - 1s 5ms/step - loss: 0.2526 - mae: 0.0737 - mse: 0.0137 - val_loss: 0.1161 - val_mae: 0.0421 - val_mse: 0.0025 - lr: 0.0414
Epoch 2/20
162/162 [==============================] - ETA: 0s - loss: 0.0661 - mae: 0.0417 - mse: 0.0025
162/162 [==============================] - 1s 5ms/step - loss: 0.0661 - mae: 0.0417 - mse: 0.0025 - val_loss: 0.0337 - val_mae: 0.0417 - val_mse: 0.0025 - lr: 0.0414
Epoch 3/20
154/162 [===========================>..] - ETA: 0s - loss: 0.0211 - mae: 0.0413 - mse: 0.0024
162/162 [==============================] - 1s 5ms/step - loss: 0.0207 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.0122 - val_mae: 0.0407 - val_mse: 0.0023 - lr: 0.0414
Epoch 4/20
157/162 [============================>.] - ETA: 0s - loss: 0.0087 - mae: 0.0403 - mse: 0.0023
162/162 [==============================] - 1s 5ms/step - loss: 0.0086 - mae: 0.0403 - mse: 0.0023 - val_loss: 0.0062 - val_mae: 0.0401 - val_mse: 0.0022 - lr: 0.0414
Epoch 5/20
160/162 [============================>.] - ETA: 0s - loss: 0.0052 - mae: 0.0397 - mse: 0.0022
162/162 [==============================] - 1s 5ms/step - loss: 0.0051 - mae: 0.0397 - mse: 0.0022 - val_loss: 0.0044 - val_mae: 0.0399 - val_mse: 0.0022 - lr: 0.0414
Epoch 6/20
158/162 [============================>.] - ETA: 0s - loss: 0.0040 - mae: 0.0393 - mse: 0.0021
162/162 [==============================] - 1s 5ms/step - loss: 0.0040 - mae: 0.0393 - mse: 0.0021 - val_loss: 0.0037 - val_mae: 0.0395 - val_mse: 0.0021 - lr: 0.0414
Epoch 7/20
126/162 [======================>.......] - ETA: 0s - loss: 0.0035 - mae: 0.0389 - mse: 0.0021
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183724-qv1yc94u\files\model-best)... Done. 0.0s
162/162 [==============================] - 1s 5ms/step - loss: 0.0035 - mae: 0.0390 - mse: 0.0021 - val_loss: 0.0033 - val_mae: 0.0393 - val_mse: 0.0021 - lr: 0.0414
Epoch 8/20
162/162 [==============================] - 1s 6ms/step - loss: 0.0032 - mae: 0.0388 - mse: 0.0021 - val_loss: 0.0031 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0414
Epoch 9/20
 79/162 [=============>................] - ETA: 0s - loss: 0.0030 - mae: 0.0387 - mse: 0.0020
162/162 [==============================] - 1s 5ms/step - loss: 0.0030 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.0029 - val_mae: 0.0389 - val_mse: 0.0020 - lr: 0.0414
Epoch 10/20
160/162 [============================>.] - ETA: 0s - loss: 0.0028 - mae: 0.0386 - mse: 0.0020
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.020699869841337204.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183724-qv1yc94u\files\model-best)... Done. 0.0s
162/162 [==============================] - 1s 5ms/step - loss: 0.0028 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0028 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0414
Epoch 11/20
 83/162 [==============>...............] - ETA: 0s - loss: 0.0027 - mae: 0.0379 - mse: 0.0019
162/162 [==============================] - 1s 5ms/step - loss: 0.0027 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0207
Epoch 12/20
140/162 [========================>.....] - ETA: 0s - loss: 0.0027 - mae: 0.0385 - mse: 0.0020
162/162 [==============================] - 1s 5ms/step - loss: 0.0027 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0207
Epoch 13/20
161/162 [============================>.] - ETA: 0s - loss: 0.0026 - mae: 0.0383 - mse: 0.0020
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.010349934920668602.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183724-qv1yc94u\files\model-best)... Done. 0.0s
162/162 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0207
Epoch 14/20
 81/162 [==============>...............] - ETA: 0s - loss: 0.0025 - mae: 0.0375 - mse: 0.0019
162/162 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0103
Epoch 15/20
132/162 [=======================>......] - ETA: 0s - loss: 0.0026 - mae: 0.0382 - mse: 0.0020
162/162 [==============================] - 1s 6ms/step - loss: 0.0026 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0103
Epoch 16/20
161/162 [============================>.] - ETA: 0s - loss: 0.0025 - mae: 0.0383 - mse: 0.0020
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.005174967460334301.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183724-qv1yc94u\files\model-best)... Done. 0.0s
162/162 [==============================] - 1s 5ms/step - loss: 0.0025 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0103
Epoch 17/20
 81/162 [==============>...............] - ETA: 0s - loss: 0.0025 - mae: 0.0377 - mse: 0.0019
162/162 [==============================] - 1s 6ms/step - loss: 0.0025 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0025 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0052
Epoch 18/20
133/162 [=======================>......] - ETA: 0s - loss: 0.0025 - mae: 0.0379 - mse: 0.0020
162/162 [==============================] - 1s 6ms/step - loss: 0.0025 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0025 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0052
Epoch 19/20
161/162 [============================>.] - ETA: 0s - loss: 0.0025 - mae: 0.0383 - mse: 0.0020
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0025874837301671505.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183724-qv1yc94u\files\model-best)... Done. 0.0s
162/162 [==============================] - 1s 5ms/step - loss: 0.0025 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0025 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0052
Epoch 20/20
 80/162 [=============>................] - ETA: 0s - loss: 0.0026 - mae: 0.0389 - mse: 0.0020
162/162 [==============================] - 1s 5ms/step - loss: 0.0025 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0025 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0026
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.04139973959215185_20_24_20epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
216/216 [==============================] - 1s 1ms/step - loss: 0.2198 - mae: 0.0663 - mse: 0.0080 - val_loss: 0.0786 - val_mae: 0.0513 - val_mse: 0.0036 - lr: 0.0414
Epoch 2/20
216/216 [==============================] - 0s 895us/step - loss: 0.0389 - mae: 0.0511 - mse: 0.0035 - val_loss: 0.0166 - val_mae: 0.0511 - val_mse: 0.0035 - lr: 0.0414
Epoch 3/20
216/216 [==============================] - 0s 928us/step - loss: 0.0099 - mae: 0.0509 - mse: 0.0035 - val_loss: 0.0062 - val_mae: 0.0508 - val_mse: 0.0035 - lr: 0.0414
Epoch 4/20
216/216 [==============================] - 0s 897us/step - loss: 0.0049 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0042 - val_mae: 0.0507 - val_mse: 0.0035 - lr: 0.0414
Epoch 5/20
216/216 [==============================] - 0s 915us/step - loss: 0.0039 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0038 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0414
Epoch 6/20
216/216 [==============================] - 0s 908us/step - loss: 0.0037 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0414
Epoch 7/20
163/216 [=====================>........] - ETA: 0s - loss: 0.0036 - mae: 0.0510 - mse: 0.0034
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.020699869841337204.
216/216 [==============================] - 0s 935us/step - loss: 0.0035 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0414
Epoch 8/20
216/216 [==============================] - 0s 935us/step - loss: 0.0035 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0207
Epoch 9/20
216/216 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0207
Epoch 10/20
167/216 [======================>.......] - ETA: 0s - loss: 0.0035 - mae: 0.0505 - mse: 0.0034
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.010349934920668602.
216/216 [==============================] - 0s 904us/step - loss: 0.0035 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0207
Epoch 11/20
216/216 [==============================] - 0s 929us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0103
Epoch 12/20
216/216 [==============================] - 0s 909us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0103
Epoch 13/20
155/216 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.005174967460334301.
216/216 [==============================] - 0s 987us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0103
Epoch 14/20
216/216 [==============================] - 0s 909us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0052
Epoch 15/20
216/216 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0052
Epoch 16/20
161/216 [=====================>........] - ETA: 0s - loss: 0.0034 - mae: 0.0508 - mse: 0.0034
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0025874837301671505.
216/216 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0052
Epoch 17/20
216/216 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0026
Epoch 18/20
216/216 [==============================] - 0s 961us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0026
Epoch 19/20
152/216 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0012937418650835752.
216/216 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0026
Epoch 20/20
216/216 [==============================] - 0s 997us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0013
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.04139973959215185_20_24_20epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
162/162 [==============================] - 0s 1ms/step - loss: 0.2366 - mae: 0.0567 - mse: 0.0053 - val_loss: 0.1100 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0414
Epoch 2/20
162/162 [==============================] - 0s 941us/step - loss: 0.0611 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0295 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0414
Epoch 3/20
162/162 [==============================] - 0s 986us/step - loss: 0.0170 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0090 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0414
Epoch 4/20
162/162 [==============================] - ETA: 0s - loss: 0.0058 - mae: 0.0379 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.020699869841337204.
162/162 [==============================] - 0s 976us/step - loss: 0.0058 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0038 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0414
Epoch 5/20
162/162 [==============================] - 0s 958us/step - loss: 0.0032 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0029 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0207
Epoch 6/20
161/162 [============================>.] - ETA: 0s - loss: 0.0026 - mae: 0.0379 - mse: 0.0019
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0023s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0016s). Check your callbacks.
162/162 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0207
Epoch 7/20
149/162 [==========================>...] - ETA: 0s - loss: 0.0023 - mae: 0.0379 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.010349934920668602.
162/162 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0207
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183724-qv1yc94u\files\model-best)... Done. 0.0s
162/162 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0207
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183724-qv1yc94u\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183724-qv1yc94u\files\model-best)... Done. 0.0s
162/162 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0207
162/162 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0207
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183724-qv1yc94u\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183724-qv1yc94u\files\model-best)... Done. 0.0s
 82/162 [==============>...............] - ETA: 0s - loss: 0.0020 - mae: 0.0380 - mse: 0.00190019 - val_loss: 0.0024 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0207
 82/162 [==============>...............] - ETA: 0s - loss: 0.0020 - mae: 0.0380 - mse: 0.00190019 - val_loss: 0.0024 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0207
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183724-qv1yc94u\files\model-best)... Done. 0.0s
162/162 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0052
162/162 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0052
162/162 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0052
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183724-qv1yc94u\files\model-best)... Done. 0.0s
162/162 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0052
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0012937418650835752. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0052
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0012937418650835752. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0052
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183724-qv1yc94u\files\model-best)... Done. 0.0s
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0012937418650835752. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0052
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183724-qv1yc94u\files\model-best)... Done. 0.0s
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0012937418650835752. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0052
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006468709325417876. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0052
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006468709325417876. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0052
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183724-qv1yc94u\files\model-best)... Done. 0.0s
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006468709325417876. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0052
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183724-qv1yc94u\files\model-best)... Done. 0.0s
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006468709325417876. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0052
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0007s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183724-qv1yc94u\files\model-best)... Done. 0.0s
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006468709325417876. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0052
Epoch 17/20educeLROnPlateau reducing learning rate to 0.0006468709325417876. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0052
Epoch 17/20educeLROnPlateau reducing learning rate to 0.0006468709325417876. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0052
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0018s). Check your callbacks.
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.04139973959215185_20_24_20epochs/model_6.h583 - val_mse: 0.0019 - lr: 0.0052
162/162 [==============================] - 0s 976us/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0026
Epoch 16/20
 80/162 [=============>................] - ETA: 0s - loss: 0.0020 - mae: 0.0384 - mse: 0.0020
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0012937418650835752.
162/162 [==============================] - 0s 942us/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0026
Epoch 17/20
162/162 [==============================] - 0s 975us/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 18/20
162/162 [==============================] - 0s 960us/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 19/20
 86/162 [==============>...............] - ETA: 0s - loss: 0.0020 - mae: 0.0382 - mse: 0.0019
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006468709325417876.
162/162 [==============================] - 0s 929us/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 20/20
162/162 [==============================] - 0s 956us/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.4687e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.04139973959215185_20_24_20epochs/model_6.h583 - val_mse: 0.0019 - lr: 0.0052
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
162/162 [==============================] - 0s 1ms/step - loss: 0.2175 - mae: 0.0597 - mse: 0.0066 - val_loss: 0.1008 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0414
Epoch 2/20
162/162 [==============================] - 0s 907us/step - loss: 0.0563 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0274 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0414
Epoch 3/20
162/162 [==============================] - 0s 941us/step - loss: 0.0160 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0086 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0414
Epoch 4/20
 86/162 [==============>...............] - ETA: 0s - loss: 0.0068 - mae: 0.0388 - mse: 0.0020
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.020699869841337204.
162/162 [==============================] - 0s 920us/step - loss: 0.0056 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0037 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0414
Epoch 5/20
162/162 [==============================] - 0s 969us/step - loss: 0.0032 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0029 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0207
Epoch 6/20
162/162 [==============================] - 0s 930us/step - loss: 0.0026 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0207
Epoch 7/20
 86/162 [==============>...............] - ETA: 0s - loss: 0.0023 - mae: 0.0381 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.010349934920668602.
162/162 [==============================] - 0s 965us/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0207
Epoch 8/20
162/162 [==============================] - 0s 982us/step - loss: 0.0021 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0103
Epoch 9/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0103
Epoch 10/20
 86/162 [==============>...............] - ETA: 0s - loss: 0.0021 - mae: 0.0380 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.005174967460334301.
162/162 [==============================] - 0s 935us/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0103
Epoch 11/20
162/162 [==============================] - 0s 914us/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0052
Epoch 12/20
162/162 [==============================] - 0s 964us/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0052
Epoch 13/20
 85/162 [==============>...............] - ETA: 0s - loss: 0.0020 - mae: 0.0385 - mse: 0.0020
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0025874837301671505.
162/162 [==============================] - 0s 924us/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0052
Epoch 14/20
162/162 [==============================] - 0s 965us/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0026
Epoch 15/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0026
Epoch 16/20
162/162 [==============================] - ETA: 0s - loss: 0.0020 - mae: 0.0379 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0012937418650835752.
162/162 [==============================] - 0s 957us/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0026
Epoch 17/20
162/162 [==============================] - 0s 946us/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 18/20
162/162 [==============================] - 0s 945us/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 19/20
 85/162 [==============>...............] - ETA: 0s - loss: 0.0020 - mae: 0.0377 - mse: 0.0019
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006468709325417876.
162/162 [==============================] - 0s 958us/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 20/20
162/162 [==============================] - 0s 934us/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.4687e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.04139973959215185_20_24_20epochs/model_7.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
162/162 [==============================] - 0s 1ms/step - loss: 0.2365 - mae: 0.0597 - mse: 0.0080 - val_loss: 0.1098 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0414
Epoch 2/20
162/162 [==============================] - 0s 945us/step - loss: 0.0618 - mae: 0.0388 - mse: 0.0021 - val_loss: 0.0308 - val_mae: 0.0393 - val_mse: 0.0021 - lr: 0.0414
Epoch 3/20
162/162 [==============================] - 0s 943us/step - loss: 0.0184 - mae: 0.0388 - mse: 0.0021 - val_loss: 0.0104 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0414
Epoch 4/20
 84/162 [==============>...............] - ETA: 0s - loss: 0.0083 - mae: 0.0385 - mse: 0.0020
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.020699869841337204.
162/162 [==============================] - 0s 937us/step - loss: 0.0070 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0049 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0414
Epoch 5/20
162/162 [==============================] - 0s 969us/step - loss: 0.0042 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0038 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0207
Epoch 6/20
162/162 [==============================] - 0s 960us/step - loss: 0.0035 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0033 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0207
Epoch 7/20
 85/162 [==============>...............] - ETA: 0s - loss: 0.0031 - mae: 0.0383 - mse: 0.0020
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.010349934920668602.
162/162 [==============================] - 0s 936us/step - loss: 0.0030 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0029 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0207
Epoch 8/20
162/162 [==============================] - 0s 964us/step - loss: 0.0028 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0028 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0103
Epoch 9/20
162/162 [==============================] - 0s 940us/step - loss: 0.0027 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0103
Epoch 10/20
 86/162 [==============>...............] - ETA: 0s - loss: 0.0026 - mae: 0.0380 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.005174967460334301.
162/162 [==============================] - 0s 929us/step - loss: 0.0026 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0103
Epoch 11/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0026 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0052
Epoch 12/20
162/162 [==============================] - 0s 913us/step - loss: 0.0025 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0026 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0052
Epoch 13/20
 84/162 [==============>...............] - ETA: 0s - loss: 0.0025 - mae: 0.0385 - mse: 0.0020
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0025874837301671505.
162/162 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0052
Epoch 14/20
162/162 [==============================] - 0s 954us/step - loss: 0.0025 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0026
Epoch 15/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0026
Epoch 16/20
159/162 [============================>.] - ETA: 0s - loss: 0.0024 - mae: 0.0380 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0012937418650835752.
162/162 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0026
Epoch 17/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0024 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0013
Epoch 18/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0024 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0013
Epoch 19/20
128/162 [======================>.......] - ETA: 0s - loss: 0.0025 - mae: 0.0385 - mse: 0.0020
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006468709325417876.
162/162 [==============================] - 0s 1ms/step - loss: 0.0024 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0013
Epoch 20/20
162/162 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 6.4687e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.04139973959215185_20_24_20epochs/model_8.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
162/162 [==============================] - 0s 2ms/step - loss: 0.2293 - mae: 0.0677 - mse: 0.0113 - val_loss: 0.1063 - val_mae: 0.0421 - val_mse: 0.0025 - lr: 0.0414
Epoch 2/20
162/162 [==============================] - 0s 964us/step - loss: 0.0608 - mae: 0.0419 - mse: 0.0025 - val_loss: 0.0313 - val_mae: 0.0417 - val_mse: 0.0025 - lr: 0.0414
Epoch 3/20
162/162 [==============================] - 0s 961us/step - loss: 0.0194 - mae: 0.0412 - mse: 0.0024 - val_loss: 0.0117 - val_mae: 0.0410 - val_mse: 0.0024 - lr: 0.0414
Epoch 4/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0084 - mae: 0.0404 - mse: 0.0023 - val_loss: 0.0062 - val_mae: 0.0405 - val_mse: 0.0023 - lr: 0.0414
Epoch 5/20
162/162 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0399 - mse: 0.0022 - val_loss: 0.0045 - val_mae: 0.0400 - val_mse: 0.0022 - lr: 0.0414
Epoch 6/20
162/162 [==============================] - 0s 955us/step - loss: 0.0041 - mae: 0.0394 - mse: 0.0021 - val_loss: 0.0038 - val_mae: 0.0399 - val_mse: 0.0022 - lr: 0.0414
Epoch 7/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0393 - mse: 0.0021 - val_loss: 0.0035 - val_mae: 0.0393 - val_mse: 0.0021 - lr: 0.0414
Epoch 8/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0033 - mae: 0.0390 - mse: 0.0021 - val_loss: 0.0032 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0414
Epoch 9/20
162/162 [==============================] - 0s 965us/step - loss: 0.0031 - mae: 0.0389 - mse: 0.0021 - val_loss: 0.0030 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0414
Epoch 10/20
162/162 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.0029 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0414
Epoch 11/20
105/162 [==================>...........] - ETA: 0s - loss: 0.0028 - mae: 0.0382 - mse: 0.0020
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.020699869841337204.
162/162 [==============================] - 0s 1ms/step - loss: 0.0028 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0028 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0414
Epoch 12/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0027 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0207
Epoch 13/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0027 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0207
Epoch 14/20
 83/162 [==============>...............] - ETA: 0s - loss: 0.0027 - mae: 0.0388 - mse: 0.0020
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.010349934920668602.
162/162 [==============================] - 0s 928us/step - loss: 0.0026 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0207
Epoch 15/20
162/162 [==============================] - 0s 993us/step - loss: 0.0026 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0103
Epoch 16/20
162/162 [==============================] - 0s 950us/step - loss: 0.0026 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0103
Epoch 17/20
 83/162 [==============>...............] - ETA: 0s - loss: 0.0026 - mae: 0.0387 - mse: 0.0020
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.005174967460334301.
162/162 [==============================] - 0s 939us/step - loss: 0.0026 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0103
Epoch 18/20
162/162 [==============================] - 0s 949us/step - loss: 0.0025 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0052
Epoch 19/20
162/162 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0052
Epoch 20/20
138/162 [========================>.....] - ETA: 0s - loss: 0.0025 - mae: 0.0381 - mse: 0.0020
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0025874837301671505.
162/162 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0052
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.04139973959215185_20_24_20epochs/model_9.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0008s). Check your callbacks.