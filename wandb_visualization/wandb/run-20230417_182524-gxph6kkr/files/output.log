Epoch 1/50
 97/122 [======================>.......] - ETA: 0s - loss: 0.0352 - mae: 0.0551 - mse: 0.0077
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0013s). Check your callbacks.
122/122 [==============================] - 2s 10ms/step - loss: 0.0287 - mae: 0.0517 - mse: 0.0066 - val_loss: 0.0027 - val_mae: 0.0403 - val_mse: 0.0023 - lr: 0.0588
Epoch 2/50
112/122 [==========================>...] - ETA: 0s - loss: 0.0025 - mae: 0.0378 - mse: 0.0020
122/122 [==============================] - 1s 11ms/step - loss: 0.0025 - mae: 0.0378 - mse: 0.0020 - val_loss: 0.0024 - val_mae: 0.0363 - val_mse: 0.0019 - lr: 0.0588
Epoch 3/50
110/122 [==========================>...] - ETA: 0s - loss: 0.0021 - mae: 0.0348 - mse: 0.0018
122/122 [==============================] - 1s 12ms/step - loss: 0.0021 - mae: 0.0347 - mse: 0.0017 - val_loss: 0.0017 - val_mae: 0.0313 - val_mse: 0.0014 - lr: 0.0588
Epoch 4/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0323 - mse: 0.0016 - val_loss: 0.0025 - val_mae: 0.0368 - val_mse: 0.0020 - lr: 0.0588
Epoch 5/50
110/122 [==========================>...] - ETA: 0s - loss: 0.0018 - mae: 0.0307 - mse: 0.0014
122/122 [==============================] - 2s 13ms/step - loss: 0.0018 - mae: 0.0306 - mse: 0.0014 - val_loss: 0.0014 - val_mae: 0.0267 - val_mse: 0.0011 - lr: 0.0588
Epoch 6/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0282 - mse: 0.0012 - val_loss: 0.0018 - val_mae: 0.0310 - val_mse: 0.0014 - lr: 0.0588
Epoch 7/50
 82/122 [===================>..........] - ETA: 0s - loss: 0.0017 - mae: 0.0303 - mse: 0.0014
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182524-gxph6kkr\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 12ms/step - loss: 0.0016 - mae: 0.0287 - mse: 0.0013 - val_loss: 0.0013 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0588
Epoch 8/50
108/122 [=========================>....] - ETA: 0s - loss: 0.0013 - mae: 0.0260 - mse: 0.0011
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.029402051120996475.
122/122 [==============================] - 0s 3ms/step - loss: 0.0013 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0015 - val_mae: 0.0280 - val_mse: 0.0012 - lr: 0.0588
Epoch 9/50
122/122 [==============================] - 1s 10ms/step - loss: 0.0013 - mae: 0.0252 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0246 - val_mse: 9.9331e-04 - lr: 0.0294
Epoch 10/50
 93/122 [=====================>........] - ETA: 0s - loss: 0.0013 - mae: 0.0254 - mse: 0.0011
122/122 [==============================] - 1s 11ms/step - loss: 0.0012 - mae: 0.0252 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0245 - val_mse: 9.7834e-04 - lr: 0.0294
Epoch 11/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0244 - mse: 9.7299e-04 - val_loss: 0.0015 - val_mae: 0.0291 - val_mse: 0.0013 - lr: 0.0294
Epoch 12/50
 87/122 [====================>.........] - ETA: 0s - loss: 0.0012 - mae: 0.0248 - mse: 0.0010
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.014701025560498238.
122/122 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0247 - mse: 9.9592e-04 - val_loss: 0.0012 - val_mae: 0.0264 - val_mse: 0.0011 - lr: 0.0294
Epoch 13/50
113/122 [==========================>...] - ETA: 0s - loss: 0.0011 - mae: 0.0237 - mse: 9.3098e-04
122/122 [==============================] - 1s 11ms/step - loss: 0.0011 - mae: 0.0238 - mse: 9.3014e-04 - val_loss: 0.0011 - val_mae: 0.0238 - val_mse: 9.2393e-04 - lr: 0.0147
Epoch 14/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0237 - mse: 9.3226e-04 - val_loss: 0.0011 - val_mae: 0.0243 - val_mse: 9.5457e-04 - lr: 0.0147
Epoch 15/50
 87/122 [====================>.........] - ETA: 0s - loss: 0.0011 - mae: 0.0238 - mse: 9.2615e-04
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.007350512780249119.
122/122 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0237 - mse: 9.2460e-04 - val_loss: 0.0011 - val_mae: 0.0246 - val_mse: 9.6471e-04 - lr: 0.0147
Epoch 16/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0233 - mse: 9.0090e-04 - val_loss: 0.0011 - val_mae: 0.0249 - val_mse: 9.7900e-04 - lr: 0.0074
Epoch 17/50
107/122 [=========================>....] - ETA: 0s - loss: 0.0010 - mae: 0.0229 - mse: 8.7569e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182524-gxph6kkr\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 12ms/step - loss: 0.0010 - mae: 0.0231 - mse: 8.9316e-04 - val_loss: 0.0010 - val_mae: 0.0235 - val_mse: 9.0386e-04 - lr: 0.0074
Epoch 18/50
122/122 [==============================] - 1s 11ms/step - loss: 0.0010 - mae: 0.0229 - mse: 8.7670e-04 - val_loss: 0.0010 - val_mae: 0.0233 - val_mse: 8.8940e-04 - lr: 0.0074
Epoch 19/50
122/122 [==============================] - 0s 2ms/step - loss: 9.9944e-04 - mae: 0.0226 - mse: 8.6349e-04 - val_loss: 0.0010 - val_mae: 0.0238 - val_mse: 9.1435e-04 - lr: 0.0074
Epoch 20/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0229 - mse: 8.7816e-04 - val_loss: 0.0011 - val_mae: 0.0246 - val_mse: 9.6360e-04 - lr: 0.0074
Epoch 21/50
108/122 [=========================>....] - ETA: 0s - loss: 0.0010 - mae: 0.0235 - mse: 9.1282e-04
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0036752563901245594.
122/122 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0233 - mse: 8.9979e-04 - val_loss: 0.0011 - val_mae: 0.0242 - val_mse: 9.4173e-04 - lr: 0.0074
Epoch 22/50
103/122 [========================>.....] - ETA: 0s - loss: 9.7975e-04 - mae: 0.0223 - mse: 8.4407e-04
122/122 [==============================] - 1s 11ms/step - loss: 9.8657e-04 - mae: 0.0224 - mse: 8.5131e-04 - val_loss: 0.0010 - val_mae: 0.0231 - val_mse: 8.7546e-04 - lr: 0.0037
Epoch 23/50
114/122 [===========================>..] - ETA: 0s - loss: 9.9163e-04 - mae: 0.0226 - mse: 8.5850e-04
122/122 [==============================] - 1s 12ms/step - loss: 9.8309e-04 - mae: 0.0225 - mse: 8.4988e-04 - val_loss: 0.0010 - val_mae: 0.0231 - val_mse: 8.7622e-04 - lr: 0.0037
Epoch 24/50
120/122 [============================>.] - ETA: 0s - loss: 9.8338e-04 - mae: 0.0225 - mse: 8.5232e-04
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0018376281950622797.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182524-gxph6kkr\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 12ms/step - loss: 9.8186e-04 - mae: 0.0225 - mse: 8.5088e-04 - val_loss: 9.9836e-04 - val_mae: 0.0231 - val_mse: 8.7090e-04 - lr: 0.0037
Epoch 25/50
 84/122 [===================>..........] - ETA: 0s - loss: 9.7491e-04 - mae: 0.0226 - mse: 8.4924e-04
122/122 [==============================] - 1s 11ms/step - loss: 9.7080e-04 - mae: 0.0224 - mse: 8.4275e-04 - val_loss: 9.9577e-04 - val_mae: 0.0230 - val_mse: 8.6473e-04 - lr: 0.0018
Epoch 26/50
122/122 [==============================] - 0s 2ms/step - loss: 9.6544e-04 - mae: 0.0223 - mse: 8.3654e-04 - val_loss: 0.0010 - val_mae: 0.0238 - val_mse: 9.1415e-04 - lr: 0.0018
Epoch 27/50
119/122 [============================>.] - ETA: 0s - loss: 9.7651e-04 - mae: 0.0225 - mse: 8.4577e-04
Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0009188140975311399.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182524-gxph6kkr\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 11ms/step - loss: 9.7175e-04 - mae: 0.0224 - mse: 8.4135e-04 - val_loss: 9.9296e-04 - val_mae: 0.0231 - val_mse: 8.7749e-04 - lr: 0.0018
Epoch 28/50
122/122 [==============================] - 0s 3ms/step - loss: 9.5885e-04 - mae: 0.0222 - mse: 8.3507e-04 - val_loss: 9.9306e-04 - val_mae: 0.0230 - val_mse: 8.6744e-04 - lr: 9.1881e-04
Epoch 29/50
111/122 [==========================>...] - ETA: 0s - loss: 9.4819e-04 - mae: 0.0221 - mse: 8.2338e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182524-gxph6kkr\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 12ms/step - loss: 9.5699e-04 - mae: 0.0222 - mse: 8.3216e-04 - val_loss: 9.8958e-04 - val_mae: 0.0230 - val_mse: 8.6389e-04 - lr: 9.1881e-04
Epoch 30/50
106/122 [=========================>....] - ETA: 0s - loss: 9.5819e-04 - mae: 0.0222 - mse: 8.3087e-04
Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0004594070487655699.
122/122 [==============================] - 0s 3ms/step - loss: 9.5878e-04 - mae: 0.0222 - mse: 8.3215e-04 - val_loss: 9.9015e-04 - val_mae: 0.0230 - val_mse: 8.6753e-04 - lr: 9.1881e-04
Epoch 31/50
122/122 [==============================] - 0s 2ms/step - loss: 9.5417e-04 - mae: 0.0221 - mse: 8.2953e-04 - val_loss: 9.8977e-04 - val_mae: 0.0230 - val_mse: 8.6304e-04 - lr: 4.5941e-04
Epoch 32/50
122/122 [==============================] - 0s 3ms/step - loss: 9.5265e-04 - mae: 0.0221 - mse: 8.2722e-04 - val_loss: 9.9096e-04 - val_mae: 0.0230 - val_mse: 8.6599e-04 - lr: 4.5941e-04
Epoch 33/50
115/122 [===========================>..] - ETA: 0s - loss: 9.5001e-04 - mae: 0.0221 - mse: 8.2670e-04
Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00022970352438278496.
122/122 [==============================] - 1s 12ms/step - loss: 9.5201e-04 - mae: 0.0221 - mse: 8.2869e-04 - val_loss: 9.8653e-04 - val_mae: 0.0230 - val_mse: 8.6267e-04 - lr: 4.5941e-04
Epoch 34/50
122/122 [==============================] - 0s 3ms/step - loss: 9.5119e-04 - mae: 0.0221 - mse: 8.2782e-04 - val_loss: 9.9038e-04 - val_mae: 0.0230 - val_mse: 8.6352e-04 - lr: 2.2970e-04
Epoch 35/50
102/122 [========================>.....] - ETA: 0s - loss: 9.6489e-04 - mae: 0.0223 - mse: 8.3952e-04
122/122 [==============================] - 1s 10ms/step - loss: 9.5092e-04 - mae: 0.0221 - mse: 8.2555e-04 - val_loss: 9.8629e-04 - val_mae: 0.0230 - val_mse: 8.6188e-04 - lr: 2.2970e-04
Epoch 36/50
116/122 [===========================>..] - ETA: 0s - loss: 9.4863e-04 - mae: 0.0221 - mse: 8.2442e-04
Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00011485176219139248.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182524-gxph6kkr\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 12ms/step - loss: 9.5121e-04 - mae: 0.0221 - mse: 8.2704e-04 - val_loss: 9.8558e-04 - val_mae: 0.0230 - val_mse: 8.6211e-04 - lr: 2.2970e-04
Epoch 37/50
122/122 [==============================] - 0s 3ms/step - loss: 9.5005e-04 - mae: 0.0221 - mse: 8.2538e-04 - val_loss: 9.8806e-04 - val_mae: 0.0230 - val_mse: 8.6278e-04 - lr: 1.1485e-04
Epoch 38/50
122/122 [==============================] - 0s 2ms/step - loss: 9.4944e-04 - mae: 0.0221 - mse: 8.2484e-04 - val_loss: 9.8577e-04 - val_mae: 0.0230 - val_mse: 8.6225e-04 - lr: 1.1485e-04
Epoch 39/50
117/122 [===========================>..] - ETA: 0s - loss: 9.4731e-04 - mae: 0.0221 - mse: 8.2405e-04
Epoch 39: ReduceLROnPlateau reducing learning rate to 5.742588109569624e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182524-gxph6kkr\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182524-gxph6kkr\files\model-best)... Done. 0.0s
122/122 [==============================] - 2s 13ms/step - loss: 9.4932e-04 - mae: 0.0221 - mse: 8.2607e-04 - val_loss: 9.8541e-04 - val_mae: 0.0230 - val_mse: 8.6244e-04 - lr: 1.1485e-04
Epoch 40/50
122/122 [==============================] - 1s 11ms/step - loss: 9.4909e-04 - mae: 0.0221 - mse: 8.2511e-04 - val_loss: 9.8501e-04 - val_mae: 0.0230 - val_mse: 8.6232e-04 - lr: 5.7426e-05
Epoch 41/50
122/122 [==============================] - 0s 2ms/step - loss: 9.4852e-04 - mae: 0.0221 - mse: 8.2538e-04 - val_loss: 9.8650e-04 - val_mae: 0.0230 - val_mse: 8.6241e-04 - lr: 5.7426e-05
Epoch 42/50
102/122 [========================>.....] - ETA: 0s - loss: 9.3689e-04 - mae: 0.0219 - mse: 8.1348e-04
Epoch 42: ReduceLROnPlateau reducing learning rate to 2.871294054784812e-05.
122/122 [==============================] - 0s 3ms/step - loss: 9.4836e-04 - mae: 0.0221 - mse: 8.2496e-04 - val_loss: 9.8585e-04 - val_mae: 0.0230 - val_mse: 8.6237e-04 - lr: 5.7426e-05
Epoch 43/50
122/122 [==============================] - 0s 3ms/step - loss: 9.4813e-04 - mae: 0.0221 - mse: 8.2463e-04 - val_loss: 9.8636e-04 - val_mae: 0.0230 - val_mse: 8.6234e-04 - lr: 2.8713e-05
Epoch 44/50
122/122 [==============================] - 0s 3ms/step - loss: 9.4817e-04 - mae: 0.0221 - mse: 8.2462e-04 - val_loss: 9.8585e-04 - val_mae: 0.0230 - val_mse: 8.6235e-04 - lr: 2.8713e-05
Epoch 45/50
117/122 [===========================>..] - ETA: 0s - loss: 9.4886e-04 - mae: 0.0221 - mse: 8.2510e-04
Epoch 45: ReduceLROnPlateau reducing learning rate to 1.435647027392406e-05.
122/122 [==============================] - 0s 3ms/step - loss: 9.4811e-04 - mae: 0.0221 - mse: 8.2438e-04 - val_loss: 9.8523e-04 - val_mae: 0.0230 - val_mse: 8.6205e-04 - lr: 2.8713e-05
Epoch 46/50
122/122 [==============================] - 0s 3ms/step - loss: 9.4784e-04 - mae: 0.0221 - mse: 8.2427e-04 - val_loss: 9.8553e-04 - val_mae: 0.0230 - val_mse: 8.6201e-04 - lr: 1.4356e-05
Epoch 47/50
122/122 [==============================] - 0s 3ms/step - loss: 9.4784e-04 - mae: 0.0221 - mse: 8.2450e-04 - val_loss: 9.8548e-04 - val_mae: 0.0230 - val_mse: 8.6205e-04 - lr: 1.4356e-05
Epoch 48/50
106/122 [=========================>....] - ETA: 0s - loss: 9.4603e-04 - mae: 0.0220 - mse: 8.2276e-04
Epoch 48: ReduceLROnPlateau reducing learning rate to 1e-05.
122/122 [==============================] - 0s 3ms/step - loss: 9.4784e-04 - mae: 0.0221 - mse: 8.2456e-04 - val_loss: 9.8562e-04 - val_mae: 0.0230 - val_mse: 8.6217e-04 - lr: 1.4356e-05
Epoch 49/50
122/122 [==============================] - 0s 3ms/step - loss: 9.4780e-04 - mae: 0.0221 - mse: 8.2421e-04 - val_loss: 9.8547e-04 - val_mae: 0.0230 - val_mse: 8.6204e-04 - lr: 1.0000e-05
Epoch 50/50
122/122 [==============================] - 0s 2ms/step - loss: 9.4777e-04 - mae: 0.0221 - mse: 8.2448e-04 - val_loss: 9.8551e-04 - val_mae: 0.0230 - val_mse: 8.6204e-04 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_adam_0.05880410116511006_20_32_50epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/50
162/162 [==============================] - 1s 3ms/step - loss: 0.0180 - mae: 0.0559 - mse: 0.0049 - val_loss: 0.0040 - val_mae: 0.0531 - val_mse: 0.0039 - lr: 0.0588
Epoch 2/50
162/162 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0509 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0588
Epoch 3/50
162/162 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0502 - val_mse: 0.0034 - lr: 0.0588
Epoch 4/50
162/162 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0501 - val_mse: 0.0034 - lr: 0.0588
Epoch 5/50
162/162 [==============================] - ETA: 0s - loss: 0.0035 - mae: 0.0505 - mse: 0.0034
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.029402051120996475.
162/162 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0505 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0508 - val_mse: 0.0035 - lr: 0.0588
Epoch 6/50
162/162 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0499 - val_mse: 0.0034 - lr: 0.0294
Epoch 7/50
162/162 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0497 - mse: 0.0033 - val_loss: 0.0033 - val_mae: 0.0484 - val_mse: 0.0032 - lr: 0.0294
Epoch 8/50
162/162 [==============================] - 0s 3ms/step - loss: 0.0032 - mae: 0.0466 - mse: 0.0030 - val_loss: 0.0029 - val_mae: 0.0409 - val_mse: 0.0025 - lr: 0.0294
Epoch 9/50
162/162 [==============================] - 0s 3ms/step - loss: 0.0029 - mae: 0.0404 - mse: 0.0025 - val_loss: 0.0025 - val_mae: 0.0354 - val_mse: 0.0020 - lr: 0.0294
Epoch 10/50
162/162 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0367 - mse: 0.0021 - val_loss: 0.0030 - val_mae: 0.0427 - val_mse: 0.0028 - lr: 0.0294
Epoch 11/50
162/162 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0347 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0322 - val_mse: 0.0017 - lr: 0.0294
Epoch 12/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0335 - mse: 0.0018 - val_loss: 0.0019 - val_mae: 0.0319 - val_mse: 0.0017 - lr: 0.0294
Epoch 13/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0328 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0326 - val_mse: 0.0017 - lr: 0.0294
Epoch 14/50
147/162 [==========================>...] - ETA: 0s - loss: 0.0022 - mae: 0.0344 - mse: 0.0019
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.014701025560498238.
162/162 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0343 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0316 - val_mse: 0.0016 - lr: 0.0294
Epoch 15/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0307 - mse: 0.0016 - val_loss: 0.0018 - val_mae: 0.0292 - val_mse: 0.0015 - lr: 0.0147
Epoch 16/50
162/162 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0307 - mse: 0.0016 - val_loss: 0.0017 - val_mae: 0.0294 - val_mse: 0.0015 - lr: 0.0147
Epoch 17/50
162/162 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0304 - mse: 0.0015 - val_loss: 0.0021 - val_mae: 0.0336 - val_mse: 0.0018 - lr: 0.0147
Epoch 18/50
151/162 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0317 - mse: 0.0016
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.007350512780249119.
162/162 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0314 - mse: 0.0016 - val_loss: 0.0018 - val_mae: 0.0316 - val_mse: 0.0016 - lr: 0.0147
Epoch 19/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0297 - mse: 0.0015 - val_loss: 0.0016 - val_mae: 0.0287 - val_mse: 0.0014 - lr: 0.0074
Epoch 20/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0293 - mse: 0.0014 - val_loss: 0.0016 - val_mae: 0.0284 - val_mse: 0.0014 - lr: 0.0074
Epoch 21/50
143/162 [=========================>....] - ETA: 0s - loss: 0.0016 - mae: 0.0291 - mse: 0.0014
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0036752563901245594.
162/162 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0292 - mse: 0.0014 - val_loss: 0.0017 - val_mae: 0.0291 - val_mse: 0.0014 - lr: 0.0074
Epoch 22/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0288 - mse: 0.0014 - val_loss: 0.0016 - val_mae: 0.0290 - val_mse: 0.0014 - lr: 0.0037
Epoch 23/50
162/162 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0287 - mse: 0.0014 - val_loss: 0.0016 - val_mae: 0.0288 - val_mse: 0.0014 - lr: 0.0037
Epoch 24/50
158/162 [============================>.] - ETA: 0s - loss: 0.0016 - mae: 0.0287 - mse: 0.0014
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0018376281950622797.
162/162 [==============================] - 0s 3ms/step - loss: 0.0016 - mae: 0.0287 - mse: 0.0014 - val_loss: 0.0016 - val_mae: 0.0281 - val_mse: 0.0014 - lr: 0.0037
Epoch 25/50
162/162 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0285 - mse: 0.0014 - val_loss: 0.0016 - val_mae: 0.0279 - val_mse: 0.0014 - lr: 0.0018
Epoch 26/50
162/162 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0283 - mse: 0.0014 - val_loss: 0.0016 - val_mae: 0.0284 - val_mse: 0.0014 - lr: 0.0018
Epoch 27/50
162/162 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0284 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0278 - val_mse: 0.0014 - lr: 0.0018
Epoch 28/50
162/162 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0282 - mse: 0.0014 - val_loss: 0.0016 - val_mae: 0.0284 - val_mse: 0.0014 - lr: 0.0018
Epoch 29/50
162/162 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0284 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0281 - val_mse: 0.0014 - lr: 0.0018
Epoch 30/50
145/162 [=========================>....] - ETA: 0s - loss: 0.0015 - mae: 0.0280 - mse: 0.0013
Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0009188140975311399.
162/162 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0283 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0278 - val_mse: 0.0013 - lr: 0.0018
Epoch 31/50
162/162 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0281 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0280 - val_mse: 0.0014 - lr: 9.1881e-04
Epoch 32/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0280 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0278 - val_mse: 0.0013 - lr: 9.1881e-04
Epoch 33/50
157/162 [============================>.] - ETA: 0s - loss: 0.0015 - mae: 0.0279 - mse: 0.0013
Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0004594070487655699.
162/162 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0279 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0277 - val_mse: 0.0013 - lr: 9.1881e-04
Epoch 34/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0279 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0276 - val_mse: 0.0013 - lr: 4.5941e-04
Epoch 35/50
162/162 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0279 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0276 - val_mse: 0.0013 - lr: 4.5941e-04
Epoch 36/50
140/162 [========================>.....] - ETA: 0s - loss: 0.0015 - mae: 0.0277 - mse: 0.0013
Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00022970352438278496.
162/162 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0279 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0276 - val_mse: 0.0013 - lr: 4.5941e-04
Epoch 37/50
162/162 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0278 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0276 - val_mse: 0.0013 - lr: 2.2970e-04
Epoch 38/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0278 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0275 - val_mse: 0.0013 - lr: 2.2970e-04
Epoch 39/50
156/162 [===========================>..] - ETA: 0s - loss: 0.0015 - mae: 0.0278 - mse: 0.0013
Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00011485176219139248.
162/162 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0278 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0275 - val_mse: 0.0013 - lr: 2.2970e-04
Epoch 40/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0278 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0277 - val_mse: 0.0013 - lr: 1.1485e-04
Epoch 41/50
162/162 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0278 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0276 - val_mse: 0.0013 - lr: 1.1485e-04
Epoch 42/50
114/162 [====================>.........] - ETA: 0s - loss: 0.0015 - mae: 0.0275 - mse: 0.0013
Epoch 42: ReduceLROnPlateau reducing learning rate to 5.742588109569624e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0278 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0275 - val_mse: 0.0013 - lr: 1.1485e-04
Epoch 43/50
162/162 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0277 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0276 - val_mse: 0.0013 - lr: 5.7426e-05
Epoch 44/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0278 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0275 - val_mse: 0.0013 - lr: 5.7426e-05
Epoch 45/50
133/162 [=======================>......] - ETA: 0s - loss: 0.0015 - mae: 0.0278 - mse: 0.0013
Epoch 45: ReduceLROnPlateau reducing learning rate to 2.871294054784812e-05.
162/162 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0277 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0275 - val_mse: 0.0013 - lr: 5.7426e-05
Epoch 46/50
162/162 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0277 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0275 - val_mse: 0.0013 - lr: 2.8713e-05
Epoch 47/50
162/162 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0277 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0275 - val_mse: 0.0013 - lr: 2.8713e-05
Epoch 48/50
162/162 [==============================] - ETA: 0s - loss: 0.0015 - mae: 0.0277 - mse: 0.0013
Epoch 48: ReduceLROnPlateau reducing learning rate to 1.435647027392406e-05.
162/162 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0277 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0275 - val_mse: 0.0013 - lr: 2.8713e-05
Epoch 49/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0277 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0275 - val_mse: 0.0013 - lr: 1.4356e-05
Epoch 50/50
162/162 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0277 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0275 - val_mse: 0.0013 - lr: 1.4356e-05
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_adam_0.05880410116511006_20_32_50epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/50
122/122 [==============================] - 1s 4ms/step - loss: 0.0181 - mae: 0.0406 - mse: 0.0024 - val_loss: 0.0022 - val_mae: 0.0393 - val_mse: 0.0021 - lr: 0.0588
Epoch 2/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0588
Epoch 3/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0588
Epoch 4/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0588
Epoch 5/50
112/122 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0380 - mse: 0.0019
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.029402051120996475.
122/122 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0588
Epoch 6/50
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0294
Epoch 7/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0294
Epoch 8/50
110/122 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.014701025560498238.
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0294
Epoch 9/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0147
Epoch 10/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0147
Epoch 11/50
104/122 [========================>.....] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.007350512780249119.
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0147
Epoch 12/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0074
Epoch 13/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0074
Epoch 14/50
 98/122 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0036752563901245594.
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0074
Epoch 15/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0037
Epoch 16/50
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0037
Epoch 17/50
 64/122 [==============>...............] - ETA: 0s - loss: 0.0020 - mae: 0.0384 - mse: 0.0020
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0018376281950622797.
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0037
Epoch 18/50
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0018
Epoch 19/50
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0018
Epoch 20/50
 72/122 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0009188140975311399.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0018
Epoch 21/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.1881e-04
Epoch 22/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.1881e-04
Epoch 23/50
 71/122 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0374 - mse: 0.0019
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0004594070487655699.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.1881e-04
Epoch 24/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.5941e-04
Epoch 25/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.5941e-04
Epoch 26/50
 98/122 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00022970352438278496.
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.5941e-04
Epoch 27/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.2970e-04
Epoch 28/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2970e-04
Epoch 29/50
109/122 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00011485176219139248.
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.2970e-04
Epoch 30/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.1485e-04
Epoch 31/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.1485e-04
Epoch 32/50
116/122 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 32: ReduceLROnPlateau reducing learning rate to 5.742588109569624e-05.
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.1485e-04
Epoch 33/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 5.7426e-05
Epoch 34/50
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 5.7426e-05
Epoch 35/50
 92/122 [=====================>........] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 35: ReduceLROnPlateau reducing learning rate to 2.871294054784812e-05.
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 5.7426e-05
Epoch 36/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.8713e-05
Epoch 37/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.8713e-05
Epoch 38/50
101/122 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.0019
Epoch 38: ReduceLROnPlateau reducing learning rate to 1.435647027392406e-05.
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.8713e-05
Epoch 39/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.4356e-05
Epoch 40/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.4356e-05
Epoch 41/50
112/122 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 41: ReduceLROnPlateau reducing learning rate to 1e-05.
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.4356e-05
Epoch 42/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 43/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0018s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0012s vs `on_train_batch_end` time: 0.0034s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_train_batch_end` time: 0.0031s). Check your callbacks.
Epoch 48/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 49/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 50/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_adam_0.05880410116511006_20_32_50epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/50
122/122 [==============================] - 1s 4ms/step - loss: 0.0199 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0588
Epoch 2/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0402 - val_mse: 0.0023 - lr: 0.0588
Epoch 3/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0588
Epoch 4/50
108/122 [=========================>....] - ETA: 0s - loss: 0.0020 - mae: 0.0382 - mse: 0.0020
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.029402051120996475.
122/122 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0588
Epoch 5/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0294
Epoch 6/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0294
Epoch 7/50
108/122 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.014701025560498238.
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0294
Epoch 8/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0147
Epoch 9/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0147
Epoch 10/50
115/122 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.007350512780249119.
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0147
Epoch 11/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0074
Epoch 12/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0074
Epoch 13/50
120/122 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0036752563901245594.
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0074
Epoch 14/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0037
Epoch 15/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0037
Epoch 16/50
 97/122 [======================>.......] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0018376281950622797.
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0037
Epoch 17/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0018
Epoch 18/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0018
Epoch 19/50
119/122 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0009188140975311399.
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0018
Epoch 20/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.1881e-04
Epoch 21/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.1881e-04
Epoch 22/50
 61/122 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0374 - mse: 0.0019
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0004594070487655699.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 9.1881e-04
Epoch 23/50
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.5941e-04
Epoch 24/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.5941e-04
Epoch 25/50
 87/122 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00022970352438278496.
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.5941e-04
Epoch 26/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2970e-04
Epoch 27/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2970e-04
Epoch 28/50
120/122 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00011485176219139248.
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2970e-04
Epoch 29/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.1485e-04
Epoch 30/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.1485e-04
Epoch 31/50
 68/122 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 31: ReduceLROnPlateau reducing learning rate to 5.742588109569624e-05.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.1485e-04
Epoch 32/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 5.7426e-05
Epoch 33/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 5.7426e-05
Epoch 34/50
114/122 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 34: ReduceLROnPlateau reducing learning rate to 2.871294054784812e-05.
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 5.7426e-05
Epoch 35/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.8713e-05
Epoch 36/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.8713e-05
Epoch 37/50
113/122 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 37: ReduceLROnPlateau reducing learning rate to 1.435647027392406e-05.
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.8713e-05
Epoch 38/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.4356e-05
Epoch 39/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.4356e-05
Epoch 40/50
 98/122 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 40: ReduceLROnPlateau reducing learning rate to 1e-05.
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.4356e-05
Epoch 41/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 42/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 43/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 44/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 45/50
 75/122 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.0019
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0025s). Check your callbacks.
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0024s). Check your callbacks.
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0024s). Check your callbacks.
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05