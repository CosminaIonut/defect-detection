Epoch 1/50
31/31 [==============================] - ETA: 0s - loss: 0.0098 - mae: 0.0825 - mse: 0.0098 - root_mean_squared_error: 0.0992
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0033s vs `on_train_batch_end` time: 0.0046s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0033s vs `on_train_batch_end` time: 0.0046s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - 2s 47ms/step - loss: 0.0098 - mae: 0.0825 - mse: 0.0098 - root_mean_squared_error: 0.0992 - val_loss: 0.0065 - val_mae: 0.0660 - val_mse: 0.0065 - val_root_mean_squared_error: 0.0807 - lr: 0.0501
Epoch 2/50
23/31 [=====================>........] - ETA: 0s - loss: 0.0055 - mae: 0.0608 - mse: 0.0055 - root_mean_squared_error: 0.0743
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_224454-pzwnzt9v\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - 1s 38ms/step - loss: 0.0053 - mae: 0.0596 - mse: 0.0053 - root_mean_squared_error: 0.0726 - val_loss: 0.0044 - val_mae: 0.0553 - val_mse: 0.0044 - val_root_mean_squared_error: 0.0660 - lr: 0.0501
Epoch 3/50
31/31 [==============================] - 1s 42ms/step - loss: 0.0040 - mae: 0.0534 - mse: 0.0040 - root_mean_squared_error: 0.0633 - val_loss: 0.0037 - val_mae: 0.0521 - val_mse: 0.0037 - val_root_mean_squared_error: 0.0610 - lr: 0.0501
Epoch 4/50
21/31 [===================>..........] - ETA: 0s - loss: 0.0036 - mae: 0.0514 - mse: 0.0036 - root_mean_squared_error: 0.0601
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_224454-pzwnzt9v\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - 1s 39ms/step - loss: 0.0036 - mae: 0.0514 - mse: 0.0036 - root_mean_squared_error: 0.0600 - val_loss: 0.0035 - val_mae: 0.0510 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0592 - lr: 0.0501
Epoch 5/50
21/31 [===================>..........] - ETA: 0s - loss: 0.0035 - mae: 0.0509 - mse: 0.0035 - root_mean_squared_error: 0.0591
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.025062937289476395.
31/31 [==============================] - 1s 46ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0035 - root_mean_squared_error: 0.0589 - val_loss: 0.0034 - val_mae: 0.0507 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0585 - lr: 0.0501
Epoch 6/50
22/31 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0502 - mse: 0.0034 - root_mean_squared_error: 0.0582
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.012531468644738197.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_224454-pzwnzt9v\files\model-best)... Done. 0.0s
31/31 [==============================] - 1s 39ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0251
Epoch 7/50
21/31 [===================>..........] - ETA: 0s - loss: 0.0034 - mae: 0.0500 - mse: 0.0034 - root_mean_squared_error: 0.0579
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.006265734322369099.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_224454-pzwnzt9v\files\model-best)... Done. 0.0s
31/31 [==============================] - 1s 47ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0125
Epoch 8/50
22/31 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0031328671611845493.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_224454-pzwnzt9v\files\model-best)... Done. 0.0s
31/31 [==============================] - 1s 39ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0063
Epoch 9/50
31/31 [==============================] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - 1s 41ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0031
Epoch 10/50
21/31 [===================>..........] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0015664335805922747.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_224454-pzwnzt9v\files\model-best)... Done. 0.0s
31/31 [==============================] - 1s 39ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0031
Epoch 11/50
22/31 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - root_mean_squared_error: 0.0584
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0007832167902961373.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_224454-pzwnzt9v\files\model-best)... Done. 0.0s
31/31 [==============================] - 1s 45ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0016
Epoch 12/50
22/31 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0582
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00039160839514806867.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_224454-pzwnzt9v\files\model-best)... Done. 0.0s
31/31 [==============================] - 1s 48ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 7.8322e-04
Epoch 13/50
29/31 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00019580419757403433.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_224454-pzwnzt9v\files\model-best)... Done. 0.0s
31/31 [==============================] - 1s 38ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 3.9161e-04
Epoch 14/50
30/31 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583
Epoch 14: ReduceLROnPlateau reducing learning rate to 9.790209878701717e-05.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_224454-pzwnzt9v\files\model-best)... Done. 0.0s
31/31 [==============================] - 1s 40ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.9580e-04
Epoch 15/50
29/31 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0582
Epoch 15: ReduceLROnPlateau reducing learning rate to 4.895104939350858e-05.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_224454-pzwnzt9v\files\model-best)... Done. 0.0s
31/31 [==============================] - 1s 40ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 9.7902e-05
Epoch 16/50
22/31 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583
Epoch 16: ReduceLROnPlateau reducing learning rate to 2.447552469675429e-05.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_224454-pzwnzt9v\files\model-best)... Done. 0.0s
31/31 [==============================] - 1s 37ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 4.8951e-05
Epoch 17/50
31/31 [==============================] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583
Epoch 17: ReduceLROnPlateau reducing learning rate to 1.2237762348377146e-05.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_224454-pzwnzt9v\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_224454-pzwnzt9v\files\model-best)... Done. 0.0s
31/31 [==============================] - 1s 47ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.4476e-05
Epoch 18/50
31/31 [==============================] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583
Epoch 18: ReduceLROnPlateau reducing learning rate to 1e-05.
31/31 [==============================] - 1s 38ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.2238e-05
Epoch 19/50
21/31 [===================>..........] - ETA: 0s - loss: 0.0034 - mae: 0.0502 - mse: 0.0034 - root_mean_squared_error: 0.0581
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - 1s 47ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 20/50
30/31 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - 1s 38ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 21/50
21/31 [===================>..........] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - 1s 48ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 22/50
22/31 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_224454-pzwnzt9v\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - 1s 39ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 23/50
31/31 [==============================] - 1s 39ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 24/50
31/31 [==============================] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_224454-pzwnzt9v\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - 1s 46ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 25/50
31/31 [==============================] - 1s 40ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 26/50
30/31 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - 1s 46ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 27/50
22/31 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_224454-pzwnzt9v\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - 1s 38ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 28/50
31/31 [==============================] - 1s 43ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 29/50
28/31 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_224454-pzwnzt9v\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - 1s 39ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 30/50
31/31 [==============================] - 1s 43ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 31/50
28/31 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - 1s 41ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 32/50
22/31 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - 1s 40ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 33/50
31/31 [==============================] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - 1s 43ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 34/50
22/31 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0584
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - 1s 40ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 35/50
31/31 [==============================] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - 1s 43ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 36/50
27/31 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0502 - mse: 0.0034 - root_mean_squared_error: 0.0581
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - 1s 39ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 37/50
31/31 [==============================] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - 1s 43ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 38/50
29/31 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 39/50
31/31 [==============================] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
29/31 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0584.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 40/50
29/31 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0584.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
22/31 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0582.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 41/50
22/31 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0582.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
22/31 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0508 - mse: 0.0034 - root_mean_squared_error: 0.0585.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 42/50
22/31 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0508 - mse: 0.0034 - root_mean_squared_error: 0.0585.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
28/31 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 43/50
28/31 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 44/50
31/31 [==============================] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_224454-pzwnzt9v\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
29/31 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0503 - mse: 0.0034 - root_mean_squared_error: 0.0581.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 45/50
22/31 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 46/50
22/31 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
29/31 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 47/50
29/31 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
22/31 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0503 - mse: 0.0034 - root_mean_squared_error: 0.0582.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 48/50
22/31 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0503 - mse: 0.0034 - root_mean_squared_error: 0.0582.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_224454-pzwnzt9v\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
31/31 [==============================] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 49/50
22/31 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 50/50
22/31 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])- val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_sgd_0.05012587571678091LR_[100]CHN_50CNNI_168BS_40DU_1P_val_mseM_50epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])- val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
Epoch 1/50
46/46 [==============================] - 1s 13ms/step - loss: 0.0185 - mae: 0.1123 - mse: 0.0185 - root_mean_squared_error: 0.1362 - val_loss: 0.0107 - val_mae: 0.0859 - val_mse: 0.0107 - val_root_mean_squared_error: 0.1037 - lr: 0.0501
Epoch 2/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0090 - mae: 0.0799 - mse: 0.0090 - root_mean_squared_error: 0.0947 - val_loss: 0.0080 - val_mae: 0.0772 - val_mse: 0.0080 - val_root_mean_squared_error: 0.0895 - lr: 0.0501
Epoch 3/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0758 - mse: 0.0078 - root_mean_squared_error: 0.0881 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0876 - lr: 0.0501
Epoch 4/50
46/46 [==============================] - ETA: 0s - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.025062937289476395.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 0.0501
Epoch 5/50
43/46 [===========================>..] - ETA: 0s - loss: 0.0075 - mae: 0.0750 - mse: 0.0075 - root_mean_squared_error: 0.0869
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.012531468644738197.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 0.0251
Epoch 6/50
45/46 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0751 - mse: 0.0076 - root_mean_squared_error: 0.0870
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.006265734322369099.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 0.0125
Epoch 7/50
42/46 [==========================>...] - ETA: 0s - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0871
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0031328671611845493.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 0.0063
Epoch 8/50
44/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0871
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0015664335805922747.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 0.0031
Epoch 9/50
44/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0751 - mse: 0.0076 - root_mean_squared_error: 0.0869
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0007832167902961373.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 0.0016
Epoch 10/50
44/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00039160839514806867.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 7.8322e-04
Epoch 11/50
42/46 [==========================>...] - ETA: 0s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00019580419757403433.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 3.9161e-04
Epoch 12/50
44/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870
Epoch 12: ReduceLROnPlateau reducing learning rate to 9.790209878701717e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.9580e-04
Epoch 13/50
45/46 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870
Epoch 13: ReduceLROnPlateau reducing learning rate to 4.895104939350858e-05.
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 9.7902e-05
Epoch 14/50
44/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0751 - mse: 0.0076 - root_mean_squared_error: 0.0869
Epoch 14: ReduceLROnPlateau reducing learning rate to 2.447552469675429e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 4.8951e-05
Epoch 15/50
46/46 [==============================] - ETA: 0s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870
Epoch 15: ReduceLROnPlateau reducing learning rate to 1.2237762348377146e-05.
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 2.4476e-05
Epoch 16/50
36/46 [======================>.......] - ETA: 0s - loss: 0.0076 - mae: 0.0751 - mse: 0.0076 - root_mean_squared_error: 0.0869
Epoch 16: ReduceLROnPlateau reducing learning rate to 1e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.2238e-05
Epoch 17/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 18/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 19/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 20/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 21/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 22/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 23/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 24/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 25/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 26/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 27/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 28/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 29/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 30/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 31/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 32/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 33/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 34/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 35/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 36/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0033s vs `on_train_batch_end` time: 0.0041s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0033s vs `on_train_batch_end` time: 0.0041s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_end` time: 0.0034s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_end` time: 0.0034s). Check your callbacks.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 44/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 45/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 46/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 47/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 48/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 49/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
Epoch 50/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 1.0000e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_sgd_0.05012587571678091LR_[100]CHN_50CNNI_168BS_40DU_1P_val_mseM_50epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
Epoch 1/50
46/46 [==============================] - 1s 9ms/step - loss: 0.0395 - mae: 0.1724 - mse: 0.0395 - root_mean_squared_error: 0.1987 - val_loss: 0.0181 - val_mae: 0.1104 - val_mse: 0.0181 - val_root_mean_squared_error: 0.1344 - lr: 0.0501
Epoch 2/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0117 - mae: 0.0891 - mse: 0.0117 - root_mean_squared_error: 0.1083 - val_loss: 0.0087 - val_mae: 0.0792 - val_mse: 0.0087 - val_root_mean_squared_error: 0.0934 - lr: 0.0501
Epoch 3/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0080 - mae: 0.0770 - mse: 0.0080 - root_mean_squared_error: 0.0896 - val_loss: 0.0077 - val_mae: 0.0758 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0878 - lr: 0.0501
Epoch 4/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0077 - mae: 0.0757 - mse: 0.0077 - root_mean_squared_error: 0.0875 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
Epoch 5/50
44/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.025062937289476395.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0501
Epoch 6/50
44/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.012531468644738197.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0251
Epoch 7/50
46/46 [==============================] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.006265734322369099.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0125
Epoch 8/50
39/46 [========================>.....] - ETA: 0s - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0873
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0031328671611845493.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0063
Epoch 9/50
42/46 [==========================>...] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0015664335805922747.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0031
Epoch 10/50
45/46 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0873
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0007832167902961373.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0016
Epoch 11/50
46/46 [==============================] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00039160839514806867.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 7.8322e-04
Epoch 12/50
45/46 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00019580419757403433.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 3.9161e-04
Epoch 13/50
44/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0874
Epoch 13: ReduceLROnPlateau reducing learning rate to 9.790209878701717e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.9580e-04
Epoch 14/50
45/46 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 14: ReduceLROnPlateau reducing learning rate to 4.895104939350858e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 9.7902e-05
Epoch 15/50
45/46 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871
Epoch 15: ReduceLROnPlateau reducing learning rate to 2.447552469675429e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 4.8951e-05
Epoch 16/50
44/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 16: ReduceLROnPlateau reducing learning rate to 1.2237762348377146e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 2.4476e-05
Epoch 17/50
40/46 [=========================>....] - ETA: 0s - loss: 0.0076 - mae: 0.0758 - mse: 0.0076 - root_mean_squared_error: 0.0874
Epoch 17: ReduceLROnPlateau reducing learning rate to 1e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.2238e-05
Epoch 18/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 19/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 20/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 21/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 22/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 23/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 24/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 25/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 26/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 27/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 28/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 29/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 30/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 31/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 32/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 33/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 34/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 35/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 36/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 37/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 38/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 39/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 40/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 41/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 42/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 43/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 44/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 45/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 46/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 47/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 48/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 49/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 50/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_sgd_0.05012587571678091LR_[100]CHN_50CNNI_168BS_40DU_1P_val_mseM_50epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
Epoch 1/50
46/46 [==============================] - 1s 10ms/step - loss: 0.0541 - mae: 0.1956 - mse: 0.0541 - root_mean_squared_error: 0.2327 - val_loss: 0.0117 - val_mae: 0.0890 - val_mse: 0.0117 - val_root_mean_squared_error: 0.1083 - lr: 0.0501
Epoch 2/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0085 - mae: 0.0785 - mse: 0.0085 - root_mean_squared_error: 0.0922 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0873 - lr: 0.0501
Epoch 3/50
41/46 [=========================>....] - ETA: 0s - loss: 0.0076 - mae: 0.0758 - mse: 0.0076 - root_mean_squared_error: 0.0874
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.025062937289476395.
46/46 [==============================] - 0s 8ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 0.0501
Epoch 4/50
41/46 [=========================>....] - ETA: 0s - loss: 0.0076 - mae: 0.0758 - mse: 0.0076 - root_mean_squared_error: 0.0874
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.012531468644738197.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0075 - val_mae: 0.0751 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0869 - lr: 0.0251
Epoch 5/50
42/46 [==========================>...] - ETA: 0s - loss: 0.0076 - mae: 0.0754 - mse: 0.0076 - root_mean_squared_error: 0.0870
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.006265734322369099.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 0.0125
Epoch 6/50
43/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0873
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0031328671611845493.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 0.0063
Epoch 7/50
45/46 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0015664335805922747.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 0.0031
Epoch 8/50
45/46 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0754 - mse: 0.0076 - root_mean_squared_error: 0.0871
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0007832167902961373.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 0.0016
Epoch 9/50
45/46 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0754 - mse: 0.0076 - root_mean_squared_error: 0.0870
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00039160839514806867.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 7.8322e-04
Epoch 10/50
44/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00019580419757403433.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 3.9161e-04
Epoch 11/50
43/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0873
Epoch 11: ReduceLROnPlateau reducing learning rate to 9.790209878701717e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.9580e-04
Epoch 12/50
41/46 [=========================>....] - ETA: 0s - loss: 0.0076 - mae: 0.0754 - mse: 0.0076 - root_mean_squared_error: 0.0870
Epoch 12: ReduceLROnPlateau reducing learning rate to 4.895104939350858e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 9.7902e-05
Epoch 13/50
42/46 [==========================>...] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871
Epoch 13: ReduceLROnPlateau reducing learning rate to 2.447552469675429e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 4.8951e-05
Epoch 14/50
44/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0754 - mse: 0.0076 - root_mean_squared_error: 0.0871
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.2237762348377146e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 2.4476e-05
Epoch 15/50
44/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.2238e-05
Epoch 16/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 17/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 18/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 19/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 20/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 21/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 22/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 23/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 24/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 25/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 26/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 27/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 28/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 29/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 30/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 31/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 32/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 33/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 34/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 35/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 36/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 37/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 38/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 39/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 40/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 41/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 42/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 43/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 44/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 45/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 46/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 47/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 48/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 49/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
Epoch 50/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 1.0000e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_sgd_0.05012587571678091LR_[100]CHN_50CNNI_168BS_40DU_1P_val_mseM_50epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
Epoch 1/50
46/46 [==============================] - 1s 9ms/step - loss: 0.1063 - mae: 0.2922 - mse: 0.1063 - root_mean_squared_error: 0.3260 - val_loss: 0.0251 - val_mae: 0.1286 - val_mse: 0.0251 - val_root_mean_squared_error: 0.1585 - lr: 0.0501
Epoch 2/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0114 - mae: 0.0876 - mse: 0.0114 - root_mean_squared_error: 0.1070 - val_loss: 0.0077 - val_mae: 0.0758 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0879 - lr: 0.0501
Epoch 3/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0874 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0501
Epoch 4/50
42/46 [==========================>...] - ETA: 0s - loss: 0.0077 - mae: 0.0758 - mse: 0.0077 - root_mean_squared_error: 0.0875
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.025062937289476395.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0501
Epoch 5/50
42/46 [==========================>...] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.012531468644738197.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0251
Epoch 6/50
44/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.006265734322369099.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0125
Epoch 7/50
43/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0874
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0031328671611845493.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0063
Epoch 8/50
39/46 [========================>.....] - ETA: 0s - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0870
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0015664335805922747.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0031
Epoch 9/50
35/46 [=====================>........] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0007832167902961373.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0016
Epoch 10/50
37/46 [=======================>......] - ETA: 0s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0874
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00039160839514806867.
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 7.8322e-04
Epoch 11/50
45/46 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0873
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00019580419757403433.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 3.9161e-04
Epoch 12/50
39/46 [========================>.....] - ETA: 0s - loss: 0.0077 - mae: 0.0759 - mse: 0.0077 - root_mean_squared_error: 0.0875
Epoch 12: ReduceLROnPlateau reducing learning rate to 9.790209878701717e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.9580e-04
Epoch 13/50
42/46 [==========================>...] - ETA: 0s - loss: 0.0076 - mae: 0.0758 - mse: 0.0076 - root_mean_squared_error: 0.0874
Epoch 13: ReduceLROnPlateau reducing learning rate to 4.895104939350858e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 9.7902e-05
Epoch 14/50
45/46 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0873
Epoch 14: ReduceLROnPlateau reducing learning rate to 2.447552469675429e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 4.8951e-05
Epoch 15/50
45/46 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 15: ReduceLROnPlateau reducing learning rate to 1.2237762348377146e-05.
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 2.4476e-05
Epoch 16/50
46/46 [==============================] - ETA: 0s - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 16: ReduceLROnPlateau reducing learning rate to 1e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.2238e-05
Epoch 17/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 18/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 19/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 20/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 21/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 22/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 23/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 24/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 25/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 26/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 27/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 28/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 29/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 30/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 31/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 32/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 33/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 34/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 35/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 36/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 37/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 38/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 39/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 40/50
46/46 [==============================] - 0s 8ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 41/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 42/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 43/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 44/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 45/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 46/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 47/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 48/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 49/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 50/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_sgd_0.05012587571678091LR_[100]CHN_50CNNI_168BS_40DU_1P_val_mseM_50epochs/model_5.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
Epoch 1/50
46/46 [==============================] - 1s 9ms/step - loss: 0.1322 - mae: 0.3142 - mse: 0.1322 - root_mean_squared_error: 0.3636 - val_loss: 0.0119 - val_mae: 0.0897 - val_mse: 0.0119 - val_root_mean_squared_error: 0.1090 - lr: 0.0501
Epoch 2/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0776 - mse: 0.0082 - root_mean_squared_error: 0.0907 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0501
Epoch 3/50
44/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0874
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.025062937289476395.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0501
Epoch 4/50
44/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.012531468644738197.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0251
Epoch 5/50
46/46 [==============================] - ETA: 0s - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.006265734322369099.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0125
Epoch 6/50
45/46 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0031328671611845493.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0063
Epoch 7/50
42/46 [==========================>...] - ETA: 0s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0873
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0015664335805922747.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0031
Epoch 8/50
41/46 [=========================>....] - ETA: 0s - loss: 0.0076 - mae: 0.0759 - mse: 0.0076 - root_mean_squared_error: 0.0874
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0007832167902961373.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0016
Epoch 9/50
46/46 [==============================] - ETA: 0s - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00039160839514806867.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 7.8322e-04
Epoch 10/50
44/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0754 - mse: 0.0076 - root_mean_squared_error: 0.0871
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00019580419757403433.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 3.9161e-04
Epoch 11/50
43/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 11: ReduceLROnPlateau reducing learning rate to 9.790209878701717e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.9580e-04
Epoch 12/50
44/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 12: ReduceLROnPlateau reducing learning rate to 4.895104939350858e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 9.7902e-05
Epoch 13/50
44/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 13: ReduceLROnPlateau reducing learning rate to 2.447552469675429e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 4.8951e-05
Epoch 14/50
45/46 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0758 - mse: 0.0076 - root_mean_squared_error: 0.0874
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.2237762348377146e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 2.4476e-05
Epoch 15/50
41/46 [=========================>....] - ETA: 0s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0874
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.2238e-05
Epoch 16/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 17/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 18/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 19/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 20/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 21/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 22/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 23/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 24/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 25/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 26/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 27/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 28/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 29/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 30/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 31/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 32/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 33/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 34/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 35/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 36/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 37/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 38/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 39/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 40/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 41/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 42/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 43/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 44/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 45/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 46/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 47/50
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 48/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 49/50
46/46 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 50/50
46/46 [==============================] - 0s 8ms/step - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_sgd_0.05012587571678091LR_[100]CHN_50CNNI_168BS_40DU_1P_val_mseM_50epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
Epoch 1/50
46/46 [==============================] - 1s 10ms/step - loss: 0.1685 - mae: 0.3437 - mse: 0.1685 - root_mean_squared_error: 0.4105 - val_loss: 0.0098 - val_mae: 0.0826 - val_mse: 0.0098 - val_root_mean_squared_error: 0.0989 - lr: 0.0501
Epoch 2/50
33/46 [====================>.........] - ETA: 0s - loss: 0.0079 - mae: 0.0764 - mse: 0.0079 - root_mean_squared_error: 0.0887
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0051s). Check your callbacks.
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
Epoch 3/50
40/46 [=========================>....] - ETA: 0s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0875
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.025062937289476395.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0874 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0501
Epoch 4/50
39/46 [========================>.....] - ETA: 0s - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0873
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.012531468644738197.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0251
Epoch 5/50
43/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0758 - mse: 0.0076 - root_mean_squared_error: 0.0874
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.006265734322369099.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0125
Epoch 6/50
44/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0754 - mse: 0.0076 - root_mean_squared_error: 0.0871
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0031328671611845493.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0063
Epoch 7/50
43/46 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0873
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0015664335805922747.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0031
Epoch 8/50
45/46 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0007832167902961373.
46/46 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0016
Epoch 9/50
11/46 [======>.......................] - ETA: 0s - loss: 0.0072 - mae: 0.0730 - mse: 0.0072 - root_mean_squared_error: 0.0849
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_train_batch_end` time: 0.0048s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_train_batch_end` time: 0.0048s). Check your callbacks.
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501
46/46 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0764 - mse: 0.0078 - root_mean_squared_error: 0.0886 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0501