wandb: WARNING The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.
Epoch 1/50
724/854 [========================>.....] - ETA: 0s - loss: 3.2064 - mae: 0.2192 - mse: 0.0680

832/854 [============================>.] - ETA: 0s - loss: 2.8042 - mae: 0.2221 - mse: 0.0694
854/854 [==============================] - 3s 3ms/step - loss: 2.7363 - mae: 0.2228 - mse: 0.0697 - val_loss: 0.0881 - val_mae: 0.2452 - val_mse: 0.0812 - lr: 0.0010
Epoch 2/50
834/854 [============================>.] - ETA: 0s - loss: 0.0809 - mae: 0.2217 - mse: 0.0687
854/854 [==============================] - 2s 3ms/step - loss: 0.0807 - mae: 0.2210 - mse: 0.0684 - val_loss: 0.0764 - val_mae: 0.2056 - val_mse: 0.0619 - lr: 0.0010
Epoch 3/50
835/854 [============================>.] - ETA: 0s - loss: 0.0694 - mae: 0.1886 - mse: 0.0545
854/854 [==============================] - 2s 3ms/step - loss: 0.0693 - mae: 0.1884 - mse: 0.0544 - val_loss: 0.0605 - val_mae: 0.1672 - val_mse: 0.0459 - lr: 0.0010
Epoch 4/50
854/854 [==============================] - 2s 3ms/step - loss: 0.0624 - mae: 0.1717 - mse: 0.0478 - val_loss: 0.0552 - val_mae: 0.1550 - val_mse: 0.0410 - lr: 0.0010
Epoch 5/50
854/854 [==============================] - 2s 2ms/step - loss: 0.0577 - mae: 0.1613 - mse: 0.0436 - val_loss: 0.0598 - val_mae: 0.1687 - val_mse: 0.0461 - lr: 0.0010
Epoch 6/50
566/854 [==================>...........] - ETA: 0s - loss: 0.0555 - mae: 0.1574 - mse: 0.0420

835/854 [============================>.] - ETA: 0s - loss: 0.0550 - mae: 0.1565 - mse: 0.0416
854/854 [==============================] - 2s 3ms/step - loss: 0.0550 - mae: 0.1567 - mse: 0.0417 - val_loss: 0.0480 - val_mae: 0.1406 - val_mse: 0.0352 - lr: 0.0010
Epoch 7/50
840/854 [============================>.] - ETA: 0s - loss: 0.0530 - mae: 0.1535 - mse: 0.0403
854/854 [==============================] - 2s 3ms/step - loss: 0.0530 - mae: 0.1535 - mse: 0.0403 - val_loss: 0.0462 - val_mae: 0.1373 - val_mse: 0.0337 - lr: 0.0010
Epoch 8/50
854/854 [==============================] - 6s 7ms/step - loss: 0.0513 - mae: 0.1508 - mse: 0.0391 - val_loss: 0.0443 - val_mae: 0.1332 - val_mse: 0.0325 - lr: 0.0010
Epoch 9/50
854/854 [==============================] - 2s 2ms/step - loss: 0.0497 - mae: 0.1481 - mse: 0.0380 - val_loss: 0.0454 - val_mae: 0.1410 - val_mse: 0.0340 - lr: 0.0010
Epoch 10/50
851/854 [============================>.] - ETA: 0s - loss: 0.0491 - mae: 0.1473 - mse: 0.0376
854/854 [==============================] - 3s 4ms/step - loss: 0.0491 - mae: 0.1473 - mse: 0.0376 - val_loss: 0.0429 - val_mae: 0.1336 - val_mse: 0.0315 - lr: 0.0010
Epoch 11/50
827/854 [============================>.] - ETA: 0s - loss: 0.0476 - mae: 0.1451 - mse: 0.0364
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\one_model\wandb\run-20230412_155910-imnda56v\files\model-best)... Done. 0.0s
854/854 [==============================] - 2s 3ms/step - loss: 0.0476 - mae: 0.1452 - mse: 0.0365 - val_loss: 0.0416 - val_mae: 0.1277 - val_mse: 0.0306 - lr: 0.0010
Epoch 12/50
854/854 [==============================] - 1s 2ms/step - loss: 0.0469 - mae: 0.1434 - mse: 0.0359 - val_loss: 0.0548 - val_mae: 0.1632 - val_mse: 0.0443 - lr: 0.0010
Epoch 13/50
837/854 [============================>.] - ETA: 0s - loss: 0.0461 - mae: 0.1419 - mse: 0.0354
854/854 [==============================] - 2s 3ms/step - loss: 0.0461 - mae: 0.1419 - mse: 0.0354 - val_loss: 0.0414 - val_mae: 0.1287 - val_mse: 0.0308 - lr: 0.0010
Epoch 14/50
847/854 [============================>.] - ETA: 0s - loss: 0.0453 - mae: 0.1407 - mse: 0.0348
854/854 [==============================] - 3s 3ms/step - loss: 0.0453 - mae: 0.1407 - mse: 0.0348 - val_loss: 0.0386 - val_mae: 0.1221 - val_mse: 0.0281 - lr: 0.0010
Epoch 15/50
854/854 [==============================] - 3s 3ms/step - loss: 0.0442 - mae: 0.1386 - mse: 0.0338 - val_loss: 0.0380 - val_mae: 0.1203 - val_mse: 0.0277 - lr: 0.0010
Epoch 16/50
854/854 [==============================] - 2s 2ms/step - loss: 0.0436 - mae: 0.1367 - mse: 0.0333 - val_loss: 0.0733 - val_mae: 0.2071 - val_mse: 0.0624 - lr: 0.0010
Epoch 17/50
854/854 [==============================] - 2s 2ms/step - loss: 0.0434 - mae: 0.1359 - mse: 0.0331 - val_loss: 0.0386 - val_mae: 0.1253 - val_mse: 0.0284 - lr: 0.0010
Epoch 18/50
409/854 [=============>................] - ETA: 0s - loss: 0.0432 - mae: 0.1353 - mse: 0.0328

832/854 [============================>.] - ETA: 0s - loss: 0.0425 - mae: 0.1334 - mse: 0.0322
854/854 [==============================] - 3s 3ms/step - loss: 0.0425 - mae: 0.1336 - mse: 0.0322 - val_loss: 0.0365 - val_mae: 0.1144 - val_mse: 0.0263 - lr: 0.0010
Epoch 19/50
854/854 [==============================] - 3s 4ms/step - loss: 0.0416 - mae: 0.1312 - mse: 0.0314 - val_loss: 0.0361 - val_mae: 0.1129 - val_mse: 0.0258 - lr: 0.0010
Epoch 20/50
854/854 [==============================] - 2s 2ms/step - loss: 0.0410 - mae: 0.1299 - mse: 0.0309 - val_loss: 0.0663 - val_mae: 0.1941 - val_mse: 0.0558 - lr: 0.0010
Epoch 21/50
854/854 [==============================] - 1s 2ms/step - loss: 0.0404 - mae: 0.1287 - mse: 0.0304 - val_loss: 0.0803 - val_mae: 0.2220 - val_mse: 0.0700 - lr: 0.0010
Epoch 22/50
833/854 [============================>.] - ETA: 0s - loss: 0.0399 - mae: 0.1267 - mse: 0.0298
854/854 [==============================] - 2s 3ms/step - loss: 0.0399 - mae: 0.1267 - mse: 0.0298 - val_loss: 0.0335 - val_mae: 0.1041 - val_mse: 0.0233 - lr: 0.0010
Epoch 23/50
854/854 [==============================] - 2s 3ms/step - loss: 0.0395 - mae: 0.1252 - mse: 0.0295 - val_loss: 0.0489 - val_mae: 0.1576 - val_mse: 0.0388 - lr: 0.0010
Epoch 24/50
691/854 [=======================>......] - ETA: 0s - loss: 0.0384 - mae: 0.1231 - mse: 0.0284

854/854 [==============================] - 2s 3ms/step - loss: 0.0386 - mae: 0.1236 - mse: 0.0286 - val_loss: 0.0328 - val_mae: 0.1016 - val_mse: 0.0229 - lr: 0.0010
Epoch 25/50
854/854 [==============================] - 2s 2ms/step - loss: 0.0386 - mae: 0.1226 - mse: 0.0286 - val_loss: 0.0507 - val_mae: 0.1620 - val_mse: 0.0403 - lr: 0.0010
Epoch 26/50
854/854 [==============================] - 2s 2ms/step - loss: 0.0378 - mae: 0.1206 - mse: 0.0279 - val_loss: 0.0527 - val_mae: 0.1682 - val_mse: 0.0427 - lr: 0.0010
Epoch 27/50
846/854 [============================>.] - ETA: 0s - loss: 0.0374 - mae: 0.1203 - mse: 0.0276
854/854 [==============================] - 3s 3ms/step - loss: 0.0374 - mae: 0.1203 - mse: 0.0276 - val_loss: 0.0316 - val_mae: 0.0987 - val_mse: 0.0220 - lr: 0.0010
Epoch 28/50
854/854 [==============================] - 2s 2ms/step - loss: 0.0373 - mae: 0.1200 - mse: 0.0275 - val_loss: 0.0399 - val_mae: 0.1320 - val_mse: 0.0303 - lr: 0.0010
Epoch 29/50
854/854 [==============================] - 2s 2ms/step - loss: 0.0369 - mae: 0.1193 - mse: 0.0273 - val_loss: 0.0422 - val_mae: 0.1363 - val_mse: 0.0326 - lr: 0.0010
Epoch 30/50
834/854 [============================>.] - ETA: 0s - loss: 0.0365 - mae: 0.1179 - mse: 0.0269
854/854 [==============================] - 2s 3ms/step - loss: 0.0366 - mae: 0.1181 - mse: 0.0270 - val_loss: 0.0308 - val_mae: 0.0958 - val_mse: 0.0213 - lr: 0.0010
Epoch 31/50
854/854 [==============================] - 2s 2ms/step - loss: 0.0362 - mae: 0.1174 - mse: 0.0266 - val_loss: 0.0359 - val_mae: 0.1216 - val_mse: 0.0264 - lr: 0.0010
Epoch 32/50
854/854 [==============================] - 2s 2ms/step - loss: 0.0360 - mae: 0.1179 - mse: 0.0266 - val_loss: 0.0324 - val_mae: 0.1067 - val_mse: 0.0229 - lr: 0.0010
Epoch 33/50
846/854 [============================>.] - ETA: 0s - loss: 0.0359 - mae: 0.1173 - mse: 0.0266
Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
854/854 [==============================] - 1s 2ms/step - loss: 0.0358 - mae: 0.1170 - mse: 0.0265 - val_loss: 0.0318 - val_mae: 0.1041 - val_mse: 0.0226 - lr: 0.0010
Epoch 34/50
831/854 [============================>.] - ETA: 0s - loss: 0.0315 - mae: 0.1030 - mse: 0.0225
854/854 [==============================] - 3s 3ms/step - loss: 0.0314 - mae: 0.1029 - mse: 0.0224 - val_loss: 0.0307 - val_mae: 0.1024 - val_mse: 0.0218 - lr: 5.0000e-04
Epoch 35/50
854/854 [==============================] - 2s 2ms/step - loss: 0.0311 - mae: 0.1023 - mse: 0.0223 - val_loss: 0.0455 - val_mae: 0.1510 - val_mse: 0.0368 - lr: 5.0000e-04
Epoch 36/50
564/854 [==================>...........] - ETA: 0s - loss: 0.0307 - mae: 0.1019 - mse: 0.0220

837/854 [============================>.] - ETA: 0s - loss: 0.0308 - mae: 0.1018 - mse: 0.0221
854/854 [==============================] - 3s 3ms/step - loss: 0.0307 - mae: 0.1018 - mse: 0.0221 - val_loss: 0.0287 - val_mae: 0.0933 - val_mse: 0.0200 - lr: 5.0000e-04
Epoch 37/50
854/854 [==============================] - 1s 2ms/step - loss: 0.0305 - mae: 0.1013 - mse: 0.0219 - val_loss: 0.0313 - val_mae: 0.1049 - val_mse: 0.0229 - lr: 5.0000e-04
Epoch 38/50
854/854 [==============================] - 3s 3ms/step - loss: 0.0302 - mae: 0.1013 - mse: 0.0219 - val_loss: 0.0280 - val_mae: 0.0908 - val_mse: 0.0194 - lr: 5.0000e-04
Epoch 39/50
854/854 [==============================] - 2s 3ms/step - loss: 0.0300 - mae: 0.1007 - mse: 0.0216 - val_loss: 0.0443 - val_mae: 0.1537 - val_mse: 0.0360 - lr: 5.0000e-04
Epoch 40/50
854/854 [==============================] - 2s 2ms/step - loss: 0.0296 - mae: 0.1001 - mse: 0.0214 - val_loss: 0.0286 - val_mae: 0.0976 - val_mse: 0.0205 - lr: 5.0000e-04
Epoch 41/50
841/854 [============================>.] - ETA: 0s - loss: 0.0295 - mae: 0.1000 - mse: 0.0214
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
854/854 [==============================] - 2s 2ms/step - loss: 0.0295 - mae: 0.1001 - mse: 0.0214 - val_loss: 0.0314 - val_mae: 0.1097 - val_mse: 0.0235 - lr: 5.0000e-04
Epoch 42/50
854/854 [==============================] - 2s 2ms/step - loss: 0.0279 - mae: 0.0938 - mse: 0.0200 - val_loss: 0.0281 - val_mae: 0.0960 - val_mse: 0.0201 - lr: 2.5000e-04
Epoch 43/50

835/854 [============================>.] - ETA: 0s - loss: 0.0278 - mae: 0.0935 - mse: 0.0199
854/854 [==============================] - 3s 3ms/step - loss: 0.0277 - mae: 0.0935 - mse: 0.0199 - val_loss: 0.0268 - val_mae: 0.0886 - val_mse: 0.0190 - lr: 2.5000e-04
Epoch 44/50
854/854 [==============================] - 2s 2ms/step - loss: 0.0276 - mae: 0.0930 - mse: 0.0198 - val_loss: 0.0276 - val_mae: 0.0945 - val_mse: 0.0198 - lr: 2.5000e-04
Epoch 45/50
854/854 [==============================] - 2s 2ms/step - loss: 0.0275 - mae: 0.0932 - mse: 0.0198 - val_loss: 0.0294 - val_mae: 0.1027 - val_mse: 0.0217 - lr: 2.5000e-04
Epoch 46/50

840/854 [============================>.] - ETA: 0s - loss: 0.0272 - mae: 0.0927 - mse: 0.0196
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\one_model\wandb\run-20230412_155910-imnda56v\files\model-best)... Done. 0.0s
854/854 [==============================] - 4s 4ms/step - loss: 0.0272 - mae: 0.0927 - mse: 0.0196 - val_loss: 0.0262 - val_mae: 0.0877 - val_mse: 0.0186 - lr: 2.5000e-04
Epoch 47/50
854/854 [==============================] - 1s 2ms/step - loss: 0.0271 - mae: 0.0928 - mse: 0.0196 - val_loss: 0.0269 - val_mae: 0.0925 - val_mse: 0.0194 - lr: 2.5000e-04
Epoch 48/50
854/854 [==============================] - 1s 2ms/step - loss: 0.0269 - mae: 0.0922 - mse: 0.0194 - val_loss: 0.0300 - val_mae: 0.1101 - val_mse: 0.0226 - lr: 2.5000e-04
Epoch 49/50
854/854 [==============================] - 1s 2ms/step - loss: 0.0267 - mae: 0.0922 - mse: 0.0194 - val_loss: 0.0265 - val_mae: 0.0927 - val_mse: 0.0191 - lr: 2.5000e-04
Epoch 50/50
854/854 [==============================] - 1s 2ms/step - loss: 0.0267 - mae: 0.0922 - mse: 0.0194 - val_loss: 0.0265 - val_mae: 0.0927 - val_mse: 0.0191 - lr: 2.5000e-04
>Saved ../../trained_models/models_segments_one_model_30.0_50epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])