(3883, 8)
(1665, 8)
Epoch 1/100
wandb: WARNING The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.


483/486 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0447 - mse: 0.0034 - root_mean_squared_error: 0.0581
486/486 [==============================] - 9s 15ms/step - loss: 0.0034 - mae: 0.0447 - mse: 0.0034 - root_mean_squared_error: 0.0581 - val_loss: 0.0022 - val_mae: 0.0401 - val_mse: 0.0022 - val_root_mean_squared_error: 0.0470 - lr: 0.0690
Epoch 2/100
483/486 [============================>.] - ETA: 0s - loss: 0.0023 - mae: 0.0402 - mse: 0.0023 - root_mean_squared_error: 0.0476
486/486 [==============================] - 7s 15ms/step - loss: 0.0023 - mae: 0.0403 - mse: 0.0023 - root_mean_squared_error: 0.0476 - val_loss: 0.0021 - val_mae: 0.0391 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0454 - lr: 0.0690
Epoch 3/100
486/486 [==============================] - 6s 13ms/step - loss: 0.0022 - mae: 0.0396 - mse: 0.0022 - root_mean_squared_error: 0.0464 - val_loss: 0.0034 - val_mae: 0.0476 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0581 - lr: 0.0690
Epoch 4/100



486/486 [==============================] - ETA: 0s - loss: 0.0023 - mae: 0.0405 - mse: 0.0023 - root_mean_squared_error: 0.0482
486/486 [==============================] - 8s 16ms/step - loss: 0.0023 - mae: 0.0405 - mse: 0.0023 - root_mean_squared_error: 0.0482 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0446 - lr: 0.0690
Epoch 5/100
486/486 [==============================] - 6s 12ms/step - loss: 0.0021 - mae: 0.0394 - mse: 0.0021 - root_mean_squared_error: 0.0462 - val_loss: 0.0020 - val_mae: 0.0387 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0448 - lr: 0.0690
Epoch 6/100



484/486 [============================>.] - ETA: 0s - loss: 0.0022 - mae: 0.0399 - mse: 0.0022 - root_mean_squared_error: 0.0471
486/486 [==============================] - 7s 15ms/step - loss: 0.0022 - mae: 0.0399 - mse: 0.0022 - root_mean_squared_error: 0.0471 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0443 - lr: 0.0690
Epoch 7/100
486/486 [==============================] - 6s 12ms/step - loss: 0.0024 - mae: 0.0412 - mse: 0.0024 - root_mean_squared_error: 0.0488 - val_loss: 0.0020 - val_mae: 0.0388 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0452 - lr: 0.0690
Epoch 8/100


486/486 [==============================] - 5s 11ms/step - loss: 0.0022 - mae: 0.0399 - mse: 0.0022 - root_mean_squared_error: 0.0473 - val_loss: 0.0026 - val_mae: 0.0424 - val_mse: 0.0026 - val_root_mean_squared_error: 0.0509 - lr: 0.0690
Epoch 9/100

486/486 [==============================] - 5s 11ms/step - loss: 0.0024 - mae: 0.0411 - mse: 0.0024 - root_mean_squared_error: 0.0489 - val_loss: 0.0033 - val_mae: 0.0468 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0571 - lr: 0.0690
Epoch 10/100


486/486 [==============================] - 5s 11ms/step - loss: 0.0022 - mae: 0.0400 - mse: 0.0022 - root_mean_squared_error: 0.0473 - val_loss: 0.0036 - val_mae: 0.0487 - val_mse: 0.0036 - val_root_mean_squared_error: 0.0596 - lr: 0.0690
Epoch 11/100


486/486 [==============================] - 6s 11ms/step - loss: 0.0023 - mae: 0.0401 - mse: 0.0023 - root_mean_squared_error: 0.0475 - val_loss: 0.0022 - val_mae: 0.0402 - val_mse: 0.0022 - val_root_mean_squared_error: 0.0472 - lr: 0.0690
Epoch 12/100


486/486 [==============================] - 6s 12ms/step - loss: 0.0023 - mae: 0.0401 - mse: 0.0023 - root_mean_squared_error: 0.0477 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0444 - lr: 0.0690
Epoch 13/100


484/486 [============================>.] - ETA: 0s - loss: 0.0023 - mae: 0.0408 - mse: 0.0023 - root_mean_squared_error: 0.0480
486/486 [==============================] - 7s 14ms/step - loss: 0.0023 - mae: 0.0408 - mse: 0.0023 - root_mean_squared_error: 0.0481 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - lr: 0.0690
Epoch 14/100

486/486 [==============================] - 6s 11ms/step - loss: 0.0022 - mae: 0.0401 - mse: 0.0022 - root_mean_squared_error: 0.0473 - val_loss: 0.0020 - val_mae: 0.0387 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0448 - lr: 0.0690
Epoch 15/100

486/486 [==============================] - 5s 11ms/step - loss: 0.0024 - mae: 0.0409 - mse: 0.0024 - root_mean_squared_error: 0.0485 - val_loss: 0.0033 - val_mae: 0.0473 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0577 - lr: 0.0690
Epoch 16/100

222/486 [============>.................] - ETA: 2s - loss: 0.0023 - mae: 0.0405 - mse: 0.0023 - root_mean_squared_error: 0.0477
Traceback (most recent call last):
  File "C:\MyDocuments\Disertatie\segments\wandb_visualization\overlap\wrapper_test_and_train.py", line 211, in <module>
    train_RNN()
  File "C:\MyDocuments\Disertatie\segments\wandb_visualization\overlap\wrapper_test_and_train.py", line 111, in train_RNN
    train_models_and_save_RNN(n_members,data,test_size,train_group_RNN, epochs, batch_size, learning_rate,optimizer,hidden_layer_size,patience,monitor,activation,dense_units)
  File "C:\MyDocuments\Disertatie\segments\wandb_visualization\overlap\test_and_train.py", line 49, in train_models_and_save_RNN
    network, history = train_model_sweep(
  File "C:\MyDocuments\Disertatie\segments\model_training\overlap\model_generating.py", line 206, in train_model_sweep
    history = network.fit(x_train, y_train, epochs=epochs, batch_size = batch_size, validation_data=(x_test, y_test),
  File "C:\Users\cosmi\AppData\Roaming\Python\Python39\site-packages\wandb\integration\keras\keras.py", line 174, in new_v2
    return old_v2(*args, **kwargs)
  File "C:\Users\cosmi\AppData\Roaming\Python\Python39\site-packages\wandb\integration\keras\keras.py", line 174, in new_v2
    return old_v2(*args, **kwargs)
  File "C:\Users\cosmi\AppData\Roaming\Python\Python39\site-packages\wandb\integration\keras\keras.py", line 174, in new_v2
    return old_v2(*args, **kwargs)
  File "C:\Users\cosmi\anaconda3\envs\tf2.12\lib\site-packages\keras\utils\traceback_utils.py", line 65, in error_handler
    return fn(*args, **kwargs)
  File "C:\Users\cosmi\anaconda3\envs\tf2.12\lib\site-packages\keras\engine\training.py", line 1564, in fit
    tmp_logs = self.train_function(iterator)
  File "C:\Users\cosmi\anaconda3\envs\tf2.12\lib\site-packages\tensorflow\python\util\traceback_utils.py", line 150, in error_handler
    return fn(*args, **kwargs)
  File "C:\Users\cosmi\anaconda3\envs\tf2.12\lib\site-packages\tensorflow\python\eager\def_function.py", line 915, in __call__
    result = self._call(*args, **kwds)
  File "C:\Users\cosmi\anaconda3\envs\tf2.12\lib\site-packages\tensorflow\python\eager\def_function.py", line 947, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File "C:\Users\cosmi\anaconda3\envs\tf2.12\lib\site-packages\tensorflow\python\eager\function.py", line 2496, in __call__
    return graph_function._call_flat(
  File "C:\Users\cosmi\anaconda3\envs\tf2.12\lib\site-packages\tensorflow\python\eager\function.py", line 1862, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File "C:\Users\cosmi\anaconda3\envs\tf2.12\lib\site-packages\tensorflow\python\eager\function.py", line 499, in call
    outputs = execute.execute(
  File "C:\Users\cosmi\anaconda3\envs\tf2.12\lib\site-packages\tensorflow\python\eager\execute.py", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,

