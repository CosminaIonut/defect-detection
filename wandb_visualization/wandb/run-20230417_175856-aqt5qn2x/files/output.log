Epoch 1/20
79/81 [============================>.] - ETA: 0s - loss: 0.0498 - mae: 0.0618 - mse: 0.0073
81/81 [==============================] - 1s 11ms/step - loss: 0.0490 - mae: 0.0614 - mse: 0.0072 - val_loss: 0.0156 - val_mae: 0.0490 - val_mse: 0.0036 - lr: 0.0912
Epoch 2/20
75/81 [==========================>...] - ETA: 0s - loss: 0.0154 - mae: 0.0400 - mse: 0.0023
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_175856-aqt5qn2x\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 8ms/step - loss: 0.0153 - mae: 0.0399 - mse: 0.0022 - val_loss: 0.0141 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0912
Epoch 3/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0152 - mae: 0.0392 - mse: 0.0021 - val_loss: 0.0144 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0912
Epoch 4/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0152 - mae: 0.0392 - mse: 0.0021 - val_loss: 0.0201 - val_mae: 0.0399 - val_mse: 0.0022 - lr: 0.0912
Epoch 5/20
79/81 [============================>.] - ETA: 0s - loss: 0.0152 - mae: 0.0384 - mse: 0.0020
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0455806665122509.
81/81 [==============================] - 0s 1ms/step - loss: 0.0151 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0150 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0912
Epoch 6/20
81/81 [==============================] - 1s 9ms/step - loss: 0.0024 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0456
Epoch 7/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0026 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0456
Epoch 8/20
78/81 [===========================>..] - ETA: 0s - loss: 0.0023 - mae: 0.0381 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.02279033325612545.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_175856-aqt5qn2x\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 9ms/step - loss: 0.0023 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0456
Epoch 9/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0228
Epoch 10/20
79/81 [============================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0379 - mse: 0.0019
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_175856-aqt5qn2x\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 9ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0228
Epoch 11/20
51/81 [=================>............] - ETA: 0s - loss: 0.0020 - mae: 0.0378 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.011395166628062725.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_175856-aqt5qn2x\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 10ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0228
Epoch 12/20
81/81 [==============================] - 1s 9ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0114
Epoch 13/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0114
Epoch 14/20
 1/81 [..............................] - ETA: 0s - loss: 0.0023 - mae: 0.0408 - mse: 0.0022
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0056975833140313625.
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0114
Epoch 15/20
 1/81 [..............................] - ETA: 0s - loss: 0.0023 - mae: 0.0430 - mse: 0.0023
81/81 [==============================] - 1s 9ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0057
Epoch 16/20
77/81 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
81/81 [==============================] - 1s 10ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0057
Epoch 17/20
79/81 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0028487916570156813.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_175856-aqt5qn2x\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_175856-aqt5qn2x\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 10ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0057
Epoch 18/20
75/81 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0008s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0015s). Check your callbacks.
81/81 [==============================] - 1s 9ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0028
Epoch 19/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0028
Epoch 20/20
 1/81 [..............................] - ETA: 0s - loss: 0.0018 - mae: 0.0371 - mse: 0.0018
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0014243958285078406.
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0028
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.09116133301013224_70_48_20epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
108/108 [==============================] - 0s 2ms/step - loss: 0.0367 - mae: 0.0641 - mse: 0.0067 - val_loss: 0.0154 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0912
Epoch 2/20
108/108 [==============================] - 0s 1ms/step - loss: 0.0182 - mae: 0.0563 - mse: 0.0048 - val_loss: 0.0156 - val_mae: 0.0506 - val_mse: 0.0035 - lr: 0.0912
Epoch 3/20
108/108 [==============================] - 0s 1ms/step - loss: 0.0175 - mae: 0.0545 - mse: 0.0043 - val_loss: 0.0166 - val_mae: 0.0530 - val_mse: 0.0040 - lr: 0.0912
Epoch 4/20
 76/108 [====================>.........] - ETA: 0s - loss: 0.0188 - mae: 0.0584 - mse: 0.0054
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0455806665122509.
108/108 [==============================] - 0s 1ms/step - loss: 0.0182 - mae: 0.0566 - mse: 0.0049 - val_loss: 0.0178 - val_mae: 0.0567 - val_mse: 0.0046 - lr: 0.0912
Epoch 5/20
108/108 [==============================] - 0s 1ms/step - loss: 0.0040 - mae: 0.0510 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0456
Epoch 6/20
108/108 [==============================] - 0s 1ms/step - loss: 0.0039 - mae: 0.0511 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0456
Epoch 7/20
 84/108 [======================>.......] - ETA: 0s - loss: 0.0040 - mae: 0.0515 - mse: 0.0035
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.02279033325612545.
108/108 [==============================] - 0s 1ms/step - loss: 0.0039 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.0060 - val_mae: 0.0532 - val_mse: 0.0040 - lr: 0.0456
Epoch 8/20
108/108 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0038 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0228
Epoch 9/20
108/108 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0228
Epoch 10/20
 78/108 [====================>.........] - ETA: 0s - loss: 0.0035 - mae: 0.0504 - mse: 0.0034
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.011395166628062725.
108/108 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0228
Epoch 11/20
108/108 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0114
Epoch 12/20
108/108 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0114
Epoch 13/20
 81/108 [=====================>........] - ETA: 0s - loss: 0.0035 - mae: 0.0508 - mse: 0.0034
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0056975833140313625.
108/108 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0114
Epoch 14/20
108/108 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0057
Epoch 15/20
108/108 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0057
Epoch 16/20
 79/108 [====================>.........] - ETA: 0s - loss: 0.0035 - mae: 0.0512 - mse: 0.0035
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0028487916570156813.
108/108 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0057
Epoch 17/20
108/108 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0028
Epoch 18/20
108/108 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0028
Epoch 19/20
 79/108 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0510 - mse: 0.0034
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0014243958285078406.
108/108 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0028
Epoch 20/20
108/108 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0014
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.09116133301013224_70_48_20epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
81/81 [==============================] - 1s 2ms/step - loss: 0.0399 - mae: 0.0548 - mse: 0.0056 - val_loss: 0.0133 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0912
Epoch 2/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0202 - mae: 0.0552 - mse: 0.0064 - val_loss: 0.0137 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0912
Epoch 3/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0179 - mae: 0.0497 - mse: 0.0048 - val_loss: 0.0176 - val_mae: 0.0531 - val_mse: 0.0042 - lr: 0.0912
Epoch 4/20
78/81 [===========================>..] - ETA: 0s - loss: 0.0199 - mae: 0.0535 - mse: 0.0065
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0455806665122509.
81/81 [==============================] - 0s 1ms/step - loss: 0.0197 - mae: 0.0529 - mse: 0.0063 - val_loss: 0.0150 - val_mae: 0.0437 - val_mse: 0.0028 - lr: 0.0912
Epoch 5/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0030 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0456
Epoch 6/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0039 - mae: 0.0388 - mse: 0.0020 - val_loss: 0.0048 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0456
Epoch 7/20
75/81 [==========================>...] - ETA: 0s - loss: 0.0041 - mae: 0.0401 - mse: 0.0022
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.02279033325612545.
81/81 [==============================] - 0s 1ms/step - loss: 0.0041 - mae: 0.0398 - mse: 0.0022 - val_loss: 0.0034 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0456
Epoch 8/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0228
Epoch 9/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0024 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0024 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0228
Epoch 10/20
70/81 [========================>.....] - ETA: 0s - loss: 0.0024 - mae: 0.0380 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.011395166628062725.
81/81 [==============================] - 0s 1ms/step - loss: 0.0024 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0228
Epoch 11/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0114
Epoch 12/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0114
Epoch 13/20
70/81 [========================>.....] - ETA: 0s - loss: 0.0021 - mae: 0.0380 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0056975833140313625.
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0114
Epoch 14/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0057
Epoch 15/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0057
Epoch 16/20
76/81 [===========================>..] - ETA: 0s - loss: 0.0020 - mae: 0.0380 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0028487916570156813.
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0057
Epoch 17/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0028
Epoch 18/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0028
Epoch 19/20
72/81 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.0019
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0014243958285078406.
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0028
Epoch 20/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.09116133301013224_70_48_20epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
81/81 [==============================] - 0s 2ms/step - loss: 0.0420 - mae: 0.0547 - mse: 0.0069 - val_loss: 0.0129 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0912
Epoch 2/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0190 - mae: 0.0545 - mse: 0.0055 - val_loss: 0.0137 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0912
Epoch 3/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0182 - mae: 0.0511 - mse: 0.0052 - val_loss: 0.0149 - val_mae: 0.0412 - val_mse: 0.0024 - lr: 0.0912
Epoch 4/20
81/81 [==============================] - ETA: 0s - loss: 0.0188 - mae: 0.0524 - mse: 0.0053
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0455806665122509.
81/81 [==============================] - 0s 1ms/step - loss: 0.0188 - mae: 0.0524 - mse: 0.0053 - val_loss: 0.0136 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0912
Epoch 5/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0035 - val_mae: 0.0395 - val_mse: 0.0021 - lr: 0.0456
Epoch 6/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0048 - mae: 0.0412 - mse: 0.0025 - val_loss: 0.0046 - val_mae: 0.0402 - val_mse: 0.0023 - lr: 0.0456
Epoch 7/20
 1/81 [..............................] - ETA: 0s - loss: 0.0047 - mae: 0.0430 - mse: 0.0024
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.02279033325612545.
81/81 [==============================] - 0s 1ms/step - loss: 0.0045 - mae: 0.0395 - mse: 0.0022 - val_loss: 0.0039 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0456
Epoch 8/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0228
Epoch 9/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0025 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0228
Epoch 10/20
79/81 [============================>.] - ETA: 0s - loss: 0.0025 - mae: 0.0382 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.011395166628062725.
81/81 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0032 - val_mae: 0.0409 - val_mse: 0.0024 - lr: 0.0228
Epoch 11/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0114
Epoch 12/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0114
Epoch 13/20
77/81 [===========================>..] - ETA: 0s - loss: 0.0021 - mae: 0.0378 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0056975833140313625.
81/81 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0114
Epoch 14/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0057
Epoch 15/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0057
Epoch 16/20
79/81 [============================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0379 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0028487916570156813.
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0057
Epoch 17/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0028
Epoch 18/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0028
Epoch 19/20
 1/81 [..............................] - ETA: 0s - loss: 0.0019 - mae: 0.0370 - mse: 0.0019
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0014243958285078406.
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0028
Epoch 20/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.09116133301013224_70_48_20epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
81/81 [==============================] - 0s 2ms/step - loss: 0.0455 - mae: 0.0593 - mse: 0.0078 - val_loss: 0.0147 - val_mae: 0.0418 - val_mse: 0.0025 - lr: 0.0912
Epoch 2/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0177 - mae: 0.0506 - mse: 0.0047 - val_loss: 0.0165 - val_mae: 0.0419 - val_mse: 0.0025 - lr: 0.0912
Epoch 3/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0186 - mae: 0.0510 - mse: 0.0056 - val_loss: 0.0141 - val_mae: 0.0401 - val_mse: 0.0022 - lr: 0.0912
Epoch 4/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0164 - mae: 0.0458 - mse: 0.0037 - val_loss: 0.0138 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0912
Epoch 5/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0183 - mae: 0.0504 - mse: 0.0051 - val_loss: 0.0141 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0912
Epoch 6/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0187 - mae: 0.0506 - mse: 0.0058 - val_loss: 0.1191 - val_mae: 0.3008 - val_mse: 0.0924 - lr: 0.0912
Epoch 7/20
75/81 [==========================>...] - ETA: 0s - loss: 0.0183 - mae: 0.0504 - mse: 0.0052
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0455806665122509.
81/81 [==============================] - 0s 1ms/step - loss: 0.0180 - mae: 0.0496 - mse: 0.0050 - val_loss: 0.0137 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0912
Epoch 8/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0024 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0033 - val_mae: 0.0409 - val_mse: 0.0024 - lr: 0.0456
Epoch 9/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0398 - mse: 0.0022 - val_loss: 0.0022 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0456
Epoch 10/20
78/81 [===========================>..] - ETA: 0s - loss: 0.0024 - mae: 0.0391 - mse: 0.0021
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.02279033325612545.
81/81 [==============================] - 0s 1ms/step - loss: 0.0026 - mae: 0.0399 - mse: 0.0022 - val_loss: 0.0049 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 0.0456
Epoch 11/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0228
Epoch 12/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0029 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0228
Epoch 13/20
81/81 [==============================] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.011395166628062725.
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0395 - val_mse: 0.0022 - lr: 0.0228
Epoch 14/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0114
Epoch 15/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0114
Epoch 16/20
 1/81 [..............................] - ETA: 0s - loss: 0.0021 - mae: 0.0399 - mse: 0.0021
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0056975833140313625.
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0114
Epoch 17/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0057
Epoch 18/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0057
Epoch 19/20
77/81 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0028487916570156813.
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0057
Epoch 20/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0028
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.09116133301013224_70_48_20epochs/model_5.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
81/81 [==============================] - 0s 2ms/step - loss: 0.0443 - mae: 0.0600 - mse: 0.0086 - val_loss: 0.0137 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0912
Epoch 2/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0171 - mae: 0.0486 - mse: 0.0039 - val_loss: 0.0145 - val_mae: 0.0400 - val_mse: 0.0022 - lr: 0.0912
Epoch 3/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0195 - mae: 0.0544 - mse: 0.0062 - val_loss: 0.1274 - val_mae: 0.3141 - val_mse: 0.1006 - lr: 0.0912
Epoch 4/20
 1/81 [..............................] - ETA: 0s - loss: 0.1218 - mae: 0.3056 - mse: 0.0950
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0455806665122509.
81/81 [==============================] - 0s 1ms/step - loss: 0.0216 - mae: 0.0557 - mse: 0.0081 - val_loss: 0.0138 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0912
Epoch 5/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0388 - mse: 0.0020 - val_loss: 0.0044 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0456
Epoch 6/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0043 - mae: 0.0396 - mse: 0.0022 - val_loss: 0.0037 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0456
Epoch 7/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0045 - mae: 0.0404 - mse: 0.0023 - val_loss: 0.0037 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0456
Epoch 8/20
77/81 [===========================>..] - ETA: 0s - loss: 0.0042 - mae: 0.0392 - mse: 0.0021
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.02279033325612545.
81/81 [==============================] - 0s 1ms/step - loss: 0.0042 - mae: 0.0391 - mse: 0.0021 - val_loss: 0.0045 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0456
Epoch 9/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0228
Epoch 10/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0228
Epoch 11/20
80/81 [============================>.] - ETA: 0s - loss: 0.0025 - mae: 0.0380 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.011395166628062725.
81/81 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0228
Epoch 12/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0114
Epoch 13/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0114
Epoch 14/20
81/81 [==============================] - ETA: 0s - loss: 0.0021 - mae: 0.0380 - mse: 0.0019
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0056975833140313625.
81/81 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0114
Epoch 15/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0057
Epoch 16/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0057
Epoch 17/20
78/81 [===========================>..] - ETA: 0s - loss: 0.0020 - mae: 0.0380 - mse: 0.0019
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0028487916570156813.
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0057
Epoch 18/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0028
Epoch 19/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0028
Epoch 20/20
41/81 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0014243958285078406.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0028
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.09116133301013224_70_48_20epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
81/81 [==============================] - 0s 2ms/step - loss: 0.0417 - mae: 0.0518 - mse: 0.0047 - val_loss: 0.0125 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0912
Epoch 2/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0156 - mae: 0.0433 - mse: 0.0028 - val_loss: 0.0175 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0912
Epoch 3/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0156 - mae: 0.0436 - mse: 0.0030 - val_loss: 0.0136 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0912
Epoch 4/20
80/81 [============================>.] - ETA: 0s - loss: 0.0158 - mae: 0.0438 - mse: 0.0030
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0455806665122509.
81/81 [==============================] - 0s 1ms/step - loss: 0.0158 - mae: 0.0437 - mse: 0.0030 - val_loss: 0.0141 - val_mae: 0.0389 - val_mse: 0.0020 - lr: 0.0912
Epoch 5/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0035 - val_mae: 0.0393 - val_mse: 0.0021 - lr: 0.0456
Epoch 6/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0042 - mae: 0.0389 - mse: 0.0021 - val_loss: 0.0040 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0456
Epoch 7/20
71/81 [=========================>....] - ETA: 0s - loss: 0.0042 - mae: 0.0387 - mse: 0.0020
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.02279033325612545.
81/81 [==============================] - 0s 1ms/step - loss: 0.0043 - mae: 0.0389 - mse: 0.0021 - val_loss: 0.0039 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0456
Epoch 8/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0228
Epoch 9/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0026 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0228
Epoch 10/20
70/81 [========================>.....] - ETA: 0s - loss: 0.0025 - mae: 0.0382 - mse: 0.0020
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.011395166628062725.
81/81 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0228
Epoch 11/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0114
Epoch 12/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0114
Epoch 13/20
78/81 [===========================>..] - ETA: 0s - loss: 0.0021 - mae: 0.0378 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0056975833140313625.
81/81 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0114
Epoch 14/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0057
Epoch 15/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0057
Epoch 16/20
80/81 [============================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0379 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0028487916570156813.
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0057
Epoch 17/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0028
Epoch 18/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0028
Epoch 19/20
81/81 [==============================] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0014243958285078406.
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0028
Epoch 20/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.09116133301013224_70_48_20epochs/model_7.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
81/81 [==============================] - 0s 2ms/step - loss: 0.0418 - mae: 0.0608 - mse: 0.0066 - val_loss: 0.0143 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0912
Epoch 2/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0167 - mae: 0.0441 - mse: 0.0033 - val_loss: 0.0137 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0912
Epoch 3/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0161 - mae: 0.0428 - mse: 0.0028 - val_loss: 0.0136 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0912
Epoch 4/20
77/81 [===========================>..] - ETA: 0s - loss: 0.0157 - mae: 0.0412 - mse: 0.0024
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0455806665122509.
81/81 [==============================] - 0s 1ms/step - loss: 0.0156 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.0136 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0912
Epoch 5/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0380 - mse: 0.0020 - val_loss: 0.0037 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0456
Epoch 6/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0041 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0039 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0456
Epoch 7/20
80/81 [============================>.] - ETA: 0s - loss: 0.0042 - mae: 0.0386 - mse: 0.0020
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.02279033325612545.
81/81 [==============================] - 0s 1ms/step - loss: 0.0042 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0042 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0456
Epoch 8/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0228
Epoch 9/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0228
Epoch 10/20
79/81 [============================>.] - ETA: 0s - loss: 0.0025 - mae: 0.0381 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.011395166628062725.
81/81 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0228
Epoch 11/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0114
Epoch 12/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0114
Epoch 13/20
77/81 [===========================>..] - ETA: 0s - loss: 0.0021 - mae: 0.0379 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0056975833140313625.
81/81 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0114
Epoch 14/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0057
Epoch 15/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0057
Epoch 16/20
78/81 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0028487916570156813.
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0057
Epoch 17/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0028
Epoch 18/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0028
Epoch 19/20
 1/81 [..............................] - ETA: 0s - loss: 0.0017 - mae: 0.0373 - mse: 0.0017
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0014243958285078406.
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0028
Epoch 20/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.09116133301013224_70_48_20epochs/model_8.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
81/81 [==============================] - 0s 2ms/step - loss: 0.0492 - mae: 0.0625 - mse: 0.0074 - val_loss: 0.0156 - val_mae: 0.0449 - val_mse: 0.0030 - lr: 0.0912
Epoch 2/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0153 - mae: 0.0401 - mse: 0.0022 - val_loss: 0.0151 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0912
Epoch 3/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0153 - mae: 0.0389 - mse: 0.0021 - val_loss: 0.0149 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0912
Epoch 4/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0151 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0143 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0912
Epoch 5/20
76/81 [===========================>..] - ETA: 0s - loss: 0.0152 - mae: 0.0390 - mse: 0.0021
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0455806665122509.
81/81 [==============================] - 0s 1ms/step - loss: 0.0152 - mae: 0.0390 - mse: 0.0021 - val_loss: 0.0142 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0912
Epoch 6/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0024 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0456
Epoch 7/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0456
Epoch 8/20
78/81 [===========================>..] - ETA: 0s - loss: 0.0023 - mae: 0.0380 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.02279033325612545.
81/81 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0456
Epoch 9/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0228
Epoch 10/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0228
Epoch 11/20
 1/81 [..............................] - ETA: 0s - loss: 0.0022 - mae: 0.0412 - mse: 0.0021
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.011395166628062725.
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0228
Epoch 12/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0114
Epoch 13/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0114
Epoch 14/20
 1/81 [..............................] - ETA: 0s - loss: 0.0021 - mae: 0.0399 - mse: 0.0021
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0056975833140313625.
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0114
Epoch 15/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0057
Epoch 16/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0057
Epoch 17/20
 1/81 [..............................] - ETA: 0s - loss: 0.0015 - mae: 0.0333 - mse: 0.0015
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0028487916570156813.
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0057
Epoch 18/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0028
Epoch 19/20
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0028
Epoch 20/20
76/81 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0014243958285078406.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_175856-aqt5qn2x\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 9ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0028
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.09116133301013224_70_48_20epochs/model_9.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])