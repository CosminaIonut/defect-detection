wandb: WARNING The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0092s). Check your callbacks.
Epoch 1/30
94/98 [===========================>..] - ETA: 0s - loss: 0.5395 - mae: 0.0708 - mse: 0.0086
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_185755-q8p4zn0d\files\model-best)... Done. 0.0s
98/98 [==============================] - 3s 24ms/step - loss: 0.5354 - mae: 0.0701 - mse: 0.0085 - val_loss: 0.4220 - val_mae: 0.0560 - val_mse: 0.0047 - lr: 0.0620
Epoch 2/30
98/98 [==============================] - 0s 3ms/step - loss: 0.4252 - mae: 0.0475 - mse: 0.0034 - val_loss: 0.4297 - val_mae: 0.0426 - val_mse: 0.0026 - lr: 0.0620
Epoch 3/30
98/98 [==============================] - 0s 4ms/step - loss: 0.4229 - mae: 0.0412 - mse: 0.0024 - val_loss: 0.4239 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0620
Epoch 4/30
72/98 [=====================>........] - ETA: 0s - loss: 0.4227 - mae: 0.0397 - mse: 0.0022
98/98 [==============================] - 2s 19ms/step - loss: 0.4230 - mae: 0.0400 - mse: 0.0022 - val_loss: 0.4177 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0620
Epoch 5/30
98/98 [==============================] - 0s 4ms/step - loss: 0.4231 - mae: 0.0405 - mse: 0.0023 - val_loss: 0.4295 - val_mae: 0.0830 - val_mse: 0.0088 - lr: 0.0620
Epoch 6/30
98/98 [==============================] - 0s 3ms/step - loss: 0.4231 - mae: 0.0413 - mse: 0.0024 - val_loss: 0.4213 - val_mae: 0.0438 - val_mse: 0.0028 - lr: 0.0620
Epoch 7/30
98/98 [==============================] - 0s 3ms/step - loss: 0.4230 - mae: 0.0410 - mse: 0.0024 - val_loss: 0.4308 - val_mae: 0.0408 - val_mse: 0.0024 - lr: 0.0620
Epoch 8/30
98/98 [==============================] - 0s 1ms/step - loss: 0.4231 - mae: 0.0426 - mse: 0.0028 - val_loss: 0.4256 - val_mae: 0.0400 - val_mse: 0.0022 - lr: 0.0620
Epoch 9/30
98/98 [==============================] - 0s 2ms/step - loss: 0.4242 - mae: 0.0425 - mse: 0.0026 - val_loss: 0.4310 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0620
Epoch 10/30
98/98 [==============================] - 0s 2ms/step - loss: 0.4230 - mae: 0.0419 - mse: 0.0028 - val_loss: 0.4505 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0620
Epoch 11/30
98/98 [==============================] - 0s 3ms/step - loss: 0.4246 - mae: 0.0418 - mse: 0.0025 - val_loss: 0.4267 - val_mae: 0.0666 - val_mse: 0.0063 - lr: 0.0620
Epoch 12/30
57/98 [================>.............] - ETA: 0s - loss: 0.4246 - mae: 0.0433 - mse: 0.0028
98/98 [==============================] - 1s 12ms/step - loss: 0.4244 - mae: 0.0446 - mse: 0.0033 - val_loss: 0.4153 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 0.0620
Epoch 13/30
69/98 [====================>.........] - ETA: 0s - loss: 0.4251 - mae: 0.0410 - mse: 0.0024
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.03100162371993065.
98/98 [==============================] - 0s 2ms/step - loss: 0.4235 - mae: 0.0408 - mse: 0.0024 - val_loss: 0.4167 - val_mae: 0.0477 - val_mse: 0.0034 - lr: 0.0620
Epoch 14/30
80/98 [=======================>......] - ETA: 0s - loss: 0.0778 - mae: 0.0384 - mse: 0.0020
98/98 [==============================] - 1s 11ms/step - loss: 0.0838 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.1131 - val_mae: 0.0426 - val_mse: 0.0026 - lr: 0.0310
Epoch 15/30
97/98 [============================>.] - ETA: 0s - loss: 0.1063 - mae: 0.0385 - mse: 0.0020
98/98 [==============================] - 1s 12ms/step - loss: 0.1063 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.1067 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0310
Epoch 16/30
98/98 [==============================] - 0s 2ms/step - loss: 0.1064 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.1083 - val_mae: 0.0424 - val_mse: 0.0026 - lr: 0.0310
Epoch 17/30
98/98 [==============================] - 0s 2ms/step - loss: 0.1065 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.1071 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0310
Epoch 18/30
98/98 [==============================] - 0s 2ms/step - loss: 0.1065 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.1081 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0310
Epoch 19/30
98/98 [==============================] - 0s 2ms/step - loss: 0.1064 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.1069 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0310
Epoch 20/30
98/98 [==============================] - 0s 2ms/step - loss: 0.1064 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.1096 - val_mae: 0.0404 - val_mse: 0.0023 - lr: 0.0310
Epoch 21/30
98/98 [==============================] - 1s 11ms/step - loss: 0.1064 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.1060 - val_mae: 0.0389 - val_mse: 0.0020 - lr: 0.0310
Epoch 22/30
88/98 [=========================>....] - ETA: 0s - loss: 0.1065 - mae: 0.0385 - mse: 0.0020
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_185755-q8p4zn0d\files\model-best)... Done. 0.0s
98/98 [==============================] - 1s 12ms/step - loss: 0.1066 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.1046 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0310
Epoch 23/30
62/98 [=================>............] - ETA: 0s - loss: 0.1064 - mae: 0.0384 - mse: 0.0020
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.015500811859965324.
98/98 [==============================] - 0s 2ms/step - loss: 0.1064 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.1065 - val_mae: 0.0413 - val_mse: 0.0024 - lr: 0.0310
Epoch 24/30
70/98 [====================>.........] - ETA: 0s - loss: 0.0206 - mae: 0.0383 - mse: 0.0020
98/98 [==============================] - 1s 12ms/step - loss: 0.0225 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0292 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0155
Epoch 25/30
93/98 [===========================>..] - ETA: 0s - loss: 0.0280 - mae: 0.0379 - mse: 0.0019
98/98 [==============================] - 1s 12ms/step - loss: 0.0280 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0289 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0155
Epoch 26/30
81/98 [=======================>......] - ETA: 0s - loss: 0.0281 - mae: 0.0379 - mse: 0.0019
98/98 [==============================] - 1s 12ms/step - loss: 0.0281 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0282 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0155
Epoch 27/30
86/98 [=========================>....] - ETA: 0s - loss: 0.0280 - mae: 0.0379 - mse: 0.0019
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0022s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0016s). Check your callbacks.
98/98 [==============================] - 1s 12ms/step - loss: 0.0280 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0280 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0155
Epoch 28/30
98/98 [==============================] - 0s 2ms/step - loss: 0.0280 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0283 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0155
Epoch 29/30
98/98 [==============================] - 0s 2ms/step - loss: 0.0280 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0297 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0155
Epoch 30/30
98/98 [==============================] - 0s 2ms/step - loss: 0.0281 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0282 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0155
>Saved ../trained_models/models_segments_overlap_rmsprop_0.06200324898080778LR_[32, 64, 128, 256]HN_40BS_10P_val_mseM_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
130/130 [==============================] - 1s 3ms/step - loss: 0.5088 - mae: 0.0764 - mse: 0.0100 - val_loss: 0.4179 - val_mae: 0.0729 - val_mse: 0.0079 - lr: 0.0620
Epoch 2/30
130/130 [==============================] - 0s 1ms/step - loss: 0.4280 - mae: 0.0632 - mse: 0.0064 - val_loss: 0.4149 - val_mae: 0.0841 - val_mse: 0.0102 - lr: 0.0620
Epoch 3/30
130/130 [==============================] - 0s 2ms/step - loss: 0.4287 - mae: 0.0622 - mse: 0.0059 - val_loss: 0.4881 - val_mae: 0.2818 - val_mse: 0.0828 - lr: 0.0620
Epoch 4/30
130/130 [==============================] - 0s 1ms/step - loss: 0.4291 - mae: 0.0636 - mse: 0.0065 - val_loss: 0.3940 - val_mae: 0.0602 - val_mse: 0.0053 - lr: 0.0620
Epoch 5/30
130/130 [==============================] - 0s 1ms/step - loss: 0.4334 - mae: 0.0694 - mse: 0.0081 - val_loss: 0.4419 - val_mae: 0.1001 - val_mse: 0.0134 - lr: 0.0620
Epoch 6/30
130/130 [==============================] - 0s 1ms/step - loss: 0.4301 - mae: 0.0645 - mse: 0.0070 - val_loss: 0.4069 - val_mae: 0.0522 - val_mse: 0.0038 - lr: 0.0620
Epoch 7/30
130/130 [==============================] - 0s 1ms/step - loss: 0.4298 - mae: 0.0647 - mse: 0.0074 - val_loss: 0.4183 - val_mae: 0.0520 - val_mse: 0.0037 - lr: 0.0620
Epoch 8/30
130/130 [==============================] - 0s 2ms/step - loss: 0.4353 - mae: 0.0662 - mse: 0.0086 - val_loss: 0.5623 - val_mae: 0.1636 - val_mse: 0.0302 - lr: 0.0620
Epoch 9/30
130/130 [==============================] - 0s 2ms/step - loss: 0.4278 - mae: 0.0626 - mse: 0.0060 - val_loss: 0.7274 - val_mae: 0.1586 - val_mse: 0.0286 - lr: 0.0620
Epoch 10/30
130/130 [==============================] - 0s 2ms/step - loss: 0.4262 - mae: 0.0586 - mse: 0.0052 - val_loss: 0.4543 - val_mae: 0.1409 - val_mse: 0.0233 - lr: 0.0620
Epoch 11/30
130/130 [==============================] - 0s 2ms/step - loss: 0.4328 - mae: 0.0688 - mse: 0.0080 - val_loss: 0.4474 - val_mae: 0.0713 - val_mse: 0.0075 - lr: 0.0620
Epoch 12/30
130/130 [==============================] - 0s 2ms/step - loss: 0.4320 - mae: 0.0653 - mse: 0.0090 - val_loss: 0.4295 - val_mae: 0.0539 - val_mse: 0.0041 - lr: 0.0620
Epoch 13/30
130/130 [==============================] - 0s 2ms/step - loss: 0.4265 - mae: 0.0618 - mse: 0.0059 - val_loss: 0.4221 - val_mae: 0.0768 - val_mse: 0.0087 - lr: 0.0620
Epoch 14/30
130/130 [==============================] - 0s 2ms/step - loss: 0.4347 - mae: 0.0661 - mse: 0.0088 - val_loss: 0.4337 - val_mae: 0.0684 - val_mse: 0.0070 - lr: 0.0620
Epoch 15/30
130/130 [==============================] - 0s 2ms/step - loss: 0.4296 - mae: 0.0659 - mse: 0.0068 - val_loss: 0.4326 - val_mae: 0.0508 - val_mse: 0.0035 - lr: 0.0620
Epoch 16/30
130/130 [==============================] - 0s 1ms/step - loss: 0.4396 - mae: 0.0769 - mse: 0.0106 - val_loss: 0.4329 - val_mae: 0.0556 - val_mse: 0.0045 - lr: 0.0620
Epoch 17/30
130/130 [==============================] - 0s 1ms/step - loss: 0.4301 - mae: 0.0673 - mse: 0.0071 - val_loss: 0.4494 - val_mae: 0.1405 - val_mse: 0.0231 - lr: 0.0620
Epoch 18/30
130/130 [==============================] - 0s 1ms/step - loss: 0.4627 - mae: 0.0878 - mse: 0.0161 - val_loss: 0.3351 - val_mae: 0.0838 - val_mse: 0.0101 - lr: 0.0620
Epoch 19/30
130/130 [==============================] - 0s 1ms/step - loss: 0.4310 - mae: 0.0726 - mse: 0.0122 - val_loss: 0.4155 - val_mae: 0.0635 - val_mse: 0.0060 - lr: 0.0620
Epoch 20/30
130/130 [==============================] - 0s 1ms/step - loss: 0.4299 - mae: 0.0674 - mse: 0.0077 - val_loss: 0.4442 - val_mae: 0.0692 - val_mse: 0.0072 - lr: 0.0620
Epoch 21/30
130/130 [==============================] - 0s 1ms/step - loss: 0.4457 - mae: 0.0781 - mse: 0.0153 - val_loss: 0.5189 - val_mae: 0.1812 - val_mse: 0.0362 - lr: 0.0620
Epoch 22/30
130/130 [==============================] - 0s 1ms/step - loss: 0.4281 - mae: 0.0644 - mse: 0.0064 - val_loss: 0.4526 - val_mae: 0.0683 - val_mse: 0.0070 - lr: 0.0620
Epoch 23/30
130/130 [==============================] - 0s 1ms/step - loss: 0.4276 - mae: 0.0603 - mse: 0.0057 - val_loss: 0.4688 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0620
Epoch 24/30
130/130 [==============================] - 0s 1ms/step - loss: 0.4331 - mae: 0.0667 - mse: 0.0075 - val_loss: 0.4429 - val_mae: 0.1198 - val_mse: 0.0178 - lr: 0.0620
Epoch 25/30
130/130 [==============================] - 0s 2ms/step - loss: 0.4405 - mae: 0.0733 - mse: 0.0112 - val_loss: 0.4030 - val_mae: 0.0506 - val_mse: 0.0035 - lr: 0.0620
Epoch 26/30
130/130 [==============================] - 0s 1ms/step - loss: 0.4284 - mae: 0.0643 - mse: 0.0065 - val_loss: 0.4114 - val_mae: 0.0529 - val_mse: 0.0039 - lr: 0.0620
Epoch 27/30
130/130 [==============================] - 0s 1ms/step - loss: 0.4293 - mae: 0.0642 - mse: 0.0067 - val_loss: 0.6186 - val_mae: 0.4127 - val_mse: 0.1737 - lr: 0.0620
Epoch 28/30
130/130 [==============================] - 0s 1ms/step - loss: 0.4566 - mae: 0.0718 - mse: 0.0122 - val_loss: 0.4598 - val_mae: 0.1677 - val_mse: 0.0315 - lr: 0.0620
Epoch 29/30
130/130 [==============================] - 0s 2ms/step - loss: 0.4290 - mae: 0.0618 - mse: 0.0060 - val_loss: 0.4257 - val_mae: 0.1191 - val_mse: 0.0176 - lr: 0.0620
Epoch 30/30
130/130 [==============================] - 0s 2ms/step - loss: 0.4277 - mae: 0.0606 - mse: 0.0063 - val_loss: 0.4332 - val_mae: 0.1446 - val_mse: 0.0243 - lr: 0.0620
>Saved ../trained_models/models_segments_overlap_rmsprop_0.06200324898080778LR_[32, 64, 128, 256]HN_40BS_10P_val_mseM_30epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
98/98 [==============================] - 1s 3ms/step - loss: 0.5544 - mae: 0.1010 - mse: 0.0218 - val_loss: 0.4150 - val_mae: 0.0443 - val_mse: 0.0029 - lr: 0.0620
Epoch 2/30
98/98 [==============================] - 0s 1ms/step - loss: 0.4421 - mae: 0.0740 - mse: 0.0120 - val_loss: 0.3846 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0620
Epoch 3/30
98/98 [==============================] - 0s 2ms/step - loss: 0.4523 - mae: 0.0816 - mse: 0.0169 - val_loss: 0.4152 - val_mae: 0.0632 - val_mse: 0.0058 - lr: 0.0620
Epoch 4/30
98/98 [==============================] - 0s 1ms/step - loss: 0.4747 - mae: 0.0967 - mse: 0.0223 - val_loss: 0.2869 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0620
Epoch 5/30
98/98 [==============================] - 0s 2ms/step - loss: 0.4204 - mae: 0.0609 - mse: 0.0081 - val_loss: 0.4343 - val_mae: 0.0462 - val_mse: 0.0032 - lr: 0.0620
Epoch 6/30
98/98 [==============================] - 0s 2ms/step - loss: 0.4354 - mae: 0.0703 - mse: 0.0142 - val_loss: 0.4310 - val_mae: 0.0409 - val_mse: 0.0023 - lr: 0.0620
Epoch 7/30
98/98 [==============================] - 0s 2ms/step - loss: 0.4459 - mae: 0.0725 - mse: 0.0172 - val_loss: 0.5753 - val_mae: 0.2192 - val_mse: 0.0500 - lr: 0.0620
Epoch 8/30
98/98 [==============================] - 0s 2ms/step - loss: 0.4826 - mae: 0.0863 - mse: 0.0214 - val_loss: 0.2357 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0620
Epoch 9/30
98/98 [==============================] - 0s 2ms/step - loss: 0.4386 - mae: 0.0969 - mse: 0.0209 - val_loss: 0.4251 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0620
Epoch 10/30
98/98 [==============================] - 0s 2ms/step - loss: 0.4587 - mae: 0.0969 - mse: 0.0228 - val_loss: 0.3612 - val_mae: 0.0397 - val_mse: 0.0022 - lr: 0.0620
Epoch 11/30
98/98 [==============================] - 0s 1ms/step - loss: 0.4419 - mae: 0.0789 - mse: 0.0139 - val_loss: 0.4269 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0620
Epoch 12/30
87/98 [=========================>....] - ETA: 0s - loss: 0.4405 - mae: 0.0717 - mse: 0.0125
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.03100162371993065.
98/98 [==============================] - 0s 2ms/step - loss: 0.5114 - mae: 0.0970 - mse: 0.0232 - val_loss: 0.2905 - val_mae: 0.2212 - val_mse: 0.0509 - lr: 0.0620
Epoch 13/30
98/98 [==============================] - 0s 2ms/step - loss: 0.0802 - mae: 0.0463 - mse: 0.0036 - val_loss: 0.1151 - val_mae: 0.0395 - val_mse: 0.0021 - lr: 0.0310
Epoch 14/30
98/98 [==============================] - 0s 2ms/step - loss: 0.1075 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.1053 - val_mae: 0.0405 - val_mse: 0.0023 - lr: 0.0310
Epoch 15/30
98/98 [==============================] - 0s 2ms/step - loss: 0.1069 - mae: 0.0402 - mse: 0.0023 - val_loss: 0.1060 - val_mae: 0.0401 - val_mse: 0.0022 - lr: 0.0310
Epoch 16/30
98/98 [==============================] - 0s 2ms/step - loss: 0.1068 - mae: 0.0396 - mse: 0.0022 - val_loss: 0.1182 - val_mae: 0.0472 - val_mse: 0.0033 - lr: 0.0310
Epoch 17/30
98/98 [==============================] - 0s 1ms/step - loss: 0.1070 - mae: 0.0421 - mse: 0.0026 - val_loss: 0.1059 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0310
Epoch 18/30
98/98 [==============================] - 0s 2ms/step - loss: 0.1083 - mae: 0.0449 - mse: 0.0036 - val_loss: 0.1116 - val_mae: 0.0395 - val_mse: 0.0021 - lr: 0.0310
Epoch 19/30
98/98 [==============================] - 0s 2ms/step - loss: 0.1069 - mae: 0.0407 - mse: 0.0023 - val_loss: 0.1081 - val_mae: 0.0393 - val_mse: 0.0021 - lr: 0.0310
Epoch 20/30
98/98 [==============================] - 0s 2ms/step - loss: 0.1069 - mae: 0.0402 - mse: 0.0023 - val_loss: 0.1061 - val_mae: 0.0393 - val_mse: 0.0021 - lr: 0.0310
Epoch 21/30
98/98 [==============================] - 0s 2ms/step - loss: 0.1067 - mae: 0.0409 - mse: 0.0024 - val_loss: 0.1059 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0310
Epoch 22/30
88/98 [=========================>....] - ETA: 0s - loss: 0.1071 - mae: 0.0421 - mse: 0.0026
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.015500811859965324.
98/98 [==============================] - 0s 2ms/step - loss: 0.1070 - mae: 0.0418 - mse: 0.0026 - val_loss: 0.1142 - val_mae: 0.0760 - val_mse: 0.0077 - lr: 0.0310
Epoch 23/30
98/98 [==============================] - 0s 2ms/step - loss: 0.0228 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0287 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0155
Epoch 24/30
98/98 [==============================] - 0s 2ms/step - loss: 0.0281 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0297 - val_mae: 0.0437 - val_mse: 0.0028 - lr: 0.0155
Epoch 25/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0281 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0288 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0155
Epoch 26/30
56/98 [================>.............] - ETA: 0s - loss: 0.0281 - mae: 0.0384 - mse: 0.0020
98/98 [==============================] - 1s 12ms/step - loss: 0.0281 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0280 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0155
Epoch 27/30
98/98 [==============================] - 0s 2ms/step - loss: 0.0281 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0283 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0155
Epoch 28/30
98/98 [==============================] - 0s 2ms/step - loss: 0.0281 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0312 - val_mae: 0.0478 - val_mse: 0.0034 - lr: 0.0155
Epoch 29/30
53/98 [===============>..............] - ETA: 0s - loss: 0.0282 - mae: 0.0382 - mse: 0.0020
98/98 [==============================] - 1s 12ms/step - loss: 0.0281 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0280 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0155
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_185755-q8p4zn0d\files\model-best)... Done. 0.0s
Epoch 2/30===========================] - 1s 12ms/step - loss: 0.0281 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0280 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0155
Epoch 2/30===========================] - 1s 12ms/step - loss: 0.0281 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0280 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0155
Epoch 13/30==========================] - 1s 12ms/step - loss: 0.0281 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0280 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0155
Epoch 13/30==========================] - 1s 12ms/step - loss: 0.0281 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0280 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0155
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_185755-q8p4zn0d\files\model-best)... Done. 0.0s
Epoch 13/30==========================] - 1s 12ms/step - loss: 0.0281 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0280 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0155
>Saved ../trained_models/models_segments_overlap_rmsprop_0.06200324898080778LR_[32, 64, 128, 256]HN_40BS_10P_val_mseM_30epochs/model_5.h5al_mse: 0.0019 - lr: 0.0155
Epoch 19/30rained_models/models_segments_overlap_rmsprop_0.06200324898080778LR_[32, 64, 128, 256]HN_40BS_10P_val_mseM_30epochs/model_5.h5al_mse: 0.0019 - lr: 0.0155
Epoch 19/30rained_models/models_segments_overlap_rmsprop_0.06200324898080778LR_[32, 64, 128, 256]HN_40BS_10P_val_mseM_30epochs/model_5.h5al_mse: 0.0019 - lr: 0.0155
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0021s). Check your callbacks.
Epoch 9/300rained_models/models_segments_overlap_rmsprop_0.06200324898080778LR_[32, 64, 128, 256]HN_40BS_10P_val_mseM_30epochs/model_5.h5al_mse: 0.0019 - lr: 0.0155
Epoch 21/30rained_models/models_segments_overlap_rmsprop_0.06200324898080778LR_[32, 64, 128, 256]HN_40BS_10P_val_mseM_30epochs/model_5.h5al_mse: 0.0019 - lr: 0.0155
Epoch 21/30rained_models/models_segments_overlap_rmsprop_0.06200324898080778LR_[32, 64, 128, 256]HN_40BS_10P_val_mseM_30epochs/model_5.h5al_mse: 0.0019 - lr: 0.0155
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0022s). Check your callbacks.
Epoch 10/30rained_models/models_segments_overlap_rmsprop_0.06200324898080778LR_[32, 64, 128, 256]HN_40BS_10P_val_mseM_30epochs/model_5.h5al_mse: 0.0019 - lr: 0.0155
Epoch 23/30rained_models/models_segments_overlap_rmsprop_0.06200324898080778LR_[32, 64, 128, 256]HN_40BS_10P_val_mseM_30epochs/model_5.h5al_mse: 0.0019 - lr: 0.0155
Epoch 23/30rained_models/models_segments_overlap_rmsprop_0.06200324898080778LR_[32, 64, 128, 256]HN_40BS_10P_val_mseM_30epochs/model_5.h5al_mse: 0.0019 - lr: 0.0155
Epoch 6/300rained_models/models_segments_overlap_rmsprop_0.06200324898080778LR_[32, 64, 128, 256]HN_40BS_10P_val_mseM_30epochs/model_5.h5al_mse: 0.0019 - lr: 0.0155
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.03100162371993065.78LR_[32, 64, 128, 256]HN_40BS_10P_val_mseM_30epochs/model_5.h5al_mse: 0.0019 - lr: 0.0155
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.015500811859965324.8LR_[32, 64, 128, 256]HN_40BS_10P_val_mseM_30epochs/model_5.h5al_mse: 0.0019 - lr: 0.0155
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.015500811859965324.8LR_[32, 64, 128, 256]HN_40BS_10P_val_mseM_30epochs/model_5.h5al_mse: 0.0019 - lr: 0.0155
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.015500811859965324.8LR_[32, 64, 128, 256]HN_40BS_10P_val_mseM_30epochs/model_5.h5al_mse: 0.0019 - lr: 0.0155