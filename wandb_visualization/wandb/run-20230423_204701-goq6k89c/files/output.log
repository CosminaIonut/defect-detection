Epoch 1/30
243/243 [==============================] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
243/243 [==============================] - 2s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0099
Epoch 2/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0099
Epoch 3/30
243/243 [==============================] - 1s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0099
Epoch 4/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0099
Epoch 5/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0099
Epoch 6/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0099
Epoch 7/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0099
Epoch 8/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0099
Epoch 9/30
243/243 [==============================] - 1s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0099
Epoch 10/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0099
Epoch 11/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0099
Epoch 12/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0099
Epoch 13/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0099
Epoch 14/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0099
Epoch 15/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0099
Epoch 16/30
226/243 [==========================>...] - ETA: 0s - loss: 0.8587 - mae: 0.9256 - mse: 0.8587
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.004955607932060957.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0099
Epoch 17/30
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0050
Epoch 18/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0050
Epoch 19/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0050
Epoch 20/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0050
Epoch 21/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0050
Epoch 22/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0050
Epoch 23/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0050
Epoch 24/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0050
Epoch 25/30
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0050
Epoch 26/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0050
Epoch 27/30
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0050
Epoch 28/30
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0050
Epoch 29/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0050
Epoch 30/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0050
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.009911215796559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
235/323 [====================>.........] - ETA: 0s - loss: 0.6422 - mae: 0.7992 - mse: 0.6422
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.

323/323 [==============================] - 3s 6ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0099
Epoch 2/30
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0099
Epoch 3/30
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0099
Epoch 4/30
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0099
Epoch 5/30
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0099
Epoch 6/30
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0099
Epoch 7/30
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0099
Epoch 8/30
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0099
Epoch 9/30
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0099
Epoch 10/30
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0099
Epoch 11/30
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0099
Epoch 12/30
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0099
Epoch 13/30
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0099
Epoch 14/30
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0099
Epoch 15/30
323/323 [==============================] - 1s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0099
Epoch 16/30
323/323 [==============================] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.004955607932060957.
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0099
Epoch 17/30
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0050
Epoch 18/30
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0050
Epoch 19/30
 84/323 [======>.......................] - ETA: 0s - loss: 0.6430 - mae: 0.7998 - mse: 0.64306431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0050
Epoch 20/30
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0050
Epoch 21/30
100/323 [========>.....................] - ETA: 0s - loss: 0.6442 - mae: 0.8005 - mse: 0.64426431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0050
Epoch 22/30
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0050
Epoch 23/30
 67/323 [=====>........................] - ETA: 0s - loss: 0.6461 - mae: 0.8017 - mse: 0.64616431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0050
Epoch 24/30
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0050
Epoch 25/30
 43/323 [==>...........................] - ETA: 0s - loss: 0.6476 - mae: 0.8026 - mse: 0.64766431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0050
Epoch 26/30
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0050
Epoch 27/30
 20/323 [>.............................] - ETA: 0s - loss: 0.6452 - mae: 0.8012 - mse: 0.64526431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0050
Epoch 28/30
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0050
Epoch 29/30
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0050
Epoch 30/30
300/323 [==========================>...] - ETA: 0s - loss: 0.6427 - mae: 0.7996 - mse: 0.6427
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0050
Epoch 1/30
108/243 [============>.................] - ETA: 0s - loss: 0.4577 - mae: 0.6751 - mse: 0.4577
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0050
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230423_204701-goq6k89c\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0099
Epoch 5/30
 95/243 [==========>...................] - ETA: 0s - loss: 0.4582 - mae: 0.6755 - mse: 0.4582
243/243 [==============================] - 1s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0099
Epoch 7/30
231/243 [===========================>..] - ETA: 0s - loss: 0.4579 - mae: 0.6753 - mse: 0.4579
214/243 [=========================>....] - ETA: 0s - loss: 0.4581 - mae: 0.6754 - mse: 0.45814578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0099
Epoch 9/30
243/243 [==============================] - 1s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0099
Epoch 10/30
243/243 [==============================] - 1s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0099
Epoch 11/30
243/243 [==============================] - 1s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0099
Epoch 12/30
243/243 [==============================] - 1s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0099
Epoch 13/30
243/243 [==============================] - 1s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0099
Epoch 14/30
 40/243 [===>..........................] - ETA: 0s - loss: 0.4575 - mae: 0.6749 - mse: 0.45754578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0099
Epoch 15/30
243/243 [==============================] - 1s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0099
Epoch 16/30
224/243 [==========================>...] - ETA: 0s - loss: 0.4576 - mae: 0.6751 - mse: 0.4576
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.004955607932060957.
243/243 [==============================] - 1s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0099
Epoch 17/30
243/243 [==============================] - 1s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0050
Epoch 18/30
243/243 [==============================] - 1s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0050
Epoch 19/30
243/243 [==============================] - 1s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0050
Epoch 20/30
  1/243 [..............................] - ETA: 2s - loss: 0.4370 - mae: 0.6603 - mse: 0.4370
243/243 [==============================] - 1s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0050
Epoch 22/30
218/243 [=========================>....] - ETA: 0s - loss: 0.4581 - mae: 0.6754 - mse: 0.4581
192/243 [======================>.......] - ETA: 0s - loss: 0.4574 - mae: 0.6749 - mse: 0.45744578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0050
243/243 [==============================] - 1s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0050
243/243 [==============================] - 1s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0050
243/243 [==============================] - 1s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0050
243/243 [==============================] - 1s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0050
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0037s vs `on_train_batch_end` time: 0.0052s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0037s vs `on_train_batch_end` time: 0.0052s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230423_204701-goq6k89c\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0099
243/243 [==============================] - 1s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0099
224/243 [==========================>...] - ETA: 0s - loss: 0.3326 - mae: 0.5751 - mse: 0.33263328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0099
243/243 [==============================] - 1s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0099
243/243 [==============================] - 1s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0099
243/243 [==============================] - 1s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0050
243/243 [==============================] - 1s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0050
179/243 [=====================>........] - ETA: 0s - loss: 0.3331 - mae: 0.5755 - mse: 0.33313328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0050
243/243 [==============================] - 1s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0050
243/243 [==============================] - 1s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0050
243/243 [==============================] - 1s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0050
243/243 [==============================] - 1s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0050
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
 60/243 [======>.......................] - ETA: 0s - loss: 0.2277 - mae: 0.4751 - mse: 0.22772277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0099
243/243 [==============================] - 1s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0099
243/243 [==============================] - 1s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0099
 90/243 [==========>...................] - ETA: 0s - loss: 0.2281 - mae: 0.4756 - mse: 0.22812277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0099
243/243 [==============================] - 1s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0099
243/243 [==============================] - 1s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0050
140/243 [================>.............] - ETA: 0s - loss: 0.2281 - mae: 0.4756 - mse: 0.22812277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0050
243/243 [==============================] - 1s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0050
243/243 [==============================] - 1s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0050
 21/243 [=>............................] - ETA: 0s - loss: 0.2271 - mae: 0.4746 - mse: 0.22712277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0050
243/243 [==============================] - 1s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0050
243/243 [==============================] - 1s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0050
243/243 [==============================] - 1s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0050
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
167/243 [===================>..........] - ETA: 0s - loss: 0.1430 - mae: 0.3757 - mse: 0.14301427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0099
243/243 [==============================] - 1s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0099
235/243 [============================>.] - ETA: 0s - loss: 0.1427 - mae: 0.3752 - mse: 0.14271427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0099
243/243 [==============================] - 1s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0099
243/243 [==============================] - 1s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0099
243/243 [==============================] - 1s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0050
243/243 [==============================] - 1s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0050
243/243 [==============================] - 1s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0050
243/243 [==============================] - 1s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0050
Epoch 29/30============================] - 1s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0050
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.009911215796559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.009911215796559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.009911215796559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 7/30trained_models/models_segments_overlap-cnn_rmsprop_0.009911215796559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 7/30trained_models/models_segments_overlap-cnn_rmsprop_0.009911215796559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 11/30rained_models/models_segments_overlap-cnn_rmsprop_0.009911215796559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 14/30rained_models/models_segments_overlap-cnn_rmsprop_0.009911215796559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 19/30educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 22/30educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 24/30educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 27/30educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 29/30educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 1/300educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 1/300educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 1/300educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 3/300educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 7/300educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 9/300educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 11/30educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 14/30educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 16/30educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 19/30educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 22/30educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 24/30educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 27/30educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 29/30educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 1/300educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 1/300educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_end` time: 0.0027s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_end` time: 0.0027s). Check your callbacks.
Epoch 1/300educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 7/300educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 7/300educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 11/30educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 14/30educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 16/30educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 19/30educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 21/30educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 23/30educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 26/30educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
Epoch 28/30educeLROnPlateau reducing learning rate to 0.004955607932060957.559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_6.h5val_mse: 0.1423 - lr: 0.0050
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.009911215796559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_9.h5val_mse: 0.1423 - lr: 0.0050
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.009911215796559717LR_[37]CHN_64CNNI_16BS_15P_val_lossM_30epochs/model_9.h5val_mse: 0.1423 - lr: 0.0050