Epoch 1/150
232/243 [===========================>..] - ETA: 0s - loss: 0.0222 - mae: 0.0459 - mse: 0.0044
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.
243/243 [==============================] - 2s 5ms/step - loss: 0.0214 - mae: 0.0457 - mse: 0.0043 - val_loss: 0.0027 - val_mae: 0.0369 - val_mse: 0.0019 - lr: 0.0523
Epoch 2/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0024 - mae: 0.0368 - mse: 0.0020 - val_loss: 0.0031 - val_mae: 0.0446 - val_mse: 0.0029 - lr: 0.0523
Epoch 3/150
237/243 [============================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0333 - mse: 0.0016
243/243 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0332 - mse: 0.0016 - val_loss: 0.0016 - val_mae: 0.0297 - val_mse: 0.0013 - lr: 0.0523
Epoch 4/150
195/243 [=======================>......] - ETA: 0s - loss: 0.0016 - mae: 0.0299 - mse: 0.0014
243/243 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0294 - mse: 0.0013 - val_loss: 0.0016 - val_mae: 0.0303 - val_mse: 0.0014 - lr: 0.0523
Epoch 5/150
202/243 [=======================>......] - ETA: 0s - loss: 0.0014 - mae: 0.0271 - mse: 0.0012
243/243 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0273 - mse: 0.0012 - val_loss: 0.0014 - val_mae: 0.0266 - val_mse: 0.0011 - lr: 0.0523
Epoch 6/150
243/243 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0267 - mse: 0.0011 - val_loss: 0.0014 - val_mae: 0.0273 - val_mse: 0.0011 - lr: 0.0523
Epoch 7/150
226/243 [==========================>...] - ETA: 0s - loss: 0.0013 - mae: 0.0254 - mse: 0.0010
243/243 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0254 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0240 - val_mse: 9.4180e-04 - lr: 0.0523
Epoch 8/150
243/243 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0254 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0235 - val_mse: 8.9594e-04 - lr: 0.0523
Epoch 9/150
240/243 [============================>.] - ETA: 0s - loss: 0.0011 - mae: 0.0239 - mse: 9.4561e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.1s
243/243 [==============================] - 1s 5ms/step - loss: 0.0011 - mae: 0.0239 - mse: 9.4419e-04 - val_loss: 0.0010 - val_mae: 0.0237 - val_mse: 9.0625e-04 - lr: 0.0523
Epoch 10/150
215/243 [=========================>....] - ETA: 0s - loss: 0.0012 - mae: 0.0241 - mse: 9.4547e-04
243/243 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0240 - mse: 9.3952e-04 - val_loss: 0.0010 - val_mae: 0.0222 - val_mse: 8.0392e-04 - lr: 0.0523
Epoch 11/150
224/243 [==========================>...] - ETA: 0s - loss: 0.0012 - mae: 0.0241 - mse: 9.3837e-04
243/243 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0240 - mse: 9.3793e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.0709e-04 - lr: 0.0523
Epoch 12/150
243/243 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0231 - mse: 8.6416e-04 - val_loss: 9.7504e-04 - val_mae: 0.0231 - val_mse: 8.7744e-04 - lr: 0.0523
Epoch 13/150
213/243 [=========================>....] - ETA: 0s - loss: 0.0011 - mae: 0.0233 - mse: 8.9334e-04
243/243 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0232 - mse: 8.8507e-04 - val_loss: 9.3041e-04 - val_mae: 0.0217 - val_mse: 7.5642e-04 - lr: 0.0523
Epoch 14/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0244 - mse: 9.8245e-04 - val_loss: 0.0011 - val_mae: 0.0243 - val_mse: 9.4396e-04 - lr: 0.0523
Epoch 15/150
162/243 [===================>..........] - ETA: 0s - loss: 9.4392e-04 - mae: 0.0221 - mse: 8.0671e-04
243/243 [==============================] - 1s 3ms/step - loss: 9.7974e-04 - mae: 0.0224 - mse: 8.2642e-04 - val_loss: 8.7002e-04 - val_mae: 0.0217 - val_mse: 7.6945e-04 - lr: 0.0523
Epoch 16/150
243/243 [==============================] - 0s 966us/step - loss: 0.0010 - mae: 0.0230 - mse: 8.6565e-04 - val_loss: 8.9908e-04 - val_mae: 0.0216 - val_mse: 7.6090e-04 - lr: 0.0523
Epoch 17/150
243/243 [==============================] - 0s 996us/step - loss: 9.9416e-04 - mae: 0.0225 - mse: 8.2614e-04 - val_loss: 9.2646e-04 - val_mae: 0.0217 - val_mse: 7.4966e-04 - lr: 0.0523
Epoch 18/150
243/243 [==============================] - 0s 947us/step - loss: 9.7623e-04 - mae: 0.0225 - mse: 8.3655e-04 - val_loss: 8.8275e-04 - val_mae: 0.0227 - val_mse: 8.0662e-04 - lr: 0.0523
Epoch 19/150
243/243 [==============================] - 0s 976us/step - loss: 0.0010 - mae: 0.0227 - mse: 8.3189e-04 - val_loss: 0.0012 - val_mae: 0.0247 - val_mse: 9.7554e-04 - lr: 0.0523
Epoch 20/150
241/243 [============================>.] - ETA: 0s - loss: 0.0010 - mae: 0.0226 - mse: 8.3272e-04
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.02613389492034912.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0227 - mse: 8.3747e-04 - val_loss: 8.3718e-04 - val_mae: 0.0209 - val_mse: 7.1750e-04 - lr: 0.0523
Epoch 21/150
241/243 [============================>.] - ETA: 0s - loss: 8.4909e-04 - mae: 0.0211 - mse: 7.3164e-04
243/243 [==============================] - 1s 3ms/step - loss: 8.4840e-04 - mae: 0.0211 - mse: 7.3079e-04 - val_loss: 8.2741e-04 - val_mae: 0.0210 - val_mse: 7.1327e-04 - lr: 0.0261
Epoch 22/150
243/243 [==============================] - 0s 1ms/step - loss: 8.5112e-04 - mae: 0.0215 - mse: 7.4989e-04 - val_loss: 0.0010 - val_mae: 0.0251 - val_mse: 9.7642e-04 - lr: 0.0261
Epoch 23/150
243/243 [==============================] - 0s 1ms/step - loss: 8.8256e-04 - mae: 0.0218 - mse: 7.7311e-04 - val_loss: 8.3267e-04 - val_mae: 0.0208 - val_mse: 7.0618e-04 - lr: 0.0261
Epoch 24/150
213/243 [=========================>....] - ETA: 0s - loss: 8.5091e-04 - mae: 0.0213 - mse: 7.4625e-04
243/243 [==============================] - 1s 6ms/step - loss: 8.3163e-04 - mae: 0.0211 - mse: 7.3055e-04 - val_loss: 8.1411e-04 - val_mae: 0.0220 - val_mse: 7.6307e-04 - lr: 0.0261
Epoch 25/150
241/243 [============================>.] - ETA: 0s - loss: 8.5167e-04 - mae: 0.0214 - mse: 7.4696e-04
243/243 [==============================] - 1s 4ms/step - loss: 8.5071e-04 - mae: 0.0213 - mse: 7.4613e-04 - val_loss: 7.7655e-04 - val_mae: 0.0205 - val_mse: 6.8415e-04 - lr: 0.0261
Epoch 26/150
243/243 [==============================] - 0s 1ms/step - loss: 8.9490e-04 - mae: 0.0218 - mse: 7.7410e-04 - val_loss: 9.4889e-04 - val_mae: 0.0232 - val_mse: 8.3561e-04 - lr: 0.0261
Epoch 27/150
243/243 [==============================] - 0s 1ms/step - loss: 8.6602e-04 - mae: 0.0213 - mse: 7.4886e-04 - val_loss: 8.2166e-04 - val_mae: 0.0195 - val_mse: 6.2542e-04 - lr: 0.0261
Epoch 28/150
243/243 [==============================] - 0s 1ms/step - loss: 8.7698e-04 - mae: 0.0212 - mse: 7.4404e-04 - val_loss: 8.1551e-04 - val_mae: 0.0219 - val_mse: 7.5217e-04 - lr: 0.0261
Epoch 29/150
197/243 [=======================>......] - ETA: 0s - loss: 7.9631e-04 - mae: 0.0205 - mse: 6.9031e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 5ms/step - loss: 8.0054e-04 - mae: 0.0204 - mse: 6.9150e-04 - val_loss: 7.6860e-04 - val_mae: 0.0200 - val_mse: 6.5255e-04 - lr: 0.0261
Epoch 30/150
243/243 [==============================] - 1s 5ms/step - loss: 8.2990e-04 - mae: 0.0205 - mse: 7.0619e-04 - val_loss: 7.3277e-04 - val_mae: 0.0193 - val_mse: 6.0649e-04 - lr: 0.0261
Epoch 31/150
243/243 [==============================] - 0s 1ms/step - loss: 8.2194e-04 - mae: 0.0205 - mse: 6.9470e-04 - val_loss: 9.1701e-04 - val_mae: 0.0222 - val_mse: 7.9663e-04 - lr: 0.0261
Epoch 32/150
219/243 [==========================>...] - ETA: 0s - loss: 8.2684e-04 - mae: 0.0205 - mse: 6.9658e-04
243/243 [==============================] - 1s 6ms/step - loss: 8.2093e-04 - mae: 0.0205 - mse: 6.9425e-04 - val_loss: 7.0105e-04 - val_mae: 0.0186 - val_mse: 5.8945e-04 - lr: 0.0261
Epoch 33/150
243/243 [==============================] - 0s 2ms/step - loss: 7.7286e-04 - mae: 0.0197 - mse: 6.6147e-04 - val_loss: 7.4236e-04 - val_mae: 0.0199 - val_mse: 6.3615e-04 - lr: 0.0261
Epoch 34/150
243/243 [==============================] - 0s 2ms/step - loss: 8.6229e-04 - mae: 0.0204 - mse: 6.9019e-04 - val_loss: 7.7248e-04 - val_mae: 0.0204 - val_mse: 6.7859e-04 - lr: 0.0261
Epoch 35/150
234/243 [===========================>..] - ETA: 0s - loss: 7.8674e-04 - mae: 0.0196 - mse: 6.5367e-04
Epoch 35: ReduceLROnPlateau reducing learning rate to 0.01306694746017456.
243/243 [==============================] - 0s 2ms/step - loss: 7.8705e-04 - mae: 0.0197 - mse: 6.5466e-04 - val_loss: 7.3428e-04 - val_mae: 0.0198 - val_mse: 6.2587e-04 - lr: 0.0261
Epoch 36/150
243/243 [==============================] - 0s 2ms/step - loss: 7.1415e-04 - mae: 0.0187 - mse: 6.1042e-04 - val_loss: 7.3875e-04 - val_mae: 0.0192 - val_mse: 6.3221e-04 - lr: 0.0131
Epoch 37/150
233/243 [===========================>..] - ETA: 0s - loss: 7.0739e-04 - mae: 0.0188 - mse: 6.0752e-04
243/243 [==============================] - 2s 7ms/step - loss: 7.0233e-04 - mae: 0.0187 - mse: 6.0255e-04 - val_loss: 6.4673e-04 - val_mae: 0.0176 - val_mse: 5.5737e-04 - lr: 0.0131
Epoch 38/150
243/243 [==============================] - 1s 3ms/step - loss: 6.8548e-04 - mae: 0.0185 - mse: 5.9117e-04 - val_loss: 8.2121e-04 - val_mae: 0.0197 - val_mse: 6.8100e-04 - lr: 0.0131
Epoch 39/150
243/243 [==============================] - 1s 3ms/step - loss: 7.1189e-04 - mae: 0.0188 - mse: 6.0684e-04 - val_loss: 7.8302e-04 - val_mae: 0.0205 - val_mse: 6.8198e-04 - lr: 0.0131
Epoch 40/150
243/243 [==============================] - 1s 3ms/step - loss: 7.0780e-04 - mae: 0.0189 - mse: 6.1150e-04 - val_loss: 6.6359e-04 - val_mae: 0.0171 - val_mse: 5.3144e-04 - lr: 0.0131
Epoch 41/150
243/243 [==============================] - 1s 3ms/step - loss: 7.0834e-04 - mae: 0.0188 - mse: 6.0923e-04 - val_loss: 6.6595e-04 - val_mae: 0.0178 - val_mse: 5.5524e-04 - lr: 0.0131
Epoch 42/150
243/243 [==============================] - 1s 3ms/step - loss: 7.0315e-04 - mae: 0.0186 - mse: 5.9968e-04 - val_loss: 9.1221e-04 - val_mae: 0.0221 - val_mse: 7.7580e-04 - lr: 0.0131
Epoch 43/150
235/243 [============================>.] - ETA: 0s - loss: 7.4350e-04 - mae: 0.0189 - mse: 6.1027e-04
243/243 [==============================] - 2s 10ms/step - loss: 7.4015e-04 - mae: 0.0189 - mse: 6.0744e-04 - val_loss: 6.2767e-04 - val_mae: 0.0178 - val_mse: 5.4220e-04 - lr: 0.0131
Epoch 44/150
243/243 [==============================] - 1s 3ms/step - loss: 6.6799e-04 - mae: 0.0183 - mse: 5.7419e-04 - val_loss: 6.4906e-04 - val_mae: 0.0185 - val_mse: 5.7000e-04 - lr: 0.0131
Epoch 45/150
243/243 [==============================] - 1s 3ms/step - loss: 7.0771e-04 - mae: 0.0187 - mse: 6.0302e-04 - val_loss: 6.5613e-04 - val_mae: 0.0181 - val_mse: 5.4718e-04 - lr: 0.0131
Epoch 46/150
243/243 [==============================] - 1s 3ms/step - loss: 7.5975e-04 - mae: 0.0192 - mse: 6.1999e-04 - val_loss: 7.8324e-04 - val_mae: 0.0206 - val_mse: 6.8156e-04 - lr: 0.0131
Epoch 47/150
240/243 [============================>.] - ETA: 0s - loss: 6.8729e-04 - mae: 0.0185 - mse: 5.8984e-04
Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00653347373008728.
243/243 [==============================] - 1s 3ms/step - loss: 6.8551e-04 - mae: 0.0185 - mse: 5.8745e-04 - val_loss: 7.1529e-04 - val_mae: 0.0190 - val_mse: 5.8096e-04 - lr: 0.0131
Epoch 48/150
243/243 [==============================] - 1s 3ms/step - loss: 6.2355e-04 - mae: 0.0172 - mse: 5.3183e-04 - val_loss: 6.7118e-04 - val_mae: 0.0184 - val_mse: 5.6566e-04 - lr: 0.0065
Epoch 49/150
236/243 [============================>.] - ETA: 0s - loss: 6.1708e-04 - mae: 0.0171 - mse: 5.2582e-04
243/243 [==============================] - 1s 3ms/step - loss: 6.2919e-04 - mae: 0.0176 - mse: 5.4380e-04 - val_loss: 5.9989e-04 - val_mae: 0.0166 - val_mse: 5.1191e-04 - lr: 0.0065
Epoch 50/150
243/243 [==============================] - 1s 3ms/step - loss: 6.1466e-04 - mae: 0.0172 - mse: 5.2682e-04 - val_loss: 6.1938e-04 - val_mae: 0.0181 - val_mse: 5.4230e-04 - lr: 0.0065
Epoch 51/150
243/243 [==============================] - 1s 3ms/step - loss: 6.2919e-04 - mae: 0.0176 - mse: 5.4380e-04 - val_loss: 5.9989e-04 - val_mae: 0.0166 - val_mse: 5.1191e-04 - lr: 0.0065
Epoch 52/150
243/243 [==============================] - 1s 3ms/step - loss: 6.1225e-04 - mae: 0.0171 - mse: 5.2257e-04 - val_loss: 6.0052e-04 - val_mae: 0.0171 - val_mse: 5.1077e-04 - lr: 0.0065
Epoch 53/150
243/243 [==============================] - 0s 2ms/step - loss: 6.4081e-04 - mae: 0.0179 - mse: 5.5298e-04 - val_loss: 6.2271e-04 - val_mae: 0.0167 - val_mse: 5.2116e-04 - lr: 0.0065
Epoch 54/150
243/243 [==============================] - 0s 994us/step - loss: 6.1508e-04 - mae: 0.0173 - mse: 5.2919e-04 - val_loss: 6.0624e-04 - val_mae: 0.0175 - val_mse: 5.1343e-04 - lr: 0.0065
Epoch 55/150
243/243 [==============================] - 0s 1ms/step - loss: 6.1744e-04 - mae: 0.0174 - mse: 5.2885e-04 - val_loss: 5.9716e-04 - val_mae: 0.0169 - val_mse: 5.0978e-04 - lr: 0.0065
Epoch 56/150
243/243 [==============================] - 0s 1ms/step - loss: 5.9911e-04 - mae: 0.0169 - mse: 5.1426e-04 - val_loss: 6.1675e-04 - val_mae: 0.0181 - val_mse: 5.3848e-04 - lr: 0.0065
Epoch 57/150
236/243 [============================>.] - ETA: 0s - loss: 6.0016e-04 - mae: 0.0170 - mse: 5.1069e-04
Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00326673686504364.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 4ms/step - loss: 6.0663e-04 - mae: 0.0171 - mse: 5.1664e-04 - val_loss: 5.7642e-04 - val_mae: 0.0161 - val_mse: 4.7076e-04 - lr: 0.0065
Epoch 58/150
243/243 [==============================] - 0s 914us/step - loss: 5.9293e-04 - mae: 0.0168 - mse: 5.0525e-04 - val_loss: 6.7707e-04 - val_mae: 0.0177 - val_mse: 5.7536e-04 - lr: 0.0033
Epoch 59/150
240/243 [============================>.] - ETA: 0s - loss: 5.8158e-04 - mae: 0.0166 - mse: 4.9821e-04
243/243 [==============================] - 1s 3ms/step - loss: 5.8161e-04 - mae: 0.0166 - mse: 4.9818e-04 - val_loss: 5.6203e-04 - val_mae: 0.0160 - val_mse: 4.7417e-04 - lr: 0.0033
Epoch 60/150
243/243 [==============================] - 0s 921us/step - loss: 5.8554e-04 - mae: 0.0167 - mse: 5.0280e-04 - val_loss: 5.7408e-04 - val_mae: 0.0163 - val_mse: 4.9156e-04 - lr: 0.0033
Epoch 61/150
243/243 [==============================] - 0s 910us/step - loss: 5.7470e-04 - mae: 0.0166 - mse: 4.9465e-04 - val_loss: 6.4546e-04 - val_mae: 0.0175 - val_mse: 5.4411e-04 - lr: 0.0033
Epoch 62/150
243/243 [==============================] - 0s 921us/step - loss: 5.7911e-04 - mae: 0.0165 - mse: 4.9718e-04 - val_loss: 6.0794e-04 - val_mae: 0.0177 - val_mse: 5.2111e-04 - lr: 0.0033
Epoch 63/150
243/243 [==============================] - 0s 957us/step - loss: 5.7321e-04 - mae: 0.0165 - mse: 4.9121e-04 - val_loss: 5.6671e-04 - val_mae: 0.0168 - val_mse: 4.8763e-04 - lr: 0.0033
Epoch 64/150
164/243 [===================>..........] - ETA: 0s - loss: 5.6530e-04 - mae: 0.0162 - mse: 4.8580e-04
243/243 [==============================] - 1s 4ms/step - loss: 5.6550e-04 - mae: 0.0163 - mse: 4.8458e-04 - val_loss: 5.6064e-04 - val_mae: 0.0162 - val_mse: 4.7622e-04 - lr: 0.0033
Epoch 65/150
243/243 [==============================] - 1s 3ms/step - loss: 5.7334e-04 - mae: 0.0167 - mse: 4.9500e-04 - val_loss: 5.5087e-04 - val_mae: 0.0160 - val_mse: 4.6454e-04 - lr: 0.0033
Epoch 66/150
243/243 [==============================] - 0s 990us/step - loss: 5.7232e-04 - mae: 0.0165 - mse: 4.9041e-04 - val_loss: 5.7564e-04 - val_mae: 0.0168 - val_mse: 4.9697e-04 - lr: 0.0033
Epoch 67/150
165/243 [===================>..........] - ETA: 0s - loss: 5.6625e-04 - mae: 0.0165 - mse: 4.8594e-04
Epoch 67: ReduceLROnPlateau reducing learning rate to 0.00163336843252182.
243/243 [==============================] - 0s 898us/step - loss: 5.7560e-04 - mae: 0.0166 - mse: 4.9432e-04 - val_loss: 6.1869e-04 - val_mae: 0.0183 - val_mse: 5.3819e-04 - lr: 0.0033
Epoch 68/150
243/243 [==============================] - 0s 990us/step - loss: 5.5973e-04 - mae: 0.0163 - mse: 4.7777e-04 - val_loss: 5.5760e-04 - val_mae: 0.0166 - val_mse: 4.8753e-04 - lr: 0.0016
Epoch 69/150
243/243 [==============================] - 0s 1ms/step - loss: 5.5952e-04 - mae: 0.0163 - mse: 4.8115e-04 - val_loss: 5.5228e-04 - val_mae: 0.0165 - val_mse: 4.7387e-04 - lr: 0.0016
Epoch 70/150
217/243 [=========================>....] - ETA: 0s - loss: 5.5825e-04 - mae: 0.0162 - mse: 4.8096e-04
243/243 [==============================] - 1s 4ms/step - loss: 5.5435e-04 - mae: 0.0161 - mse: 4.7683e-04 - val_loss: 5.4305e-04 - val_mae: 0.0158 - val_mse: 4.6210e-04 - lr: 0.0016
Epoch 71/150
243/243 [==============================] - 0s 935us/step - loss: 5.5314e-04 - mae: 0.0161 - mse: 4.7631e-04 - val_loss: 5.4540e-04 - val_mae: 0.0159 - val_mse: 4.6373e-04 - lr: 0.0016
Epoch 72/150
165/243 [===================>..........] - ETA: 0s - loss: 5.5998e-04 - mae: 0.0164 - mse: 4.8033e-04
243/243 [==============================] - 1s 4ms/step - loss: 5.5540e-04 - mae: 0.0162 - mse: 4.7628e-04 - val_loss: 5.3996e-04 - val_mae: 0.0159 - val_mse: 4.6357e-04 - lr: 0.0016
Epoch 73/150
243/243 [==============================] - 0s 929us/step - loss: 5.5284e-04 - mae: 0.0161 - mse: 4.7373e-04 - val_loss: 5.4396e-04 - val_mae: 0.0161 - val_mse: 4.7221e-04 - lr: 0.0016
Epoch 74/150
243/243 [==============================] - 0s 900us/step - loss: 5.4952e-04 - mae: 0.0161 - mse: 4.7385e-04 - val_loss: 5.6122e-04 - val_mae: 0.0167 - val_mse: 4.8825e-04 - lr: 0.0016
Epoch 75/150
163/243 [===================>..........] - ETA: 0s - loss: 5.6348e-04 - mae: 0.0163 - mse: 4.8365e-04
243/243 [==============================] - 1s 3ms/step - loss: 5.5586e-04 - mae: 0.0162 - mse: 4.7788e-04 - val_loss: 5.3755e-04 - val_mae: 0.0159 - val_mse: 4.6165e-04 - lr: 0.0016
Epoch 76/150
243/243 [==============================] - 0s 915us/step - loss: 5.5676e-04 - mae: 0.0163 - mse: 4.7827e-04 - val_loss: 5.4181e-04 - val_mae: 0.0163 - val_mse: 4.6676e-04 - lr: 0.0016
Epoch 77/150
166/243 [===================>..........] - ETA: 0s - loss: 5.2529e-04 - mae: 0.0158 - mse: 4.4958e-04
Epoch 77: ReduceLROnPlateau reducing learning rate to 0.00081668421626091.
243/243 [==============================] - 0s 905us/step - loss: 5.4875e-04 - mae: 0.0161 - mse: 4.7159e-04 - val_loss: 5.9799e-04 - val_mae: 0.0173 - val_mse: 5.1376e-04 - lr: 0.0016
Epoch 78/150
243/243 [==============================] - 0s 1ms/step - loss: 5.3968e-04 - mae: 0.0158 - mse: 4.6195e-04 - val_loss: 5.3911e-04 - val_mae: 0.0161 - val_mse: 4.6668e-04 - lr: 8.1668e-04
Epoch 79/150
163/243 [===================>..........] - ETA: 0s - loss: 5.4407e-04 - mae: 0.0158 - mse: 4.7057e-04
243/243 [==============================] - 1s 3ms/step - loss: 5.4205e-04 - mae: 0.0159 - mse: 4.6766e-04 - val_loss: 5.3453e-04 - val_mae: 0.0158 - val_mse: 4.5844e-04 - lr: 8.1668e-04
Epoch 80/150
239/243 [============================>.] - ETA: 0s - loss: 5.3972e-04 - mae: 0.0158 - mse: 4.6384e-04
243/243 [==============================] - 1s 4ms/step - loss: 5.3936e-04 - mae: 0.0158 - mse: 4.6348e-04 - val_loss: 5.3391e-04 - val_mae: 0.0158 - val_mse: 4.5883e-04 - lr: 8.1668e-04
Epoch 81/150
243/243 [==============================] - 0s 939us/step - loss: 5.3946e-04 - mae: 0.0158 - mse: 4.6489e-04 - val_loss: 5.4922e-04 - val_mae: 0.0163 - val_mse: 4.7428e-04 - lr: 8.1668e-04
Epoch 82/150
243/243 [==============================] - 0s 962us/step - loss: 5.3704e-04 - mae: 0.0158 - mse: 4.6257e-04 - val_loss: 5.4830e-04 - val_mae: 0.0159 - val_mse: 4.6961e-04 - lr: 8.1668e-04
Epoch 83/150
243/243 [==============================] - 0s 905us/step - loss: 5.3763e-04 - mae: 0.0158 - mse: 4.6234e-04 - val_loss: 5.3870e-04 - val_mae: 0.0157 - val_mse: 4.5760e-04 - lr: 8.1668e-04
Epoch 84/150
241/243 [============================>.] - ETA: 0s - loss: 5.4069e-04 - mae: 0.0158 - mse: 4.6305e-04
243/243 [==============================] - 1s 3ms/step - loss: 5.4025e-04 - mae: 0.0158 - mse: 4.6264e-04 - val_loss: 5.3154e-04 - val_mae: 0.0158 - val_mse: 4.5945e-04 - lr: 8.1668e-04
Epoch 85/150
243/243 [==============================] - 0s 921us/step - loss: 5.3773e-04 - mae: 0.0158 - mse: 4.6207e-04 - val_loss: 5.3656e-04 - val_mae: 0.0160 - val_mse: 4.6439e-04 - lr: 8.1668e-04
Epoch 86/150
243/243 [==============================] - 0s 919us/step - loss: 5.3625e-04 - mae: 0.0158 - mse: 4.6187e-04 - val_loss: 5.3282e-04 - val_mae: 0.0158 - val_mse: 4.5714e-04 - lr: 8.1668e-04
Epoch 87/150
243/243 [==============================] - 0s 913us/step - loss: 5.3696e-04 - mae: 0.0158 - mse: 4.6124e-04 - val_loss: 5.3338e-04 - val_mae: 0.0161 - val_mse: 4.6185e-04 - lr: 8.1668e-04
Epoch 88/150
164/243 [===================>..........] - ETA: 0s - loss: 5.3441e-04 - mae: 0.0158 - mse: 4.6113e-04
243/243 [==============================] - 1s 4ms/step - loss: 5.3775e-04 - mae: 0.0158 - mse: 4.6435e-04 - val_loss: 5.3056e-04 - val_mae: 0.0159 - val_mse: 4.5911e-04 - lr: 8.1668e-04
Epoch 89/150
243/243 [==============================] - 0s 952us/step - loss: 5.3666e-04 - mae: 0.0158 - mse: 4.6328e-04 - val_loss: 5.4587e-04 - val_mae: 0.0159 - val_mse: 4.7056e-04 - lr: 8.1668e-04
Epoch 90/150
243/243 [==============================] - 0s 892us/step - loss: 5.3577e-04 - mae: 0.0158 - mse: 4.6284e-04 - val_loss: 5.4054e-04 - val_mae: 0.0160 - val_mse: 4.6348e-04 - lr: 8.1668e-04
Epoch 91/150
165/243 [===================>..........] - ETA: 0s - loss: 5.2862e-04 - mae: 0.0157 - mse: 4.5393e-04
243/243 [==============================] - 1s 4ms/step - loss: 5.3435e-04 - mae: 0.0157 - mse: 4.5968e-04 - val_loss: 5.2799e-04 - val_mae: 0.0157 - val_mse: 4.5542e-04 - lr: 8.1668e-04
Epoch 92/150
243/243 [==============================] - 0s 908us/step - loss: 5.3451e-04 - mae: 0.0158 - mse: 4.6006e-04 - val_loss: 5.4127e-04 - val_mae: 0.0160 - val_mse: 4.6777e-04 - lr: 8.1668e-04
Epoch 93/150
243/243 [==============================] - 0s 917us/step - loss: 5.3618e-04 - mae: 0.0159 - mse: 4.6430e-04 - val_loss: 5.3703e-04 - val_mae: 0.0158 - val_mse: 4.6067e-04 - lr: 8.1668e-04
Epoch 94/150
243/243 [==============================] - 0s 982us/step - loss: 5.3180e-04 - mae: 0.0157 - mse: 4.5741e-04 - val_loss: 5.2978e-04 - val_mae: 0.0157 - val_mse: 4.5396e-04 - lr: 8.1668e-04
Epoch 95/150
243/243 [==============================] - 0s 907us/step - loss: 5.3127e-04 - mae: 0.0157 - mse: 4.5733e-04 - val_loss: 5.4260e-04 - val_mae: 0.0159 - val_mse: 4.6523e-04 - lr: 8.1668e-04
Epoch 96/150
243/243 [==============================] - ETA: 0s - loss: 5.3876e-04 - mae: 0.0159 - mse: 4.6370e-04
Epoch 96: ReduceLROnPlateau reducing learning rate to 0.000408342108130455.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 4ms/step - loss: 5.3876e-04 - mae: 0.0159 - mse: 4.6370e-04 - val_loss: 5.2739e-04 - val_mae: 0.0158 - val_mse: 4.5301e-04 - lr: 8.1668e-04
Epoch 97/150
239/243 [============================>.] - ETA: 0s - loss: 5.3009e-04 - mae: 0.0156 - mse: 4.5538e-04
243/243 [==============================] - 1s 4ms/step - loss: 5.3020e-04 - mae: 0.0156 - mse: 4.5553e-04 - val_loss: 5.2464e-04 - val_mae: 0.0157 - val_mse: 4.5213e-04 - lr: 4.0834e-04
Epoch 98/150
243/243 [==============================] - 0s 1ms/step - loss: 5.2795e-04 - mae: 0.0156 - mse: 4.5519e-04 - val_loss: 5.2517e-04 - val_mae: 0.0156 - val_mse: 4.5072e-04 - lr: 4.0834e-04
Epoch 99/150
243/243 [==============================] - 0s 1ms/step - loss: 5.3023e-04 - mae: 0.0157 - mse: 4.5567e-04 - val_loss: 5.3059e-04 - val_mae: 0.0157 - val_mse: 4.5530e-04 - lr: 4.0834e-04
Epoch 100/150
231/243 [===========================>..] - ETA: 0s - loss: 5.2745e-04 - mae: 0.0156 - mse: 4.5358e-04
243/243 [==============================] - 1s 3ms/step - loss: 5.2889e-04 - mae: 0.0156 - mse: 4.5494e-04 - val_loss: 5.2430e-04 - val_mae: 0.0157 - val_mse: 4.5106e-04 - lr: 4.0834e-04
Epoch 101/150
243/243 [==============================] - 0s 926us/step - loss: 5.2887e-04 - mae: 0.0156 - mse: 4.5442e-04 - val_loss: 5.3222e-04 - val_mae: 0.0158 - val_mse: 4.5867e-04 - lr: 4.0834e-04
Epoch 102/150
243/243 [==============================] - 0s 912us/step - loss: 5.2858e-04 - mae: 0.0156 - mse: 4.5596e-04 - val_loss: 5.3277e-04 - val_mae: 0.0162 - val_mse: 4.6204e-04 - lr: 4.0834e-04
Epoch 103/150
243/243 [==============================] - 0s 908us/step - loss: 5.3001e-04 - mae: 0.0157 - mse: 4.5729e-04 - val_loss: 5.2475e-04 - val_mae: 0.0156 - val_mse: 4.5119e-04 - lr: 4.0834e-04
Epoch 104/150
243/243 [==============================] - 0s 916us/step - loss: 5.2761e-04 - mae: 0.0157 - mse: 4.5481e-04 - val_loss: 5.2473e-04 - val_mae: 0.0156 - val_mse: 4.4973e-04 - lr: 4.0834e-04
Epoch 105/150
243/243 [==============================] - 0s 1000us/step - loss: 5.2765e-04 - mae: 0.0156 - mse: 4.5367e-04 - val_loss: 5.2468e-04 - val_mae: 0.0156 - val_mse: 4.5117e-04 - lr: 4.0834e-04
Epoch 106/150
164/243 [===================>..........] - ETA: 0s - loss: 5.1780e-04 - mae: 0.0154 - mse: 4.4508e-04
Epoch 106: ReduceLROnPlateau reducing learning rate to 0.0002041710540652275.
243/243 [==============================] - 0s 922us/step - loss: 5.2712e-04 - mae: 0.0156 - mse: 4.5417e-04 - val_loss: 5.2597e-04 - val_mae: 0.0156 - val_mse: 4.5172e-04 - lr: 4.0834e-04
Epoch 107/150
240/243 [============================>.] - ETA: 0s - loss: 5.2632e-04 - mae: 0.0156 - mse: 4.5293e-04
243/243 [==============================] - 1s 4ms/step - loss: 5.2640e-04 - mae: 0.0156 - mse: 4.5301e-04 - val_loss: 5.2397e-04 - val_mae: 0.0156 - val_mse: 4.5064e-04 - lr: 2.0417e-04
Epoch 108/150
243/243 [==============================] - 0s 937us/step - loss: 5.2477e-04 - mae: 0.0155 - mse: 4.5206e-04 - val_loss: 5.2448e-04 - val_mae: 0.0156 - val_mse: 4.5102e-04 - lr: 2.0417e-04
Epoch 109/150
243/243 [==============================] - 0s 904us/step - loss: 5.2502e-04 - mae: 0.0156 - mse: 4.5283e-04 - val_loss: 5.2682e-04 - val_mae: 0.0156 - val_mse: 4.5221e-04 - lr: 2.0417e-04
Epoch 110/150
243/243 [==============================] - 0s 916us/step - loss: 5.2362e-04 - mae: 0.0156 - mse: 4.5076e-04 - val_loss: 5.2591e-04 - val_mae: 0.0158 - val_mse: 4.5368e-04 - lr: 2.0417e-04
Epoch 111/150
243/243 [==============================] - 0s 898us/step - loss: 5.2494e-04 - mae: 0.0155 - mse: 4.5200e-04 - val_loss: 5.2540e-04 - val_mae: 0.0156 - val_mse: 4.5219e-04 - lr: 2.0417e-04
Epoch 112/150
243/243 [==============================] - 0s 966us/step - loss: 5.2529e-04 - mae: 0.0156 - mse: 4.5297e-04 - val_loss: 5.2494e-04 - val_mae: 0.0157 - val_mse: 4.5226e-04 - lr: 2.0417e-04
Epoch 113/150
242/243 [============================>.] - ETA: 0s - loss: 5.2433e-04 - mae: 0.0155 - mse: 4.5136e-04
243/243 [==============================] - 1s 3ms/step - loss: 5.2409e-04 - mae: 0.0155 - mse: 4.5113e-04 - val_loss: 5.2337e-04 - val_mae: 0.0156 - val_mse: 4.5083e-04 - lr: 2.0417e-04
Epoch 114/150
243/243 [==============================] - 0s 929us/step - loss: 5.2389e-04 - mae: 0.0155 - mse: 4.5178e-04 - val_loss: 5.2598e-04 - val_mae: 0.0157 - val_mse: 4.5284e-04 - lr: 2.0417e-04
Epoch 115/150
164/243 [===================>..........] - ETA: 0s - loss: 5.1924e-04 - mae: 0.0154 - mse: 4.4688e-04
243/243 [==============================] - 1s 3ms/step - loss: 5.2382e-04 - mae: 0.0155 - mse: 4.5187e-04 - val_loss: 5.2168e-04 - val_mae: 0.0156 - val_mse: 4.5012e-04 - lr: 2.0417e-04
Epoch 116/150
212/243 [=========================>....] - ETA: 0s - loss: 5.1825e-04 - mae: 0.0155 - mse: 4.4561e-04
Epoch 116: ReduceLROnPlateau reducing learning rate to 0.00010208552703261375.
243/243 [==============================] - 0s 1ms/step - loss: 5.2280e-04 - mae: 0.0155 - mse: 4.5050e-04 - val_loss: 5.2442e-04 - val_mae: 0.0159 - val_mse: 4.5386e-04 - lr: 2.0417e-04
Epoch 117/150
243/243 [==============================] - 0s 916us/step - loss: 5.2360e-04 - mae: 0.0156 - mse: 4.5106e-04 - val_loss: 5.2805e-04 - val_mae: 0.0157 - val_mse: 4.5415e-04 - lr: 1.0209e-04
Epoch 118/150
162/243 [===================>..........] - ETA: 0s - loss: 5.3260e-04 - mae: 0.0156 - mse: 4.5944e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 3ms/step - loss: 5.2250e-04 - mae: 0.0155 - mse: 4.4971e-04 - val_loss: 5.2105e-04 - val_mae: 0.0156 - val_mse: 4.4983e-04 - lr: 1.0209e-04
Epoch 119/150
243/243 [==============================] - 0s 959us/step - loss: 5.2317e-04 - mae: 0.0155 - mse: 4.5099e-04 - val_loss: 5.2495e-04 - val_mae: 0.0156 - val_mse: 4.5160e-04 - lr: 1.0209e-04
Epoch 120/150
243/243 [==============================] - 0s 921us/step - loss: 5.2326e-04 - mae: 0.0155 - mse: 4.5095e-04 - val_loss: 5.2400e-04 - val_mae: 0.0156 - val_mse: 4.5129e-04 - lr: 1.0209e-04
Epoch 121/150
243/243 [==============================] - 0s 908us/step - loss: 5.2290e-04 - mae: 0.0155 - mse: 4.5044e-04 - val_loss: 5.2391e-04 - val_mae: 0.0157 - val_mse: 4.5203e-04 - lr: 1.0209e-04
Epoch 122/150
243/243 [==============================] - 0s 904us/step - loss: 5.2317e-04 - mae: 0.0155 - mse: 4.5070e-04 - val_loss: 5.2207e-04 - val_mae: 0.0156 - val_mse: 4.5019e-04 - lr: 1.0209e-04
Epoch 123/150
243/243 [==============================] - 0s 1ms/step - loss: 5.2309e-04 - mae: 0.0155 - mse: 4.5072e-04 - val_loss: 5.2264e-04 - val_mae: 0.0156 - val_mse: 4.5064e-04 - lr: 1.0209e-04
Epoch 124/150
243/243 [==============================] - 0s 903us/step - loss: 5.2330e-04 - mae: 0.0155 - mse: 4.5065e-04 - val_loss: 5.2208e-04 - val_mae: 0.0156 - val_mse: 4.5012e-04 - lr: 1.0209e-04
Epoch 125/150
243/243 [==============================] - 0s 915us/step - loss: 5.2247e-04 - mae: 0.0155 - mse: 4.5081e-04 - val_loss: 5.2628e-04 - val_mae: 0.0158 - val_mse: 4.5430e-04 - lr: 1.0209e-04
Epoch 126/150
163/243 [===================>..........] - ETA: 0s - loss: 5.2925e-04 - mae: 0.0157 - mse: 4.5646e-04
Epoch 126: ReduceLROnPlateau reducing learning rate to 5.104276351630688e-05.
243/243 [==============================] - 0s 914us/step - loss: 5.2278e-04 - mae: 0.0155 - mse: 4.5031e-04 - val_loss: 5.2325e-04 - val_mae: 0.0157 - val_mse: 4.5124e-04 - lr: 1.0209e-04
Epoch 127/150
243/243 [==============================] - 0s 906us/step - loss: 5.2214e-04 - mae: 0.0155 - mse: 4.4987e-04 - val_loss: 5.2260e-04 - val_mae: 0.0156 - val_mse: 4.5038e-04 - lr: 5.1043e-05
Epoch 128/150
243/243 [==============================] - 0s 916us/step - loss: 5.2202e-04 - mae: 0.0155 - mse: 4.4959e-04 - val_loss: 5.2473e-04 - val_mae: 0.0157 - val_mse: 4.5206e-04 - lr: 5.1043e-05
Epoch 129/150
243/243 [==============================] - 0s 946us/step - loss: 5.2217e-04 - mae: 0.0155 - mse: 4.4987e-04 - val_loss: 5.2228e-04 - val_mae: 0.0156 - val_mse: 4.5005e-04 - lr: 5.1043e-05
Epoch 130/150
243/243 [==============================] - 0s 907us/step - loss: 5.2174e-04 - mae: 0.0155 - mse: 4.4910e-04 - val_loss: 5.2117e-04 - val_mae: 0.0156 - val_mse: 4.4896e-04 - lr: 5.1043e-05
Epoch 131/150
243/243 [==============================] - 0s 911us/step - loss: 5.2250e-04 - mae: 0.0155 - mse: 4.5054e-04 - val_loss: 5.2368e-04 - val_mae: 0.0157 - val_mse: 4.5181e-04 - lr: 5.1043e-05
Epoch 132/150
243/243 [==============================] - 0s 906us/step - loss: 5.2189e-04 - mae: 0.0155 - mse: 4.4960e-04 - val_loss: 5.2233e-04 - val_mae: 0.0156 - val_mse: 4.5012e-04 - lr: 5.1043e-05
Epoch 133/150
243/243 [==============================] - 0s 973us/step - loss: 5.2230e-04 - mae: 0.0155 - mse: 4.4985e-04 - val_loss: 5.2176e-04 - val_mae: 0.0156 - val_mse: 4.4936e-04 - lr: 5.1043e-05
Epoch 134/150
243/243 [==============================] - 0s 903us/step - loss: 5.2203e-04 - mae: 0.0155 - mse: 4.4996e-04 - val_loss: 5.2388e-04 - val_mae: 0.0156 - val_mse: 4.5123e-04 - lr: 5.1043e-05
Epoch 135/150
243/243 [==============================] - 0s 918us/step - loss: 5.2193e-04 - mae: 0.0155 - mse: 4.4955e-04 - val_loss: 5.2322e-04 - val_mae: 0.0156 - val_mse: 4.5096e-04 - lr: 5.1043e-05
Epoch 136/150
162/243 [===================>..........] - ETA: 0s - loss: 5.2053e-04 - mae: 0.0155 - mse: 4.4820e-04
Epoch 136: ReduceLROnPlateau reducing learning rate to 2.552138175815344e-05.
243/243 [==============================] - 0s 910us/step - loss: 5.2183e-04 - mae: 0.0155 - mse: 4.4943e-04 - val_loss: 5.2358e-04 - val_mae: 0.0156 - val_mse: 4.5090e-04 - lr: 5.1043e-05
Epoch 137/150
243/243 [==============================] - 0s 905us/step - loss: 5.2167e-04 - mae: 0.0155 - mse: 4.4926e-04 - val_loss: 5.2279e-04 - val_mae: 0.0156 - val_mse: 4.5037e-04 - lr: 2.5521e-05
Epoch 138/150
243/243 [==============================] - 0s 918us/step - loss: 5.2154e-04 - mae: 0.0155 - mse: 4.4933e-04 - val_loss: 5.2360e-04 - val_mae: 0.0156 - val_mse: 4.5124e-04 - lr: 2.5521e-05
Epoch 139/150
243/243 [==============================] - 0s 920us/step - loss: 5.2151e-04 - mae: 0.0155 - mse: 4.4904e-04 - val_loss: 5.2187e-04 - val_mae: 0.0156 - val_mse: 4.4980e-04 - lr: 2.5521e-05
Epoch 140/150
243/243 [==============================] - 0s 949us/step - loss: 5.2170e-04 - mae: 0.0155 - mse: 4.4950e-04 - val_loss: 5.2252e-04 - val_mae: 0.0156 - val_mse: 4.5044e-04 - lr: 2.5521e-05
Epoch 141/150
243/243 [==============================] - 0s 1ms/step - loss: 5.2156e-04 - mae: 0.0155 - mse: 4.4924e-04 - val_loss: 5.2170e-04 - val_mae: 0.0156 - val_mse: 4.4956e-04 - lr: 2.5521e-05
Epoch 142/150
243/243 [==============================] - 0s 901us/step - loss: 5.2171e-04 - mae: 0.0155 - mse: 4.4960e-04 - val_loss: 5.2227e-04 - val_mae: 0.0156 - val_mse: 4.5014e-04 - lr: 2.5521e-05
Epoch 143/150
243/243 [==============================] - 0s 981us/step - loss: 5.2151e-04 - mae: 0.0155 - mse: 4.4942e-04 - val_loss: 5.2261e-04 - val_mae: 0.0156 - val_mse: 4.5044e-04 - lr: 2.5521e-05
Epoch 144/150
243/243 [==============================] - 0s 912us/step - loss: 5.2145e-04 - mae: 0.0155 - mse: 4.4903e-04 - val_loss: 5.2180e-04 - val_mae: 0.0156 - val_mse: 4.4967e-04 - lr: 2.5521e-05
Epoch 145/150
243/243 [==============================] - 0s 911us/step - loss: 5.2152e-04 - mae: 0.0155 - mse: 4.4940e-04 - val_loss: 5.2210e-04 - val_mae: 0.0156 - val_mse: 4.4989e-04 - lr: 2.5521e-05
Epoch 146/150
161/243 [==================>...........] - ETA: 0s - loss: 5.1250e-04 - mae: 0.0153 - mse: 4.4074e-04
Epoch 146: ReduceLROnPlateau reducing learning rate to 1.276069087907672e-05.
243/243 [==============================] - 0s 918us/step - loss: 5.2120e-04 - mae: 0.0155 - mse: 4.4932e-04 - val_loss: 5.2432e-04 - val_mae: 0.0157 - val_mse: 4.5186e-04 - lr: 2.5521e-05
Epoch 147/150
243/243 [==============================] - 0s 913us/step - loss: 5.2156e-04 - mae: 0.0155 - mse: 4.4912e-04 - val_loss: 5.2285e-04 - val_mae: 0.0156 - val_mse: 4.5044e-04 - lr: 1.2761e-05
Epoch 148/150
243/243 [==============================] - 0s 918us/step - loss: 5.2138e-04 - mae: 0.0155 - mse: 4.4908e-04 - val_loss: 5.2259e-04 - val_mae: 0.0156 - val_mse: 4.5035e-04 - lr: 1.2761e-05
Epoch 149/150
243/243 [==============================] - 0s 915us/step - loss: 5.2132e-04 - mae: 0.0155 - mse: 4.4907e-04 - val_loss: 5.2244e-04 - val_mae: 0.0156 - val_mse: 4.5029e-04 - lr: 1.2761e-05
Epoch 150/150
243/243 [==============================] - 0s 904us/step - loss: 5.2128e-04 - mae: 0.0155 - mse: 4.4909e-04 - val_loss: 5.2221e-04 - val_mae: 0.0156 - val_mse: 4.5005e-04 - lr: 1.2761e-05
>Saved ../trained_models/models_segments_overlap_adam_0.05226779065999622LR_[30]HN_16BS_10P_val_mseM_150epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
323/323 [==============================] - 1s 1ms/step - loss: 0.0154 - mae: 0.0551 - mse: 0.0046 - val_loss: 0.0034 - val_mae: 0.0502 - val_mse: 0.0034 - lr: 0.0523
Epoch 2/150
323/323 [==============================] - 0s 873us/step - loss: 0.0035 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0502 - val_mse: 0.0034 - lr: 0.0523
Epoch 3/150
323/323 [==============================] - 0s 866us/step - loss: 0.0035 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0496 - val_mse: 0.0033 - lr: 0.0523
Epoch 4/150
323/323 [==============================] - 0s 884us/step - loss: 0.0035 - mae: 0.0488 - mse: 0.0032 - val_loss: 0.0041 - val_mae: 0.0447 - val_mse: 0.0029 - lr: 0.0523
Epoch 5/150
323/323 [==============================] - 0s 866us/step - loss: 0.0030 - mae: 0.0404 - mse: 0.0025 - val_loss: 0.0024 - val_mae: 0.0359 - val_mse: 0.0020 - lr: 0.0523
Epoch 6/150
323/323 [==============================] - 0s 881us/step - loss: 0.0024 - mae: 0.0362 - mse: 0.0021 - val_loss: 0.0033 - val_mae: 0.0456 - val_mse: 0.0031 - lr: 0.0523
Epoch 7/150
323/323 [==============================] - 0s 917us/step - loss: 0.0021 - mae: 0.0337 - mse: 0.0018 - val_loss: 0.0019 - val_mae: 0.0322 - val_mse: 0.0017 - lr: 0.0523
Epoch 8/150
323/323 [==============================] - 0s 896us/step - loss: 0.0020 - mae: 0.0326 - mse: 0.0017 - val_loss: 0.0017 - val_mae: 0.0293 - val_mse: 0.0014 - lr: 0.0523
Epoch 9/150
323/323 [==============================] - 0s 887us/step - loss: 0.0019 - mae: 0.0316 - mse: 0.0016 - val_loss: 0.0017 - val_mae: 0.0292 - val_mse: 0.0014 - lr: 0.0523
Epoch 10/150
323/323 [==============================] - 0s 880us/step - loss: 0.0018 - mae: 0.0310 - mse: 0.0016 - val_loss: 0.0016 - val_mae: 0.0277 - val_mse: 0.0013 - lr: 0.0523
Epoch 11/150
323/323 [==============================] - 0s 886us/step - loss: 0.0018 - mae: 0.0307 - mse: 0.0015 - val_loss: 0.0019 - val_mae: 0.0323 - val_mse: 0.0017 - lr: 0.0523
Epoch 12/150
323/323 [==============================] - 0s 879us/step - loss: 0.0017 - mae: 0.0302 - mse: 0.0015 - val_loss: 0.0016 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0523
Epoch 13/150
323/323 [==============================] - 0s 890us/step - loss: 0.0018 - mae: 0.0307 - mse: 0.0015 - val_loss: 0.0020 - val_mae: 0.0323 - val_mse: 0.0016 - lr: 0.0523
Epoch 14/150
323/323 [==============================] - 0s 886us/step - loss: 0.0017 - mae: 0.0298 - mse: 0.0014 - val_loss: 0.0014 - val_mae: 0.0265 - val_mse: 0.0012 - lr: 0.0523
Epoch 15/150
323/323 [==============================] - 0s 935us/step - loss: 0.0017 - mae: 0.0293 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0266 - val_mse: 0.0012 - lr: 0.0523
Epoch 16/150
323/323 [==============================] - 0s 894us/step - loss: 0.0017 - mae: 0.0300 - mse: 0.0015 - val_loss: 0.0016 - val_mae: 0.0287 - val_mse: 0.0014 - lr: 0.0523
Epoch 17/150
323/323 [==============================] - 0s 881us/step - loss: 0.0016 - mae: 0.0292 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0263 - val_mse: 0.0012 - lr: 0.0523
Epoch 18/150
323/323 [==============================] - 0s 879us/step - loss: 0.0017 - mae: 0.0296 - mse: 0.0014 - val_loss: 0.0019 - val_mae: 0.0320 - val_mse: 0.0016 - lr: 0.0523
Epoch 19/150
323/323 [==============================] - 0s 882us/step - loss: 0.0017 - mae: 0.0296 - mse: 0.0014 - val_loss: 0.0014 - val_mae: 0.0264 - val_mse: 0.0012 - lr: 0.0523
Epoch 20/150
323/323 [==============================] - 0s 888us/step - loss: 0.0017 - mae: 0.0292 - mse: 0.0014 - val_loss: 0.0039 - val_mae: 0.0501 - val_mse: 0.0035 - lr: 0.0523
Epoch 21/150
323/323 [==============================] - 0s 870us/step - loss: 0.0017 - mae: 0.0291 - mse: 0.0014 - val_loss: 0.0019 - val_mae: 0.0313 - val_mse: 0.0015 - lr: 0.0523
Epoch 22/150
323/323 [==============================] - 0s 875us/step - loss: 0.0017 - mae: 0.0295 - mse: 0.0014 - val_loss: 0.0017 - val_mae: 0.0264 - val_mse: 0.0012 - lr: 0.0523
Epoch 23/150
323/323 [==============================] - 0s 931us/step - loss: 0.0016 - mae: 0.0288 - mse: 0.0014 - val_loss: 0.0017 - val_mae: 0.0306 - val_mse: 0.0015 - lr: 0.0523
Epoch 24/150
246/323 [=====================>........] - ETA: 0s - loss: 0.0018 - mae: 0.0297 - mse: 0.0014
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.02613389492034912.
323/323 [==============================] - 0s 888us/step - loss: 0.0017 - mae: 0.0296 - mse: 0.0014 - val_loss: 0.0019 - val_mae: 0.0336 - val_mse: 0.0018 - lr: 0.0523
Epoch 25/150
323/323 [==============================] - 0s 891us/step - loss: 0.0014 - mae: 0.0277 - mse: 0.0013 - val_loss: 0.0013 - val_mae: 0.0266 - val_mse: 0.0012 - lr: 0.0261
Epoch 26/150
323/323 [==============================] - 0s 883us/step - loss: 0.0014 - mae: 0.0281 - mse: 0.0013 - val_loss: 0.0013 - val_mae: 0.0265 - val_mse: 0.0012 - lr: 0.0261
Epoch 27/150
323/323 [==============================] - 0s 881us/step - loss: 0.0014 - mae: 0.0281 - mse: 0.0013 - val_loss: 0.0013 - val_mae: 0.0266 - val_mse: 0.0012 - lr: 0.0261
Epoch 28/150
323/323 [==============================] - 0s 879us/step - loss: 0.0014 - mae: 0.0281 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0279 - val_mse: 0.0013 - lr: 0.0261
Epoch 29/150
323/323 [==============================] - 0s 915us/step - loss: 0.0014 - mae: 0.0280 - mse: 0.0013 - val_loss: 0.0013 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.0261
Epoch 30/150
323/323 [==============================] - 0s 928us/step - loss: 0.0014 - mae: 0.0279 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0292 - val_mse: 0.0014 - lr: 0.0261
Epoch 31/150
323/323 [==============================] - 0s 892us/step - loss: 0.0014 - mae: 0.0279 - mse: 0.0013 - val_loss: 0.0018 - val_mae: 0.0331 - val_mse: 0.0017 - lr: 0.0261
Epoch 32/150
323/323 [==============================] - 0s 907us/step - loss: 0.0014 - mae: 0.0280 - mse: 0.0013 - val_loss: 0.0013 - val_mae: 0.0260 - val_mse: 0.0011 - lr: 0.0261
Epoch 33/150
323/323 [==============================] - 0s 929us/step - loss: 0.0015 - mae: 0.0281 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0267 - val_mse: 0.0012 - lr: 0.0261
Epoch 34/150
249/323 [======================>.......] - ETA: 0s - loss: 0.0014 - mae: 0.0279 - mse: 0.0013
Epoch 34: ReduceLROnPlateau reducing learning rate to 0.01306694746017456.
323/323 [==============================] - 0s 890us/step - loss: 0.0014 - mae: 0.0278 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0261
Epoch 35/150
323/323 [==============================] - 0s 884us/step - loss: 0.0013 - mae: 0.0274 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.0131
Epoch 36/150
323/323 [==============================] - 0s 884us/step - loss: 0.0013 - mae: 0.0272 - mse: 0.0012 - val_loss: 0.0015 - val_mae: 0.0296 - val_mse: 0.0014 - lr: 0.0131
Epoch 37/150
323/323 [==============================] - 0s 873us/step - loss: 0.0013 - mae: 0.0274 - mse: 0.0012 - val_loss: 0.0015 - val_mae: 0.0291 - val_mse: 0.0014 - lr: 0.0131
Epoch 38/150
323/323 [==============================] - 0s 937us/step - loss: 0.0013 - mae: 0.0270 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0270 - val_mse: 0.0012 - lr: 0.0131
Epoch 39/150
323/323 [==============================] - 0s 887us/step - loss: 0.0013 - mae: 0.0273 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0268 - val_mse: 0.0012 - lr: 0.0131
Epoch 40/150
323/323 [==============================] - 0s 870us/step - loss: 0.0013 - mae: 0.0270 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0131
Epoch 41/150
323/323 [==============================] - 0s 868us/step - loss: 0.0013 - mae: 0.0271 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0260 - val_mse: 0.0011 - lr: 0.0131
Epoch 42/150
323/323 [==============================] - 0s 870us/step - loss: 0.0013 - mae: 0.0273 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0266 - val_mse: 0.0011 - lr: 0.0131
Epoch 43/150
323/323 [==============================] - 0s 884us/step - loss: 0.0013 - mae: 0.0271 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 0.0131
Epoch 44/150
323/323 [==============================] - 0s 877us/step - loss: 0.0013 - mae: 0.0272 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 0.0131
Epoch 45/150
323/323 [==============================] - 0s 863us/step - loss: 0.0013 - mae: 0.0271 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0131
Epoch 46/150
323/323 [==============================] - 0s 917us/step - loss: 0.0013 - mae: 0.0270 - mse: 0.0012 - val_loss: 0.0016 - val_mae: 0.0307 - val_mse: 0.0015 - lr: 0.0131
Epoch 47/150
323/323 [==============================] - 0s 882us/step - loss: 0.0013 - mae: 0.0271 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0131
Epoch 48/150
323/323 [==============================] - 0s 876us/step - loss: 0.0013 - mae: 0.0273 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0131
Epoch 49/150
323/323 [==============================] - 0s 876us/step - loss: 0.0013 - mae: 0.0274 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0253 - val_mse: 0.0011 - lr: 0.0131
Epoch 50/150
249/323 [======================>.......] - ETA: 0s - loss: 0.0013 - mae: 0.0268 - mse: 0.0012
Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00653347373008728.
323/323 [==============================] - 0s 875us/step - loss: 0.0013 - mae: 0.0269 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0263 - val_mse: 0.0011 - lr: 0.0131
Epoch 51/150
323/323 [==============================] - 0s 883us/step - loss: 0.0012 - mae: 0.0266 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0255 - val_mse: 0.0011 - lr: 0.0065
Epoch 52/150
323/323 [==============================] - 0s 881us/step - loss: 0.0013 - mae: 0.0268 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 0.0065
Epoch 53/150
323/323 [==============================] - 0s 946us/step - loss: 0.0012 - mae: 0.0265 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 0.0065
Epoch 54/150
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0265 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0065
Epoch 55/150
323/323 [==============================] - 0s 876us/step - loss: 0.0012 - mae: 0.0265 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0270 - val_mse: 0.0012 - lr: 0.0065
Epoch 56/150
323/323 [==============================] - 0s 876us/step - loss: 0.0012 - mae: 0.0266 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 0.0065
Epoch 57/150
323/323 [==============================] - 0s 865us/step - loss: 0.0012 - mae: 0.0266 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0262 - val_mse: 0.0011 - lr: 0.0065
Epoch 58/150
323/323 [==============================] - 0s 912us/step - loss: 0.0012 - mae: 0.0266 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.0065
Epoch 59/150
323/323 [==============================] - 0s 882us/step - loss: 0.0012 - mae: 0.0266 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0276 - val_mse: 0.0013 - lr: 0.0065
Epoch 60/150
248/323 [======================>.......] - ETA: 0s - loss: 0.0012 - mae: 0.0263 - mse: 0.0011
Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00326673686504364.
323/323 [==============================] - 0s 874us/step - loss: 0.0012 - mae: 0.0265 - mse: 0.0011 - val_loss: 0.0014 - val_mae: 0.0278 - val_mse: 0.0013 - lr: 0.0065
Epoch 61/150
323/323 [==============================] - 0s 952us/step - loss: 0.0012 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0033
Epoch 62/150
323/323 [==============================] - 0s 893us/step - loss: 0.0012 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0261 - val_mse: 0.0011 - lr: 0.0033
Epoch 63/150
323/323 [==============================] - 0s 886us/step - loss: 0.0012 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0255 - val_mse: 0.0011 - lr: 0.0033
Epoch 64/150
323/323 [==============================] - 0s 873us/step - loss: 0.0012 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.0033
Epoch 65/150
323/323 [==============================] - 0s 898us/step - loss: 0.0012 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 0.0033
Epoch 66/150
323/323 [==============================] - 0s 899us/step - loss: 0.0012 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 0.0033
Epoch 67/150
323/323 [==============================] - 0s 897us/step - loss: 0.0012 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 0.0033
Epoch 68/150
323/323 [==============================] - 0s 884us/step - loss: 0.0012 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 0.0033
Epoch 69/150
323/323 [==============================] - 0s 879us/step - loss: 0.0012 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0261 - val_mse: 0.0011 - lr: 0.0033
Epoch 70/150
251/323 [======================>.......] - ETA: 0s - loss: 0.0012 - mae: 0.0268 - mse: 0.0012
Epoch 70: ReduceLROnPlateau reducing learning rate to 0.00163336843252182.
323/323 [==============================] - 0s 886us/step - loss: 0.0012 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0255 - val_mse: 0.0011 - lr: 0.0033
Epoch 71/150
323/323 [==============================] - 0s 881us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0255 - val_mse: 0.0011 - lr: 0.0016
Epoch 72/150
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 73/150
323/323 [==============================] - 0s 874us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0255 - val_mse: 0.0011 - lr: 0.0016
Epoch 74/150
323/323 [==============================] - 0s 869us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 0.0016
Epoch 75/150
323/323 [==============================] - 0s 883us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0262 - val_mse: 0.0011 - lr: 0.0016
Epoch 76/150
323/323 [==============================] - 0s 892us/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0253 - val_mse: 0.0011 - lr: 0.0016
Epoch 77/150
323/323 [==============================] - 0s 899us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0253 - val_mse: 0.0011 - lr: 0.0016
Epoch 78/150
323/323 [==============================] - 0s 870us/step - loss: 0.0012 - mae: 0.0260 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 0.0016
Epoch 79/150
247/323 [=====================>........] - ETA: 0s - loss: 0.0012 - mae: 0.0262 - mse: 0.0011
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0025s). Check your callbacks.
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011933-n8876e0u\files\model-best)... Done. 0.0s
323/323 [==============================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
243/243 [==============================] - 0s 893us/step - loss: 0.0010 - mae: 0.0237 - mse: 8.9125e-04 - val_loss: 0.0012 - val_mae: 0.0274 - val_mse: 0.0011 - lr: 0.0261
Epoch 31/150
243/243 [==============================] - 0s 914us/step - loss: 0.0010 - mae: 0.0235 - mse: 8.8389e-04 - val_loss: 9.3965e-04 - val_mae: 0.0232 - val_mse: 8.5705e-04 - lr: 0.0261
Epoch 32/150
234/243 [===========================>..] - ETA: 0s - loss: 9.9394e-04 - mae: 0.0234 - mse: 8.7958e-04
Epoch 32: ReduceLROnPlateau reducing learning rate to 0.01306694746017456.
243/243 [==============================] - 0s 969us/step - loss: 0.0010 - mae: 0.0235 - mse: 8.8683e-04 - val_loss: 0.0013 - val_mae: 0.0286 - val_mse: 0.0012 - lr: 0.0261
Epoch 33/150
243/243 [==============================] - 0s 900us/step - loss: 9.5668e-04 - mae: 0.0231 - mse: 8.5563e-04 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 9.7056e-04 - lr: 0.0131
Epoch 34/150
243/243 [==============================] - 0s 913us/step - loss: 9.2502e-04 - mae: 0.0229 - mse: 8.4142e-04 - val_loss: 9.1398e-04 - val_mae: 0.0230 - val_mse: 8.3514e-04 - lr: 0.0131
Epoch 35/150
243/243 [==============================] - 0s 897us/step - loss: 9.2794e-04 - mae: 0.0231 - mse: 8.4702e-04 - val_loss: 9.2798e-04 - val_mae: 0.0234 - val_mse: 8.5087e-04 - lr: 0.0131
Epoch 36/150
243/243 [==============================] - 0s 892us/step - loss: 9.1617e-04 - mae: 0.0229 - mse: 8.3793e-04 - val_loss: 8.9910e-04 - val_mae: 0.0225 - val_mse: 8.2691e-04 - lr: 0.0131
Epoch 37/150
243/243 [==============================] - 0s 889us/step - loss: 9.0443e-04 - mae: 0.0228 - mse: 8.2891e-04 - val_loss: 9.4961e-04 - val_mae: 0.0240 - val_mse: 8.8583e-04 - lr: 0.0131
Epoch 38/150
243/243 [==============================] - 0s 913us/step - loss: 9.2290e-04 - mae: 0.0230 - mse: 8.4549e-04 - val_loss: 9.0208e-04 - val_mae: 0.0230 - val_mse: 8.3347e-04 - lr: 0.0131
Epoch 39/150
243/243 [==============================] - 0s 902us/step - loss: 8.9823e-04 - mae: 0.0227 - mse: 8.1755e-04 - val_loss: 9.6941e-04 - val_mae: 0.0232 - val_mse: 8.8864e-04 - lr: 0.0131
Epoch 40/150
243/243 [==============================] - 0s 905us/step - loss: 9.1596e-04 - mae: 0.0228 - mse: 8.3166e-04 - val_loss: 9.0439e-04 - val_mae: 0.0232 - val_mse: 8.3854e-04 - lr: 0.0131
Epoch 41/150
243/243 [==============================] - 0s 903us/step - loss: 9.0881e-04 - mae: 0.0228 - mse: 8.2657e-04 - val_loss: 9.3935e-04 - val_mae: 0.0228 - val_mse: 8.6261e-04 - lr: 0.0131
Epoch 42/150
243/243 [==============================] - 0s 962us/step - loss: 8.8654e-04 - mae: 0.0226 - mse: 8.1457e-04 - val_loss: 8.7934e-04 - val_mae: 0.0224 - val_mse: 8.0214e-04 - lr: 0.0131
Epoch 43/150
243/243 [==============================] - 0s 881us/step - loss: 9.0643e-04 - mae: 0.0226 - mse: 8.1519e-04 - val_loss: 9.0975e-04 - val_mae: 0.0224 - val_mse: 8.3774e-04 - lr: 0.0131
Epoch 44/150
241/243 [============================>.] - ETA: 0s - loss: 8.9606e-04 - mae: 0.0225 - mse: 8.0732e-04
Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00653347373008728.
243/243 [==============================] - 0s 918us/step - loss: 8.9577e-04 - mae: 0.0225 - mse: 8.0708e-04 - val_loss: 9.2108e-04 - val_mae: 0.0235 - val_mse: 8.4357e-04 - lr: 0.0131
Epoch 45/150
243/243 [==============================] - 0s 919us/step - loss: 8.6283e-04 - mae: 0.0222 - mse: 7.9347e-04 - val_loss: 8.9146e-04 - val_mae: 0.0230 - val_mse: 8.1598e-04 - lr: 0.0065
Epoch 46/150
243/243 [==============================] - 0s 907us/step - loss: 8.6287e-04 - mae: 0.0223 - mse: 7.9187e-04 - val_loss: 9.3244e-04 - val_mae: 0.0228 - val_mse: 8.5850e-04 - lr: 0.0065
Epoch 47/150
243/243 [==============================] - 0s 905us/step - loss: 8.6040e-04 - mae: 0.0222 - mse: 7.8615e-04 - val_loss: 8.6615e-04 - val_mae: 0.0224 - val_mse: 8.1202e-04 - lr: 0.0065
Epoch 48/150
243/243 [==============================] - 0s 919us/step - loss: 8.4353e-04 - mae: 0.0220 - mse: 7.7867e-04 - val_loss: 9.1984e-04 - val_mae: 0.0226 - val_mse: 8.4365e-04 - lr: 0.0065
Epoch 49/150
243/243 [==============================] - 0s 918us/step - loss: 8.4125e-04 - mae: 0.0219 - mse: 7.7600e-04 - val_loss: 9.2728e-04 - val_mae: 0.0228 - val_mse: 8.6254e-04 - lr: 0.0065
Epoch 50/150
243/243 [==============================] - 0s 909us/step - loss: 8.7093e-04 - mae: 0.0224 - mse: 8.0208e-04 - val_loss: 9.2051e-04 - val_mae: 0.0226 - val_mse: 8.4413e-04 - lr: 0.0065
Epoch 51/150
243/243 [==============================] - 0s 909us/step - loss: 8.4451e-04 - mae: 0.0220 - mse: 7.7770e-04 - val_loss: 8.5556e-04 - val_mae: 0.0223 - val_mse: 8.0026e-04 - lr: 0.0065
Epoch 52/150
243/243 [==============================] - 0s 958us/step - loss: 8.5746e-04 - mae: 0.0223 - mse: 7.8986e-04 - val_loss: 8.5970e-04 - val_mae: 0.0223 - val_mse: 7.8975e-04 - lr: 0.0065
Epoch 53/150
243/243 [==============================] - 0s 917us/step - loss: 8.4675e-04 - mae: 0.0220 - mse: 7.8066e-04 - val_loss: 8.5116e-04 - val_mae: 0.0221 - val_mse: 7.7838e-04 - lr: 0.0065
Epoch 54/150
241/243 [============================>.] - ETA: 0s - loss: 8.5605e-04 - mae: 0.0222 - mse: 7.9290e-04
Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00326673686504364.
243/243 [==============================] - 0s 923us/step - loss: 8.5506e-04 - mae: 0.0222 - mse: 7.9190e-04 - val_loss: 8.5988e-04 - val_mae: 0.0220 - val_mse: 7.9271e-04 - lr: 0.0065
Epoch 55/150
243/243 [==============================] - 0s 924us/step - loss: 8.2803e-04 - mae: 0.0218 - mse: 7.6447e-04 - val_loss: 8.4441e-04 - val_mae: 0.0220 - val_mse: 7.8471e-04 - lr: 0.0033
Epoch 56/150
243/243 [==============================] - 0s 934us/step - loss: 8.2410e-04 - mae: 0.0218 - mse: 7.6221e-04 - val_loss: 8.5985e-04 - val_mae: 0.0220 - val_mse: 7.9898e-04 - lr: 0.0033
Epoch 57/150
243/243 [==============================] - 0s 930us/step - loss: 8.2248e-04 - mae: 0.0218 - mse: 7.6209e-04 - val_loss: 9.0775e-04 - val_mae: 0.0226 - val_mse: 8.3584e-04 - lr: 0.0033
Epoch 58/150
243/243 [==============================] - 0s 911us/step - loss: 8.0926e-04 - mae: 0.0215 - mse: 7.5047e-04 - val_loss: 8.4232e-04 - val_mae: 0.0219 - val_mse: 7.7959e-04 - lr: 0.0033
Epoch 59/150
243/243 [==============================] - 0s 909us/step - loss: 8.1611e-04 - mae: 0.0217 - mse: 7.5616e-04 - val_loss: 8.6413e-04 - val_mae: 0.0221 - val_mse: 7.9560e-04 - lr: 0.0033
Epoch 60/150
243/243 [==============================] - 0s 935us/step - loss: 8.2334e-04 - mae: 0.0218 - mse: 7.6541e-04 - val_loss: 8.4007e-04 - val_mae: 0.0219 - val_mse: 7.7808e-04 - lr: 0.0033
Epoch 61/150
243/243 [==============================] - 0s 923us/step - loss: 8.1722e-04 - mae: 0.0217 - mse: 7.5830e-04 - val_loss: 8.3981e-04 - val_mae: 0.0220 - val_mse: 7.9065e-04 - lr: 0.0033
Epoch 62/150
243/243 [==============================] - 0s 984us/step - loss: 8.1187e-04 - mae: 0.0216 - mse: 7.5605e-04 - val_loss: 8.3336e-04 - val_mae: 0.0220 - val_mse: 7.7704e-04 - lr: 0.0033
Epoch 63/150
243/243 [==============================] - 0s 989us/step - loss: 8.1451e-04 - mae: 0.0217 - mse: 7.5879e-04 - val_loss: 9.3238e-04 - val_mae: 0.0229 - val_mse: 8.6503e-04 - lr: 0.0033
Epoch 64/150
243/243 [==============================] - ETA: 0s - loss: 8.0654e-04 - mae: 0.0215 - mse: 7.5030e-04
Epoch 64: ReduceLROnPlateau reducing learning rate to 0.00163336843252182.
243/243 [==============================] - 0s 925us/step - loss: 8.0654e-04 - mae: 0.0215 - mse: 7.5030e-04 - val_loss: 8.9757e-04 - val_mae: 0.0226 - val_mse: 8.4433e-04 - lr: 0.0033
Epoch 65/150
243/243 [==============================] - 0s 924us/step - loss: 7.9805e-04 - mae: 0.0214 - mse: 7.4526e-04 - val_loss: 8.7851e-04 - val_mae: 0.0223 - val_mse: 8.1961e-04 - lr: 0.0016
Epoch 66/150
243/243 [==============================] - 0s 922us/step - loss: 7.9762e-04 - mae: 0.0214 - mse: 7.4410e-04 - val_loss: 8.6701e-04 - val_mae: 0.0222 - val_mse: 8.1050e-04 - lr: 0.0016
Epoch 67/150
243/243 [==============================] - 0s 905us/step - loss: 8.0581e-04 - mae: 0.0216 - mse: 7.5240e-04 - val_loss: 9.0986e-04 - val_mae: 0.0228 - val_mse: 8.5439e-04 - lr: 0.0016
Epoch 68/150
243/243 [==============================] - 0s 921us/step - loss: 7.9441e-04 - mae: 0.0214 - mse: 7.4047e-04 - val_loss: 8.3381e-04 - val_mae: 0.0219 - val_mse: 7.7808e-04 - lr: 0.0016
Epoch 69/150
243/243 [==============================] - 0s 912us/step - loss: 7.9386e-04 - mae: 0.0214 - mse: 7.4025e-04 - val_loss: 8.3605e-04 - val_mae: 0.0223 - val_mse: 7.8305e-04 - lr: 0.0016
Epoch 70/150
243/243 [==============================] - 0s 910us/step - loss: 8.0442e-04 - mae: 0.0216 - mse: 7.4994e-04 - val_loss: 8.5035e-04 - val_mae: 0.0220 - val_mse: 7.9273e-04 - lr: 0.0016
Epoch 71/150
243/243 [==============================] - 0s 922us/step - loss: 8.0035e-04 - mae: 0.0215 - mse: 7.4486e-04 - val_loss: 8.3026e-04 - val_mae: 0.0221 - val_mse: 7.7552e-04 - lr: 0.0016
Epoch 72/150
243/243 [==============================] - 0s 943us/step - loss: 7.9539e-04 - mae: 0.0215 - mse: 7.4100e-04 - val_loss: 8.4532e-04 - val_mae: 0.0225 - val_mse: 7.9407e-04 - lr: 0.0016
Epoch 73/150
243/243 [==============================] - 0s 936us/step - loss: 7.8811e-04 - mae: 0.0214 - mse: 7.3574e-04 - val_loss: 8.3355e-04 - val_mae: 0.0219 - val_mse: 7.7674e-04 - lr: 0.0016
Epoch 74/150
235/243 [============================>.] - ETA: 0s - loss: 7.9141e-04 - mae: 0.0214 - mse: 7.3627e-04
Epoch 74: ReduceLROnPlateau reducing learning rate to 0.00081668421626091.
243/243 [==============================] - 0s 928us/step - loss: 7.9368e-04 - mae: 0.0214 - mse: 7.3863e-04 - val_loss: 8.4948e-04 - val_mae: 0.0227 - val_mse: 7.9905e-04 - lr: 0.0016
Epoch 75/150
243/243 [==============================] - 0s 922us/step - loss: 7.8503e-04 - mae: 0.0213 - mse: 7.3241e-04 - val_loss: 8.3367e-04 - val_mae: 0.0218 - val_mse: 7.8195e-04 - lr: 8.1668e-04
Epoch 76/150
243/243 [==============================] - 0s 905us/step - loss: 7.8726e-04 - mae: 0.0214 - mse: 7.3555e-04 - val_loss: 8.2573e-04 - val_mae: 0.0218 - val_mse: 7.7514e-04 - lr: 8.1668e-04
Epoch 77/150
243/243 [==============================] - 0s 904us/step - loss: 7.8422e-04 - mae: 0.0213 - mse: 7.3256e-04 - val_loss: 8.2350e-04 - val_mae: 0.0219 - val_mse: 7.7151e-04 - lr: 8.1668e-04
Epoch 78/150
243/243 [==============================] - 0s 906us/step - loss: 7.8232e-04 - mae: 0.0212 - mse: 7.2974e-04 - val_loss: 8.2870e-04 - val_mae: 0.0218 - val_mse: 7.7863e-04 - lr: 8.1668e-04
Epoch 79/150
243/243 [==============================] - 0s 913us/step - loss: 7.8516e-04 - mae: 0.0213 - mse: 7.3353e-04 - val_loss: 8.4284e-04 - val_mae: 0.0219 - val_mse: 7.9164e-04 - lr: 8.1668e-04
Epoch 80/150
243/243 [==============================] - 0s 913us/step - loss: 7.8733e-04 - mae: 0.0213 - mse: 7.3829e-04 - val_loss: 8.2531e-04 - val_mae: 0.0218 - val_mse: 7.7415e-04 - lr: 8.1668e-04
Epoch 81/150
243/243 [==============================] - 0s 908us/step - loss: 7.8044e-04 - mae: 0.0212 - mse: 7.3024e-04 - val_loss: 8.2192e-04 - val_mae: 0.0218 - val_mse: 7.7110e-04 - lr: 8.1668e-04
Epoch 82/150
243/243 [==============================] - 0s 959us/step - loss: 7.8882e-04 - mae: 0.0213 - mse: 7.3746e-04 - val_loss: 8.2499e-04 - val_mae: 0.0218 - val_mse: 7.7347e-04 - lr: 8.1668e-04
Epoch 83/150
243/243 [==============================] - 0s 926us/step - loss: 7.8386e-04 - mae: 0.0213 - mse: 7.3316e-04 - val_loss: 8.2567e-04 - val_mae: 0.0218 - val_mse: 7.7430e-04 - lr: 8.1668e-04
Epoch 84/150
243/243 [==============================] - ETA: 0s - loss: 7.8108e-04 - mae: 0.0212 - mse: 7.3027e-04
Epoch 84: ReduceLROnPlateau reducing learning rate to 0.000408342108130455.
243/243 [==============================] - 0s 921us/step - loss: 7.8108e-04 - mae: 0.0212 - mse: 7.3027e-04 - val_loss: 8.2076e-04 - val_mae: 0.0219 - val_mse: 7.7028e-04 - lr: 8.1668e-04
Epoch 85/150
243/243 [==============================] - 0s 910us/step - loss: 7.8046e-04 - mae: 0.0212 - mse: 7.3021e-04 - val_loss: 8.2338e-04 - val_mae: 0.0218 - val_mse: 7.7203e-04 - lr: 4.0834e-04
Epoch 86/150
243/243 [==============================] - 0s 912us/step - loss: 7.7941e-04 - mae: 0.0212 - mse: 7.2945e-04 - val_loss: 8.2163e-04 - val_mae: 0.0220 - val_mse: 7.7303e-04 - lr: 4.0834e-04
Epoch 87/150
243/243 [==============================] - 0s 899us/step - loss: 7.8026e-04 - mae: 0.0212 - mse: 7.3076e-04 - val_loss: 8.2068e-04 - val_mae: 0.0218 - val_mse: 7.6986e-04 - lr: 4.0834e-04
Epoch 88/150
243/243 [==============================] - 0s 922us/step - loss: 7.7762e-04 - mae: 0.0212 - mse: 7.2713e-04 - val_loss: 8.2060e-04 - val_mae: 0.0218 - val_mse: 7.7027e-04 - lr: 4.0834e-04
Epoch 89/150
243/243 [==============================] - 0s 911us/step - loss: 7.7801e-04 - mae: 0.0212 - mse: 7.2789e-04 - val_loss: 8.4122e-04 - val_mae: 0.0219 - val_mse: 7.8976e-04 - lr: 4.0834e-04
Epoch 90/150
243/243 [==============================] - 0s 926us/step - loss: 7.7645e-04 - mae: 0.0212 - mse: 7.2600e-04 - val_loss: 8.3913e-04 - val_mae: 0.0219 - val_mse: 7.8789e-04 - lr: 4.0834e-04
Epoch 91/150
243/243 [==============================] - 0s 908us/step - loss: 7.7666e-04 - mae: 0.0212 - mse: 7.2734e-04 - val_loss: 8.2572e-04 - val_mae: 0.0218 - val_mse: 7.7590e-04 - lr: 4.0834e-04
Epoch 92/150
243/243 [==============================] - 0s 976us/step - loss: 7.7791e-04 - mae: 0.0212 - mse: 7.2832e-04 - val_loss: 8.2108e-04 - val_mae: 0.0218 - val_mse: 7.7080e-04 - lr: 4.0834e-04
Epoch 93/150
243/243 [==============================] - 0s 919us/step - loss: 7.7772e-04 - mae: 0.0212 - mse: 7.2770e-04 - val_loss: 8.2074e-04 - val_mae: 0.0218 - val_mse: 7.7120e-04 - lr: 4.0834e-04
Epoch 94/150
243/243 [==============================] - ETA: 0s - loss: 7.7839e-04 - mae: 0.0212 - mse: 7.2929e-04
Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0002041710540652275.
243/243 [==============================] - 0s 915us/step - loss: 7.7839e-04 - mae: 0.0212 - mse: 7.2929e-04 - val_loss: 8.2348e-04 - val_mae: 0.0218 - val_mse: 7.7262e-04 - lr: 4.0834e-04
Epoch 95/150
243/243 [==============================] - 0s 928us/step - loss: 7.7616e-04 - mae: 0.0212 - mse: 7.2652e-04 - val_loss: 8.3520e-04 - val_mae: 0.0219 - val_mse: 7.8392e-04 - lr: 2.0417e-04
Epoch 96/150
243/243 [==============================] - 0s 914us/step - loss: 7.7506e-04 - mae: 0.0211 - mse: 7.2511e-04 - val_loss: 8.1912e-04 - val_mae: 0.0218 - val_mse: 7.6959e-04 - lr: 2.0417e-04
Epoch 97/150
243/243 [==============================] - 0s 906us/step - loss: 7.7466e-04 - mae: 0.0211 - mse: 7.2524e-04 - val_loss: 8.1929e-04 - val_mae: 0.0219 - val_mse: 7.7109e-04 - lr: 2.0417e-04
Epoch 98/150
243/243 [==============================] - 0s 962us/step - loss: 7.7539e-04 - mae: 0.0211 - mse: 7.2635e-04 - val_loss: 8.2328e-04 - val_mae: 0.0218 - val_mse: 7.7349e-04 - lr: 2.0417e-04
Epoch 99/150
243/243 [==============================] - 0s 1ms/step - loss: 7.7365e-04 - mae: 0.0211 - mse: 7.2440e-04 - val_loss: 8.1925e-04 - val_mae: 0.0218 - val_mse: 7.7030e-04 - lr: 2.0417e-04
Epoch 100/150
243/243 [==============================] - 0s 917us/step - loss: 7.7418e-04 - mae: 0.0211 - mse: 7.2555e-04 - val_loss: 8.1856e-04 - val_mae: 0.0219 - val_mse: 7.7017e-04 - lr: 2.0417e-04
Epoch 101/150
243/243 [==============================] - 0s 900us/step - loss: 7.7488e-04 - mae: 0.0211 - mse: 7.2566e-04 - val_loss: 8.2159e-04 - val_mae: 0.0218 - val_mse: 7.7192e-04 - lr: 2.0417e-04
Epoch 102/150
243/243 [==============================] - 0s 914us/step - loss: 7.7372e-04 - mae: 0.0211 - mse: 7.2480e-04 - val_loss: 8.1888e-04 - val_mae: 0.0219 - val_mse: 7.7078e-04 - lr: 2.0417e-04
Epoch 103/150
243/243 [==============================] - 0s 909us/step - loss: 7.7597e-04 - mae: 0.0212 - mse: 7.2708e-04 - val_loss: 8.1758e-04 - val_mae: 0.0218 - val_mse: 7.6910e-04 - lr: 2.0417e-04
Epoch 104/150
165/243 [===================>..........] - ETA: 0s - loss: 7.7276e-04 - mae: 0.0212 - mse: 7.2350e-04
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0002s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0027s). Check your callbacks.
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016
Epoch 30/150===========================] - 0s 890us/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 0.0016