Epoch 1/30
 1/17 [>.............................] - ETA: 5s - loss: 0.7629 - mae: 0.4229 - mse: 0.1805
17/17 [==============================] - 1s 45ms/step - loss: 0.0838 - mae: 0.0819 - mse: 0.0162 - val_loss: 0.0153 - val_mae: 0.1054 - val_mse: 0.0130 - lr: 0.0844
Epoch 2/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0164 - mae: 0.1102 - mse: 0.0141
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184250-3yw8pfjl\files\model-best)... Done. 0.0s
17/17 [==============================] - 1s 50ms/step - loss: 0.0139 - mae: 0.0593 - mse: 0.0053 - val_loss: 0.0149 - val_mae: 0.0649 - val_mse: 0.0060 - lr: 0.0844
Epoch 3/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0484 - mse: 0.0035 - val_loss: 0.0206 - val_mae: 0.0718 - val_mse: 0.0071 - lr: 0.0844
Epoch 4/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0212 - mae: 0.0750 - mse: 0.0076
17/17 [==============================] - 1s 42ms/step - loss: 0.0097 - mae: 0.0498 - mse: 0.0037 - val_loss: 0.0060 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0844
Epoch 5/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0084 - mae: 0.0445 - mse: 0.0029 - val_loss: 0.0061 - val_mae: 0.0396 - val_mse: 0.0021 - lr: 0.0844
Epoch 6/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0076 - mae: 0.0422 - mse: 0.0026 - val_loss: 0.0069 - val_mae: 0.0409 - val_mse: 0.0023 - lr: 0.0844
Epoch 7/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0392 - mse: 0.0022
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.04218948632478714.
17/17 [==============================] - 0s 2ms/step - loss: 0.0068 - mae: 0.0391 - mse: 0.0021 - val_loss: 0.0071 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0844
Epoch 8/30
17/17 [==============================] - 1s 40ms/step - loss: 0.0023 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 0.0422
Epoch 9/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0039 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0422
Epoch 10/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0032 - val_mae: 0.0381 - val_mse: 0.0020 - lr: 0.0422
Epoch 11/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0042 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0422
Epoch 12/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0041 - mae: 0.0381 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.02109474316239357.
17/17 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0031 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0422
Epoch 13/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0029 - mae: 0.0358 - mse: 0.0018
17/17 [==============================] - 1s 42ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 0.0211
Epoch 14/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 0.0211
Epoch 15/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0376 - mse: 0.0019
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.010547371581196785.
17/17 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0379 - val_mse: 0.0020 - lr: 0.0211
Epoch 16/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0377 - mse: 0.0019
17/17 [==============================] - 1s 42ms/step - loss: 0.0019 - mae: 0.0375 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 0.0105
Epoch 17/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0375 - val_mse: 0.0019 - lr: 0.0105
Epoch 18/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0373 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 0.0105
Epoch 19/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0371 - mse: 0.0018 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0105
Epoch 20/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0393 - mse: 0.0020
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0052736857905983925.
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0369 - mse: 0.0018 - val_loss: 0.0022 - val_mae: 0.0380 - val_mse: 0.0020 - lr: 0.0105
Epoch 21/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0389 - mse: 0.0021
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_184250-3yw8pfjl\files\model-best)... Done. 0.0s
17/17 [==============================] - 1s 43ms/step - loss: 0.0019 - mae: 0.0368 - mse: 0.0018 - val_loss: 0.0019 - val_mae: 0.0367 - val_mse: 0.0018 - lr: 0.0053
Epoch 22/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0365 - mse: 0.0018 - val_loss: 0.0019 - val_mae: 0.0368 - val_mse: 0.0018 - lr: 0.0053
Epoch 23/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0368 - mse: 0.0018
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0026368428952991962.
17/17 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0363 - mse: 0.0018 - val_loss: 0.0019 - val_mae: 0.0368 - val_mse: 0.0018 - lr: 0.0053
Epoch 24/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0353 - mse: 0.0017
17/17 [==============================] - 1s 42ms/step - loss: 0.0018 - mae: 0.0363 - mse: 0.0018 - val_loss: 0.0019 - val_mae: 0.0370 - val_mse: 0.0018 - lr: 0.0026
Epoch 25/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0363 - mse: 0.0018 - val_loss: 0.0019 - val_mae: 0.0366 - val_mse: 0.0018 - lr: 0.0026
Epoch 26/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0350 - mse: 0.0016
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0013184214476495981.
17/17 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0362 - mse: 0.0018 - val_loss: 0.0019 - val_mae: 0.0366 - val_mse: 0.0018 - lr: 0.0026
Epoch 27/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0360 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0369 - val_mse: 0.0018 - lr: 0.0013
Epoch 28/30
17/17 [==============================] - 1s 43ms/step - loss: 0.0018 - mae: 0.0362 - mse: 0.0018 - val_loss: 0.0018 - val_mae: 0.0363 - val_mse: 0.0018 - lr: 0.0013
Epoch 29/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0373 - mse: 0.0018
Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0006592107238247991.
17/17 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0360 - mse: 0.0017 - val_loss: 0.0018 - val_mae: 0.0362 - val_mse: 0.0018 - lr: 0.0013
Epoch 30/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0370 - mse: 0.0018
17/17 [==============================] - 1s 48ms/step - loss: 0.0018 - mae: 0.0360 - mse: 0.0017 - val_loss: 0.0018 - val_mae: 0.0363 - val_mse: 0.0018 - lr: 6.5921e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.0843789707857179_30_240_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
22/22 [==============================] - 0s 7ms/step - loss: 0.0669 - mae: 0.0850 - mse: 0.0126 - val_loss: 0.0081 - val_mae: 0.0600 - val_mse: 0.0053 - lr: 0.0844
Epoch 2/30
22/22 [==============================] - 0s 2ms/step - loss: 0.0076 - mae: 0.0578 - mse: 0.0048 - val_loss: 0.0065 - val_mae: 0.0537 - val_mse: 0.0040 - lr: 0.0844
Epoch 3/30
22/22 [==============================] - 0s 2ms/step - loss: 0.0070 - mae: 0.0517 - mse: 0.0037 - val_loss: 0.0082 - val_mae: 0.0516 - val_mse: 0.0037 - lr: 0.0844
Epoch 4/30
22/22 [==============================] - 0s 2ms/step - loss: 0.0083 - mae: 0.0511 - mse: 0.0035 - val_loss: 0.0083 - val_mae: 0.0506 - val_mse: 0.0035 - lr: 0.0844
Epoch 5/30
22/22 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0539 - mse: 0.0040 - val_loss: 0.0080 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0844
Epoch 6/30
22/22 [==============================] - 0s 2ms/step - loss: 0.0081 - mae: 0.0509 - mse: 0.0035 - val_loss: 0.0082 - val_mae: 0.0517 - val_mse: 0.0036 - lr: 0.0844
Epoch 7/30
 1/22 [>.............................] - ETA: 0s - loss: 0.0083 - mae: 0.0524 - mse: 0.0037
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.04218948632478714.
22/22 [==============================] - 0s 2ms/step - loss: 0.0085 - mae: 0.0517 - mse: 0.0036 - val_loss: 0.0084 - val_mae: 0.0508 - val_mse: 0.0035 - lr: 0.0844
Epoch 8/30
22/22 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0506 - val_mse: 0.0035 - lr: 0.0422
Epoch 9/30
22/22 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0422
Epoch 10/30
 1/22 [>.............................] - ETA: 0s - loss: 0.0030 - mae: 0.0458 - mse: 0.0029
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.02109474316239357.
22/22 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0050 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0422
Epoch 11/30
22/22 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0211
Epoch 12/30
22/22 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0040 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0211
Epoch 13/30
 1/22 [>.............................] - ETA: 0s - loss: 0.0038 - mae: 0.0483 - mse: 0.0032
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.010547371581196785.
22/22 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0211
Epoch 14/30
22/22 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0508 - val_mse: 0.0035 - lr: 0.0105
Epoch 15/30
22/22 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0105
Epoch 16/30
 1/22 [>.............................] - ETA: 0s - loss: 0.0035 - mae: 0.0514 - mse: 0.0035
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0052736857905983925.
22/22 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0105
Epoch 17/30
22/22 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0053
Epoch 18/30
22/22 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0053
Epoch 19/30
 1/22 [>.............................] - ETA: 0s - loss: 0.0035 - mae: 0.0511 - mse: 0.0034
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0026368428952991962.
22/22 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0053
Epoch 20/30
22/22 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0026
Epoch 21/30
22/22 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0026
Epoch 22/30
 1/22 [>.............................] - ETA: 0s - loss: 0.0038 - mae: 0.0548 - mse: 0.0038
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0013184214476495981.
22/22 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0026
Epoch 23/30
22/22 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0013
Epoch 24/30
22/22 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0013
Epoch 25/30
 1/22 [>.............................] - ETA: 0s - loss: 0.0035 - mae: 0.0512 - mse: 0.0035
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0006592107238247991.
22/22 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0013
Epoch 26/30
22/22 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.5921e-04
Epoch 27/30
22/22 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.5921e-04
Epoch 28/30
 1/22 [>.............................] - ETA: 0s - loss: 0.0032 - mae: 0.0483 - mse: 0.0032
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00032960536191239953.
22/22 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.5921e-04
Epoch 29/30
22/22 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.2961e-04
Epoch 30/30
22/22 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.2961e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.0843789707857179_30_240_30epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
17/17 [==============================] - 0s 7ms/step - loss: 0.0725 - mae: 0.0745 - mse: 0.0104 - val_loss: 0.0101 - val_mae: 0.0787 - val_mse: 0.0081 - lr: 0.0844
Epoch 2/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0458 - mse: 0.0031 - val_loss: 0.0040 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0844
Epoch 3/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0389 - mse: 0.0021 - val_loss: 0.0052 - val_mae: 0.0409 - val_mse: 0.0024 - lr: 0.0844
Epoch 4/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0400 - mse: 0.0022 - val_loss: 0.0067 - val_mae: 0.0393 - val_mse: 0.0021 - lr: 0.0844
Epoch 5/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0067 - mae: 0.0397 - mse: 0.0021
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.04218948632478714.
17/17 [==============================] - 0s 2ms/step - loss: 0.0072 - mae: 0.0394 - mse: 0.0021 - val_loss: 0.0085 - val_mae: 0.0457 - val_mse: 0.0031 - lr: 0.0844
Epoch 6/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0422
Epoch 7/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0044 - val_mae: 0.0409 - val_mse: 0.0023 - lr: 0.0422
Epoch 8/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0045 - mae: 0.0410 - mse: 0.0024
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.02109474316239357.
17/17 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0031 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0422
Epoch 9/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0389 - val_mse: 0.0020 - lr: 0.0211
Epoch 10/30
17/17 [==============================] - 0s 5ms/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0211
Epoch 11/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0379 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.010547371581196785.
17/17 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0211
Epoch 12/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0105
Epoch 13/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0105
Epoch 14/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0355 - mse: 0.0018
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0052736857905983925.
17/17 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0105
Epoch 15/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0053
Epoch 16/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0053
Epoch 17/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0026368428952991962.
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0053
Epoch 18/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0026
Epoch 19/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0026
Epoch 20/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0399 - mse: 0.0020
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0013184214476495981.
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0026
Epoch 21/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 22/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0013
Epoch 23/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0405 - mse: 0.0021
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0006592107238247991.
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 24/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.5921e-04
Epoch 25/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.5921e-04
Epoch 26/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0359 - mse: 0.0017
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00032960536191239953.
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.5921e-04
Epoch 27/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.2961e-04
Epoch 28/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.2961e-04
Epoch 29/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0384 - mse: 0.0020
Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00016480268095619977.
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.2961e-04
Epoch 30/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6480e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.0843789707857179_30_240_30epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
17/17 [==============================] - 0s 7ms/step - loss: 0.0640 - mae: 0.0514 - mse: 0.0046 - val_loss: 0.0028 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0844
Epoch 2/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0045 - val_mae: 0.0396 - val_mse: 0.0021 - lr: 0.0844
Epoch 3/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0421 - mse: 0.0025 - val_loss: 0.0057 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0844
Epoch 4/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0059 - mae: 0.0405 - mse: 0.0021
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.04218948632478714.
17/17 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0146 - val_mae: 0.0718 - val_mse: 0.0071 - lr: 0.0844
Epoch 5/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0031 - mae: 0.0400 - mse: 0.0022 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0422
Epoch 6/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0025 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0030 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0422
Epoch 7/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0394 - mse: 0.0020
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.02109474316239357.
17/17 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0030 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0422
Epoch 8/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0211
Epoch 9/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0211
Epoch 10/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0023 - mae: 0.0381 - mse: 0.0020
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.010547371581196785.
17/17 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0211
Epoch 11/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0105
Epoch 12/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0105
Epoch 13/30
17/17 [==============================] - ETA: 0s - loss: 0.0020 - mae: 0.0379 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0052736857905983925.
17/17 [==============================] - 0s 6ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0105
Epoch 14/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0053
Epoch 15/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0053
Epoch 16/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0388 - mse: 0.0020
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0026368428952991962.
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0053
Epoch 17/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0026
Epoch 18/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0026
Epoch 19/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0402 - mse: 0.0021
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0013184214476495981.
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0026
Epoch 20/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 21/30
17/17 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 22/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0375 - mse: 0.0018
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006592107238247991.
17/17 [==============================] - 0s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 23/30
17/17 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.5921e-04
Epoch 24/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0399 - mse: 0.0021
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0007s vs `on_train_batch_end` time: 0.0009s). Check your callbacks.
17/17 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0211e-04
Epoch 25/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0395 - mse: 0.0020
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00032960536191239953.
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.5921e-04
Epoch 26/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.2961e-04
Epoch 27/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.2961e-04
Epoch 28/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0419 - mse: 0.0022
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00016480268095619977.
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.2961e-04
Epoch 29/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6480e-04
Epoch 30/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6480e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.0843789707857179_30_240_30epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
17/17 [==============================] - 0s 7ms/step - loss: 0.0751 - mae: 0.0618 - mse: 0.0098 - val_loss: 0.0025 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0844
Epoch 2/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0038 - mae: 0.0387 - mse: 0.0021 - val_loss: 0.0045 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0844
Epoch 3/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0066 - mae: 0.0468 - mse: 0.0035 - val_loss: 0.0078 - val_mae: 0.0395 - val_mse: 0.0022 - lr: 0.0844
Epoch 4/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0077 - mae: 0.0385 - mse: 0.0020
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.04218948632478714.
17/17 [==============================] - 0s 3ms/step - loss: 0.0073 - mae: 0.0438 - mse: 0.0028 - val_loss: 0.0069 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0844
Epoch 5/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0422
Epoch 6/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0032 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0422
Epoch 7/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0031 - mae: 0.0391 - mse: 0.0020
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.02109474316239357.
17/17 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0032 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0422
Epoch 8/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0211
Epoch 9/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0211
Epoch 10/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0381 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.010547371581196785.
17/17 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0390 - val_mse: 0.0020 - lr: 0.0211
Epoch 11/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0105
Epoch 12/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0105
Epoch 13/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0382 - mse: 0.0020
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0052736857905983925.
17/17 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0105
Epoch 14/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0053
Epoch 15/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0053
Epoch 16/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0017 - mae: 0.0353 - mse: 0.0017
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0026368428952991962.
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0053
Epoch 17/30
17/17 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0026
Epoch 18/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0026
Epoch 19/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0370 - mse: 0.0019
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0013184214476495981.
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0026
Epoch 20/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 21/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0013
Epoch 22/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.0019
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006592107238247991.
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0013
Epoch 23/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.5921e-04
Epoch 24/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.5921e-04
Epoch 25/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0392 - mse: 0.0020
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00032960536191239953.
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.5921e-04
Epoch 26/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.2961e-04
Epoch 27/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.2961e-04
Epoch 28/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.0019
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00016480268095619977.
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.2961e-04
Epoch 29/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6480e-04
Epoch 30/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6480e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.0843789707857179_30_240_30epochs/model_5.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
17/17 [==============================] - 0s 7ms/step - loss: 0.0759 - mae: 0.0673 - mse: 0.0073 - val_loss: 0.0027 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0844
Epoch 2/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0042 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0844
Epoch 3/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0050 - mae: 0.0400 - mse: 0.0022 - val_loss: 0.0055 - val_mae: 0.0394 - val_mse: 0.0021 - lr: 0.0844
Epoch 4/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0068 - mae: 0.0404 - mse: 0.0023 - val_loss: 0.0074 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0844
Epoch 5/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0067 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0228 - val_mae: 0.1060 - val_mse: 0.0132 - lr: 0.0844
Epoch 6/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0106 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0062 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0844
Epoch 7/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0063 - mae: 0.0394 - mse: 0.0021
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.04218948632478714.
17/17 [==============================] - 0s 3ms/step - loss: 0.0063 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0083 - val_mae: 0.0462 - val_mse: 0.0032 - lr: 0.0844
Epoch 8/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0422
Epoch 9/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0042 - val_mae: 0.0402 - val_mse: 0.0022 - lr: 0.0422
Epoch 10/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0042 - mae: 0.0395 - mse: 0.0022
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.02109474316239357.
17/17 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0036 - val_mae: 0.0396 - val_mse: 0.0021 - lr: 0.0422
Epoch 11/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0211
Epoch 12/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0211
Epoch 13/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0025 - mae: 0.0387 - mse: 0.0020
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.010547371581196785.
17/17 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0211
Epoch 14/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0105
Epoch 15/30
17/17 [==============================] - 0s 6ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0105
Epoch 16/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0052736857905983925.
17/17 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0105
Epoch 17/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0053
Epoch 18/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0053
Epoch 19/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0392 - mse: 0.0021
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0026368428952991962.
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0053
Epoch 20/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0026
Epoch 21/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0026
Epoch 22/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0364 - mse: 0.0018
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0013184214476495981.
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0026
Epoch 23/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 24/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0013
Epoch 25/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0006592107238247991.
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 26/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.5921e-04
Epoch 27/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.5921e-04
Epoch 28/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0363 - mse: 0.0018
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00032960536191239953.
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.5921e-04
Epoch 29/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.2961e-04
Epoch 30/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.2961e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.0843789707857179_30_240_30epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
17/17 [==============================] - 0s 8ms/step - loss: 0.0810 - mae: 0.0724 - mse: 0.0105 - val_loss: 0.0034 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0844
Epoch 2/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0424 - mse: 0.0026 - val_loss: 0.0061 - val_mae: 0.0479 - val_mse: 0.0034 - lr: 0.0844
Epoch 3/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0395 - mse: 0.0022 - val_loss: 0.0068 - val_mae: 0.0452 - val_mse: 0.0030 - lr: 0.0844
Epoch 4/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0068 - mae: 0.0450 - mse: 0.0030
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.04218948632478714.
17/17 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0412 - mse: 0.0024 - val_loss: 0.0067 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0844
Epoch 5/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0422
Epoch 6/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0028 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.0030 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0422
Epoch 7/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0028 - mae: 0.0375 - mse: 0.0018
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.02109474316239357.
17/17 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0029 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0422
Epoch 8/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0211e-04
Epoch 9/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0211
Epoch 10/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0364 - mse: 0.0018
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.010547371581196785.
17/17 [==============================] - 0s 3ms/step - loss: 0.0023 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0211
Epoch 11/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0105
Epoch 12/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0105
Epoch 13/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0384 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0052736857905983925.
17/17 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0105
Epoch 14/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0053
Epoch 15/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0053
Epoch 16/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0026368428952991962.
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0053
Epoch 17/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0026
Epoch 18/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0026
Epoch 19/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0392 - mse: 0.0021
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0013184214476495981.
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0026
Epoch 20/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 21/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 22/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0361 - mse: 0.0018
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0006592107238247991.
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0013
Epoch 23/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.5921e-04
Epoch 24/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.5921e-04
Epoch 25/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0402 - mse: 0.0021
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00032960536191239953.
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.5921e-04
Epoch 26/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.2961e-04
Epoch 27/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.2961e-04
Epoch 28/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0371 - mse: 0.0018
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00016480268095619977.
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.2961e-04
Epoch 29/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.6480e-04
Epoch 30/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.6480e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.0843789707857179_30_240_30epochs/model_7.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
17/17 [==============================] - 0s 8ms/step - loss: 0.0807 - mae: 0.0871 - mse: 0.0149 - val_loss: 0.0056 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0844
Epoch 2/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0079 - mae: 0.0527 - mse: 0.0042 - val_loss: 0.0060 - val_mae: 0.0476 - val_mse: 0.0034 - lr: 0.0844
Epoch 3/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0062 - mae: 0.0452 - mse: 0.0030 - val_loss: 0.0073 - val_mae: 0.0409 - val_mse: 0.0023 - lr: 0.0844
Epoch 4/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0074 - mae: 0.0419 - mse: 0.0024
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.04218948632478714.
17/17 [==============================] - 0s 2ms/step - loss: 0.0069 - mae: 0.0421 - mse: 0.0025 - val_loss: 0.0064 - val_mae: 0.0390 - val_mse: 0.0020 - lr: 0.0844
Epoch 5/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0422
Epoch 6/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0031 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0422
Epoch 7/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0029 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0422
Epoch 8/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0032 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0422
Epoch 9/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0035 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0422
Epoch 10/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0033 - mae: 0.0373 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.02109474316239357.
17/17 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0032 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0422
Epoch 11/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0211
Epoch 12/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0211
Epoch 13/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0374 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.010547371581196785.
17/17 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0211
Epoch 14/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0105
Epoch 15/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0105
Epoch 16/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0022 - mae: 0.0404 - mse: 0.0021
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0052736857905983925.
17/17 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0105
Epoch 17/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0053
Epoch 18/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0053
Epoch 19/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0026368428952991962.
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0053
Epoch 20/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0026
Epoch 21/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0026
Epoch 22/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.0019
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0013184214476495981.
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0026
Epoch 23/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0013
Epoch 24/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 25/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0006592107238247991.
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 26/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.5921e-04
Epoch 27/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.5921e-04
Epoch 28/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0385 - mse: 0.0020
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00032960536191239953.
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.5921e-04
Epoch 29/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.2961e-04
Epoch 30/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.2961e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.0843789707857179_30_240_30epochs/model_8.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
17/17 [==============================] - 0s 8ms/step - loss: 0.0789 - mae: 0.0764 - mse: 0.0157 - val_loss: 0.0066 - val_mae: 0.0420 - val_mse: 0.0025 - lr: 0.0844
Epoch 2/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0080 - mae: 0.0492 - mse: 0.0036 - val_loss: 0.0050 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0844
Epoch 3/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0564 - mse: 0.0048 - val_loss: 0.0062 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0844
Epoch 4/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0494 - mse: 0.0037 - val_loss: 0.0085 - val_mae: 0.0509 - val_mse: 0.0039 - lr: 0.0844
Epoch 5/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0085 - mae: 0.0505 - mse: 0.0039
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.04218948632478714.
17/17 [==============================] - 0s 3ms/step - loss: 0.0107 - mae: 0.0535 - mse: 0.0043 - val_loss: 0.0072 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0844
Epoch 6/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0030 - mae: 0.0398 - mse: 0.0022 - val_loss: 0.0028 - val_mae: 0.0407 - val_mse: 0.0023 - lr: 0.0422
Epoch 7/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0033 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.0054 - val_mae: 0.0462 - val_mse: 0.0032 - lr: 0.0422
Epoch 8/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0051 - mae: 0.0435 - mse: 0.0029
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.02109474316239357.
17/17 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0408 - mse: 0.0024 - val_loss: 0.0045 - val_mae: 0.0436 - val_mse: 0.0028 - lr: 0.0422
Epoch 9/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0389 - mse: 0.0021 - val_loss: 0.0022 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0211
Epoch 10/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0024 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.0024 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0211
Epoch 11/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0024 - mae: 0.0396 - mse: 0.0021
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.010547371581196785.
17/17 [==============================] - 0s 3ms/step - loss: 0.0025 - mae: 0.0388 - mse: 0.0020 - val_loss: 0.0025 - val_mae: 0.0401 - val_mse: 0.0022 - lr: 0.0211
Epoch 12/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0105
Epoch 13/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0105
Epoch 14/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0018 - mae: 0.0352 - mse: 0.0017
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0052736857905983925.
17/17 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0105
Epoch 15/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0053
Epoch 16/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0053
Epoch 17/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0021 - mae: 0.0398 - mse: 0.0021
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0026368428952991962.
17/17 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0399 - val_mse: 0.0022 - lr: 0.0053
Epoch 18/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0026
Epoch 19/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0026
Epoch 20/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0013184214476495981.
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0026
Epoch 21/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 22/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 23/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.0019
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0006592107238247991.
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 24/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.5921e-04
Epoch 25/30
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.5921e-04
Epoch 26/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00032960536191239953.
17/17 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 6.5921e-04
Epoch 27/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.2961e-04
Epoch 28/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.2961e-04
Epoch 29/30
 1/17 [>.............................] - ETA: 0s - loss: 0.0019 - mae: 0.0369 - mse: 0.0019
Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00016480268095619977.
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.2961e-04
Epoch 30/30
17/17 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.6480e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.0843789707857179_30_240_30epochs/model_9.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])