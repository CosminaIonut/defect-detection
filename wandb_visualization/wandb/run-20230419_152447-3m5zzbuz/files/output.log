Epoch 1/30
210/243 [========================>.....] - ETA: 0s - loss: 0.0251 - mae: 0.0487 - mse: 0.0042
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0004s vs `on_train_batch_end` time: 0.0018s). Check your callbacks.
243/243 [==============================] - 2s 6ms/step - loss: 0.0229 - mae: 0.0474 - mse: 0.0039 - val_loss: 0.0084 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0650
Epoch 2/30
215/243 [=========================>....] - ETA: 0s - loss: 0.0087 - mae: 0.0384 - mse: 0.0020
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.03248210251331329.
243/243 [==============================] - 1s 3ms/step - loss: 0.0087 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0114 - val_mae: 0.0454 - val_mse: 0.0031 - lr: 0.0650
Epoch 3/30
231/243 [===========================>..] - ETA: 0s - loss: 0.0023 - mae: 0.0369 - mse: 0.0019
243/243 [==============================] - 2s 6ms/step - loss: 0.0023 - mae: 0.0369 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0364 - val_mse: 0.0018 - lr: 0.0325
Epoch 4/30
215/243 [=========================>....] - ETA: 0s - loss: 0.0022 - mae: 0.0345 - mse: 0.0017
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.016241051256656647.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_152447-3m5zzbuz\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 6ms/step - loss: 0.0021 - mae: 0.0343 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0324 - val_mse: 0.0015 - lr: 0.0325
Epoch 5/30
236/243 [============================>.] - ETA: 0s - loss: 0.0016 - mae: 0.0309 - mse: 0.0014
243/243 [==============================] - 1s 6ms/step - loss: 0.0016 - mae: 0.0308 - mse: 0.0014 - val_loss: 0.0016 - val_mae: 0.0295 - val_mse: 0.0013 - lr: 0.0162
Epoch 6/30
220/243 [==========================>...] - ETA: 0s - loss: 0.0015 - mae: 0.0283 - mse: 0.0013
243/243 [==============================] - 1s 6ms/step - loss: 0.0015 - mae: 0.0282 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0275 - val_mse: 0.0012 - lr: 0.0162
Epoch 7/30
220/243 [==========================>...] - ETA: 0s - loss: 0.0014 - mae: 0.0264 - mse: 0.0011
243/243 [==============================] - 2s 6ms/step - loss: 0.0014 - mae: 0.0265 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0249 - val_mse: 9.9587e-04 - lr: 0.0162
Epoch 8/30
210/243 [========================>.....] - ETA: 0s - loss: 0.0013 - mae: 0.0250 - mse: 0.0010
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.008120525628328323.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_152447-3m5zzbuz\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0250 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0240 - val_mse: 9.3301e-04 - lr: 0.0162
Epoch 9/30
213/243 [=========================>....] - ETA: 0s - loss: 0.0011 - mae: 0.0240 - mse: 9.4656e-04
243/243 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0237 - mse: 9.3273e-04 - val_loss: 0.0011 - val_mae: 0.0242 - val_mse: 9.4379e-04 - lr: 0.0081
Epoch 10/30
221/243 [==========================>...] - ETA: 0s - loss: 0.0011 - mae: 0.0231 - mse: 8.8990e-04
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.004060262814164162.
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0232 - mse: 8.9936e-04 - val_loss: 0.0011 - val_mae: 0.0247 - val_mse: 9.7525e-04 - lr: 0.0081
Epoch 11/30
235/243 [============================>.] - ETA: 0s - loss: 0.0010 - mae: 0.0229 - mse: 8.7244e-04
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.002030131407082081.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_152447-3m5zzbuz\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_152447-3m5zzbuz\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 6ms/step - loss: 0.0010 - mae: 0.0228 - mse: 8.6824e-04 - val_loss: 9.9808e-04 - val_mae: 0.0233 - val_mse: 8.7815e-04 - lr: 0.0041
Epoch 12/30
214/243 [=========================>....] - ETA: 0s - loss: 9.7527e-04 - mae: 0.0225 - mse: 8.5113e-04
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0010150657035410404.
243/243 [==============================] - 1s 6ms/step - loss: 9.7708e-04 - mae: 0.0225 - mse: 8.5373e-04 - val_loss: 9.9130e-04 - val_mae: 0.0232 - val_mse: 8.7549e-04 - lr: 0.0020
Epoch 13/30
217/243 [=========================>....] - ETA: 0s - loss: 9.6076e-04 - mae: 0.0224 - mse: 8.4498e-04
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005075328517705202.
243/243 [==============================] - 1s 3ms/step - loss: 9.6513e-04 - mae: 0.0225 - mse: 8.4834e-04 - val_loss: 9.9222e-04 - val_mae: 0.0230 - val_mse: 8.6378e-04 - lr: 0.0010
Epoch 14/30
215/243 [=========================>....] - ETA: 0s - loss: 9.6201e-04 - mae: 0.0224 - mse: 8.3870e-04
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002537664258852601.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_152447-3m5zzbuz\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 6ms/step - loss: 9.6103e-04 - mae: 0.0223 - mse: 8.3809e-04 - val_loss: 9.8669e-04 - val_mae: 0.0231 - val_mse: 8.6740e-04 - lr: 5.0753e-04
Epoch 15/30
220/243 [==========================>...] - ETA: 0s - loss: 9.5795e-04 - mae: 0.0224 - mse: 8.4006e-04
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00012688321294263005.
243/243 [==============================] - 1s 3ms/step - loss: 9.5652e-04 - mae: 0.0223 - mse: 8.3842e-04 - val_loss: 9.8778e-04 - val_mae: 0.0231 - val_mse: 8.6892e-04 - lr: 2.5377e-04
Epoch 16/30
239/243 [============================>.] - ETA: 0s - loss: 9.5742e-04 - mae: 0.0223 - mse: 8.3958e-04
Epoch 16: ReduceLROnPlateau reducing learning rate to 6.344160647131503e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_152447-3m5zzbuz\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 6ms/step - loss: 9.5579e-04 - mae: 0.0223 - mse: 8.3795e-04 - val_loss: 9.8587e-04 - val_mae: 0.0231 - val_mse: 8.6865e-04 - lr: 1.2688e-04
Epoch 17/30
242/243 [============================>.] - ETA: 0s - loss: 9.5509e-04 - mae: 0.0223 - mse: 8.3806e-04
Epoch 17: ReduceLROnPlateau reducing learning rate to 3.172080323565751e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_152447-3m5zzbuz\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_152447-3m5zzbuz\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 6ms/step - loss: 9.5500e-04 - mae: 0.0223 - mse: 8.3798e-04 - val_loss: 9.8476e-04 - val_mae: 0.0231 - val_mse: 8.6841e-04 - lr: 6.3442e-05
Epoch 18/30
240/243 [============================>.] - ETA: 0s - loss: 9.5153e-04 - mae: 0.0223 - mse: 8.3527e-04
Epoch 18: ReduceLROnPlateau reducing learning rate to 1.5860401617828757e-05.
243/243 [==============================] - 1s 3ms/step - loss: 9.5463e-04 - mae: 0.0223 - mse: 8.3836e-04 - val_loss: 9.8529e-04 - val_mae: 0.0231 - val_mse: 8.6869e-04 - lr: 3.1721e-05
Epoch 19/30
241/243 [============================>.] - ETA: 0s - loss: 9.5551e-04 - mae: 0.0223 - mse: 8.3885e-04
Epoch 19: ReduceLROnPlateau reducing learning rate to 1e-05.
243/243 [==============================] - 1s 2ms/step - loss: 9.5437e-04 - mae: 0.0223 - mse: 8.3772e-04 - val_loss: 9.8521e-04 - val_mae: 0.0231 - val_mse: 8.6861e-04 - lr: 1.5860e-05
Epoch 20/30
243/243 [==============================] - 1s 3ms/step - loss: 9.5427e-04 - mae: 0.0223 - mse: 8.3764e-04 - val_loss: 9.8522e-04 - val_mae: 0.0231 - val_mse: 8.6861e-04 - lr: 1.0000e-05
Epoch 21/30
243/243 [==============================] - 1s 3ms/step - loss: 9.5423e-04 - mae: 0.0223 - mse: 8.3761e-04 - val_loss: 9.8525e-04 - val_mae: 0.0231 - val_mse: 8.6867e-04 - lr: 1.0000e-05
Epoch 22/30
243/243 [==============================] - 1s 3ms/step - loss: 9.5414e-04 - mae: 0.0223 - mse: 8.3759e-04 - val_loss: 9.8491e-04 - val_mae: 0.0231 - val_mse: 8.6858e-04 - lr: 1.0000e-05
Epoch 23/30
243/243 [==============================] - 2s 7ms/step - loss: 9.5411e-04 - mae: 0.0223 - mse: 8.3773e-04 - val_loss: 9.8470e-04 - val_mae: 0.0231 - val_mse: 8.6851e-04 - lr: 1.0000e-05
Epoch 24/30
243/243 [==============================] - 1s 3ms/step - loss: 9.5413e-04 - mae: 0.0223 - mse: 8.3792e-04 - val_loss: 9.8479e-04 - val_mae: 0.0231 - val_mse: 8.6859e-04 - lr: 1.0000e-05
Epoch 25/30
243/243 [==============================] - 1s 3ms/step - loss: 9.5409e-04 - mae: 0.0223 - mse: 8.3794e-04 - val_loss: 9.8488e-04 - val_mae: 0.0231 - val_mse: 8.6861e-04 - lr: 1.0000e-05
Epoch 26/30
243/243 [==============================] - 1s 3ms/step - loss: 9.5405e-04 - mae: 0.0223 - mse: 8.3764e-04 - val_loss: 9.8487e-04 - val_mae: 0.0231 - val_mse: 8.6867e-04 - lr: 1.0000e-05
Epoch 27/30
243/243 [==============================] - 1s 3ms/step - loss: 9.5400e-04 - mae: 0.0223 - mse: 8.3775e-04 - val_loss: 9.8479e-04 - val_mae: 0.0231 - val_mse: 8.6865e-04 - lr: 1.0000e-05
Epoch 28/30
243/243 [==============================] - 1s 3ms/step - loss: 9.5397e-04 - mae: 0.0223 - mse: 8.3794e-04 - val_loss: 9.8475e-04 - val_mae: 0.0231 - val_mse: 8.6862e-04 - lr: 1.0000e-05
Epoch 29/30
243/243 [==============================] - 1s 3ms/step - loss: 9.5390e-04 - mae: 0.0223 - mse: 8.3777e-04 - val_loss: 9.8493e-04 - val_mae: 0.0231 - val_mse: 8.6872e-04 - lr: 1.0000e-05
Epoch 30/30
243/243 [==============================] - 1s 3ms/step - loss: 9.5389e-04 - mae: 0.0223 - mse: 8.3762e-04 - val_loss: 9.8474e-04 - val_mae: 0.0231 - val_mse: 8.6858e-04 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.06496420660779698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
323/323 [==============================] - 2s 4ms/step - loss: 0.0201 - mae: 0.0571 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0515 - val_mse: 0.0036 - lr: 0.0650
Epoch 2/30
298/323 [==========================>...] - ETA: 0s - loss: 0.0106 - mae: 0.0524 - mse: 0.0038
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.03248210251331329.
323/323 [==============================] - 1s 3ms/step - loss: 0.0105 - mae: 0.0524 - mse: 0.0038 - val_loss: 0.0107 - val_mae: 0.0528 - val_mse: 0.0039 - lr: 0.0650
Epoch 3/30
323/323 [==============================] - 1s 2ms/step - loss: 0.0037 - mae: 0.0511 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0325
Epoch 4/30
323/323 [==============================] - ETA: 0s - loss: 0.0037 - mae: 0.0512 - mse: 0.0035
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.016241051256656647.
323/323 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0512 - mse: 0.0035 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0325
Epoch 5/30
311/323 [===========================>..] - ETA: 0s - loss: 0.0035 - mae: 0.0506 - mse: 0.0034
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.008120525628328323.
323/323 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0162
Epoch 6/30
320/323 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.004060262814164162.
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0081
Epoch 7/30
307/323 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.002030131407082081.
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0041
Epoch 8/30
321/323 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0010150657035410404.
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0020
Epoch 9/30
276/323 [========================>.....] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034
181/323 [===============>..............] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.00340034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0010
Epoch 10/30
287/323 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0508 - mse: 0.0034
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002537664258852601.
323/323 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 5.0753e-04
Epoch 11/30
288/323 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00012688321294263005.
323/323 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 2.5377e-04
Epoch 12/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.1721e-05
Epoch 12: ReduceLROnPlateau reducing learning rate to 6.344160647131503e-05.
323/323 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.2688e-04
Epoch 13/30
323/323 [==============================] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 13: ReduceLROnPlateau reducing learning rate to 3.172080323565751e-05.
323/323 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.3442e-05
Epoch 14/30
303/323 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.5860401617828757e-05.
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.1721e-05
Epoch 15/30
308/323 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.5860e-05
Epoch 16/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 17/30
236/323 [====================>.........] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
308/323 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
281/323 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.00340034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0214 - mae: 0.0468 - mse: 0.0036 - val_loss: 0.0200 - val_mae: 0.0921 - val_mse: 0.0104 - lr: 0.0650e-05
243/243 [==============================] - 1s 2ms/step - loss: 0.0022 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0400 - val_mse: 0.0022 - lr: 0.0325e-05
212/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190020 - val_loss: 0.0027 - val_mae: 0.0400 - val_mse: 0.0022 - lr: 0.0325e-05
212/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190020 - val_loss: 0.0027 - val_mae: 0.0400 - val_mse: 0.0022 - lr: 0.0325e-05
149/243 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.00190020 - val_loss: 0.0027 - val_mae: 0.0400 - val_mse: 0.0022 - lr: 0.0325e-05
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
241/243 [============================>.] - ETA: 0s - loss: 0.0096 - mae: 0.0433 - mse: 0.00280019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0325e-05
133/243 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.00190020 - val_loss: 0.0026 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0325e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0041e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0010e-05
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.2688e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.5860e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 3/30=============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 5/30=============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 8/30=============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.002030131407082081.: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002537664258852601. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 17: ReduceLROnPlateau reducing learning rate to 3.172080323565751e-05. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 20/30educeLROnPlateau reducing learning rate to 3.172080323565751e-05. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 25/30educeLROnPlateau reducing learning rate to 3.172080323565751e-05. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 27/30educeLROnPlateau reducing learning rate to 3.172080323565751e-05. 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.06496420660779698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_5.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.06496420660779698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_5.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_5.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.016241051256656647.98LR_[70]HN_16BS_1P_val_lossM_30epochs/model_5.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 7/30educeLROnPlateau reducing learning rate to 0.016241051256656647.98LR_[70]HN_16BS_1P_val_lossM_30epochs/model_5.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 13/30duceLROnPlateau reducing learning rate to 0.016241051256656647.98LR_[70]HN_16BS_1P_val_lossM_30epochs/model_5.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 16/30duceLROnPlateau reducing learning rate to 0.016241051256656647.98LR_[70]HN_16BS_1P_val_lossM_30epochs/model_5.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 16/30duceLROnPlateau reducing learning rate to 0.016241051256656647.98LR_[70]HN_16BS_1P_val_lossM_30epochs/model_5.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 22/30duceLROnPlateau reducing learning rate to 0.016241051256656647.98LR_[70]HN_16BS_1P_val_lossM_30epochs/model_5.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 25/30duceLROnPlateau reducing learning rate to 0.016241051256656647.98LR_[70]HN_16BS_1P_val_lossM_30epochs/model_5.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 28/30duceLROnPlateau reducing learning rate to 0.016241051256656647.98LR_[70]HN_16BS_1P_val_lossM_30epochs/model_5.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.06496420660779698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_6.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.06496420660779698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_6.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_6.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 5/30educeLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_6.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 7/30educeLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_6.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 10/30duceLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_6.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 13/30duceLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_6.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 16/30duceLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_6.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 19/30duceLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_6.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 22/30duceLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_6.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 25/30duceLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_6.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 28/30duceLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_6.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.06496420660779698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 5/30educeLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 8/30educeLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 11/30duceLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 13/30duceLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 16/30duceLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 20/30duceLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 23/30duceLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 26/30duceLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 29/30duceLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 1/300duceLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.03248210251331329.698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.016241051256656647.98LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.002030131407082081.98LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 10/30duceLROnPlateau reducing learning rate to 0.002030131407082081.98LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 13/30duceLROnPlateau reducing learning rate to 0.002030131407082081.98LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 16/30duceLROnPlateau reducing learning rate to 0.002030131407082081.98LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 20/30duceLROnPlateau reducing learning rate to 0.002030131407082081.98LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 23/30duceLROnPlateau reducing learning rate to 0.002030131407082081.98LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 26/30duceLROnPlateau reducing learning rate to 0.002030131407082081.98LR_[70]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.06496420660779698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_9.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.06496420660779698LR_[70]HN_16BS_1P_val_lossM_30epochs/model_9.h5mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05