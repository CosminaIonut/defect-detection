Epoch 1/150
 63/122 [==============>...............] - ETA: 0s - loss: 0.0256 - mae: 0.0606 - mse: 0.0076
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_142009-6kx2tg06\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 7ms/step - loss: 0.0162 - mae: 0.0534 - mse: 0.0055 - val_loss: 0.0057 - val_mae: 0.0518 - val_mse: 0.0040 - lr: 0.0672
Epoch 2/150
122/122 [==============================] - 1s 6ms/step - loss: 0.0042 - mae: 0.0391 - mse: 0.0021 - val_loss: 0.0039 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 0.0672
Epoch 3/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0040 - mae: 0.0375 - mse: 0.0019 - val_loss: 0.0045 - val_mae: 0.0367 - val_mse: 0.0019 - lr: 0.0672
Epoch 4/150
 99/122 [=======================>......] - ETA: 0s - loss: 0.0040 - mae: 0.0375 - mse: 0.0019
122/122 [==============================] - 1s 6ms/step - loss: 0.0040 - mae: 0.0373 - mse: 0.0019 - val_loss: 0.0037 - val_mae: 0.0371 - val_mse: 0.0018 - lr: 0.0672
Epoch 5/150
 67/122 [===============>..............] - ETA: 0s - loss: 0.0040 - mae: 0.0368 - mse: 0.0019
122/122 [==============================] - 1s 6ms/step - loss: 0.0040 - mae: 0.0366 - mse: 0.0019 - val_loss: 0.0035 - val_mae: 0.0350 - val_mse: 0.0017 - lr: 0.0672
Epoch 6/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0040 - mae: 0.0360 - mse: 0.0018 - val_loss: 0.0051 - val_mae: 0.0416 - val_mse: 0.0026 - lr: 0.0672
Epoch 7/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0038 - mae: 0.0337 - mse: 0.0016 - val_loss: 0.0040 - val_mae: 0.0393 - val_mse: 0.0021 - lr: 0.0672
Epoch 8/150
 79/122 [==================>...........] - ETA: 0s - loss: 0.0039 - mae: 0.0344 - mse: 0.0017
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_142009-6kx2tg06\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 6ms/step - loss: 0.0038 - mae: 0.0336 - mse: 0.0017 - val_loss: 0.0033 - val_mae: 0.0303 - val_mse: 0.0014 - lr: 0.0672
Epoch 9/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0313 - mse: 0.0015 - val_loss: 0.0046 - val_mae: 0.0397 - val_mse: 0.0022 - lr: 0.0672
Epoch 10/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0309 - mse: 0.0015 - val_loss: 0.0058 - val_mae: 0.0437 - val_mse: 0.0028 - lr: 0.0672
Epoch 11/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0304 - mse: 0.0014 - val_loss: 0.0040 - val_mae: 0.0364 - val_mse: 0.0020 - lr: 0.0672
Epoch 12/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0302 - mse: 0.0014 - val_loss: 0.0041 - val_mae: 0.0362 - val_mse: 0.0019 - lr: 0.0672
Epoch 13/150
122/122 [==============================] - 0s 925us/step - loss: 0.0036 - mae: 0.0300 - mse: 0.0014 - val_loss: 0.0054 - val_mae: 0.0403 - val_mse: 0.0023 - lr: 0.0672
Epoch 14/150
122/122 [==============================] - 0s 910us/step - loss: 0.0036 - mae: 0.0291 - mse: 0.0013 - val_loss: 0.0042 - val_mae: 0.0362 - val_mse: 0.0020 - lr: 0.0672
Epoch 15/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0293 - mse: 0.0013 - val_loss: 0.0033 - val_mae: 0.0264 - val_mse: 0.0011 - lr: 0.0672
Epoch 16/150
122/122 [==============================] - 0s 925us/step - loss: 0.0036 - mae: 0.0288 - mse: 0.0013 - val_loss: 0.0049 - val_mae: 0.0355 - val_mse: 0.0018 - lr: 0.0672
Epoch 17/150
122/122 [==============================] - 0s 951us/step - loss: 0.0035 - mae: 0.0282 - mse: 0.0013 - val_loss: 0.0056 - val_mae: 0.0481 - val_mse: 0.0034 - lr: 0.0672
Epoch 18/150
 78/122 [==================>...........] - ETA: 0s - loss: 0.0036 - mae: 0.0288 - mse: 0.0013
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.03359174355864525.
122/122 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0287 - mse: 0.0013 - val_loss: 0.0037 - val_mae: 0.0301 - val_mse: 0.0014 - lr: 0.0672
Epoch 19/150
122/122 [==============================] - 1s 6ms/step - loss: 0.0013 - mae: 0.0249 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0237 - val_mse: 8.7592e-04 - lr: 0.0336
Epoch 20/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0244 - mse: 9.8841e-04 - val_loss: 0.0014 - val_mae: 0.0261 - val_mse: 0.0011 - lr: 0.0336
Epoch 21/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0243 - mse: 9.5976e-04 - val_loss: 0.0013 - val_mae: 0.0243 - val_mse: 9.1895e-04 - lr: 0.0336
Epoch 22/150
 90/122 [=====================>........] - ETA: 0s - loss: 0.0012 - mae: 0.0243 - mse: 9.6258e-04
122/122 [==============================] - 1s 6ms/step - loss: 0.0012 - mae: 0.0243 - mse: 9.5381e-04 - val_loss: 0.0010 - val_mae: 0.0231 - val_mse: 8.4087e-04 - lr: 0.0336
Epoch 23/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0245 - mse: 9.6696e-04 - val_loss: 0.0014 - val_mae: 0.0268 - val_mse: 0.0011 - lr: 0.0336
Epoch 24/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0242 - mse: 9.5491e-04 - val_loss: 0.0019 - val_mae: 0.0329 - val_mse: 0.0016 - lr: 0.0336
Epoch 25/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0242 - mse: 9.3981e-04 - val_loss: 0.0014 - val_mae: 0.0256 - val_mse: 0.0010 - lr: 0.0336
Epoch 26/150
122/122 [==============================] - 0s 946us/step - loss: 0.0012 - mae: 0.0241 - mse: 9.4862e-04 - val_loss: 0.0027 - val_mae: 0.0379 - val_mse: 0.0023 - lr: 0.0336
Epoch 27/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0240 - mse: 9.4011e-04 - val_loss: 0.0015 - val_mae: 0.0279 - val_mse: 0.0012 - lr: 0.0336
Epoch 28/150
122/122 [==============================] - 0s 990us/step - loss: 0.0012 - mae: 0.0239 - mse: 9.3004e-04 - val_loss: 0.0011 - val_mae: 0.0222 - val_mse: 8.0355e-04 - lr: 0.0336
Epoch 29/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0240 - mse: 9.4407e-04 - val_loss: 0.0017 - val_mae: 0.0304 - val_mse: 0.0015 - lr: 0.0336
Epoch 30/150
105/122 [========================>.....] - ETA: 0s - loss: 0.0012 - mae: 0.0241 - mse: 9.3998e-04
122/122 [==============================] - 1s 6ms/step - loss: 0.0012 - mae: 0.0241 - mse: 9.3956e-04 - val_loss: 9.7592e-04 - val_mae: 0.0219 - val_mse: 7.6253e-04 - lr: 0.0336
Epoch 31/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0240 - mse: 9.2026e-04 - val_loss: 0.0015 - val_mae: 0.0277 - val_mse: 0.0012 - lr: 0.0336
Epoch 32/150
 65/122 [==============>...............] - ETA: 0s - loss: 0.0012 - mae: 0.0240 - mse: 9.1922e-04
Epoch 32: ReduceLROnPlateau reducing learning rate to 0.016795871779322624.
122/122 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0239 - mse: 9.2298e-04 - val_loss: 0.0011 - val_mae: 0.0244 - val_mse: 9.1710e-04 - lr: 0.0336
Epoch 33/150
 85/122 [===================>..........] - ETA: 0s - loss: 9.1532e-04 - mae: 0.0218 - mse: 7.7691e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_142009-6kx2tg06\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 6ms/step - loss: 9.3935e-04 - mae: 0.0222 - mse: 8.0181e-04 - val_loss: 9.6772e-04 - val_mae: 0.0227 - val_mse: 8.4953e-04 - lr: 0.0168
Epoch 34/150
122/122 [==============================] - 0s 1ms/step - loss: 9.3644e-04 - mae: 0.0221 - mse: 8.0825e-04 - val_loss: 0.0011 - val_mae: 0.0245 - val_mse: 9.6610e-04 - lr: 0.0168
Epoch 35/150
122/122 [==============================] - 0s 1ms/step - loss: 9.2669e-04 - mae: 0.0222 - mse: 8.0082e-04 - val_loss: 0.0011 - val_mae: 0.0255 - val_mse: 0.0010 - lr: 0.0168
Epoch 36/150
122/122 [==============================] - 1s 7ms/step - loss: 9.4532e-04 - mae: 0.0224 - mse: 8.1680e-04 - val_loss: 8.8051e-04 - val_mae: 0.0219 - val_mse: 7.6679e-04 - lr: 0.0168
Epoch 37/150
122/122 [==============================] - 0s 1ms/step - loss: 9.3431e-04 - mae: 0.0224 - mse: 8.1055e-04 - val_loss: 9.8637e-04 - val_mae: 0.0237 - val_mse: 8.6208e-04 - lr: 0.0168
Epoch 38/150
 82/122 [===================>..........] - ETA: 0s - loss: 9.1725e-04 - mae: 0.0220 - mse: 7.9238e-04
122/122 [==============================] - 1s 6ms/step - loss: 9.2180e-04 - mae: 0.0221 - mse: 8.0007e-04 - val_loss: 8.4482e-04 - val_mae: 0.0215 - val_mse: 7.2425e-04 - lr: 0.0168
Epoch 39/150
 82/122 [===================>..........] - ETA: 0s - loss: 9.1914e-04 - mae: 0.0224 - mse: 7.9908e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_142009-6kx2tg06\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 6ms/step - loss: 9.1235e-04 - mae: 0.0222 - mse: 7.9133e-04 - val_loss: 8.3572e-04 - val_mae: 0.0216 - val_mse: 7.3488e-04 - lr: 0.0168
Epoch 40/150
122/122 [==============================] - 0s 1ms/step - loss: 9.2436e-04 - mae: 0.0224 - mse: 8.0412e-04 - val_loss: 8.9509e-04 - val_mae: 0.0214 - val_mse: 7.3063e-04 - lr: 0.0168
Epoch 41/150
122/122 [==============================] - 0s 963us/step - loss: 9.1376e-04 - mae: 0.0223 - mse: 7.9752e-04 - val_loss: 8.5373e-04 - val_mae: 0.0220 - val_mse: 7.5345e-04 - lr: 0.0168
Epoch 42/150
122/122 [==============================] - 0s 1ms/step - loss: 9.1179e-04 - mae: 0.0221 - mse: 7.9294e-04 - val_loss: 0.0011 - val_mae: 0.0255 - val_mse: 0.0010 - lr: 0.0168
Epoch 43/150
122/122 [==============================] - 0s 1ms/step - loss: 9.1069e-04 - mae: 0.0222 - mse: 7.9482e-04 - val_loss: 9.0923e-04 - val_mae: 0.0232 - val_mse: 8.2331e-04 - lr: 0.0168
Epoch 44/150
122/122 [==============================] - 0s 1ms/step - loss: 8.9685e-04 - mae: 0.0220 - mse: 7.8535e-04 - val_loss: 8.7302e-04 - val_mae: 0.0224 - val_mse: 7.7780e-04 - lr: 0.0168
Epoch 45/150
122/122 [==============================] - 1s 6ms/step - loss: 9.1508e-04 - mae: 0.0223 - mse: 8.0233e-04 - val_loss: 8.2951e-04 - val_mae: 0.0217 - val_mse: 7.3479e-04 - lr: 0.0168
Epoch 46/150
 82/122 [===================>..........] - ETA: 0s - loss: 9.1145e-04 - mae: 0.0222 - mse: 7.9818e-04
Epoch 46: ReduceLROnPlateau reducing learning rate to 0.008397935889661312.
122/122 [==============================] - 0s 1ms/step - loss: 8.9860e-04 - mae: 0.0221 - mse: 7.8705e-04 - val_loss: 0.0010 - val_mae: 0.0242 - val_mse: 8.9856e-04 - lr: 0.0168
Epoch 47/150
 56/122 [============>.................] - ETA: 0s - loss: 8.2216e-04 - mae: 0.0216 - mse: 7.4082e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_142009-6kx2tg06\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 6ms/step - loss: 8.2395e-04 - mae: 0.0214 - mse: 7.4326e-04 - val_loss: 8.0352e-04 - val_mae: 0.0213 - val_mse: 7.3042e-04 - lr: 0.0084
Epoch 48/150
122/122 [==============================] - 0s 1ms/step - loss: 8.2029e-04 - mae: 0.0213 - mse: 7.4153e-04 - val_loss: 8.6526e-04 - val_mae: 0.0230 - val_mse: 8.0938e-04 - lr: 0.0084
Epoch 49/150
122/122 [==============================] - 0s 1ms/step - loss: 8.1747e-04 - mae: 0.0214 - mse: 7.4377e-04 - val_loss: 8.0520e-04 - val_mae: 0.0211 - val_mse: 7.1947e-04 - lr: 0.0084
Epoch 50/150
122/122 [==============================] - 0s 1ms/step - loss: 8.1096e-04 - mae: 0.0213 - mse: 7.3759e-04 - val_loss: 8.6020e-04 - val_mae: 0.0216 - val_mse: 7.5910e-04 - lr: 0.0084
Epoch 51/150
122/122 [==============================] - 0s 1ms/step - loss: 8.0292e-04 - mae: 0.0212 - mse: 7.2613e-04 - val_loss: 8.1789e-04 - val_mae: 0.0222 - val_mse: 7.5666e-04 - lr: 0.0084
Epoch 52/150
122/122 [==============================] - 0s 1ms/step - loss: 8.0523e-04 - mae: 0.0212 - mse: 7.3438e-04 - val_loss: 8.2863e-04 - val_mae: 0.0214 - val_mse: 7.4602e-04 - lr: 0.0084
Epoch 53/150
122/122 [==============================] - 0s 960us/step - loss: 8.1993e-04 - mae: 0.0215 - mse: 7.4598e-04 - val_loss: 9.2264e-04 - val_mae: 0.0228 - val_mse: 8.4292e-04 - lr: 0.0084
Epoch 54/150
122/122 [==============================] - 0s 1ms/step - loss: 7.9984e-04 - mae: 0.0212 - mse: 7.3081e-04 - val_loss: 8.3170e-04 - val_mae: 0.0214 - val_mse: 7.4549e-04 - lr: 0.0084
Epoch 55/150
 84/122 [===================>..........] - ETA: 0s - loss: 8.1261e-04 - mae: 0.0213 - mse: 7.4293e-04
122/122 [==============================] - 1s 6ms/step - loss: 7.9879e-04 - mae: 0.0212 - mse: 7.2917e-04 - val_loss: 7.7608e-04 - val_mae: 0.0213 - val_mse: 7.2274e-04 - lr: 0.0084
Epoch 56/150
122/122 [==============================] - 0s 1ms/step - loss: 8.0125e-04 - mae: 0.0213 - mse: 7.3459e-04 - val_loss: 8.9904e-04 - val_mae: 0.0234 - val_mse: 8.3698e-04 - lr: 0.0084
Epoch 57/150
122/122 [==============================] - 0s 1ms/step - loss: 7.9619e-04 - mae: 0.0213 - mse: 7.2460e-04 - val_loss: 0.0010 - val_mae: 0.0241 - val_mse: 9.3063e-04 - lr: 0.0084
Epoch 58/150
122/122 [==============================] - 0s 1ms/step - loss: 8.0639e-04 - mae: 0.0213 - mse: 7.3713e-04 - val_loss: 7.8622e-04 - val_mae: 0.0211 - val_mse: 7.2062e-04 - lr: 0.0084
Epoch 59/150
 95/122 [======================>.......] - ETA: 0s - loss: 8.0262e-04 - mae: 0.0214 - mse: 7.3504e-04
122/122 [==============================] - 1s 6ms/step - loss: 7.9879e-04 - mae: 0.0212 - mse: 7.2917e-04 - val_loss: 7.7608e-04 - val_mae: 0.0213 - val_mse: 7.2274e-04 - lr: 0.0084
122/122 [==============================] - 0s 1ms/step - loss: 7.9561e-04 - mae: 0.0212 - mse: 7.2918e-04 - val_loss: 8.8389e-04 - val_mae: 0.0223 - val_mse: 8.0748e-04 - lr: 0.0084
Epoch 64/150
122/122 [==============================] - 0s 1ms/step - loss: 7.9454e-04 - mae: 0.0212 - mse: 7.2925e-04 - val_loss: 8.2946e-04 - val_mae: 0.0215 - val_mse: 7.5284e-04 - lr: 0.0084
Epoch 65/150
 88/122 [====================>.........] - ETA: 0s - loss: 7.9728e-04 - mae: 0.0213 - mse: 7.3218e-04
Epoch 65: ReduceLROnPlateau reducing learning rate to 0.004198967944830656.
122/122 [==============================] - 0s 1ms/step - loss: 7.9663e-04 - mae: 0.0213 - mse: 7.3245e-04 - val_loss: 7.7278e-04 - val_mae: 0.0209 - val_mse: 7.0273e-04 - lr: 0.0084
Epoch 66/150
122/122 [==============================] - 0s 1ms/step - loss: 7.5868e-04 - mae: 0.0208 - mse: 7.0127e-04 - val_loss: 8.7557e-04 - val_mae: 0.0234 - val_mse: 8.3237e-04 - lr: 0.0042
Epoch 67/150
 86/122 [====================>.........] - ETA: 0s - loss: 7.5948e-04 - mae: 0.0208 - mse: 7.0583e-04
122/122 [==============================] - 0s 1ms/step - loss: 7.9561e-04 - mae: 0.0212 - mse: 7.2918e-04 - val_loss: 8.8389e-04 - val_mae: 0.0223 - val_mse: 8.0748e-04 - lr: 0.0084
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_142009-6kx2tg06\files\model-best)... Done. 0.0s
122/122 [==============================] - 0s 1ms/step - loss: 7.9561e-04 - mae: 0.0212 - mse: 7.2918e-04 - val_loss: 8.8389e-04 - val_mae: 0.0223 - val_mse: 8.0748e-04 - lr: 0.0084
122/122 [==============================] - 0s 1ms/step - loss: 7.9561e-04 - mae: 0.0212 - mse: 7.2918e-04 - val_loss: 8.8389e-04 - val_mae: 0.0223 - val_mse: 8.0748e-04 - lr: 0.0084
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_142009-6kx2tg06\files\model-best)... Done. 0.0s
122/122 [==============================] - 0s 1ms/step - loss: 7.5333e-04 - mae: 0.0208 - mse: 7.0085e-04 - val_loss: 7.6899e-04 - val_mae: 0.0210 - val_mse: 7.1140e-04 - lr: 0.0042
122/122 [==============================] - 0s 1ms/step - loss: 7.5333e-04 - mae: 0.0208 - mse: 7.0085e-04 - val_loss: 7.6899e-04 - val_mae: 0.0210 - val_mse: 7.1140e-04 - lr: 0.0042
122/122 [==============================] - 0s 1ms/step - loss: 7.3883e-04 - mae: 0.0207 - mse: 6.9182e-04 - val_loss: 7.7665e-04 - val_mae: 0.0211 - val_mse: 7.2118e-04 - lr: 0.0021
122/122 [==============================] - 0s 1ms/step - loss: 7.3883e-04 - mae: 0.0207 - mse: 6.9182e-04 - val_loss: 7.7665e-04 - val_mae: 0.0211 - val_mse: 7.2118e-04 - lr: 0.0021
122/122 [==============================] - 0s 1ms/step - loss: 7.3883e-04 - mae: 0.0207 - mse: 6.9182e-04 - val_loss: 7.7665e-04 - val_mae: 0.0211 - val_mse: 7.2118e-04 - lr: 0.0021
 70/122 [================>.............] - ETA: 0s - loss: 7.2889e-04 - mae: 0.0206 - mse: 6.8694e-04e-04 - val_loss: 7.7665e-04 - val_mae: 0.0211 - val_mse: 7.2118e-04 - lr: 0.0021
 70/122 [================>.............] - ETA: 0s - loss: 7.2889e-04 - mae: 0.0206 - mse: 6.8694e-04e-04 - val_loss: 7.7665e-04 - val_mae: 0.0211 - val_mse: 7.2118e-04 - lr: 0.0021
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_142009-6kx2tg06\files\model-best)... Done. 0.0s
 70/122 [================>.............] - ETA: 0s - loss: 7.2889e-04 - mae: 0.0206 - mse: 6.8694e-04e-04 - val_loss: 7.7665e-04 - val_mae: 0.0211 - val_mse: 7.2118e-04 - lr: 0.0021
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_142009-6kx2tg06\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_142009-6kx2tg06\files\model-best)... Done. 0.0s
122/122 [==============================] - 0s 1ms/step - loss: 7.2313e-04 - mae: 0.0205 - mse: 6.8018e-04 - val_loss: 7.2881e-04 - val_mae: 0.0207 - val_mse: 6.8477e-04 - lr: 5.2487e-04
122/122 [==============================] - 0s 1ms/step - loss: 7.2313e-04 - mae: 0.0205 - mse: 6.8018e-04 - val_loss: 7.2881e-04 - val_mae: 0.0207 - val_mse: 6.8477e-04 - lr: 5.2487e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_142009-6kx2tg06\files\model-best)... Done. 0.0s
122/122 [==============================] - 0s 1ms/step - loss: 7.2313e-04 - mae: 0.0205 - mse: 6.8018e-04 - val_loss: 7.2881e-04 - val_mae: 0.0207 - val_mse: 6.8477e-04 - lr: 5.2487e-04
122/122 [==============================] - 0s 989us/step - loss: 7.1933e-04 - mae: 0.0205 - mse: 6.7826e-04 - val_loss: 7.2601e-04 - val_mae: 0.0207 - val_mse: 6.8492e-04 - lr: 1.6402e-05
Epoch 144/150
122/122 [==============================] - 0s 1ms/step - loss: 7.1948e-04 - mae: 0.0205 - mse: 6.7843e-04 - val_loss: 7.2595e-04 - val_mae: 0.0207 - val_mse: 6.8490e-04 - lr: 3.2804e-05
Epoch 145/150
 83/122 [===================>..........] - ETA: 0s - loss: 7.1330e-04 - mae: 0.0203 - mse: 6.7216e-04
Epoch 145: ReduceLROnPlateau reducing learning rate to 1.640221853449475e-05.
122/122 [==============================] - 0s 950us/step - loss: 7.1949e-04 - mae: 0.0204 - mse: 6.7834e-04 - val_loss: 7.2577e-04 - val_mae: 0.0207 - val_mse: 6.8479e-04 - lr: 3.2804e-05
Epoch 146/150
122/122 [==============================] - 0s 1ms/step - loss: 7.1931e-04 - mae: 0.0205 - mse: 6.7830e-04 - val_loss: 7.2569e-04 - val_mae: 0.0207 - val_mse: 6.8469e-04 - lr: 1.6402e-05
Epoch 147/150
122/122 [==============================] - 0s 1ms/step - loss: 7.1934e-04 - mae: 0.0204 - mse: 6.7824e-04 - val_loss: 7.2577e-04 - val_mae: 0.0207 - val_mse: 6.8475e-04 - lr: 1.6402e-05
Epoch 148/150
122/122 [==============================] - 0s 1ms/step - loss: 7.1931e-04 - mae: 0.0205 - mse: 6.7832e-04 - val_loss: 7.2590e-04 - val_mae: 0.0207 - val_mse: 6.8487e-04 - lr: 1.6402e-05
Epoch 149/150
122/122 [==============================] - 0s 1ms/step - loss: 7.1933e-04 - mae: 0.0205 - mse: 6.7833e-04 - val_loss: 7.2591e-04 - val_mae: 0.0207 - val_mse: 6.8486e-04 - lr: 1.6402e-05
Epoch 150/150
122/122 [==============================] - 0s 989us/step - loss: 7.1933e-04 - mae: 0.0205 - mse: 6.7826e-04 - val_loss: 7.2601e-04 - val_mae: 0.0207 - val_mse: 6.8492e-04 - lr: 1.6402e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.06718349009916817LR_[20]HN_32BS_10P_val_lossM_150epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
162/162 [==============================] - 1s 2ms/step - loss: 0.0120 - mae: 0.0552 - mse: 0.0045 - val_loss: 0.0053 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0672
Epoch 2/150
162/162 [==============================] - 0s 984us/step - loss: 0.0056 - mae: 0.0512 - mse: 0.0035 - val_loss: 0.0064 - val_mae: 0.0545 - val_mse: 0.0042 - lr: 0.0672
Epoch 3/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0056 - mae: 0.0515 - mse: 0.0035 - val_loss: 0.0054 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0672
Epoch 4/150
162/162 [==============================] - 0s 995us/step - loss: 0.0056 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.0054 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0672
Epoch 5/150
162/162 [==============================] - 0s 985us/step - loss: 0.0056 - mae: 0.0514 - mse: 0.0036 - val_loss: 0.0055 - val_mae: 0.0512 - val_mse: 0.0036 - lr: 0.0672
Epoch 6/150
162/162 [==============================] - 0s 972us/step - loss: 0.0056 - mae: 0.0511 - mse: 0.0035 - val_loss: 0.0070 - val_mae: 0.0563 - val_mse: 0.0045 - lr: 0.0672
Epoch 7/150
162/162 [==============================] - 0s 972us/step - loss: 0.0056 - mae: 0.0511 - mse: 0.0035 - val_loss: 0.0057 - val_mae: 0.0511 - val_mse: 0.0036 - lr: 0.0672
Epoch 8/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0056 - mae: 0.0511 - mse: 0.0035 - val_loss: 0.0098 - val_mae: 0.0653 - val_mse: 0.0064 - lr: 0.0672
Epoch 9/150
162/162 [==============================] - 0s 985us/step - loss: 0.0056 - mae: 0.0512 - mse: 0.0035 - val_loss: 0.0053 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0672
Epoch 10/150
162/162 [==============================] - 0s 985us/step - loss: 0.0055 - mae: 0.0510 - mse: 0.0035 - val_loss: 0.0057 - val_mae: 0.0513 - val_mse: 0.0036 - lr: 0.0672
Epoch 11/150
 90/162 [===============>..............] - ETA: 0s - loss: 0.0057 - mae: 0.0516 - mse: 0.0036
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.03359174355864525.
162/162 [==============================] - 0s 988us/step - loss: 0.0056 - mae: 0.0515 - mse: 0.0036 - val_loss: 0.0055 - val_mae: 0.0518 - val_mse: 0.0037 - lr: 0.0672
Epoch 12/150
162/162 [==============================] - 0s 988us/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0336
Epoch 13/150
162/162 [==============================] - 0s 984us/step - loss: 0.0035 - mae: 0.0509 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0508 - val_mse: 0.0035 - lr: 0.0336
Epoch 14/150
162/162 [==============================] - 0s 985us/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0043 - val_mae: 0.0533 - val_mse: 0.0040 - lr: 0.0336
Epoch 15/150
162/162 [==============================] - 0s 902us/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0336
Epoch 16/150
162/162 [==============================] - 0s 980us/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0336
Epoch 17/150
162/162 [==============================] - 0s 940us/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0336
Epoch 18/150
162/162 [==============================] - 0s 994us/step - loss: 0.0035 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0512 - val_mse: 0.0035 - lr: 0.0336
Epoch 19/150
162/162 [==============================] - 0s 980us/step - loss: 0.0035 - mae: 0.0509 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0506 - val_mse: 0.0034 - lr: 0.0336
Epoch 20/150
162/162 [==============================] - 0s 997us/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0336
Epoch 21/150
162/162 [==============================] - 0s 976us/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0507 - val_mse: 0.0035 - lr: 0.0336
Epoch 22/150
 86/162 [==============>...............] - ETA: 0s - loss: 0.0035 - mae: 0.0509 - mse: 0.0034
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.016795871779322624.
162/162 [==============================] - 0s 974us/step - loss: 0.0035 - mae: 0.0510 - mse: 0.0035 - val_loss: 0.0037 - val_mae: 0.0513 - val_mse: 0.0036 - lr: 0.0336
Epoch 23/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0168
Epoch 24/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0168
Epoch 25/150
162/162 [==============================] - 0s 979us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0168
Epoch 26/150
162/162 [==============================] - 0s 994us/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0168
Epoch 27/150
162/162 [==============================] - 0s 994us/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0168
Epoch 28/150
162/162 [==============================] - 0s 959us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0513 - val_mse: 0.0036 - lr: 0.0168
Epoch 29/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0168
Epoch 30/150
162/162 [==============================] - 0s 984us/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0168
Epoch 31/150
162/162 [==============================] - 0s 991us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0168
Epoch 32/150
 82/162 [==============>...............] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034
Epoch 32: ReduceLROnPlateau reducing learning rate to 0.008397935889661312.
162/162 [==============================] - 0s 976us/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0168
Epoch 33/150
162/162 [==============================] - 0s 921us/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0084
Epoch 34/150
162/162 [==============================] - 0s 997us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0084
Epoch 35/150
162/162 [==============================] - 0s 942us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0084
Epoch 36/150
162/162 [==============================] - 0s 972us/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0084
Epoch 37/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0084
Epoch 38/150
162/162 [==============================] - 0s 878us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0084
Epoch 39/150
162/162 [==============================] - 0s 885us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - lr: 0.0084
Epoch 40/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0084
Epoch 41/150
162/162 [==============================] - 0s 959us/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0084
Epoch 42/150
 88/162 [===============>..............] - ETA: 0s - loss: 0.0034 - mae: 0.0508 - mse: 0.0034
Epoch 42: ReduceLROnPlateau reducing learning rate to 0.004198967944830656.
162/162 [==============================] - 0s 970us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0084
Epoch 43/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0042
Epoch 44/150
162/162 [==============================] - 0s 951us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0042
Epoch 45/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0042
Epoch 46/150
162/162 [==============================] - 0s 975us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0042
Epoch 47/150
162/162 [==============================] - 0s 999us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0042
Epoch 48/150
162/162 [==============================] - 0s 899us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0042
Epoch 49/150
162/162 [==============================] - 0s 872us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0042
Epoch 50/150
162/162 [==============================] - 0s 940us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0042
Epoch 51/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0042
Epoch 52/150
 87/162 [===============>..............] - ETA: 0s - loss: 0.0035 - mae: 0.0512 - mse: 0.0035
Epoch 52: ReduceLROnPlateau reducing learning rate to 0.002099483972415328.
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0042
Epoch 53/150
162/162 [==============================] - 0s 955us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0021
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0033s). Check your callbacks.
162/162 [==============================] - 0s 956us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0021
Epoch 55/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0021
Epoch 56/150
162/162 [==============================] - 0s 974us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0021
Epoch 57/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0021
Epoch 58/150
162/162 [==============================] - 0s 882us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0021
Epoch 59/150
162/162 [==============================] - 0s 971us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0021
Epoch 60/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0021
Epoch 61/150
162/162 [==============================] - 0s 876us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0021
Epoch 62/150
102/162 [=================>............] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034
Epoch 62: ReduceLROnPlateau reducing learning rate to 0.001049741986207664.
162/162 [==============================] - 0s 959us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0021
Epoch 63/150
162/162 [==============================] - 0s 976us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0010
Epoch 64/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0010
Epoch 65/150
162/162 [==============================] - 0s 976us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0010
Epoch 66/150
162/162 [==============================] - 0s 973us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0010
Epoch 67/150
162/162 [==============================] - 0s 987us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0010
Epoch 68/150
162/162 [==============================] - 0s 985us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0010
Epoch 69/150
162/162 [==============================] - 0s 985us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0010
Epoch 70/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0010
Epoch 71/150
162/162 [==============================] - 0s 973us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0010
Epoch 72/150
 87/162 [===============>..............] - ETA: 0s - loss: 0.0035 - mae: 0.0512 - mse: 0.0035
Epoch 72: ReduceLROnPlateau reducing learning rate to 0.000524870993103832.
162/162 [==============================] - 0s 980us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0010
Epoch 73/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 5.2487e-04
Epoch 74/150
162/162 [==============================] - 0s 992us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 5.2487e-04
Epoch 75/150
162/162 [==============================] - 0s 972us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 5.2487e-04
Epoch 76/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 5.2487e-04
Epoch 77/150
162/162 [==============================] - 0s 966us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 5.2487e-04
Epoch 78/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 5.2487e-04
Epoch 79/150
162/162 [==============================] - 0s 982us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 5.2487e-04
Epoch 80/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 5.2487e-04
Epoch 81/150
162/162 [==============================] - 0s 975us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 5.2487e-04
Epoch 82/150
 91/162 [===============>..............] - ETA: 0s - loss: 0.0034 - mae: 0.0502 - mse: 0.0034
Epoch 82: ReduceLROnPlateau reducing learning rate to 0.000262435496551916.
162/162 [==============================] - 0s 993us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 5.2487e-04
Epoch 83/150
162/162 [==============================] - 0s 934us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 2.6244e-04
Epoch 84/150
162/162 [==============================] - 0s 982us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 2.6244e-04
Epoch 85/150
162/162 [==============================] - 0s 976us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 2.6244e-04
Epoch 86/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 2.6244e-04
Epoch 87/150
162/162 [==============================] - 0s 906us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 2.6244e-04
Epoch 88/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 2.6244e-04
Epoch 89/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 2.6244e-04
Epoch 90/150
162/162 [==============================] - 0s 933us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 2.6244e-04
Epoch 91/150
162/162 [==============================] - 0s 972us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 2.6244e-04
Epoch 92/150
 96/162 [================>.............] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 92: ReduceLROnPlateau reducing learning rate to 0.000131217748275958.
162/162 [==============================] - 0s 974us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 2.6244e-04
Epoch 93/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.3122e-04
Epoch 94/150
162/162 [==============================] - 0s 992us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.3122e-04
Epoch 95/150
162/162 [==============================] - 0s 972us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.3122e-04
Epoch 96/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.3122e-04
Epoch 97/150
162/162 [==============================] - 0s 974us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.3122e-04
Epoch 98/150
162/162 [==============================] - 0s 974us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.3122e-04
Epoch 99/150
162/162 [==============================] - 0s 988us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.3122e-04
Epoch 100/150
162/162 [==============================] - 0s 943us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.3122e-04
Epoch 101/150
162/162 [==============================] - 0s 993us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.3122e-04
Epoch 102/150
 94/162 [================>.............] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034
Epoch 102: ReduceLROnPlateau reducing learning rate to 6.5608874137979e-05.
162/162 [==============================] - 0s 946us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.3122e-04
Epoch 103/150
162/162 [==============================] - 0s 990us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.5609e-05
Epoch 104/150
162/162 [==============================] - 0s 990us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.5609e-05
Epoch 105/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.5609e-05
Epoch 106/150
162/162 [==============================] - 0s 969us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.5609e-05
Epoch 107/150
162/162 [==============================] - 0s 998us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.5609e-05
Epoch 108/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.5609e-05
Epoch 109/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.5609e-05
Epoch 110/150
162/162 [==============================] - 0s 948us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.5609e-05
Epoch 111/150
162/162 [==============================] - 0s 976us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.5609e-05
Epoch 112/150
 92/162 [================>.............] - ETA: 0s - loss: 0.0035 - mae: 0.0510 - mse: 0.0035
Epoch 112: ReduceLROnPlateau reducing learning rate to 3.28044370689895e-05.
162/162 [==============================] - 0s 996us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.5609e-05
Epoch 113/150
162/162 [==============================] - 0s 972us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.2804e-05
Epoch 114/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.2804e-05
Epoch 115/150
162/162 [==============================] - 0s 959us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.2804e-05
Epoch 116/150
162/162 [==============================] - 0s 942us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.2804e-05
Epoch 117/150
162/162 [==============================] - 0s 878us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.2804e-05
Epoch 118/150
162/162 [==============================] - 0s 962us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.2804e-05
Epoch 119/150
162/162 [==============================] - 0s 996us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.2804e-05
Epoch 120/150
162/162 [==============================] - 0s 939us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.2804e-05
Epoch 121/150
162/162 [==============================] - 0s 987us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.2804e-05
Epoch 122/150
 79/162 [=============>................] - ETA: 0s - loss: 0.0034 - mae: 0.0510 - mse: 0.0034
Epoch 122: ReduceLROnPlateau reducing learning rate to 1.640221853449475e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.2804e-05
Epoch 123/150
162/162 [==============================] - 0s 973us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6402e-05
Epoch 124/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6402e-05
Epoch 125/150
162/162 [==============================] - 0s 992us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6402e-05
Epoch 126/150
162/162 [==============================] - 0s 984us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6402e-05
Epoch 127/150
162/162 [==============================] - 0s 941us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6402e-05
Epoch 128/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6402e-05
Epoch 129/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6402e-05
Epoch 130/150
162/162 [==============================] - 0s 952us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6402e-05
Epoch 131/150
162/162 [==============================] - 0s 981us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6402e-05
Epoch 132/150
 88/162 [===============>..............] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034
Epoch 132: ReduceLROnPlateau reducing learning rate to 1e-05.
162/162 [==============================] - 0s 984us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6402e-05
Epoch 133/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 134/150
162/162 [==============================] - 0s 978us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 135/150
162/162 [==============================] - 0s 982us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 136/150
162/162 [==============================] - 0s 949us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 137/150
162/162 [==============================] - 0s 875us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 138/150
162/162 [==============================] - 0s 987us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 139/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 140/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 141/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 142/150
162/162 [==============================] - 0s 959us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 143/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 144/150
162/162 [==============================] - 0s 887us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 145/150
162/162 [==============================] - 0s 976us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 146/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 147/150
162/162 [==============================] - 0s 984us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 148/150
162/162 [==============================] - 0s 977us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 149/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 150/150
162/162 [==============================] - 0s 981us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.06718349009916817LR_[20]HN_32BS_10P_val_lossM_150epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
122/122 [==============================] - 1s 2ms/step - loss: 0.0109 - mae: 0.0423 - mse: 0.0028 - val_loss: 0.0038 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0672
Epoch 2/150
122/122 [==============================] - 0s 986us/step - loss: 0.0042 - mae: 0.0393 - mse: 0.0021 - val_loss: 0.0048 - val_mae: 0.0433 - val_mse: 0.0027 - lr: 0.0672
Epoch 3/150
122/122 [==============================] - 0s 922us/step - loss: 0.0041 - mae: 0.0390 - mse: 0.0021 - val_loss: 0.0047 - val_mae: 0.0396 - val_mse: 0.0021 - lr: 0.0672
Epoch 4/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0042 - mae: 0.0391 - mse: 0.0021 - val_loss: 0.0040 - val_mae: 0.0396 - val_mse: 0.0021 - lr: 0.0672
Epoch 5/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0042 - mae: 0.0394 - mse: 0.0021 - val_loss: 0.0038 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0672
Epoch 6/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0041 - mae: 0.0390 - mse: 0.0021 - val_loss: 0.0039 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0672
Epoch 7/150
122/122 [==============================] - 0s 999us/step - loss: 0.0041 - mae: 0.0390 - mse: 0.0021 - val_loss: 0.0042 - val_mae: 0.0401 - val_mse: 0.0022 - lr: 0.0672
Epoch 8/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0041 - mae: 0.0389 - mse: 0.0021 - val_loss: 0.0038 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0672
Epoch 9/150
122/122 [==============================] - 0s 920us/step - loss: 0.0041 - mae: 0.0390 - mse: 0.0021 - val_loss: 0.0042 - val_mae: 0.0407 - val_mse: 0.0023 - lr: 0.0672
Epoch 10/150
122/122 [==============================] - 0s 934us/step - loss: 0.0042 - mae: 0.0394 - mse: 0.0021 - val_loss: 0.0046 - val_mae: 0.0396 - val_mse: 0.0021 - lr: 0.0672
Epoch 11/150
 91/122 [=====================>........] - ETA: 0s - loss: 0.0041 - mae: 0.0390 - mse: 0.0021
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.03359174355864525.
122/122 [==============================] - 0s 1ms/step - loss: 0.0041 - mae: 0.0391 - mse: 0.0021 - val_loss: 0.0042 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0672
Epoch 12/150
122/122 [==============================] - 0s 997us/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0336
Epoch 13/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0393 - val_mse: 0.0021 - lr: 0.0336
Epoch 14/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0336
Epoch 15/150
122/122 [==============================] - 0s 906us/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0336
Epoch 16/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0336
Epoch 17/150
122/122 [==============================] - 0s 985us/step - loss: 0.0020 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0336
Epoch 18/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0336
Epoch 19/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0336
Epoch 20/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0419 - val_mse: 0.0025 - lr: 0.0336
Epoch 21/150
122/122 [==============================] - 0s 909us/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0393 - val_mse: 0.0021 - lr: 0.0336
Epoch 22/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0336
Epoch 23/150
122/122 [==============================] - 0s 969us/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0394 - val_mse: 0.0021 - lr: 0.0336
Epoch 24/150
 87/122 [====================>.........] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.016795871779322624.
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0336
Epoch 25/150
122/122 [==============================] - 0s 915us/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0168
Epoch 26/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0168
Epoch 27/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0168
Epoch 28/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0168
Epoch 29/150
122/122 [==============================] - 0s 999us/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0168
Epoch 30/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0168
Epoch 31/150
122/122 [==============================] - 0s 967us/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0168
Epoch 32/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0168
Epoch 33/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0168
Epoch 34/150
 87/122 [====================>.........] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019
Epoch 34: ReduceLROnPlateau reducing learning rate to 0.008397935889661312.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0168
Epoch 35/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0084
Epoch 36/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0084
Epoch 37/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0084
Epoch 38/150
122/122 [==============================] - 0s 946us/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0084
Epoch 39/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0084
Epoch 40/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0084
Epoch 41/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0084
Epoch 42/150
122/122 [==============================] - 0s 879us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0084
Epoch 43/150
122/122 [==============================] - 0s 934us/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0084
Epoch 44/150
 80/122 [==================>...........] - ETA: 0s - loss: 0.0020 - mae: 0.0382 - mse: 0.0020
Epoch 44: ReduceLROnPlateau reducing learning rate to 0.004198967944830656.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0084
Epoch 45/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0042
Epoch 46/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0042
Epoch 47/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0042
Epoch 48/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0042
Epoch 49/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0042
Epoch 50/150
122/122 [==============================] - 0s 996us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0042
Epoch 51/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0042
Epoch 52/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0042
Epoch 53/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0042
Epoch 54/150
 85/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 54: ReduceLROnPlateau reducing learning rate to 0.002099483972415328.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0042
Epoch 55/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0021
Epoch 56/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0021
Epoch 57/150
122/122 [==============================] - 0s 934us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0021
Epoch 58/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0021
Epoch 59/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0021
Epoch 60/150
122/122 [==============================] - 0s 916us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0021
Epoch 61/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0021
Epoch 62/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0021
Epoch 63/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0021
Epoch 64/150
 96/122 [======================>.......] - ETA: 0s - loss: 0.0019 - mae: 0.0382 - mse: 0.0019
Epoch 64: ReduceLROnPlateau reducing learning rate to 0.001049741986207664.
122/122 [==============================] - 0s 920us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0021
Epoch 65/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0010
Epoch 66/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0010
Epoch 67/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0010
Epoch 68/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0010
Epoch 69/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0010
Epoch 70/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0010
Epoch 71/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0010
Epoch 72/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0010
Epoch 73/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0010
Epoch 74/150
 94/122 [======================>.......] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 74: ReduceLROnPlateau reducing learning rate to 0.000524870993103832.
122/122 [==============================] - 0s 905us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0010
Epoch 75/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 5.2487e-04
Epoch 76/150
122/122 [==============================] - 0s 909us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 5.2487e-04
Epoch 77/150
122/122 [==============================] - 0s 929us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 5.2487e-04
Epoch 78/150
122/122 [==============================] - 0s 908us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 5.2487e-04
Epoch 79/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 5.2487e-04
Epoch 80/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 5.2487e-04
Epoch 81/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 5.2487e-04
Epoch 82/150
122/122 [==============================] - 0s 980us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 5.2487e-04
Epoch 83/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 5.2487e-04
Epoch 84/150
 78/122 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 84: ReduceLROnPlateau reducing learning rate to 0.000262435496551916.
122/122 [==============================] - 0s 900us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 5.2487e-04
Epoch 85/150
122/122 [==============================] - 0s 919us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.6244e-04
Epoch 86/150
122/122 [==============================] - 0s 954us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.6244e-04
Epoch 87/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.6244e-04
Epoch 88/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.6244e-04
Epoch 89/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.6244e-04
Epoch 90/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.6244e-04
Epoch 91/150
122/122 [==============================] - 0s 978us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.6244e-04
Epoch 92/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.6244e-04
Epoch 93/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.6244e-04
Epoch 94/150
100/122 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 94: ReduceLROnPlateau reducing learning rate to 0.000131217748275958.
122/122 [==============================] - 0s 906us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.6244e-04
Epoch 95/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.3122e-04
Epoch 96/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.3122e-04
Epoch 97/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.3122e-04
Epoch 98/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.3122e-04
Epoch 99/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.3122e-04
Epoch 100/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.3122e-04
Epoch 101/150
122/122 [==============================] - 0s 925us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.3122e-04
Epoch 102/150
122/122 [==============================] - 0s 940us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.3122e-04
Epoch 103/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.3122e-04
Epoch 104/150
 97/122 [======================>.......] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 104: ReduceLROnPlateau reducing learning rate to 6.5608874137979e-05.
122/122 [==============================] - 0s 928us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.3122e-04
Epoch 105/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.5609e-05
Epoch 106/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.5609e-05
Epoch 107/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.5609e-05
Epoch 108/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.5609e-05
Epoch 109/150
122/122 [==============================] - 0s 969us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.5609e-05
Epoch 110/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.5609e-05
Epoch 111/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.5609e-05
Epoch 112/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.5609e-05
Epoch 113/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.5609e-05
Epoch 114/150
119/122 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 114: ReduceLROnPlateau reducing learning rate to 3.28044370689895e-05.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.5609e-05
Epoch 115/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.2804e-05
Epoch 116/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.2804e-05
Epoch 117/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.2804e-05
Epoch 118/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.2804e-05
Epoch 119/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.2804e-05
Epoch 120/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.2804e-05
Epoch 121/150
122/122 [==============================] - 0s 941us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.2804e-05
Epoch 122/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.2804e-05
Epoch 123/150
122/122 [==============================] - 0s 922us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.2804e-05
Epoch 124/150
 62/122 [==============>...............] - ETA: 0s - loss: 0.0020 - mae: 0.0384 - mse: 0.0020
Epoch 124: ReduceLROnPlateau reducing learning rate to 1.640221853449475e-05.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.2804e-05
Epoch 125/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
Epoch 126/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
Epoch 127/150
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
Epoch 128/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
Epoch 129/150
122/122 [==============================] - 0s 988us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
Epoch 130/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
Epoch 131/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
Epoch 132/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
Epoch 133/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
Epoch 134/150
 99/122 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.0019
Epoch 134: ReduceLROnPlateau reducing learning rate to 1e-05.
122/122 [==============================] - 0s 930us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
Epoch 135/150
122/122 [==============================] - 0s 921us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 136/150
122/122 [==============================] - 0s 934us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 137/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 138/150
122/122 [==============================] - 0s 964us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 139/150
122/122 [==============================] - 0s 909us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 140/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 141/150
122/122 [==============================] - 0s 904us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 142/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 143/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 144/150
  1/122 [..............................] - ETA: 0s - loss: 0.0022 - mae: 0.0417 - mse: 0.0022
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0004s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0018s). Check your callbacks.
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0002s vs `on_train_batch_end` time: 0.0014s). Check your callbacks.
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0027s). Check your callbacks.
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05
122/122 [==============================] - 0s 936us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6402e-05