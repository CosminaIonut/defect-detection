Epoch 1/50
72/87 [=======================>......] - ETA: 0s - loss: 0.1797 - mae: 0.4227 - mse: 0.1797
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.
87/87 [==============================] - 2s 16ms/step - loss: 0.1753 - mae: 0.4173 - mse: 0.1753 - val_loss: 0.1508 - val_mae: 0.3872 - val_mse: 0.1508 - lr: 0.0010
Epoch 2/50
64/87 [=====================>........] - ETA: 0s - loss: 0.1330 - mae: 0.3633 - mse: 0.1330
87/87 [==============================] - 1s 14ms/step - loss: 0.1272 - mae: 0.3550 - mse: 0.1272 - val_loss: 0.1041 - val_mae: 0.3212 - val_mse: 0.1041 - lr: 0.0010
Epoch 3/50
69/87 [======================>.......] - ETA: 0s - loss: 0.0874 - mae: 0.2938 - mse: 0.0874
87/87 [==============================] - 1s 13ms/step - loss: 0.0834 - mae: 0.2866 - mse: 0.0834 - val_loss: 0.0640 - val_mae: 0.2511 - val_mse: 0.0640 - lr: 0.0010
Epoch 4/50
85/87 [============================>.] - ETA: 0s - loss: 0.0485 - mae: 0.2174 - mse: 0.0485
87/87 [==============================] - 1s 14ms/step - loss: 0.0482 - mae: 0.2167 - mse: 0.0482 - val_loss: 0.0342 - val_mae: 0.1825 - val_mse: 0.0342 - lr: 0.0010
Epoch 5/50
73/87 [========================>.....] - ETA: 0s - loss: 0.0254 - mae: 0.1559 - mse: 0.0254
87/87 [==============================] - 1s 12ms/step - loss: 0.0240 - mae: 0.1510 - mse: 0.0240 - val_loss: 0.0155 - val_mae: 0.1206 - val_mse: 0.0155 - lr: 0.0010
Epoch 6/50
81/87 [==========================>...] - ETA: 0s - loss: 0.0102 - mae: 0.0958 - mse: 0.0102
87/87 [==============================] - 1s 12ms/step - loss: 0.0099 - mae: 0.0942 - mse: 0.0099 - val_loss: 0.0057 - val_mae: 0.0693 - val_mse: 0.0057 - lr: 0.0010
Epoch 7/50
87/87 [==============================] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.0034
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\no_overlap\wandb\run-20230408_172224-zbch7k9w\files\model-best)... Done. 0.0s
87/87 [==============================] - 1s 12ms/step - loss: 0.0034 - mae: 0.0499 - mse: 0.0034 - val_loss: 0.0018 - val_mae: 0.0349 - val_mse: 0.0018 - lr: 0.0010
Epoch 8/50
66/87 [=====================>........] - ETA: 0s - loss: 0.0013 - mae: 0.0297 - mse: 0.0013
87/87 [==============================] - 1s 15ms/step - loss: 0.0012 - mae: 0.0287 - mse: 0.0012 - val_loss: 9.5033e-04 - val_mae: 0.0267 - val_mse: 9.5033e-04 - lr: 0.0010
Epoch 9/50
87/87 [==============================] - 1s 14ms/step - loss: 8.5536e-04 - mae: 0.0252 - mse: 8.5536e-04 - val_loss: 9.0996e-04 - val_mae: 0.0263 - val_mse: 9.0996e-04 - lr: 0.0010
Epoch 10/50
87/87 [==============================] - 0s 2ms/step - loss: 8.4942e-04 - mae: 0.0252 - mse: 8.4942e-04 - val_loss: 9.1002e-04 - val_mae: 0.0263 - val_mse: 9.1002e-04 - lr: 0.0010
Epoch 11/50
67/87 [======================>.......] - ETA: 0s - loss: 8.3012e-04 - mae: 0.0248 - mse: 8.3012e-04
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
87/87 [==============================] - 0s 2ms/step - loss: 8.4955e-04 - mae: 0.0252 - mse: 8.4955e-04 - val_loss: 9.1005e-04 - val_mae: 0.0263 - val_mse: 9.1005e-04 - lr: 0.0010
Epoch 12/50
87/87 [==============================] - 0s 2ms/step - loss: 8.4881e-04 - mae: 0.0252 - mse: 8.4881e-04 - val_loss: 9.1002e-04 - val_mae: 0.0263 - val_mse: 9.1002e-04 - lr: 5.0000e-04
Epoch 13/50
87/87 [==============================] - 0s 2ms/step - loss: 8.4879e-04 - mae: 0.0252 - mse: 8.4879e-04 - val_loss: 9.1017e-04 - val_mae: 0.0263 - val_mse: 9.1017e-04 - lr: 5.0000e-04
Epoch 14/50
64/87 [=====================>........] - ETA: 0s - loss: 8.4109e-04 - mae: 0.0250 - mse: 8.4109e-04
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
87/87 [==============================] - 0s 2ms/step - loss: 8.4866e-04 - mae: 0.0252 - mse: 8.4866e-04 - val_loss: 9.1022e-04 - val_mae: 0.0263 - val_mse: 9.1022e-04 - lr: 5.0000e-04
Epoch 15/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4838e-04 - mae: 0.0252 - mse: 8.4838e-04 - val_loss: 9.1001e-04 - val_mae: 0.0263 - val_mse: 9.1001e-04 - lr: 2.5000e-04
Epoch 16/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4839e-04 - mae: 0.0252 - mse: 8.4839e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 2.5000e-04
Epoch 17/50
69/87 [======================>.......] - ETA: 0s - loss: 8.5032e-04 - mae: 0.0253 - mse: 8.5032e-04
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
87/87 [==============================] - 0s 2ms/step - loss: 8.4850e-04 - mae: 0.0252 - mse: 8.4850e-04 - val_loss: 9.0997e-04 - val_mae: 0.0263 - val_mse: 9.0997e-04 - lr: 2.5000e-04
Epoch 18/50
87/87 [==============================] - 0s 2ms/step - loss: 8.4829e-04 - mae: 0.0252 - mse: 8.4829e-04 - val_loss: 9.0999e-04 - val_mae: 0.0263 - val_mse: 9.0999e-04 - lr: 1.2500e-04
Epoch 19/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4829e-04 - mae: 0.0252 - mse: 8.4829e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 1.2500e-04
Epoch 20/50
68/87 [======================>.......] - ETA: 0s - loss: 8.4808e-04 - mae: 0.0251 - mse: 8.4808e-04
Epoch 20: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
87/87 [==============================] - 0s 3ms/step - loss: 8.4829e-04 - mae: 0.0252 - mse: 8.4829e-04 - val_loss: 9.0999e-04 - val_mae: 0.0263 - val_mse: 9.0999e-04 - lr: 1.2500e-04
Epoch 21/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4817e-04 - mae: 0.0252 - mse: 8.4817e-04 - val_loss: 9.1002e-04 - val_mae: 0.0263 - val_mse: 9.1002e-04 - lr: 6.2500e-05
Epoch 22/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4819e-04 - mae: 0.0252 - mse: 8.4819e-04 - val_loss: 9.1000e-04 - val_mae: 0.0263 - val_mse: 9.1000e-04 - lr: 6.2500e-05
Epoch 23/50
86/87 [============================>.] - ETA: 0s - loss: 8.4751e-04 - mae: 0.0251 - mse: 8.4751e-04
Epoch 23: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.
87/87 [==============================] - 0s 3ms/step - loss: 8.4821e-04 - mae: 0.0252 - mse: 8.4821e-04 - val_loss: 9.0999e-04 - val_mae: 0.0263 - val_mse: 9.0999e-04 - lr: 6.2500e-05
Epoch 24/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4815e-04 - mae: 0.0252 - mse: 8.4815e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 3.1250e-05
Epoch 25/50
87/87 [==============================] - 0s 2ms/step - loss: 8.4814e-04 - mae: 0.0252 - mse: 8.4814e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 3.1250e-05
Epoch 26/50
75/87 [========================>.....] - ETA: 0s - loss: 8.4204e-04 - mae: 0.0251 - mse: 8.4204e-04
Epoch 26: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.
87/87 [==============================] - 0s 3ms/step - loss: 8.4814e-04 - mae: 0.0252 - mse: 8.4814e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 3.1250e-05
Epoch 27/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4812e-04 - mae: 0.0252 - mse: 8.4812e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 1.5625e-05
Epoch 28/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4812e-04 - mae: 0.0252 - mse: 8.4812e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 1.5625e-05
Epoch 29/50
77/87 [=========================>....] - ETA: 0s - loss: 8.4661e-04 - mae: 0.0251 - mse: 8.4661e-04
Epoch 29: ReduceLROnPlateau reducing learning rate to 1e-05.
87/87 [==============================] - 0s 3ms/step - loss: 8.4813e-04 - mae: 0.0252 - mse: 8.4813e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 1.5625e-05
Epoch 30/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4811e-04 - mae: 0.0252 - mse: 8.4811e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 1.0000e-05
Epoch 31/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4812e-04 - mae: 0.0252 - mse: 8.4812e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 1.0000e-05
Epoch 32/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4812e-04 - mae: 0.0252 - mse: 8.4812e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 1.0000e-05
Epoch 33/50
87/87 [==============================] - 0s 2ms/step - loss: 8.4812e-04 - mae: 0.0252 - mse: 8.4812e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 1.0000e-05
Epoch 34/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4812e-04 - mae: 0.0252 - mse: 8.4812e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 1.0000e-05
Epoch 35/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4811e-04 - mae: 0.0252 - mse: 8.4811e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 1.0000e-05
Epoch 36/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4812e-04 - mae: 0.0252 - mse: 8.4812e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 1.0000e-05
Epoch 37/50
87/87 [==============================] - 0s 2ms/step - loss: 8.4812e-04 - mae: 0.0252 - mse: 8.4812e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 1.0000e-05
Epoch 38/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4812e-04 - mae: 0.0252 - mse: 8.4812e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 1.0000e-05
Epoch 39/50
87/87 [==============================] - 0s 2ms/step - loss: 8.4811e-04 - mae: 0.0252 - mse: 8.4811e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 1.0000e-05
Epoch 40/50
87/87 [==============================] - 0s 2ms/step - loss: 8.4812e-04 - mae: 0.0252 - mse: 8.4812e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 1.0000e-05
Epoch 41/50
87/87 [==============================] - 0s 2ms/step - loss: 8.4811e-04 - mae: 0.0252 - mse: 8.4811e-04 - val_loss: 9.0999e-04 - val_mae: 0.0263 - val_mse: 9.0999e-04 - lr: 1.0000e-05
Epoch 42/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4812e-04 - mae: 0.0252 - mse: 8.4812e-04 - val_loss: 9.0999e-04 - val_mae: 0.0263 - val_mse: 9.0999e-04 - lr: 1.0000e-05
Epoch 43/50
87/87 [==============================] - 0s 2ms/step - loss: 8.4812e-04 - mae: 0.0252 - mse: 8.4812e-04 - val_loss: 9.0999e-04 - val_mae: 0.0263 - val_mse: 9.0999e-04 - lr: 1.0000e-05
Epoch 44/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4812e-04 - mae: 0.0252 - mse: 8.4812e-04 - val_loss: 9.0999e-04 - val_mae: 0.0263 - val_mse: 9.0999e-04 - lr: 1.0000e-05
Epoch 45/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4812e-04 - mae: 0.0252 - mse: 8.4812e-04 - val_loss: 9.0999e-04 - val_mae: 0.0263 - val_mse: 9.0999e-04 - lr: 1.0000e-05
Epoch 46/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4812e-04 - mae: 0.0252 - mse: 8.4812e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 1.0000e-05
Epoch 47/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4812e-04 - mae: 0.0252 - mse: 8.4812e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 1.0000e-05
Epoch 48/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4812e-04 - mae: 0.0252 - mse: 8.4812e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 1.0000e-05
Epoch 49/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4812e-04 - mae: 0.0252 - mse: 8.4812e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 1.0000e-05
Epoch 50/50
87/87 [==============================] - 0s 3ms/step - loss: 8.4812e-04 - mae: 0.0252 - mse: 8.4812e-04 - val_loss: 9.0998e-04 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 1.0000e-05
>Saved ../../trained_models/models_segments_no_overlap-baseline-RMSprop30.0_50epochs/model_10.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])