Epoch 1/50
35/35 [==============================] - ETA: 0s - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230428_231916-9r3dj4sk\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.
35/35 [==============================] - 3s 52ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 0.0338
Epoch 2/50
35/35 [==============================] - 0s 9ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 0.0338
Epoch 3/50
35/35 [==============================] - 0s 9ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 0.0338
Epoch 4/50
33/35 [===========================>..] - ETA: 0s - loss: 0.0061 - mae: 0.0657 - mse: 0.0061 - root_mean_squared_error: 0.0782
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.016878830268979073.
35/35 [==============================] - 2s 45ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 0.0338
Epoch 5/50
35/35 [==============================] - 0s 9ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 0.0169
Epoch 6/50
35/35 [==============================] - 0s 9ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 0.0169
Epoch 7/50
26/35 [=====================>........] - ETA: 0s - loss: 0.0061 - mae: 0.0657 - mse: 0.0061 - root_mean_squared_error: 0.0783
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.008439415134489536.
35/35 [==============================] - 0s 8ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 0.0169
Epoch 8/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 0.0084
Epoch 9/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 0.0084
Epoch 10/50
34/35 [============================>.] - ETA: 0s - loss: 0.0061 - mae: 0.0655 - mse: 0.0061 - root_mean_squared_error: 0.0782
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.004219707567244768.
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 0.0084
Epoch 11/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 0.0042
Epoch 12/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 0.0042
Epoch 13/50
34/35 [============================>.] - ETA: 0s - loss: 0.0061 - mae: 0.0655 - mse: 0.0061 - root_mean_squared_error: 0.0781
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.002109853783622384.
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 0.0042
Epoch 14/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 0.0021
Epoch 15/50
35/35 [==============================] - 0s 9ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 0.0021
Epoch 16/50
32/35 [==========================>...] - ETA: 0s - loss: 0.0061 - mae: 0.0654 - mse: 0.0061 - root_mean_squared_error: 0.0780
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.001054926891811192.
35/35 [==============================] - 0s 9ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 0.0021
Epoch 17/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 0.0011
Epoch 18/50
35/35 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 0.0011
Epoch 19/50
33/35 [===========================>..] - ETA: 0s - loss: 0.0061 - mae: 0.0655 - mse: 0.0061 - root_mean_squared_error: 0.0781
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.000527463445905596.
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 0.0011
Epoch 20/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 5.2746e-04
Epoch 21/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 5.2746e-04
Epoch 22/50
34/35 [============================>.] - ETA: 0s - loss: 0.0061 - mae: 0.0654 - mse: 0.0061 - root_mean_squared_error: 0.0781
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.000263731722952798.
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 5.2746e-04
Epoch 23/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 2.6373e-04
Epoch 24/50
35/35 [==============================] - 0s 8ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 2.6373e-04
Epoch 25/50
34/35 [============================>.] - ETA: 0s - loss: 0.0061 - mae: 0.0657 - mse: 0.0061 - root_mean_squared_error: 0.0783
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.000131865861476399.
35/35 [==============================] - 0s 9ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 2.6373e-04
Epoch 26/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 1.3187e-04
Epoch 27/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 1.3187e-04
Epoch 28/50
35/35 [==============================] - ETA: 0s - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782
Epoch 28: ReduceLROnPlateau reducing learning rate to 6.59329307381995e-05.
35/35 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 1.3187e-04
Epoch 29/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 6.5933e-05
Epoch 30/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 6.5933e-05
Epoch 31/50
35/35 [==============================] - ETA: 0s - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782
Epoch 31: ReduceLROnPlateau reducing learning rate to 3.296646536909975e-05.
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 6.5933e-05
Epoch 32/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 3.2966e-05
Epoch 33/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 3.2966e-05
Epoch 34/50
29/35 [=======================>......] - ETA: 0s - loss: 0.0060 - mae: 0.0651 - mse: 0.0060 - root_mean_squared_error: 0.0777
Epoch 34: ReduceLROnPlateau reducing learning rate to 1.6483232684549876e-05.
35/35 [==============================] - 0s 8ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 3.2966e-05
Epoch 35/50
35/35 [==============================] - 0s 8ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 1.6483e-05
Epoch 36/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 1.6483e-05
Epoch 37/50
33/35 [===========================>..] - ETA: 0s - loss: 0.0061 - mae: 0.0657 - mse: 0.0061 - root_mean_squared_error: 0.0783
Epoch 37: ReduceLROnPlateau reducing learning rate to 1e-05.
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 1.6483e-05
Epoch 38/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 1.0000e-05
Epoch 39/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 1.0000e-05
Epoch 40/50
35/35 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 1.0000e-05
Epoch 41/50
35/35 [==============================] - 0s 9ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 1.0000e-05
Epoch 42/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 1.0000e-05
Epoch 43/50
35/35 [==============================] - 0s 9ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 1.0000e-05
Epoch 44/50
35/35 [==============================] - 0s 9ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 1.0000e-05
Epoch 45/50
35/35 [==============================] - 0s 8ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 1.0000e-05
Epoch 46/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 1.0000e-05
Epoch 47/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 1.0000e-05
Epoch 48/50
35/35 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 1.0000e-05
Epoch 49/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 1.0000e-05
Epoch 50/50
35/35 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0656 - mse: 0.0061 - root_mean_squared_error: 0.0782 - val_loss: 0.0062 - val_mae: 0.0662 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0789 - lr: 1.0000e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn_adam_0.033757659693377275LR_[124, 516]CHN_16CNNI_112BS_100DU_3P_val_mseM_50epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
Epoch 1/50
21/47 [============>.................] - ETA: 0s - loss: 0.0402 - mae: 0.1916 - mse: 0.0402 - root_mean_squared_error: 0.2005
47/47 [==============================] - 0s 6ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 0.0169e-05
Epoch 6/50
47/47 [==============================] - 0s 5ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 0.0169
Epoch 7/50
13/47 [=======>......................] - ETA: 0s - loss: 0.0398 - mae: 0.1906 - mse: 0.0398 - root_mean_squared_error: 0.1995
47/47 [==============================] - 0s 6ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 0.0042e-05
Epoch 12/50
37/47 [======================>.......] - ETA: 0s - loss: 0.0398 - mae: 0.1909 - mse: 0.0398 - root_mean_squared_error: 0.1996
47/47 [==============================] - 0s 6ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 0.0011e-05
Epoch 18/50
47/47 [==============================] - 0s 6ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 0.0011
Epoch 19/50
38/47 [=======================>......] - ETA: 0s - loss: 0.0396 - mae: 0.1901 - mse: 0.0396 - root_mean_squared_error: 0.1989
47/47 [==============================] - 0s 7ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 2.6373e-04
Epoch 24/50
47/47 [==============================] - 0s 6ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 2.6373e-04
Epoch 25/50
42/47 [=========================>....] - ETA: 0s - loss: 0.0396 - mae: 0.1903 - mse: 0.0396 - root_mean_squared_error: 0.1990
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.000131865861476399.
47/47 [==============================] - 0s 7ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 2.6373e-04
Epoch 26/50
25/47 [==============>...............] - ETA: 0s - loss: 0.0393 - mae: 0.1896 - mse: 0.0393 - root_mean_squared_error: 0.1984
47/47 [==============================] - 0s 6ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 6.5933e-05
Epoch 30/50
47/47 [==============================] - 0s 6ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 6.5933e-05
Epoch 31/50
45/47 [===========================>..] - ETA: 0s - loss: 0.0396 - mae: 0.1903 - mse: 0.0396 - root_mean_squared_error: 0.1991
Epoch 31: ReduceLROnPlateau reducing learning rate to 3.296646536909975e-05.
47/47 [==============================] - 0s 6ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 6.5933e-05
Epoch 32/50
47/47 [==============================] - 0s 6ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 3.2966e-05
Epoch 33/50
23/47 [=============>................] - ETA: 0s - loss: 0.0392 - mae: 0.1893 - mse: 0.0392 - root_mean_squared_error: 0.1980
47/47 [==============================] - 0s 8ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 1.6483e-05
Epoch 36/50
47/47 [==============================] - 0s 6ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 1.6483e-05
Epoch 37/50
46/47 [============================>.] - ETA: 0s - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1990
Epoch 37: ReduceLROnPlateau reducing learning rate to 1e-05.
47/47 [==============================] - 0s 6ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 1.6483e-05
Epoch 38/50
47/47 [==============================] - 0s 6ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 1.0000e-05
Epoch 39/50
47/47 [==============================] - 0s 6ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 1.0000e-05
Epoch 40/50
 1/47 [..............................] - ETA: 0s - loss: 0.0409 - mae: 0.1941 - mse: 0.0409 - root_mean_squared_error: 0.2023
47/47 [==============================] - 0s 6ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 1.0000e-05
Epoch 43/50
47/47 [==============================] - 0s 6ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 1.0000e-05
Epoch 44/50
47/47 [==============================] - 0s 7ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 1.0000e-05
Epoch 45/50
47/47 [==============================] - 0s 6ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 1.0000e-05
Epoch 46/50
45/47 [===========================>..] - ETA: 0s - loss: 0.0396 - mae: 0.1904 - mse: 0.0396 - root_mean_squared_error: 0.1991
47/47 [==============================] - 0s 7ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 1.0000e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn_adam_0.033757659693377275LR_[124, 516]CHN_16CNNI_112BS_100DU_3P_val_mseM_50epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
Epoch 1/50
47/47 [==============================] - 0s 7ms/step - loss: 0.0396 - mae: 0.1902 - mse: 0.0396 - root_mean_squared_error: 0.1989 - val_loss: 0.0393 - val_mae: 0.1895 - val_mse: 0.0393 - val_root_mean_squared_error: 0.1983 - lr: 1.0000e-05
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 0.0042e-05
Epoch 13/50
33/35 [===========================>..] - ETA: 0s - loss: 0.1011 - mae: 0.3149 - mse: 0.1011 - root_mean_squared_error: 0.3180
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.002109853783622384.
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 0.0042
Epoch 14/50
 9/35 [======>.......................] - ETA: 0s - loss: 0.0986 - mae: 0.3108 - mse: 0.0986 - root_mean_squared_error: 0.3140
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 0.0011e-05
Epoch 19/50
34/35 [============================>.] - ETA: 0s - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3179
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.000527463445905596.
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 0.0011
Epoch 20/50
35/35 [==============================] - 0s 6ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 5.2746e-04
Epoch 21/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 5.2746e-04
Epoch 22/50
28/35 [=======================>......] - ETA: 0s - loss: 0.1013 - mae: 0.3153 - mse: 0.1013 - root_mean_squared_error: 0.3183
25/35 [====================>.........] - ETA: 0s - loss: 0.1009 - mae: 0.3147 - mse: 0.1009 - root_mean_squared_error: 0.31773178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 2.6373e-04
Epoch 25/50
33/35 [===========================>..] - ETA: 0s - loss: 0.1011 - mae: 0.3149 - mse: 0.1011 - root_mean_squared_error: 0.3179
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.000131865861476399.
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 2.6373e-04
Epoch 26/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 1.3187e-04
Epoch 27/50
35/35 [==============================] - 0s 6ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 1.3187e-04
Epoch 28/50
32/35 [==========================>...] - ETA: 0s - loss: 0.1009 - mae: 0.3146 - mse: 0.1009 - root_mean_squared_error: 0.3176
Epoch 28: ReduceLROnPlateau reducing learning rate to 6.59329307381995e-05.
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 1.3187e-04
Epoch 29/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 6.5933e-05
Epoch 30/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 1.6483e-05
Epoch 31/50
35/35 [==============================] - ETA: 0s - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178
Epoch 31: ReduceLROnPlateau reducing learning rate to 3.296646536909975e-05.
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 6.5933e-05
Epoch 32/50
35/35 [==============================] - 0s 8ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 3.2966e-05
Epoch 33/50
35/35 [==============================] - 0s 8ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 3.2966e-05
Epoch 34/50
33/35 [===========================>..] - ETA: 0s - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178
Epoch 34: ReduceLROnPlateau reducing learning rate to 1.6483232684549876e-05.
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 3.2966e-05
Epoch 35/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 1.6483e-05
Epoch 36/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 1.6483e-05
Epoch 37/50
34/35 [============================>.] - ETA: 0s - loss: 0.1009 - mae: 0.3147 - mse: 0.1009 - root_mean_squared_error: 0.3177
Epoch 37: ReduceLROnPlateau reducing learning rate to 1e-05.
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 1.6483e-05
Epoch 38/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 1.0000e-05
Epoch 39/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 1.0000e-05
Epoch 40/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 1.0000e-05
Epoch 41/50
35/35 [==============================] - 0s 8ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 1.0000e-05
Epoch 42/50
35/35 [==============================] - 0s 8ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 1.0000e-05
Epoch 43/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 1.0000e-05
Epoch 44/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 1.0000e-05
Epoch 45/50
35/35 [==============================] - 0s 6ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 1.0000e-05
Epoch 46/50
35/35 [==============================] - 0s 6ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 1.0000e-05
Epoch 47/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 1.0000e-05
Epoch 48/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 1.0000e-05
Epoch 49/50
35/35 [==============================] - 0s 6ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 1.0000e-05
Epoch 50/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 1.0000e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn_adam_0.033757659693377275LR_[124, 516]CHN_16CNNI_112BS_100DU_3P_val_mseM_50epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
Epoch 1/50
Epoch 4/50===========================] - 0s 6ms/step - loss: 0.1010 - mae: 0.3148 - mse: 0.1010 - root_mean_squared_error: 0.3178 - val_loss: 0.1014 - val_mae: 0.3154 - val_mse: 0.1014 - val_root_mean_squared_error: 0.3185 - lr: 1.0000e-05
32/35 [==========================>...] - ETA: 0s - loss: 0.1739 - mae: 0.4148 - mse: 0.1739 - root_mean_squared_error: 0.4171
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.016878830268979073.
35/35 [==============================] - 0s 8ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 0.0338
Epoch 5/50
 1/35 [..............................] - ETA: 0s - loss: 0.1819 - mae: 0.4245 - mse: 0.1819 - root_mean_squared_error: 0.4265
35/35 [==============================] - 0s 6ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 0.0084e-05
Epoch 11/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 0.0042
Epoch 12/50
35/35 [==============================] - 0s 8ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 0.0042
Epoch 13/50
27/35 [======================>.......] - ETA: 0s - loss: 0.1738 - mae: 0.4146 - mse: 0.1738 - root_mean_squared_error: 0.4169
Epoch 18/50==========================] - 0s 6ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 0.0084e-05
35/35 [==============================] - 0s 7ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 0.0011
Epoch 19/50
34/35 [============================>.] - ETA: 0s - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4172
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.000527463445905596.
35/35 [==============================] - 0s 7ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 0.0011
Epoch 20/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 5.2746e-04
Epoch 21/50
35/35 [==============================] - 0s 8ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 5.2746e-04
Epoch 22/50
 1/35 [..............................] - ETA: 0s - loss: 0.1756 - mae: 0.4169 - mse: 0.1756 - root_mean_squared_error: 0.4191
35/35 [==============================] - ETA: 0s - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.41714171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 0.0084e-05
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.000131865861476399.
35/35 [==============================] - 0s 6ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 2.6373e-04
Epoch 26/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 1.3187e-04
Epoch 27/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 1.3187e-04
Epoch 28/50
33/35 [===========================>..] - ETA: 0s - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4172
Epoch 28: ReduceLROnPlateau reducing learning rate to 6.59329307381995e-05.
35/35 [==============================] - 0s 7ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 1.3187e-04
Epoch 29/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 6.5933e-05
Epoch 30/50
19/35 [===============>..............] - ETA: 0s - loss: 0.1738 - mae: 0.4146 - mse: 0.1738 - root_mean_squared_error: 0.4169
Epoch 32/50==========================] - ETA: 0s - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.41714171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 0.0084e-05
35/35 [==============================] - 0s 8ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 3.2966e-05
Epoch 33/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 3.2966e-05
Epoch 34/50
34/35 [============================>.] - ETA: 0s - loss: 0.1739 - mae: 0.4148 - mse: 0.1739 - root_mean_squared_error: 0.4171
Epoch 34: ReduceLROnPlateau reducing learning rate to 1.6483232684549876e-05.
35/35 [==============================] - 0s 7ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 3.2966e-05
Epoch 35/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 1.6483e-05
Epoch 36/50
35/35 [==============================] - 0s 6ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 1.6483e-05
Epoch 37/50
35/35 [==============================] - ETA: 0s - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171
Epoch 37: ReduceLROnPlateau reducing learning rate to 1e-05.
35/35 [==============================] - 0s 6ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 1.6483e-05
Epoch 38/50
22/35 [=================>............] - ETA: 0s - loss: 0.1747 - mae: 0.4156 - mse: 0.1747 - root_mean_squared_error: 0.4179
35/35 [==============================] - 0s 7ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 1.0000e-05
Epoch 40/50
35/35 [==============================] - 0s 8ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 1.0000e-05
Epoch 41/50
35/35 [==============================] - 0s 8ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 1.0000e-05
Epoch 42/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 1.0000e-05
Epoch 43/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 1.0000e-05
Epoch 44/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 1.0000e-05
Epoch 45/50
35/35 [==============================] - 0s 7ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 1.0000e-05
Epoch 46/50
35/35 [==============================] - ETA: 0s - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171
Epoch 49/50==========================] - 0s 7ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 1.0000e-05
35/35 [==============================] - 0s 7ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 1.0000e-05
Epoch 50/50
35/35 [==============================] - 0s 8ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 1.0000e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn_adam_0.033757659693377275LR_[124, 516]CHN_16CNNI_112BS_100DU_3P_val_mseM_50epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
Epoch 1/50
Epoch 49/50==========================] - 0s 7ms/step - loss: 0.1740 - mae: 0.4148 - mse: 0.1740 - root_mean_squared_error: 0.4171 - val_loss: 0.1745 - val_mae: 0.4154 - val_mse: 0.1745 - val_root_mean_squared_error: 0.4178 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.0035s). Check your callbacks.
35/35 [==============================] - 0s 6ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 0.0169e-05
Epoch 7/50
35/35 [==============================] - ETA: 0s - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.008439415134489536.
35/35 [==============================] - 0s 6ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 0.0169
Epoch 8/50
23/35 [==================>...........] - ETA: 0s - loss: 0.2672 - mae: 0.5151 - mse: 0.2672 - root_mean_squared_error: 0.5169
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.002109853783622384.0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 0.0169e-05
35/35 [==============================] - 0s 8ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 0.0042
Epoch 14/50
35/35 [==============================] - 0s 7ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 0.0021
Epoch 15/50
35/35 [==============================] - 0s 6ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 0.0021
Epoch 16/50
35/35 [==============================] - ETA: 0s - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.001054926891811192.
35/35 [==============================] - 0s 7ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 0.0021
Epoch 17/50
 1/35 [..............................] - ETA: 0s - loss: 0.2687 - mae: 0.5167 - mse: 0.2687 - root_mean_squared_error: 0.5183
35/35 [==============================] - 0s 6ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 5.2746e-04
Epoch 21/50
35/35 [==============================] - 0s 8ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 5.2746e-04
Epoch 22/50
34/35 [============================>.] - ETA: 0s - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.000263731722952798.
35/35 [==============================] - 0s 9ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 5.2746e-04
Epoch 23/50
12/35 [=========>....................] - ETA: 0s - loss: 0.2668 - mae: 0.5146 - mse: 0.2668 - root_mean_squared_error: 0.5165
Epoch 28/50==========================] - 0s 6ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 5.2746e-04
24/35 [===================>..........] - ETA: 0s - loss: 0.2668 - mae: 0.5147 - mse: 0.2668 - root_mean_squared_error: 0.5166
Epoch 28: ReduceLROnPlateau reducing learning rate to 6.59329307381995e-05.
35/35 [==============================] - 0s 6ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 1.3187e-04
Epoch 29/50
35/35 [==============================] - 0s 7ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 6.5933e-05
Epoch 30/50
35/35 [==============================] - 0s 7ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 6.5933e-05
Epoch 31/50
35/35 [==============================] - ETA: 0s - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167
35/35 [==============================] - 0s 7ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 3.2966e-05
Epoch 35/50
35/35 [==============================] - 0s 7ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 1.6483e-05
Epoch 36/50
35/35 [==============================] - 0s 7ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 1.6483e-05
Epoch 37/50
34/35 [============================>.] - ETA: 0s - loss: 0.2668 - mae: 0.5147 - mse: 0.2668 - root_mean_squared_error: 0.5166
Epoch 37: ReduceLROnPlateau reducing learning rate to 1e-05.
35/35 [==============================] - 0s 7ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 1.6483e-05
Epoch 38/50
35/35 [==============================] - 0s 7ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 1.0000e-05
Epoch 39/50
35/35 [==============================] - 0s 7ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 1.0000e-05
Epoch 40/50
20/35 [================>.............] - ETA: 0s - loss: 0.2670 - mae: 0.5149 - mse: 0.2670 - root_mean_squared_error: 0.5167
Epoch 43/50==========================] - 0s 7ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 3.2966e-05
35/35 [==============================] - 0s 8ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 1.0000e-05
Epoch 44/50
35/35 [==============================] - 0s 7ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 1.0000e-05
Epoch 45/50
35/35 [==============================] - 0s 7ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 1.0000e-05
Epoch 46/50
35/35 [==============================] - 0s 7ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 1.0000e-05
Epoch 47/50
35/35 [==============================] - 0s 7ms/step - loss: 0.2669 - mae: 0.5148 - mse: 0.2669 - root_mean_squared_error: 0.5167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 1.0000e-05
Epoch 48/50
12/35 [=========>....................] - ETA: 0s - loss: 0.2682 - mae: 0.5160 - mse: 0.2682 - root_mean_squared_error: 0.5178
29/35 [=======================>......] - ETA: 0s - loss: 0.3801 - mae: 0.6150 - mse: 0.3801 - root_mean_squared_error: 0.6165 167 - val_loss: 0.2676 - val_mae: 0.5154 - val_mse: 0.2676 - val_root_mean_squared_error: 0.5173 - lr: 3.2966e-05
35/35 [==============================] - 1s 17ms/step - loss: 0.3799 - mae: 0.6148 - mse: 0.3799 - root_mean_squared_error: 0.6164 - val_loss: 0.3807 - val_mae: 0.6154 - val_mse: 0.3807 - val_root_mean_squared_error: 0.6170 - lr: 0.0338-05
22/35 [=================>............] - ETA: 0s - loss: 0.3797 - mae: 0.6146 - mse: 0.3797 - root_mean_squared_error: 0.6162.6164 - val_loss: 0.3807 - val_mae: 0.6154 - val_mse: 0.3807 - val_root_mean_squared_error: 0.6170 - lr: 0.0338-05
Epoch 23/50=======================>..] - ETA: 0s - loss: 0.3798 - mae: 0.6147 - mse: 0.3798 - root_mean_squared_error: 0.6163.6164 - val_loss: 0.3807 - val_mae: 0.6154 - val_mse: 0.3807 - val_root_mean_squared_error: 0.6170 - lr: 0.0338-05
35/35 [==============================] - 0s 9ms/step - loss: 0.3799 - mae: 0.6148 - mse: 0.3799 - root_mean_squared_error: 0.6164 - val_loss: 0.3807 - val_mae: 0.6154 - val_mse: 0.3807 - val_root_mean_squared_error: 0.6170 - lr: 2.6373e-04
Epoch 24/50
16/35 [============>.................] - ETA: 0s - loss: 0.3796 - mae: 0.6146 - mse: 0.3796 - root_mean_squared_error: 0.6161
35/35 [==============================] - 0s 7ms/step - loss: 0.3799 - mae: 0.6148 - mse: 0.3799 - root_mean_squared_error: 0.6164 - val_loss: 0.3807 - val_mae: 0.6154 - val_mse: 0.3807 - val_root_mean_squared_error: 0.6170 - lr: 6.5933e-05
Epoch 31/50
33/35 [===========================>..] - ETA: 0s - loss: 0.3798 - mae: 0.6147 - mse: 0.3798 - root_mean_squared_error: 0.6163
Epoch 31: ReduceLROnPlateau reducing learning rate to 3.296646536909975e-05.
35/35 [==============================] - 0s 7ms/step - loss: 0.3799 - mae: 0.6148 - mse: 0.3799 - root_mean_squared_error: 0.6164 - val_loss: 0.3807 - val_mae: 0.6154 - val_mse: 0.3807 - val_root_mean_squared_error: 0.6170 - lr: 6.5933e-05
Epoch 32/50
23/35 [==================>...........] - ETA: 0s - loss: 0.3795 - mae: 0.6145 - mse: 0.3795 - root_mean_squared_error: 0.6160
Epoch 37: ReduceLROnPlateau reducing learning rate to 1e-05. 0.3799 - mae: 0.6148 - mse: 0.3799 - root_mean_squared_error: 0.6164 - val_loss: 0.3807 - val_mae: 0.6154 - val_mse: 0.3807 - val_root_mean_squared_error: 0.6170 - lr: 6.5933e-05
35/35 [==============================] - 0s 7ms/step - loss: 0.3799 - mae: 0.6148 - mse: 0.3799 - root_mean_squared_error: 0.6164 - val_loss: 0.3807 - val_mae: 0.6154 - val_mse: 0.3807 - val_root_mean_squared_error: 0.6170 - lr: 1.6483e-05
Epoch 38/50
35/35 [==============================] - 0s 7ms/step - loss: 0.3799 - mae: 0.6148 - mse: 0.3799 - root_mean_squared_error: 0.6164 - val_loss: 0.3807 - val_mae: 0.6154 - val_mse: 0.3807 - val_root_mean_squared_error: 0.6170 - lr: 1.0000e-05
Epoch 39/50
35/35 [==============================] - 0s 7ms/step - loss: 0.3799 - mae: 0.6148 - mse: 0.3799 - root_mean_squared_error: 0.6164 - val_loss: 0.3807 - val_mae: 0.6154 - val_mse: 0.3807 - val_root_mean_squared_error: 0.6170 - lr: 1.0000e-05
Epoch 40/50
33/35 [===========================>..] - ETA: 0s - loss: 0.3798 - mae: 0.6147 - mse: 0.3798 - root_mean_squared_error: 0.6163
35/35 [==============================] - 0s 6ms/step - loss: 0.3799 - mae: 0.6148 - mse: 0.3799 - root_mean_squared_error: 0.6164 - val_loss: 0.3807 - val_mae: 0.6154 - val_mse: 0.3807 - val_root_mean_squared_error: 0.6170 - lr: 1.0000e-05
Epoch 47/50
35/35 [==============================] - 0s 6ms/step - loss: 0.3799 - mae: 0.6148 - mse: 0.3799 - root_mean_squared_error: 0.6164 - val_loss: 0.3807 - val_mae: 0.6154 - val_mse: 0.3807 - val_root_mean_squared_error: 0.6170 - lr: 1.0000e-05
Epoch 48/50
23/35 [==================>...........] - ETA: 0s - loss: 0.3802 - mae: 0.6151 - mse: 0.3802 - root_mean_squared_error: 0.6166
35/35 [==============================] - 0s 6ms/step - loss: 0.3799 - mae: 0.6148 - mse: 0.3799 - root_mean_squared_error: 0.6164 - val_loss: 0.3807 - val_mae: 0.6154 - val_mse: 0.3807 - val_root_mean_squared_error: 0.6170 - lr: 1.0000e-05
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.016878830268979073. 0.6148 - mse: 0.3799 - root_mean_squared_error: 0.6164 - val_loss: 0.3807 - val_mae: 0.6154 - val_mse: 0.3807 - val_root_mean_squared_error: 0.6170 - lr: 1.0000e-05
35/35 [==============================] - 0s 6ms/step - loss: 0.5129 - mae: 0.7148 - mse: 0.5129 - root_mean_squared_error: 0.7162 - val_loss: 0.5138 - val_mae: 0.7154 - val_mse: 0.5138 - val_root_mean_squared_error: 0.7168 - lr: 0.0042e-05
Epoch 19/50==========================] - 0s 6ms/step - loss: 0.5129 - mae: 0.7148 - mse: 0.5129 - root_mean_squared_error: 0.7162 - val_loss: 0.5138 - val_mae: 0.7154 - val_mse: 0.5138 - val_root_mean_squared_error: 0.7168 - lr: 0.0042e-05
35/35 [==============================] - 0s 8ms/step - loss: 0.5129 - mae: 0.7148 - mse: 0.5129 - root_mean_squared_error: 0.7162 - val_loss: 0.5138 - val_mae: 0.7154 - val_mse: 0.5138 - val_root_mean_squared_error: 0.7168 - lr: 2.6373e-04
24/35 [===================>..........] - ETA: 0s - loss: 0.5133 - mae: 0.7151 - mse: 0.5133 - root_mean_squared_error: 0.71647162 - val_loss: 0.5138 - val_mae: 0.7154 - val_mse: 0.5138 - val_root_mean_squared_error: 0.7168 - lr: 2.6373e-04
35/35 [==============================] - 0s 6ms/step - loss: 0.5129 - mae: 0.7148 - mse: 0.5129 - root_mean_squared_error: 0.7162 - val_loss: 0.5138 - val_mae: 0.7154 - val_mse: 0.5138 - val_root_mean_squared_error: 0.7168 - lr: 1.0000e-05
Epoch 50/50==========================] - 0s 6ms/step - loss: 0.5129 - mae: 0.7148 - mse: 0.5129 - root_mean_squared_error: 0.7162 - val_loss: 0.5138 - val_mae: 0.7154 - val_mse: 0.5138 - val_root_mean_squared_error: 0.7168 - lr: 1.0000e-05
34/35 [============================>.] - ETA: 0s - loss: 0.6659 - mae: 0.8149 - mse: 0.6659 - root_mean_squared_error: 0.81607162 - val_loss: 0.5138 - val_mae: 0.7154 - val_mse: 0.5138 - val_root_mean_squared_error: 0.7168 - lr: 1.0000e-05
Epoch 14/50========================>.] - ETA: 0s - loss: 0.6659 - mae: 0.8149 - mse: 0.6659 - root_mean_squared_error: 0.81607162 - val_loss: 0.5138 - val_mae: 0.7154 - val_mse: 0.5138 - val_root_mean_squared_error: 0.7168 - lr: 1.0000e-05
35/35 [==============================] - 0s 7ms/step - loss: 0.6658 - mae: 0.8148 - mse: 0.6658 - root_mean_squared_error: 0.8160 - val_loss: 0.6669 - val_mae: 0.8154 - val_mse: 0.6669 - val_root_mean_squared_error: 0.8166 - lr: 5.2746e-04
Epoch 28: ReduceLROnPlateau reducing learning rate to 6.59329307381995e-05.0.8148 - mse: 0.6658 - root_mean_squared_error: 0.8160 - val_loss: 0.6669 - val_mae: 0.8154 - val_mse: 0.6669 - val_root_mean_squared_error: 0.8166 - lr: 5.2746e-04
35/35 [==============================] - 0s 7ms/step - loss: 0.6658 - mae: 0.8148 - mse: 0.6658 - root_mean_squared_error: 0.8160 - val_loss: 0.6669 - val_mae: 0.8154 - val_mse: 0.6669 - val_root_mean_squared_error: 0.8166 - lr: 1.6483e-05
Epoch 44/50==========================] - 0s 7ms/step - loss: 0.6658 - mae: 0.8148 - mse: 0.6658 - root_mean_squared_error: 0.8160 - val_loss: 0.6669 - val_mae: 0.8154 - val_mse: 0.6669 - val_root_mean_squared_error: 0.8166 - lr: 1.6483e-05
Epoch 44/50==========================] - 0s 7ms/step - loss: 0.6658 - mae: 0.8148 - mse: 0.6658 - root_mean_squared_error: 0.8160 - val_loss: 0.6669 - val_mae: 0.8154 - val_mse: 0.6669 - val_root_mean_squared_error: 0.8166 - lr: 1.6483e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0043s vs `on_train_batch_end` time: 0.0055s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0043s vs `on_train_batch_end` time: 0.0055s). Check your callbacks.
35/35 [==============================] - 0s 9ms/step - loss: 0.8388 - mae: 0.9148 - mse: 0.8388 - root_mean_squared_error: 0.9159 - val_loss: 0.8400 - val_mae: 0.9154 - val_mse: 0.8400 - val_root_mean_squared_error: 0.9165 - lr: 0.0338e-05
35/35 [==============================] - 0s 7ms/step - loss: 0.8388 - mae: 0.9148 - mse: 0.8388 - root_mean_squared_error: 0.9159 - val_loss: 0.8400 - val_mae: 0.9154 - val_mse: 0.8400 - val_root_mean_squared_error: 0.9165 - lr: 0.0021e-05
Epoch 24/50==========================] - 0s 7ms/step - loss: 0.8388 - mae: 0.9148 - mse: 0.8388 - root_mean_squared_error: 0.9159 - val_loss: 0.8400 - val_mae: 0.9154 - val_mse: 0.8400 - val_root_mean_squared_error: 0.9165 - lr: 0.0021e-05
31/35 [=========================>....] - ETA: 0s - loss: 0.8397 - mae: 0.9153 - mse: 0.8397 - root_mean_squared_error: 0.91639159 - val_loss: 0.8400 - val_mae: 0.9154 - val_mse: 0.8400 - val_root_mean_squared_error: 0.9165 - lr: 0.0021e-05
Epoch 38/50=====================>....] - ETA: 0s - loss: 0.8397 - mae: 0.9153 - mse: 0.8397 - root_mean_squared_error: 0.91639159 - val_loss: 0.8400 - val_mae: 0.9154 - val_mse: 0.8400 - val_root_mean_squared_error: 0.9165 - lr: 0.0021e-05
34/35 [============================>.] - ETA: 0s - loss: 0.8385 - mae: 0.9146 - mse: 0.8385 - root_mean_squared_error: 0.91579159 - val_loss: 0.8400 - val_mae: 0.9154 - val_mse: 0.8400 - val_root_mean_squared_error: 0.9165 - lr: 0.0021e-05
35/35 [==============================] - 0s 6ms/step - loss: 0.8388 - mae: 0.9148 - mse: 0.8388 - root_mean_squared_error: 0.9159 - val_loss: 0.8400 - val_mae: 0.9154 - val_mse: 0.8400 - val_root_mean_squared_error: 0.9165 - lr: 1.0000e-05
35/35 [==============================] - 0s 6ms/step - loss: 0.8388 - mae: 0.9148 - mse: 0.8388 - root_mean_squared_error: 0.9159 - val_loss: 0.8400 - val_mae: 0.9154 - val_mse: 0.8400 - val_root_mean_squared_error: 0.9165 - lr: 1.0000e-05