Epoch 1/30
46/81 [================>.............] - ETA: 0s - loss: 0.0704 - mae: 0.0642 - mse: 0.0089
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_203959-0pt7cboo\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 10ms/step - loss: 0.0468 - mae: 0.0605 - mse: 0.0070 - val_loss: 0.0136 - val_mae: 0.0497 - val_mse: 0.0037 - lr: 0.0777
Epoch 2/30
54/81 [===================>..........] - ETA: 0s - loss: 0.0123 - mae: 0.0429 - mse: 0.0026
81/81 [==============================] - 1s 9ms/step - loss: 0.0121 - mae: 0.0416 - mse: 0.0025 - val_loss: 0.0107 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0777
Epoch 3/30
44/81 [===============>..............] - ETA: 0s - loss: 0.0115 - mae: 0.0389 - mse: 0.0020
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.03886633738875389.
81/81 [==============================] - 0s 2ms/step - loss: 0.0115 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0110 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0777
Epoch 4/30
49/81 [=================>............] - ETA: 0s - loss: 0.0032 - mae: 0.0379 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.019433168694376945.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_203959-0pt7cboo\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 10ms/step - loss: 0.0036 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0039 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0389
Epoch 5/30
49/81 [=================>............] - ETA: 0s - loss: 0.0023 - mae: 0.0377 - mse: 0.0019
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.009716584347188473.
81/81 [==============================] - 1s 9ms/step - loss: 0.0024 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0194
Epoch 6/30
69/81 [========================>.....] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.004858292173594236.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_203959-0pt7cboo\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 9ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0097
Epoch 7/30
51/81 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.002429146086797118.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_203959-0pt7cboo\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 11ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0049
Epoch 8/30
50/81 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.001214573043398559.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_203959-0pt7cboo\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 10ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0024
Epoch 9/30
46/81 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0006072865216992795.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_203959-0pt7cboo\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 9ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0012
Epoch 10/30
47/81 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0003036432608496398.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_203959-0pt7cboo\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_203959-0pt7cboo\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 10ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.0729e-04
Epoch 11/30
53/81 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0001518216304248199.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_203959-0pt7cboo\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 10ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.0364e-04
Epoch 12/30
48/81 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 7.591081521240994e-05.
81/81 [==============================] - 1s 10ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.5182e-04
Epoch 13/30
47/81 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 3.795540760620497e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_203959-0pt7cboo\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_203959-0pt7cboo\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 10ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.5911e-05
Epoch 14/30
44/81 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.8977703803102486e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_203959-0pt7cboo\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 11ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.7955e-05
Epoch 15/30
58/81 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.
81/81 [==============================] - 1s 9ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.8978e-05
Epoch 16/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 17/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 18/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 19/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 20/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 21/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 22/30
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 23/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 24/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 25/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 26/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 27/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 28/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 29/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 30/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.07773267341593894LR_[70]HN_48BS_1P_val_mseM_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
108/108 [==============================] - 1s 2ms/step - loss: 0.0379 - mae: 0.0671 - mse: 0.0072 - val_loss: 0.0123 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0777
Epoch 2/30
 91/108 [========================>.....] - ETA: 0s - loss: 0.0133 - mae: 0.0527 - mse: 0.0038
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.03886633738875389.
108/108 [==============================] - 0s 2ms/step - loss: 0.0133 - mae: 0.0527 - mse: 0.0038 - val_loss: 0.0124 - val_mae: 0.0515 - val_mse: 0.0036 - lr: 0.0777
Epoch 3/30
 93/108 [========================>.....] - ETA: 0s - loss: 0.0053 - mae: 0.0506 - mse: 0.0034
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.019433168694376945.
108/108 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0509 - mse: 0.0035 - val_loss: 0.0056 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0389
Epoch 4/30
 51/108 [=============>................] - ETA: 0s - loss: 0.0038 - mae: 0.0510 - mse: 0.0034
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.009716584347188473.
108/108 [==============================] - 0s 1ms/step - loss: 0.0039 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0040 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0194
Epoch 5/30
 60/108 [===============>..............] - ETA: 0s - loss: 0.0035 - mae: 0.0504 - mse: 0.0034
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.004858292173594236.
108/108 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0097
Epoch 6/30
 48/108 [============>.................] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.002429146086797118.
108/108 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0049
Epoch 7/30
 58/108 [===============>..............] - ETA: 0s - loss: 0.0034 - mae: 0.0511 - mse: 0.0034
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.001214573043398559.
108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0024
Epoch 8/30
 62/108 [================>.............] - ETA: 0s - loss: 0.0033 - mae: 0.0501 - mse: 0.0033
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0006072865216992795.
108/108 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0012
Epoch 9/30
 67/108 [=================>............] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003036432608496398.
108/108 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.0729e-04
Epoch 10/30
 95/108 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001518216304248199.
108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.0364e-04
Epoch 11/30
 96/108 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 11: ReduceLROnPlateau reducing learning rate to 7.591081521240994e-05.
108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.5182e-04
Epoch 12/30
101/108 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0503 - mse: 0.0034
Epoch 12: ReduceLROnPlateau reducing learning rate to 3.795540760620497e-05.
108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 7.5911e-05
Epoch 13/30
 89/108 [=======================>......] - ETA: 0s - loss: 0.0034 - mae: 0.0508 - mse: 0.0034
Epoch 13: ReduceLROnPlateau reducing learning rate to 1.8977703803102486e-05.
108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.7955e-05
Epoch 14/30
 63/108 [================>.............] - ETA: 0s - loss: 0.0034 - mae: 0.0510 - mse: 0.0034
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.
108/108 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.8978e-05
Epoch 15/30
108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 16/30
108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 17/30
108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 18/30
108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 19/30
108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 20/30
108/108 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 21/30
108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 22/30
108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 23/30
108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 24/30
108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 25/30
108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 26/30
108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 27/30
108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 28/30
108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 29/30
108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 30/30
108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.07773267341593894LR_[70]HN_48BS_1P_val_mseM_30epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
81/81 [==============================] - 0s 3ms/step - loss: 0.0392 - mae: 0.0513 - mse: 0.0048 - val_loss: 0.0106 - val_mae: 0.0404 - val_mse: 0.0023 - lr: 0.0777
Epoch 2/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0129 - mae: 0.0457 - mse: 0.0034 - val_loss: 0.0108 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0777
Epoch 3/30
49/81 [=================>............] - ETA: 0s - loss: 0.0133 - mae: 0.0461 - mse: 0.0034
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.03886633738875389.
81/81 [==============================] - 0s 2ms/step - loss: 0.0140 - mae: 0.0487 - mse: 0.0041 - val_loss: 0.0109 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0777
Epoch 4/30
41/81 [==============>...............] - ETA: 0s - loss: 0.0032 - mae: 0.0376 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.019433168694376945.
81/81 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0037 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0389
Epoch 5/30
53/81 [==================>...........] - ETA: 0s - loss: 0.0023 - mae: 0.0376 - mse: 0.0019
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.009716584347188473.
81/81 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0026 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0194
Epoch 6/30
39/81 [=============>................] - ETA: 0s - loss: 0.0020 - mae: 0.0382 - mse: 0.0019
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.004858292173594236.
81/81 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0097
Epoch 7/30
66/81 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.002429146086797118.
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0049
Epoch 8/30
45/81 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0373 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.001214573043398559.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0024
Epoch 9/30
57/81 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0006072865216992795.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0012
Epoch 10/30
45/81 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0003036432608496398.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.0729e-04
Epoch 11/30
41/81 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0001518216304248199.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.0364e-04
Epoch 12/30
55/81 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 7.591081521240994e-05.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.5182e-04
Epoch 13/30
57/81 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 3.795540760620497e-05.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.5911e-05
Epoch 14/30
56/81 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.8977703803102486e-05.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.7955e-05
Epoch 15/30
48/81 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.8978e-05
Epoch 16/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 17/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 18/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 19/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 20/30
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 21/30
69/81 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_203959-0pt7cboo\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 11ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 22/30
38/81 [=============>................] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
81/81 [==============================] - 1s 11ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
81/81 [==============================] - 1s 11ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_203959-0pt7cboo\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 11ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230418_203959-0pt7cboo\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 11ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.002429146086797118.: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
59/81 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.8978e-05
Epoch 16/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 17/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 18/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 19/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 20/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 21/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 22/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 23/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 24/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 25/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 26/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 27/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 28/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 29/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 30/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.07773267341593894LR_[70]HN_48BS_1P_val_mseM_30epochs/model_5.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
81/81 [==============================] - 1s 2ms/step - loss: 0.0449 - mae: 0.0559 - mse: 0.0063 - val_loss: 0.0099 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0777
Epoch 2/30
52/81 [==================>...........] - ETA: 0s - loss: 0.0125 - mae: 0.0447 - mse: 0.0030
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.03886633738875389.
81/81 [==============================] - 0s 2ms/step - loss: 0.0131 - mae: 0.0465 - mse: 0.0035 - val_loss: 0.0105 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0777
Epoch 3/30
40/81 [=============>................] - ETA: 0s - loss: 0.0033 - mae: 0.0381 - mse: 0.0019
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.019433168694376945.
81/81 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0066 - val_mae: 0.0453 - val_mse: 0.0030 - lr: 0.0389
Epoch 4/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0194
Epoch 5/30
39/81 [=============>................] - ETA: 0s - loss: 0.0025 - mae: 0.0382 - mse: 0.0020
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.009716584347188473.
81/81 [==============================] - 0s 2ms/step - loss: 0.0025 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0194
Epoch 6/30
52/81 [==================>...........] - ETA: 0s - loss: 0.0020 - mae: 0.0376 - mse: 0.0019
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.004858292173594236.
81/81 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0097
Epoch 7/30
65/81 [=======================>......] - ETA: 0s - loss: 0.0020 - mae: 0.0382 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.002429146086797118.
81/81 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0049
Epoch 8/30
49/81 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.001214573043398559.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0024
Epoch 9/30
58/81 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0006072865216992795.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0012
Epoch 10/30
51/81 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0003036432608496398.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.0729e-04
Epoch 11/30
41/81 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0371 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0001518216304248199.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.0364e-04
Epoch 12/30
65/81 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 7.591081521240994e-05.
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.5182e-04
Epoch 13/30
52/81 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0374 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 3.795540760620497e-05.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.5911e-05
Epoch 14/30
46/81 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.8977703803102486e-05.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.7955e-05
Epoch 15/30
52/81 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.8978e-05
Epoch 16/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 17/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 18/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 19/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 20/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 21/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 22/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 23/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 24/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 25/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 26/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 27/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 28/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 29/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 30/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.07773267341593894LR_[70]HN_48BS_1P_val_mseM_30epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
81/81 [==============================] - 1s 2ms/step - loss: 0.0416 - mae: 0.0501 - mse: 0.0044 - val_loss: 0.0095 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0777
Epoch 2/30
50/81 [=================>............] - ETA: 0s - loss: 0.0123 - mae: 0.0443 - mse: 0.0029
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.03886633738875389.
81/81 [==============================] - 0s 2ms/step - loss: 0.0122 - mae: 0.0440 - mse: 0.0029 - val_loss: 0.0104 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0777
Epoch 3/30
47/81 [================>.............] - ETA: 0s - loss: 0.0032 - mae: 0.0378 - mse: 0.0019
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.019433168694376945.
81/81 [==============================] - 0s 3ms/step - loss: 0.0036 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0046 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0389
Epoch 4/30
80/81 [============================>.] - ETA: 0s - loss: 0.0024 - mae: 0.0379 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.009716584347188473.
81/81 [==============================] - 0s 1ms/step - loss: 0.0024 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0026 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0194
Epoch 5/30
 1/81 [..............................] - ETA: 0s - loss: 0.0023 - mae: 0.0367 - mse: 0.0017
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.004858292173594236.
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0097
Epoch 6/30
47/81 [================>.............] - ETA: 0s - loss: 0.0020 - mae: 0.0382 - mse: 0.0019
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.002429146086797118.: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0049
Epoch 7/30
48/81 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.001214573043398559.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0024
Epoch 8/30
47/81 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0006072865216992795.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0012
Epoch 9/30
42/81 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.0019
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003036432608496398.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.0729e-04
Epoch 10/30
42/81 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001518216304248199.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.0364e-04
Epoch 11/30
55/81 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 7.591081521240994e-05.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.5182e-04
Epoch 12/30
45/81 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 3.795540760620497e-05.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.5911e-05
Epoch 13/30
54/81 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 1.8977703803102486e-05.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.7955e-05
Epoch 14/30
44/81 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0383 - mse: 0.0019
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.8978e-05
Epoch 15/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 16/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 17/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 18/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 19/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 20/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 21/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 22/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 23/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 24/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 25/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 26/30
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 27/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 28/30
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 29/30
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 30/30
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.07773267341593894LR_[70]HN_48BS_1P_val_mseM_30epochs/model_7.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
81/81 [==============================] - 1s 3ms/step - loss: 0.0421 - mae: 0.0610 - mse: 0.0065 - val_loss: 0.0088 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0777
Epoch 2/30
46/81 [================>.............] - ETA: 0s - loss: 0.0116 - mae: 0.0405 - mse: 0.0023
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.03886633738875389.
81/81 [==============================] - 0s 2ms/step - loss: 0.0121 - mae: 0.0421 - mse: 0.0026 - val_loss: 0.0109 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0777
Epoch 3/30
49/81 [=================>............] - ETA: 0s - loss: 0.0033 - mae: 0.0380 - mse: 0.0020
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.019433168694376945.
81/81 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0049 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0389
Epoch 4/30
46/81 [================>.............] - ETA: 0s - loss: 0.0023 - mae: 0.0377 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.009716584347188473.
81/81 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0029 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0194
Epoch 5/30
45/81 [===============>..............] - ETA: 0s - loss: 0.0020 - mae: 0.0378 - mse: 0.0019
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.004858292173594236.
81/81 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0097
Epoch 6/30
52/81 [==================>...........] - ETA: 0s - loss: 0.0020 - mae: 0.0382 - mse: 0.0019
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.002429146086797118.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0049
Epoch 7/30
46/81 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0374 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.001214573043398559.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0024
Epoch 8/30
43/81 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0006072865216992795.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0012
Epoch 9/30
54/81 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003036432608496398.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.0729e-04
Epoch 10/30
48/81 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001518216304248199.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.0364e-04
Epoch 11/30
53/81 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 7.591081521240994e-05.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.5182e-04
Epoch 12/30
39/81 [=============>................] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 3.795540760620497e-05.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.5911e-05
Epoch 13/30
48/81 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 1.8977703803102486e-05.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.7955e-05
Epoch 14/30
43/81 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.8978e-05
Epoch 15/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 16/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 17/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 18/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 19/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 20/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 21/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 22/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 23/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 24/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 25/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 26/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 27/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 28/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 29/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 30/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.07773267341593894LR_[70]HN_48BS_1P_val_mseM_30epochs/model_8.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
81/81 [==============================] - 1s 3ms/step - loss: 0.0504 - mae: 0.0627 - mse: 0.0073 - val_loss: 0.0108 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0777
Epoch 2/30
41/81 [==============>...............] - ETA: 0s - loss: 0.0123 - mae: 0.0415 - mse: 0.0025
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.03886633738875389.
81/81 [==============================] - 0s 2ms/step - loss: 0.0119 - mae: 0.0403 - mse: 0.0023 - val_loss: 0.0109 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0777
Epoch 3/30
42/81 [==============>...............] - ETA: 0s - loss: 0.0034 - mae: 0.0377 - mse: 0.0019
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.019433168694376945.
81/81 [==============================] - 0s 2ms/step - loss: 0.0037 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0049 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0389
Epoch 4/30
46/81 [================>.............] - ETA: 0s - loss: 0.0023 - mae: 0.0381 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.009716584347188473.
81/81 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0026 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0194
Epoch 5/30
42/81 [==============>...............] - ETA: 0s - loss: 0.0020 - mae: 0.0379 - mse: 0.0019
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.004858292173594236.
81/81 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0097
Epoch 6/30
45/81 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.002429146086797118.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0049
Epoch 7/30
52/81 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.001214573043398559.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0024
Epoch 8/30
45/81 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0006072865216992795.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0012
Epoch 9/30
42/81 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.0019
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003036432608496398.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.0729e-04
Epoch 10/30
48/81 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0382 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001518216304248199.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.0364e-04
Epoch 11/30
54/81 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 7.591081521240994e-05.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.5182e-04
Epoch 12/30
41/81 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 3.795540760620497e-05.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.5911e-05
Epoch 13/30
56/81 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 1.8977703803102486e-05.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.7955e-05
Epoch 14/30
47/81 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.8978e-05
Epoch 15/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 16/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 17/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 18/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 19/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 20/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 21/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 22/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 23/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 24/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 25/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 26/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 27/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 28/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 29/30
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 30/30
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.07773267341593894LR_[70]HN_48BS_1P_val_mseM_30epochs/model_9.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0025s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.