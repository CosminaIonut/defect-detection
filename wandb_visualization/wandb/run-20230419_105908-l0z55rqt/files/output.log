Epoch 1/20
42/81 [==============>...............] - ETA: 0s - loss: 8.9891 - mae: 0.1297 - mse: 0.0357
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
81/81 [==============================] - 2s 15ms/step - loss: 8.2929 - mae: 0.0867 - mse: 0.0196 - val_loss: 6.9097 - val_mae: 0.0411 - val_mse: 0.0024 - lr: 0.0214
Epoch 2/20
40/81 [=============>................] - ETA: 0s - loss: 6.3616 - mae: 0.0413 - mse: 0.0024
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.010675729252398014.
81/81 [==============================] - 1s 15ms/step - loss: 5.8485 - mae: 0.0418 - mse: 0.0025 - val_loss: 4.8779 - val_mae: 0.0428 - val_mse: 0.0026 - lr: 0.0214
Epoch 3/20
47/81 [================>.............] - ETA: 0s - loss: 4.6100 - mae: 0.0430 - mse: 0.0027
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.005337864626199007.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 14ms/step - loss: 4.4481 - mae: 0.0432 - mse: 0.0027 - val_loss: 4.0672 - val_mae: 0.0435 - val_mse: 0.0027 - lr: 0.0107
Epoch 4/20
45/81 [===============>..............] - ETA: 0s - loss: 3.9582 - mae: 0.0427 - mse: 0.0026
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0026689323130995035.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 14ms/step - loss: 3.8834 - mae: 0.0437 - mse: 0.0028 - val_loss: 3.7152 - val_mae: 0.0439 - val_mse: 0.0028 - lr: 0.0053
Epoch 5/20
45/81 [===============>..............] - ETA: 0s - loss: 3.6651 - mae: 0.0438 - mse: 0.0028
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0013344661565497518.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 14ms/step - loss: 3.6302 - mae: 0.0439 - mse: 0.0028 - val_loss: 3.5511 - val_mae: 0.0441 - val_mse: 0.0028 - lr: 0.0027
Epoch 6/20
46/81 [================>.............] - ETA: 0s - loss: 3.5266 - mae: 0.0444 - mse: 0.0029
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0006672330782748759.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 14ms/step - loss: 3.5102 - mae: 0.0441 - mse: 0.0028 - val_loss: 3.4718 - val_mae: 0.0442 - val_mse: 0.0028 - lr: 0.0013
Epoch 7/20
44/81 [===============>..............] - ETA: 0s - loss: 3.4603 - mae: 0.0442 - mse: 0.0028
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00033361653913743794.
81/81 [==============================] - 1s 17ms/step - loss: 3.4518 - mae: 0.0442 - mse: 0.0028 - val_loss: 3.4329 - val_mae: 0.0442 - val_mse: 0.0028 - lr: 6.6723e-04
Epoch 8/20
45/81 [===============>..............] - ETA: 0s - loss: 3.4271 - mae: 0.0445 - mse: 0.0029
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00016680826956871897.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 14ms/step - loss: 3.4230 - mae: 0.0442 - mse: 0.0028 - val_loss: 3.4136 - val_mae: 0.0443 - val_mse: 0.0028 - lr: 3.3362e-04
Epoch 9/20
46/81 [================>.............] - ETA: 0s - loss: 3.4105 - mae: 0.0434 - mse: 0.0027
Epoch 9: ReduceLROnPlateau reducing learning rate to 8.340413478435948e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 14ms/step - loss: 3.4086 - mae: 0.0442 - mse: 0.0028 - val_loss: 3.4040 - val_mae: 0.0443 - val_mse: 0.0028 - lr: 1.6681e-04
Epoch 10/20
39/81 [=============>................] - ETA: 0s - loss: 3.4028 - mae: 0.0444 - mse: 0.0029
Epoch 10: ReduceLROnPlateau reducing learning rate to 4.170206739217974e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 14ms/step - loss: 3.4015 - mae: 0.0442 - mse: 0.0028 - val_loss: 3.3992 - val_mae: 0.0443 - val_mse: 0.0028 - lr: 8.3404e-05
Epoch 11/20
48/81 [================>.............] - ETA: 0s - loss: 3.3985 - mae: 0.0445 - mse: 0.0029
Epoch 11: ReduceLROnPlateau reducing learning rate to 2.085103369608987e-05.
81/81 [==============================] - 1s 14ms/step - loss: 3.3980 - mae: 0.0442 - mse: 0.0028 - val_loss: 3.3968 - val_mae: 0.0443 - val_mse: 0.0028 - lr: 4.1702e-05
Epoch 12/20
43/81 [==============>...............] - ETA: 0s - loss: 3.3965 - mae: 0.0445 - mse: 0.0029
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.0425516848044936e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 16ms/step - loss: 3.3962 - mae: 0.0442 - mse: 0.0028 - val_loss: 3.3956 - val_mae: 0.0443 - val_mse: 0.0028 - lr: 2.0851e-05
Epoch 13/20
47/81 [================>.............] - ETA: 0s - loss: 3.3954 - mae: 0.0437 - mse: 0.0028
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 14ms/step - loss: 3.3953 - mae: 0.0442 - mse: 0.0028 - val_loss: 3.3950 - val_mae: 0.0443 - val_mse: 0.0028 - lr: 1.0426e-05
Epoch 14/20
40/81 [=============>................] - ETA: 0s - loss: 3.3948 - mae: 0.0435 - mse: 0.0028
81/81 [==============================] - 1s 15ms/step - loss: 3.3947 - mae: 0.0442 - mse: 0.0028 - val_loss: 3.3944 - val_mae: 0.0443 - val_mse: 0.0028 - lr: 1.0000e-05
Epoch 15/20
81/81 [==============================] - 1s 14ms/step - loss: 3.3942 - mae: 0.0442 - mse: 0.0028 - val_loss: 3.3939 - val_mae: 0.0443 - val_mse: 0.0028 - lr: 1.0000e-05
Epoch 16/20
46/81 [================>.............] - ETA: 0s - loss: 3.3938 - mae: 0.0442 - mse: 0.0028
81/81 [==============================] - 1s 14ms/step - loss: 3.3936 - mae: 0.0442 - mse: 0.0028 - val_loss: 3.3933 - val_mae: 0.0443 - val_mse: 0.0028 - lr: 1.0000e-05
Epoch 17/20
43/81 [==============>...............] - ETA: 0s - loss: 3.3931 - mae: 0.0433 - mse: 0.0028
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 17ms/step - loss: 3.3931 - mae: 0.0442 - mse: 0.0028 - val_loss: 3.3928 - val_mae: 0.0443 - val_mse: 0.0028 - lr: 1.0000e-05
Epoch 18/20
43/81 [==============>...............] - ETA: 0s - loss: 3.3926 - mae: 0.0437 - mse: 0.0028
81/81 [==============================] - 1s 14ms/step - loss: 3.3925 - mae: 0.0442 - mse: 0.0028 - val_loss: 3.3923 - val_mae: 0.0443 - val_mse: 0.0028 - lr: 1.0000e-05
Epoch 19/20
48/81 [================>.............] - ETA: 0s - loss: 3.3922 - mae: 0.0447 - mse: 0.0029
81/81 [==============================] - 1s 14ms/step - loss: 3.3920 - mae: 0.0442 - mse: 0.0028 - val_loss: 3.3917 - val_mae: 0.0443 - val_mse: 0.0028 - lr: 1.0000e-05
Epoch 20/20
44/81 [===============>..............] - ETA: 0s - loss: 3.3916 - mae: 0.0446 - mse: 0.0029
81/81 [==============================] - 1s 14ms/step - loss: 3.3915 - mae: 0.0442 - mse: 0.0028 - val_loss: 3.3912 - val_mae: 0.0443 - val_mse: 0.0028 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_sgd_0.021351458030224757LR_[32, 64, 128, 256]HN_48BS_1P_val_mseM_20epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
108/108 [==============================] - 1s 3ms/step - loss: 7.7986 - mae: 0.0799 - mse: 0.0121 - val_loss: 6.1063 - val_mae: 0.0518 - val_mse: 0.0036 - lr: 0.0214
Epoch 2/20
 90/108 [========================>.....] - ETA: 0s - loss: 5.0737 - mae: 0.0520 - mse: 0.0037
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.010675729252398014.
108/108 [==============================] - 0s 2ms/step - loss: 4.8991 - mae: 0.0519 - mse: 0.0037 - val_loss: 3.8372 - val_mae: 0.0522 - val_mse: 0.0037 - lr: 0.0214
Epoch 3/20
 98/108 [==========================>...] - ETA: 0s - loss: 3.4369 - mae: 0.0522 - mse: 0.0037
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.005337864626199007.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
108/108 [==============================] - 1s 10ms/step - loss: 3.4033 - mae: 0.0523 - mse: 0.0038 - val_loss: 3.0194 - val_mae: 0.0524 - val_mse: 0.0038 - lr: 0.0107
Epoch 4/20
 94/108 [=========================>....] - ETA: 0s - loss: 2.8629 - mae: 0.0519 - mse: 0.0037
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0026689323130995035.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
108/108 [==============================] - 1s 11ms/step - loss: 2.8426 - mae: 0.0522 - mse: 0.0037 - val_loss: 2.6795 - val_mae: 0.0526 - val_mse: 0.0038 - lr: 0.0053
Epoch 5/20
 91/108 [========================>.....] - ETA: 0s - loss: 2.6110 - mae: 0.0520 - mse: 0.0037
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0013344661565497518.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
108/108 [==============================] - 1s 11ms/step - loss: 2.5997 - mae: 0.0523 - mse: 0.0038 - val_loss: 2.5245 - val_mae: 0.0527 - val_mse: 0.0038 - lr: 0.0027
Epoch 6/20
 89/108 [=======================>......] - ETA: 0s - loss: 2.4926 - mae: 0.0521 - mse: 0.0037
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0006672330782748759.
108/108 [==============================] - 1s 12ms/step - loss: 2.4865 - mae: 0.0524 - mse: 0.0038 - val_loss: 2.4504 - val_mae: 0.0527 - val_mse: 0.0038 - lr: 0.0013
Epoch 7/20
 70/108 [==================>...........] - ETA: 0s - loss: 2.4379 - mae: 0.0520 - mse: 0.0037
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00033361653913743794.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
108/108 [==============================] - 1s 11ms/step - loss: 2.4319 - mae: 0.0524 - mse: 0.0038 - val_loss: 2.4142 - val_mae: 0.0527 - val_mse: 0.0038 - lr: 6.6723e-04
Epoch 8/20
 95/108 [=========================>....] - ETA: 0s - loss: 2.4060 - mae: 0.0520 - mse: 0.0037
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00016680826956871897.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
108/108 [==============================] - 1s 10ms/step - loss: 2.4050 - mae: 0.0524 - mse: 0.0038 - val_loss: 2.3963 - val_mae: 0.0527 - val_mse: 0.0038 - lr: 3.3362e-04
Epoch 9/20
 94/108 [=========================>....] - ETA: 0s - loss: 2.3923 - mae: 0.0521 - mse: 0.0038
Epoch 9: ReduceLROnPlateau reducing learning rate to 8.340413478435948e-05.
108/108 [==============================] - 1s 11ms/step - loss: 2.3917 - mae: 0.0524 - mse: 0.0038 - val_loss: 2.3874 - val_mae: 0.0527 - val_mse: 0.0038 - lr: 1.6681e-04
Epoch 10/20
 95/108 [=========================>....] - ETA: 0s - loss: 2.3853 - mae: 0.0521 - mse: 0.0037
Epoch 10: ReduceLROnPlateau reducing learning rate to 4.170206739217974e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
108/108 [==============================] - 1s 12ms/step - loss: 2.3851 - mae: 0.0524 - mse: 0.0038 - val_loss: 2.3830 - val_mae: 0.0527 - val_mse: 0.0038 - lr: 8.3404e-05
Epoch 11/20
 93/108 [========================>.....] - ETA: 0s - loss: 2.3820 - mae: 0.0524 - mse: 0.0038
Epoch 11: ReduceLROnPlateau reducing learning rate to 2.085103369608987e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
108/108 [==============================] - 1s 11ms/step - loss: 2.3818 - mae: 0.0524 - mse: 0.0038 - val_loss: 2.3808 - val_mae: 0.0527 - val_mse: 0.0038 - lr: 4.1702e-05
Epoch 12/20
 90/108 [========================>.....] - ETA: 0s - loss: 2.3802 - mae: 0.0522 - mse: 0.0038
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.0425516848044936e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
108/108 [==============================] - 1s 11ms/step - loss: 2.3802 - mae: 0.0524 - mse: 0.0038 - val_loss: 2.3797 - val_mae: 0.0527 - val_mse: 0.0038 - lr: 2.0851e-05
Epoch 13/20
 91/108 [========================>.....] - ETA: 0s - loss: 2.3794 - mae: 0.0521 - mse: 0.0037
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
108/108 [==============================] - 1s 11ms/step - loss: 2.3793 - mae: 0.0524 - mse: 0.0038 - val_loss: 2.3791 - val_mae: 0.0527 - val_mse: 0.0038 - lr: 1.0426e-05
Epoch 14/20
 93/108 [========================>.....] - ETA: 0s - loss: 2.3788 - mae: 0.0522 - mse: 0.0038
108/108 [==============================] - 1s 13ms/step - loss: 2.3788 - mae: 0.0524 - mse: 0.0038 - val_loss: 2.3786 - val_mae: 0.0527 - val_mse: 0.0038 - lr: 1.0000e-05
Epoch 15/20
 87/108 [=======================>......] - ETA: 0s - loss: 2.3784 - mae: 0.0524 - mse: 0.0038
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_105908-l0z55rqt\files\model-best)... Done. 0.0s
108/108 [==============================] - 2s 15ms/step - loss: 2.3783 - mae: 0.0524 - mse: 0.0038 - val_loss: 2.3781 - val_mae: 0.0527 - val_mse: 0.0038 - lr: 1.0000e-05
Epoch 16/20
 91/108 [========================>.....] - ETA: 0s - loss: 2.3778 - mae: 0.0524 - mse: 0.0038
108/108 [==============================] - 1s 12ms/step - loss: 2.3778 - mae: 0.0524 - mse: 0.0038 - val_loss: 2.3776 - val_mae: 0.0527 - val_mse: 0.0038 - lr: 1.0000e-05
Epoch 17/20
 87/108 [=======================>......] - ETA: 0s - loss: 2.3773 - mae: 0.0521 - mse: 0.0037
108/108 [==============================] - 1s 12ms/step - loss: 2.3773 - mae: 0.0524 - mse: 0.0038 - val_loss: 2.3771 - val_mae: 0.0527 - val_mse: 0.0038 - lr: 1.0000e-05
Epoch 18/20
 77/108 [====================>.........] - ETA: 0s - loss: 2.3768 - mae: 0.0521 - mse: 0.0037
108/108 [==============================] - 1s 13ms/step - loss: 2.3768 - mae: 0.0524 - mse: 0.0038 - val_loss: 2.3766 - val_mae: 0.0527 - val_mse: 0.0038 - lr: 1.0000e-05
Epoch 19/20
 85/108 [======================>.......] - ETA: 0s - loss: 2.3764 - mae: 0.0527 - mse: 0.0038
108/108 [==============================] - 1s 12ms/step - loss: 2.3763 - mae: 0.0524 - mse: 0.0038 - val_loss: 2.3760 - val_mae: 0.0527 - val_mse: 0.0038 - lr: 1.0000e-05
Epoch 20/20
108/108 [==============================] - 2s 16ms/step - loss: 2.3758 - mae: 0.0524 - mse: 0.0038 - val_loss: 2.3755 - val_mae: 0.0527 - val_mse: 0.0038 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_sgd_0.021351458030224757LR_[32, 64, 128, 256]HN_48BS_1P_val_mseM_20epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
81/81 [==============================] - 1s 4ms/step - loss: 8.1921 - mae: 0.0602 - mse: 0.0062 - val_loss: 6.8347 - val_mae: 0.0390 - val_mse: 0.0020 - lr: 0.0214
Epoch 2/20
61/81 [=====================>........] - ETA: 0s - loss: 6.0232 - mae: 0.0382 - mse: 0.0020
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.010675729252398014.
81/81 [==============================] - 0s 3ms/step - loss: 5.7831 - mae: 0.0387 - mse: 0.0020 - val_loss: 4.8212 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0214
Epoch 3/20
70/81 [========================>.....] - ETA: 0s - loss: 4.4456 - mae: 0.0385 - mse: 0.0020
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.005337864626199007.
81/81 [==============================] - 0s 2ms/step - loss: 4.3950 - mae: 0.0387 - mse: 0.0020 - val_loss: 4.0175 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0107
Epoch 4/20
73/81 [==========================>...] - ETA: 0s - loss: 3.8513 - mae: 0.0387 - mse: 0.0020
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0026689323130995035.
81/81 [==============================] - 0s 2ms/step - loss: 3.8352 - mae: 0.0387 - mse: 0.0020 - val_loss: 3.6684 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0053
Epoch 5/20
70/81 [========================>.....] - ETA: 0s - loss: 3.5945 - mae: 0.0386 - mse: 0.0020
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0013344661565497518.
81/81 [==============================] - 0s 2ms/step - loss: 3.5840 - mae: 0.0387 - mse: 0.0020 - val_loss: 3.5056 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0027
Epoch 6/20
75/81 [==========================>...] - ETA: 0s - loss: 3.4678 - mae: 0.0387 - mse: 0.0020
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0006672330782748759.
81/81 [==============================] - 0s 2ms/step - loss: 3.4650 - mae: 0.0387 - mse: 0.0020 - val_loss: 3.4270 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0013
Epoch 7/20
75/81 [==========================>...] - ETA: 0s - loss: 3.4085 - mae: 0.0386 - mse: 0.0020
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00033361653913743794.
81/81 [==============================] - 0s 2ms/step - loss: 3.4071 - mae: 0.0387 - mse: 0.0020 - val_loss: 3.3884 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 6.6723e-04
Epoch 8/20
73/81 [==========================>...] - ETA: 0s - loss: 3.3794 - mae: 0.0387 - mse: 0.0020
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00016680826956871897.
81/81 [==============================] - 0s 2ms/step - loss: 3.3786 - mae: 0.0387 - mse: 0.0020 - val_loss: 3.3693 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 3.3362e-04
Epoch 9/20
75/81 [==========================>...] - ETA: 0s - loss: 3.3647 - mae: 0.0388 - mse: 0.0020
Epoch 9: ReduceLROnPlateau reducing learning rate to 8.340413478435948e-05.
81/81 [==============================] - 0s 2ms/step - loss: 3.3644 - mae: 0.0387 - mse: 0.0020 - val_loss: 3.3598 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 1.6681e-04
Epoch 10/20
70/81 [========================>.....] - ETA: 0s - loss: 3.3576 - mae: 0.0388 - mse: 0.0021
Epoch 10: ReduceLROnPlateau reducing learning rate to 4.170206739217974e-05.
81/81 [==============================] - 0s 2ms/step - loss: 3.3573 - mae: 0.0387 - mse: 0.0020 - val_loss: 3.3550 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 8.3404e-05
Epoch 11/20
80/81 [============================>.] - ETA: 0s - loss: 3.3538 - mae: 0.0387 - mse: 0.0020
Epoch 11: ReduceLROnPlateau reducing learning rate to 2.085103369608987e-05.
81/81 [==============================] - 0s 2ms/step - loss: 3.3538 - mae: 0.0387 - mse: 0.0020 - val_loss: 3.3526 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 4.1702e-05
Epoch 12/20
81/81 [==============================] - ETA: 0s - loss: 3.3520 - mae: 0.0387 - mse: 0.0020
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.0425516848044936e-05.
81/81 [==============================] - 0s 2ms/step - loss: 3.3520 - mae: 0.0387 - mse: 0.0020 - val_loss: 3.3514 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 2.0851e-05
Epoch 13/20
78/81 [===========================>..] - ETA: 0s - loss: 3.3511 - mae: 0.0387 - mse: 0.0020
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
81/81 [==============================] - 0s 2ms/step - loss: 3.3511 - mae: 0.0387 - mse: 0.0020 - val_loss: 3.3508 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 1.0426e-05
Epoch 14/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3506 - mae: 0.0387 - mse: 0.0020 - val_loss: 3.3503 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 1.0000e-05
Epoch 15/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3500 - mae: 0.0387 - mse: 0.0020 - val_loss: 3.3498 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 1.0000e-05
Epoch 16/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3495 - mae: 0.0387 - mse: 0.0020 - val_loss: 3.3492 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 1.0000e-05
Epoch 17/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3489 - mae: 0.0387 - mse: 0.0020 - val_loss: 3.3487 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 1.0000e-05
Epoch 18/20
81/81 [==============================] - 0s 3ms/step - loss: 3.3484 - mae: 0.0387 - mse: 0.0020 - val_loss: 3.3481 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 1.0000e-05
Epoch 19/20
81/81 [==============================] - 0s 3ms/step - loss: 3.3478 - mae: 0.0387 - mse: 0.0020 - val_loss: 3.3476 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 1.0000e-05
Epoch 20/20
81/81 [==============================] - 0s 3ms/step - loss: 3.3473 - mae: 0.0387 - mse: 0.0020 - val_loss: 3.3470 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_sgd_0.021351458030224757LR_[32, 64, 128, 256]HN_48BS_1P_val_mseM_20epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
81/81 [==============================] - 1s 3ms/step - loss: 8.2310 - mae: 0.0448 - mse: 0.0029 - val_loss: 6.8692 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0214
Epoch 2/20
50/81 [=================>............] - ETA: 0s - loss: 6.1927 - mae: 0.0382 - mse: 0.0019
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.010675729252398014.
81/81 [==============================] - 0s 2ms/step - loss: 5.8119 - mae: 0.0379 - mse: 0.0019 - val_loss: 4.8448 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0214
Epoch 3/20
49/81 [=================>............] - ETA: 0s - loss: 4.5679 - mae: 0.0374 - mse: 0.0019
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.005337864626199007.
81/81 [==============================] - 0s 2ms/step - loss: 4.4163 - mae: 0.0378 - mse: 0.0019 - val_loss: 4.0368 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0107
Epoch 4/20
47/81 [================>.............] - ETA: 0s - loss: 3.9239 - mae: 0.0375 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0026689323130995035.
81/81 [==============================] - 0s 2ms/step - loss: 3.8535 - mae: 0.0378 - mse: 0.0019 - val_loss: 3.6858 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0053
Epoch 5/20
46/81 [================>.............] - ETA: 0s - loss: 3.6349 - mae: 0.0385 - mse: 0.0020
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0013344661565497518.
81/81 [==============================] - 0s 2ms/step - loss: 3.6010 - mae: 0.0379 - mse: 0.0019 - val_loss: 3.5222 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0027
Epoch 6/20
47/81 [================>.............] - ETA: 0s - loss: 3.4973 - mae: 0.0378 - mse: 0.0019
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0006672330782748759.
81/81 [==============================] - 0s 2ms/step - loss: 3.4814 - mae: 0.0379 - mse: 0.0019 - val_loss: 3.4432 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 7/20
49/81 [=================>............] - ETA: 0s - loss: 3.4305 - mae: 0.0378 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00033361653913743794.
81/81 [==============================] - 0s 2ms/step - loss: 3.4231 - mae: 0.0379 - mse: 0.0019 - val_loss: 3.4043 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.6723e-04
Epoch 8/20
49/81 [=================>............] - ETA: 0s - loss: 3.3980 - mae: 0.0377 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00016680826956871897.
81/81 [==============================] - 0s 2ms/step - loss: 3.3944 - mae: 0.0379 - mse: 0.0019 - val_loss: 3.3851 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.3362e-04
Epoch 9/20
46/81 [================>.............] - ETA: 0s - loss: 3.3822 - mae: 0.0382 - mse: 0.0019
Epoch 9: ReduceLROnPlateau reducing learning rate to 8.340413478435948e-05.
81/81 [==============================] - 0s 2ms/step - loss: 3.3801 - mae: 0.0379 - mse: 0.0019 - val_loss: 3.3755 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.6681e-04
Epoch 10/20
59/81 [====================>.........] - ETA: 0s - loss: 3.3736 - mae: 0.0376 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 4.170206739217974e-05.
81/81 [==============================] - 0s 1ms/step - loss: 3.3730 - mae: 0.0379 - mse: 0.0019 - val_loss: 3.3707 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 8.3404e-05
Epoch 11/20
60/81 [=====================>........] - ETA: 0s - loss: 3.3698 - mae: 0.0379 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 2.085103369608987e-05.
81/81 [==============================] - 0s 1ms/step - loss: 3.3695 - mae: 0.0379 - mse: 0.0019 - val_loss: 3.3684 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.1702e-05
Epoch 12/20
58/81 [====================>.........] - ETA: 0s - loss: 3.3679 - mae: 0.0377 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.0425516848044936e-05.
81/81 [==============================] - 0s 1ms/step - loss: 3.3677 - mae: 0.0379 - mse: 0.0019 - val_loss: 3.3672 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.0851e-05
Epoch 13/20
58/81 [====================>.........] - ETA: 0s - loss: 3.3669 - mae: 0.0380 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
81/81 [==============================] - 0s 1ms/step - loss: 3.3668 - mae: 0.0379 - mse: 0.0019 - val_loss: 3.3666 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0426e-05
Epoch 14/20
81/81 [==============================] - 0s 1ms/step - loss: 3.3663 - mae: 0.0379 - mse: 0.0019 - val_loss: 3.3660 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 15/20
81/81 [==============================] - 0s 1ms/step - loss: 3.3657 - mae: 0.0379 - mse: 0.0019 - val_loss: 3.3655 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 16/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3652 - mae: 0.0379 - mse: 0.0019 - val_loss: 3.3649 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 17/20
81/81 [==============================] - 0s 1ms/step - loss: 3.3646 - mae: 0.0379 - mse: 0.0019 - val_loss: 3.3644 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 18/20
81/81 [==============================] - 0s 1ms/step - loss: 3.3641 - mae: 0.0379 - mse: 0.0019 - val_loss: 3.3638 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 19/20
81/81 [==============================] - 0s 1ms/step - loss: 3.3635 - mae: 0.0379 - mse: 0.0019 - val_loss: 3.3633 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 20/20
81/81 [==============================] - 0s 1ms/step - loss: 3.3630 - mae: 0.0379 - mse: 0.0019 - val_loss: 3.3627 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_sgd_0.021351458030224757LR_[32, 64, 128, 256]HN_48BS_1P_val_mseM_20epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
81/81 [==============================] - 1s 3ms/step - loss: 8.3289 - mae: 0.0379 - mse: 0.0019 - val_loss: 6.9516 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 0.0214
Epoch 2/20
56/81 [===================>..........] - ETA: 0s - loss: 6.1894 - mae: 0.0372 - mse: 0.0019
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.010675729252398014.
81/81 [==============================] - 0s 1ms/step - loss: 5.8815 - mae: 0.0371 - mse: 0.0018 - val_loss: 4.9028 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0214
Epoch 3/20
59/81 [====================>.........] - ETA: 0s - loss: 4.5736 - mae: 0.0372 - mse: 0.0019
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.005337864626199007.
81/81 [==============================] - 0s 1ms/step - loss: 4.4692 - mae: 0.0373 - mse: 0.0019 - val_loss: 4.0850 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 0.0107
Epoch 4/20
57/81 [====================>.........] - ETA: 0s - loss: 3.9495 - mae: 0.0371 - mse: 0.0018
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0026689323130995035.
81/81 [==============================] - 0s 1ms/step - loss: 3.8995 - mae: 0.0374 - mse: 0.0019 - val_loss: 3.7298 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 0.0053
Epoch 5/20
59/81 [====================>.........] - ETA: 0s - loss: 3.6654 - mae: 0.0375 - mse: 0.0019
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0013344661565497518.
81/81 [==============================] - 0s 1ms/step - loss: 3.6440 - mae: 0.0374 - mse: 0.0019 - val_loss: 3.5643 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 0.0027
Epoch 6/20
56/81 [===================>..........] - ETA: 0s - loss: 3.5347 - mae: 0.0372 - mse: 0.0019
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0006672330782748759.
81/81 [==============================] - 0s 1ms/step - loss: 3.5229 - mae: 0.0375 - mse: 0.0019 - val_loss: 3.4843 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 0.0013
Epoch 7/20
57/81 [====================>.........] - ETA: 0s - loss: 3.4696 - mae: 0.0374 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00033361653913743794.
81/81 [==============================] - 0s 1ms/step - loss: 3.4640 - mae: 0.0375 - mse: 0.0019 - val_loss: 3.4450 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 6.6723e-04
Epoch 8/20
58/81 [====================>.........] - ETA: 0s - loss: 3.4376 - mae: 0.0373 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00016680826956871897.
81/81 [==============================] - 0s 1ms/step - loss: 3.4349 - mae: 0.0375 - mse: 0.0019 - val_loss: 3.4255 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 3.3362e-04
Epoch 9/20
56/81 [===================>..........] - ETA: 0s - loss: 3.4219 - mae: 0.0377 - mse: 0.0019
Epoch 9: ReduceLROnPlateau reducing learning rate to 8.340413478435948e-05.
81/81 [==============================] - 0s 1ms/step - loss: 3.4205 - mae: 0.0375 - mse: 0.0019 - val_loss: 3.4158 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 1.6681e-04
Epoch 10/20
58/81 [====================>.........] - ETA: 0s - loss: 3.4140 - mae: 0.0374 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 4.170206739217974e-05.
81/81 [==============================] - 0s 1ms/step - loss: 3.4133 - mae: 0.0375 - mse: 0.0019 - val_loss: 3.4110 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 8.3404e-05
Epoch 11/20
56/81 [===================>..........] - ETA: 0s - loss: 3.4101 - mae: 0.0374 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 2.085103369608987e-05.
81/81 [==============================] - 0s 1ms/step - loss: 3.4097 - mae: 0.0375 - mse: 0.0019 - val_loss: 3.4086 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 4.1702e-05
Epoch 12/20
60/81 [=====================>........] - ETA: 0s - loss: 3.4081 - mae: 0.0373 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.0425516848044936e-05.
81/81 [==============================] - 0s 1ms/step - loss: 3.4079 - mae: 0.0375 - mse: 0.0019 - val_loss: 3.4074 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 2.0851e-05
Epoch 13/20
57/81 [====================>.........] - ETA: 0s - loss: 3.4071 - mae: 0.0373 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
81/81 [==============================] - 0s 1ms/step - loss: 3.4070 - mae: 0.0375 - mse: 0.0019 - val_loss: 3.4068 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 1.0426e-05
Epoch 14/20
81/81 [==============================] - 0s 1ms/step - loss: 3.4065 - mae: 0.0375 - mse: 0.0019 - val_loss: 3.4062 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 15/20
81/81 [==============================] - 0s 1ms/step - loss: 3.4059 - mae: 0.0375 - mse: 0.0019 - val_loss: 3.4057 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 16/20
81/81 [==============================] - 0s 1ms/step - loss: 3.4054 - mae: 0.0375 - mse: 0.0019 - val_loss: 3.4051 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 17/20
81/81 [==============================] - 0s 1ms/step - loss: 3.4048 - mae: 0.0375 - mse: 0.0019 - val_loss: 3.4046 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 18/20
81/81 [==============================] - 0s 2ms/step - loss: 3.4042 - mae: 0.0375 - mse: 0.0019 - val_loss: 3.4040 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 19/20
81/81 [==============================] - 0s 4ms/step - loss: 3.4037 - mae: 0.0375 - mse: 0.0019 - val_loss: 3.4035 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 20/20
81/81 [==============================] - 0s 2ms/step - loss: 3.4031 - mae: 0.0375 - mse: 0.0019 - val_loss: 3.4029 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_sgd_0.021351458030224757LR_[32, 64, 128, 256]HN_48BS_1P_val_mseM_20epochs/model_5.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
81/81 [==============================] - 1s 3ms/step - loss: 8.2972 - mae: 0.0542 - mse: 0.0046 - val_loss: 6.9234 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0214
Epoch 2/20
47/81 [================>.............] - ETA: 0s - loss: 6.2807 - mae: 0.0384 - mse: 0.0020
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.010675729252398014.
81/81 [==============================] - 0s 2ms/step - loss: 5.8579 - mae: 0.0383 - mse: 0.0020 - val_loss: 4.8834 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0214
Epoch 3/20
50/81 [=================>............] - ETA: 0s - loss: 4.5994 - mae: 0.0381 - mse: 0.0020
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.005337864626199007.
81/81 [==============================] - 0s 2ms/step - loss: 4.4515 - mae: 0.0383 - mse: 0.0020 - val_loss: 4.0690 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0107
Epoch 4/20
52/81 [==================>...........] - ETA: 0s - loss: 3.9446 - mae: 0.0385 - mse: 0.0020
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0026689323130995035.
81/81 [==============================] - 0s 1ms/step - loss: 3.8843 - mae: 0.0383 - mse: 0.0020 - val_loss: 3.7153 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0053
Epoch 5/20
54/81 [===================>..........] - ETA: 0s - loss: 3.6561 - mae: 0.0383 - mse: 0.0020
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0013344661565497518.
81/81 [==============================] - 0s 2ms/step - loss: 3.6298 - mae: 0.0383 - mse: 0.0020 - val_loss: 3.5504 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0027
Epoch 6/20
42/81 [==============>...............] - ETA: 0s - loss: 3.5277 - mae: 0.0378 - mse: 0.0019
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0006672330782748759.
81/81 [==============================] - 0s 2ms/step - loss: 3.5093 - mae: 0.0383 - mse: 0.0020 - val_loss: 3.4708 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0013
Epoch 7/20
80/81 [============================>.] - ETA: 0s - loss: 3.4508 - mae: 0.0384 - mse: 0.0020
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00033361653913743794.
81/81 [==============================] - 0s 2ms/step - loss: 3.4506 - mae: 0.0383 - mse: 0.0020 - val_loss: 3.4317 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 6.6723e-04
Epoch 8/20
64/81 [======================>.......] - ETA: 0s - loss: 3.4236 - mae: 0.0384 - mse: 0.0020
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00016680826956871897.
81/81 [==============================] - 0s 2ms/step - loss: 3.4216 - mae: 0.0383 - mse: 0.0020 - val_loss: 3.4123 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 3.3362e-04
Epoch 9/20
71/81 [=========================>....] - ETA: 0s - loss: 3.4078 - mae: 0.0382 - mse: 0.0020
Epoch 9: ReduceLROnPlateau reducing learning rate to 8.340413478435948e-05.
81/81 [==============================] - 0s 2ms/step - loss: 3.4073 - mae: 0.0383 - mse: 0.0020 - val_loss: 3.4026 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 1.6681e-04
Epoch 10/20
75/81 [==========================>...] - ETA: 0s - loss: 3.4003 - mae: 0.0384 - mse: 0.0020
Epoch 10: ReduceLROnPlateau reducing learning rate to 4.170206739217974e-05.
81/81 [==============================] - 0s 2ms/step - loss: 3.4001 - mae: 0.0383 - mse: 0.0020 - val_loss: 3.3978 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 8.3404e-05
Epoch 11/20
73/81 [==========================>...] - ETA: 0s - loss: 3.3966 - mae: 0.0382 - mse: 0.0020
Epoch 11: ReduceLROnPlateau reducing learning rate to 2.085103369608987e-05.
81/81 [==============================] - 0s 2ms/step - loss: 3.3965 - mae: 0.0383 - mse: 0.0020 - val_loss: 3.3954 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 4.1702e-05
Epoch 12/20
76/81 [===========================>..] - ETA: 0s - loss: 3.3947 - mae: 0.0381 - mse: 0.0020
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.0425516848044936e-05.
81/81 [==============================] - 0s 2ms/step - loss: 3.3947 - mae: 0.0383 - mse: 0.0020 - val_loss: 3.3942 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 2.0851e-05
Epoch 13/20
78/81 [===========================>..] - ETA: 0s - loss: 3.3938 - mae: 0.0384 - mse: 0.0020
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
81/81 [==============================] - 0s 2ms/step - loss: 3.3938 - mae: 0.0383 - mse: 0.0020 - val_loss: 3.3936 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 1.0426e-05
Epoch 14/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3933 - mae: 0.0383 - mse: 0.0020 - val_loss: 3.3930 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 15/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3927 - mae: 0.0383 - mse: 0.0020 - val_loss: 3.3925 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 16/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3922 - mae: 0.0383 - mse: 0.0020 - val_loss: 3.3919 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 17/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3916 - mae: 0.0383 - mse: 0.0020 - val_loss: 3.3914 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 18/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3911 - mae: 0.0383 - mse: 0.0020 - val_loss: 3.3908 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 19/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3905 - mae: 0.0383 - mse: 0.0020 - val_loss: 3.3903 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 20/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3900 - mae: 0.0383 - mse: 0.0020 - val_loss: 3.3897 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_sgd_0.021351458030224757LR_[32, 64, 128, 256]HN_48BS_1P_val_mseM_20epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
81/81 [==============================] - 1s 3ms/step - loss: 8.3138 - mae: 0.0718 - mse: 0.0094 - val_loss: 6.9341 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0214
Epoch 2/20
53/81 [==================>...........] - ETA: 0s - loss: 6.2129 - mae: 0.0388 - mse: 0.0021
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.010675729252398014.
81/81 [==============================] - 0s 2ms/step - loss: 5.8675 - mae: 0.0389 - mse: 0.0021 - val_loss: 4.8919 - val_mae: 0.0394 - val_mse: 0.0022 - lr: 0.0214
Epoch 3/20
49/81 [=================>............] - ETA: 0s - loss: 4.6126 - mae: 0.0391 - mse: 0.0021
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.005337864626199007.
81/81 [==============================] - 0s 2ms/step - loss: 4.4597 - mae: 0.0392 - mse: 0.0021 - val_loss: 4.0768 - val_mae: 0.0397 - val_mse: 0.0022 - lr: 0.0107
Epoch 4/20
49/81 [=================>............] - ETA: 0s - loss: 3.9587 - mae: 0.0397 - mse: 0.0022
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0026689323130995035.
81/81 [==============================] - 0s 2ms/step - loss: 3.8919 - mae: 0.0393 - mse: 0.0021 - val_loss: 3.7227 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 0.0053
Epoch 5/20
81/81 [==============================] - ETA: 0s - loss: 3.6371 - mae: 0.0395 - mse: 0.0022
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0013344661565497518.
81/81 [==============================] - 0s 4ms/step - loss: 3.6371 - mae: 0.0395 - mse: 0.0022 - val_loss: 3.5577 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 0.0027
Epoch 6/20
53/81 [==================>...........] - ETA: 0s - loss: 3.5296 - mae: 0.0393 - mse: 0.0021
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0006672330782748759.
81/81 [==============================] - 0s 3ms/step - loss: 3.5165 - mae: 0.0395 - mse: 0.0022 - val_loss: 3.4779 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 0.0013
Epoch 7/20
81/81 [==============================] - ETA: 0s - loss: 3.4577 - mae: 0.0395 - mse: 0.0022
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00033361653913743794.
81/81 [==============================] - 0s 2ms/step - loss: 3.4577 - mae: 0.0395 - mse: 0.0022 - val_loss: 3.4388 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 6.6723e-04
Epoch 8/20
59/81 [====================>.........] - ETA: 0s - loss: 3.4313 - mae: 0.0395 - mse: 0.0022
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00016680826956871897.
81/81 [==============================] - 0s 3ms/step - loss: 3.4287 - mae: 0.0395 - mse: 0.0022 - val_loss: 3.4194 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 3.3362e-04
Epoch 9/20
70/81 [========================>.....] - ETA: 0s - loss: 3.4149 - mae: 0.0393 - mse: 0.0021
Epoch 9: ReduceLROnPlateau reducing learning rate to 8.340413478435948e-05.
81/81 [==============================] - 0s 2ms/step - loss: 3.4143 - mae: 0.0395 - mse: 0.0022 - val_loss: 3.4097 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 1.6681e-04
Epoch 10/20
63/81 [======================>.......] - ETA: 0s - loss: 3.4077 - mae: 0.0396 - mse: 0.0022
Epoch 10: ReduceLROnPlateau reducing learning rate to 4.170206739217974e-05.
81/81 [==============================] - 0s 2ms/step - loss: 3.4072 - mae: 0.0395 - mse: 0.0022 - val_loss: 3.4049 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 8.3404e-05
Epoch 11/20
74/81 [==========================>...] - ETA: 0s - loss: 3.4037 - mae: 0.0394 - mse: 0.0021
Epoch 11: ReduceLROnPlateau reducing learning rate to 2.085103369608987e-05.
81/81 [==============================] - 0s 2ms/step - loss: 3.4036 - mae: 0.0395 - mse: 0.0022 - val_loss: 3.4025 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 4.1702e-05
Epoch 12/20
68/81 [========================>.....] - ETA: 0s - loss: 3.4019 - mae: 0.0396 - mse: 0.0022
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.0425516848044936e-05.
81/81 [==============================] - 0s 2ms/step - loss: 3.4018 - mae: 0.0395 - mse: 0.0022 - val_loss: 3.4013 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 2.0851e-05
Epoch 13/20
62/81 [=====================>........] - ETA: 0s - loss: 3.4010 - mae: 0.0395 - mse: 0.0022
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
81/81 [==============================] - 0s 3ms/step - loss: 3.4009 - mae: 0.0395 - mse: 0.0022 - val_loss: 3.4007 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 1.0426e-05
Epoch 14/20
81/81 [==============================] - 0s 3ms/step - loss: 3.4003 - mae: 0.0395 - mse: 0.0022 - val_loss: 3.4001 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 1.0000e-05
Epoch 15/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3998 - mae: 0.0395 - mse: 0.0022 - val_loss: 3.3996 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 1.0000e-05
Epoch 16/20
81/81 [==============================] - 0s 3ms/step - loss: 3.3992 - mae: 0.0395 - mse: 0.0022 - val_loss: 3.3990 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 1.0000e-05
Epoch 17/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3987 - mae: 0.0395 - mse: 0.0022 - val_loss: 3.3985 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 1.0000e-05
Epoch 18/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3981 - mae: 0.0395 - mse: 0.0022 - val_loss: 3.3979 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 1.0000e-05
Epoch 19/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3976 - mae: 0.0395 - mse: 0.0022 - val_loss: 3.3974 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 1.0000e-05
Epoch 20/20
81/81 [==============================] - 0s 3ms/step - loss: 3.3970 - mae: 0.0395 - mse: 0.0022 - val_loss: 3.3968 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_sgd_0.021351458030224757LR_[32, 64, 128, 256]HN_48BS_1P_val_mseM_20epochs/model_7.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
81/81 [==============================] - 1s 4ms/step - loss: 8.2735 - mae: 0.1014 - mse: 0.0198 - val_loss: 6.8931 - val_mae: 0.0399 - val_mse: 0.0023 - lr: 0.0214
Epoch 2/20
57/81 [====================>.........] - ETA: 0s - loss: 6.1256 - mae: 0.0396 - mse: 0.0022
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.010675729252398014.
81/81 [==============================] - 0s 2ms/step - loss: 5.8333 - mae: 0.0397 - mse: 0.0022 - val_loss: 4.8640 - val_mae: 0.0403 - val_mse: 0.0023 - lr: 0.0214
Epoch 3/20
78/81 [===========================>..] - ETA: 0s - loss: 4.4480 - mae: 0.0402 - mse: 0.0023
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.005337864626199007.
81/81 [==============================] - 0s 2ms/step - loss: 4.4345 - mae: 0.0402 - mse: 0.0023 - val_loss: 4.0541 - val_mae: 0.0408 - val_mse: 0.0024 - lr: 0.0107
Epoch 4/20
42/81 [==============>...............] - ETA: 0s - loss: 3.9517 - mae: 0.0405 - mse: 0.0023
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0026689323130995035.
81/81 [==============================] - 0s 2ms/step - loss: 3.8704 - mae: 0.0404 - mse: 0.0023 - val_loss: 3.7024 - val_mae: 0.0410 - val_mse: 0.0024 - lr: 0.0053
Epoch 5/20
46/81 [================>.............] - ETA: 0s - loss: 3.6513 - mae: 0.0409 - mse: 0.0024
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0013344661565497518.
81/81 [==============================] - 0s 2ms/step - loss: 3.6173 - mae: 0.0406 - mse: 0.0023 - val_loss: 3.5384 - val_mae: 0.0410 - val_mse: 0.0024 - lr: 0.0027
Epoch 6/20
49/81 [=================>............] - ETA: 0s - loss: 3.5124 - mae: 0.0405 - mse: 0.0023
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0006672330782748759.
81/81 [==============================] - 0s 2ms/step - loss: 3.4974 - mae: 0.0406 - mse: 0.0023 - val_loss: 3.4592 - val_mae: 0.0411 - val_mse: 0.0024 - lr: 0.0013
Epoch 7/20
49/81 [=================>............] - ETA: 0s - loss: 3.4464 - mae: 0.0404 - mse: 0.0023
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00033361653913743794.
81/81 [==============================] - 0s 2ms/step - loss: 3.4391 - mae: 0.0406 - mse: 0.0023 - val_loss: 3.4203 - val_mae: 0.0411 - val_mse: 0.0024 - lr: 6.6723e-04
Epoch 8/20
49/81 [=================>............] - ETA: 0s - loss: 3.4139 - mae: 0.0404 - mse: 0.0023
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00016680826956871897.
81/81 [==============================] - 0s 2ms/step - loss: 3.4103 - mae: 0.0407 - mse: 0.0024 - val_loss: 3.4010 - val_mae: 0.0411 - val_mse: 0.0024 - lr: 3.3362e-04
Epoch 9/20
49/81 [=================>............] - ETA: 0s - loss: 3.3978 - mae: 0.0406 - mse: 0.0024
Epoch 9: ReduceLROnPlateau reducing learning rate to 8.340413478435948e-05.
81/81 [==============================] - 0s 2ms/step - loss: 3.3960 - mae: 0.0407 - mse: 0.0024 - val_loss: 3.3914 - val_mae: 0.0411 - val_mse: 0.0024 - lr: 1.6681e-04
Epoch 10/20
47/81 [================>.............] - ETA: 0s - loss: 3.3898 - mae: 0.0408 - mse: 0.0024
Epoch 10: ReduceLROnPlateau reducing learning rate to 4.170206739217974e-05.
81/81 [==============================] - 0s 2ms/step - loss: 3.3889 - mae: 0.0407 - mse: 0.0024 - val_loss: 3.3866 - val_mae: 0.0411 - val_mse: 0.0024 - lr: 8.3404e-05
Epoch 11/20
73/81 [==========================>...] - ETA: 0s - loss: 3.3854 - mae: 0.0406 - mse: 0.0023
Epoch 11: ReduceLROnPlateau reducing learning rate to 2.085103369608987e-05.
81/81 [==============================] - 0s 2ms/step - loss: 3.3853 - mae: 0.0407 - mse: 0.0024 - val_loss: 3.3842 - val_mae: 0.0411 - val_mse: 0.0024 - lr: 4.1702e-05
Epoch 12/20
59/81 [====================>.........] - ETA: 0s - loss: 3.3837 - mae: 0.0405 - mse: 0.0023
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.0425516848044936e-05.
81/81 [==============================] - 0s 3ms/step - loss: 3.3835 - mae: 0.0407 - mse: 0.0024 - val_loss: 3.3830 - val_mae: 0.0411 - val_mse: 0.0024 - lr: 2.0851e-05
Epoch 13/20
46/81 [================>.............] - ETA: 0s - loss: 3.3827 - mae: 0.0406 - mse: 0.0023
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
81/81 [==============================] - 0s 4ms/step - loss: 3.3826 - mae: 0.0407 - mse: 0.0024 - val_loss: 3.3824 - val_mae: 0.0411 - val_mse: 0.0024 - lr: 1.0426e-05
Epoch 14/20
81/81 [==============================] - 0s 3ms/step - loss: 3.3821 - mae: 0.0407 - mse: 0.0024 - val_loss: 3.3819 - val_mae: 0.0411 - val_mse: 0.0024 - lr: 1.0000e-05
Epoch 15/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3815 - mae: 0.0407 - mse: 0.0024 - val_loss: 3.3813 - val_mae: 0.0411 - val_mse: 0.0024 - lr: 1.0000e-05
Epoch 16/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3810 - mae: 0.0407 - mse: 0.0024 - val_loss: 3.3808 - val_mae: 0.0411 - val_mse: 0.0024 - lr: 1.0000e-05
Epoch 17/20
81/81 [==============================] - 0s 3ms/step - loss: 3.3804 - mae: 0.0407 - mse: 0.0024 - val_loss: 3.3802 - val_mae: 0.0411 - val_mse: 0.0024 - lr: 1.0000e-05
Epoch 18/20
81/81 [==============================] - 0s 3ms/step - loss: 3.3799 - mae: 0.0407 - mse: 0.0024 - val_loss: 3.3797 - val_mae: 0.0411 - val_mse: 0.0024 - lr: 1.0000e-05
Epoch 19/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3793 - mae: 0.0407 - mse: 0.0024 - val_loss: 3.3791 - val_mae: 0.0411 - val_mse: 0.0024 - lr: 1.0000e-05
Epoch 20/20
81/81 [==============================] - 0s 3ms/step - loss: 3.3788 - mae: 0.0407 - mse: 0.0024 - val_loss: 3.3786 - val_mae: 0.0411 - val_mse: 0.0024 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_sgd_0.021351458030224757LR_[32, 64, 128, 256]HN_48BS_1P_val_mseM_20epochs/model_8.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
81/81 [==============================] - 1s 4ms/step - loss: 8.3042 - mae: 0.1059 - mse: 0.0259 - val_loss: 6.9150 - val_mae: 0.0427 - val_mse: 0.0026 - lr: 0.0214
Epoch 2/20
65/81 [=======================>......] - ETA: 0s - loss: 6.0455 - mae: 0.0427 - mse: 0.0027
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.010675729252398014.
81/81 [==============================] - 0s 2ms/step - loss: 5.8529 - mae: 0.0431 - mse: 0.0027 - val_loss: 4.8817 - val_mae: 0.0444 - val_mse: 0.0029 - lr: 0.0214
Epoch 3/20
68/81 [========================>.....] - ETA: 0s - loss: 4.5119 - mae: 0.0440 - mse: 0.0028
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.005337864626199007.
81/81 [==============================] - 0s 2ms/step - loss: 4.4513 - mae: 0.0443 - mse: 0.0029 - val_loss: 4.0703 - val_mae: 0.0451 - val_mse: 0.0030 - lr: 0.0107
Epoch 4/20
62/81 [=====================>........] - ETA: 0s - loss: 3.9253 - mae: 0.0447 - mse: 0.0029
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0026689323130995035.
81/81 [==============================] - 0s 3ms/step - loss: 3.8862 - mae: 0.0446 - mse: 0.0029 - val_loss: 3.7179 - val_mae: 0.0454 - val_mse: 0.0031 - lr: 0.0053
Epoch 5/20
67/81 [=======================>......] - ETA: 0s - loss: 3.6461 - mae: 0.0451 - mse: 0.0030
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0013344661565497518.
81/81 [==============================] - 0s 4ms/step - loss: 3.6327 - mae: 0.0450 - mse: 0.0030 - val_loss: 3.5536 - val_mae: 0.0456 - val_mse: 0.0031 - lr: 0.0027
Epoch 6/20
73/81 [==========================>...] - ETA: 0s - loss: 3.5163 - mae: 0.0449 - mse: 0.0030
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0006672330782748759.
81/81 [==============================] - 0s 3ms/step - loss: 3.5126 - mae: 0.0451 - mse: 0.0030 - val_loss: 3.4743 - val_mae: 0.0457 - val_mse: 0.0031 - lr: 0.0013
Epoch 7/20
65/81 [=======================>......] - ETA: 0s - loss: 3.4578 - mae: 0.0453 - mse: 0.0030
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00033361653913743794.
81/81 [==============================] - 0s 3ms/step - loss: 3.4541 - mae: 0.0452 - mse: 0.0030 - val_loss: 3.4353 - val_mae: 0.0458 - val_mse: 0.0031 - lr: 6.6723e-04
Epoch 8/20
62/81 [=====================>........] - ETA: 0s - loss: 3.4274 - mae: 0.0446 - mse: 0.0030
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00016680826956871897.
81/81 [==============================] - 0s 3ms/step - loss: 3.4253 - mae: 0.0452 - mse: 0.0030 - val_loss: 3.4160 - val_mae: 0.0458 - val_mse: 0.0031 - lr: 3.3362e-04
Epoch 9/20
57/81 [====================>.........] - ETA: 0s - loss: 3.4124 - mae: 0.0462 - mse: 0.0031
Epoch 9: ReduceLROnPlateau reducing learning rate to 8.340413478435948e-05.
81/81 [==============================] - 0s 3ms/step - loss: 3.4110 - mae: 0.0452 - mse: 0.0030 - val_loss: 3.4064 - val_mae: 0.0458 - val_mse: 0.0031 - lr: 1.6681e-04
Epoch 10/20
72/81 [=========================>....] - ETA: 0s - loss: 3.4041 - mae: 0.0450 - mse: 0.0030
Epoch 10: ReduceLROnPlateau reducing learning rate to 4.170206739217974e-05.
81/81 [==============================] - 0s 2ms/step - loss: 3.4038 - mae: 0.0452 - mse: 0.0030 - val_loss: 3.4016 - val_mae: 0.0458 - val_mse: 0.0031 - lr: 8.3404e-05
Epoch 11/20
73/81 [==========================>...] - ETA: 0s - loss: 3.4004 - mae: 0.0453 - mse: 0.0030
Epoch 11: ReduceLROnPlateau reducing learning rate to 2.085103369608987e-05.
81/81 [==============================] - 0s 3ms/step - loss: 3.4003 - mae: 0.0452 - mse: 0.0030 - val_loss: 3.3992 - val_mae: 0.0458 - val_mse: 0.0031 - lr: 4.1702e-05
Epoch 12/20
58/81 [====================>.........] - ETA: 0s - loss: 3.3987 - mae: 0.0452 - mse: 0.0030
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.0425516848044936e-05.
81/81 [==============================] - 0s 3ms/step - loss: 3.3985 - mae: 0.0452 - mse: 0.0030 - val_loss: 3.3980 - val_mae: 0.0458 - val_mse: 0.0031 - lr: 2.0851e-05
Epoch 13/20
59/81 [====================>.........] - ETA: 0s - loss: 3.3977 - mae: 0.0452 - mse: 0.0030
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
81/81 [==============================] - 0s 2ms/step - loss: 3.3976 - mae: 0.0452 - mse: 0.0030 - val_loss: 3.3974 - val_mae: 0.0458 - val_mse: 0.0031 - lr: 1.0426e-05
Epoch 14/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3970 - mae: 0.0452 - mse: 0.0030 - val_loss: 3.3968 - val_mae: 0.0458 - val_mse: 0.0031 - lr: 1.0000e-05
Epoch 15/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3965 - mae: 0.0452 - mse: 0.0030 - val_loss: 3.3963 - val_mae: 0.0458 - val_mse: 0.0031 - lr: 1.0000e-05
Epoch 16/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3959 - mae: 0.0452 - mse: 0.0030 - val_loss: 3.3957 - val_mae: 0.0458 - val_mse: 0.0031 - lr: 1.0000e-05
Epoch 17/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3954 - mae: 0.0452 - mse: 0.0030 - val_loss: 3.3952 - val_mae: 0.0458 - val_mse: 0.0031 - lr: 1.0000e-05
Epoch 18/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3948 - mae: 0.0452 - mse: 0.0030 - val_loss: 3.3946 - val_mae: 0.0458 - val_mse: 0.0031 - lr: 1.0000e-05
Epoch 19/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3943 - mae: 0.0452 - mse: 0.0030 - val_loss: 3.3941 - val_mae: 0.0458 - val_mse: 0.0031 - lr: 1.0000e-05
Epoch 20/20
81/81 [==============================] - 0s 2ms/step - loss: 3.3938 - mae: 0.0452 - mse: 0.0030 - val_loss: 3.3936 - val_mae: 0.0458 - val_mse: 0.0031 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_sgd_0.021351458030224757LR_[32, 64, 128, 256]HN_48BS_1P_val_mseM_20epochs/model_9.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_train_batch_end` time: 0.0014s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0021s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0014s). Check your callbacks.