Epoch 1/150
159/162 [============================>.] - ETA: 0s - loss: 0.0036 - mae: 0.0512 - mse: 0.0036 - root_mean_squared_error: 0.0597
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0065s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0065s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
162/162 [==============================] - 2s 14ms/step - loss: 0.0036 - mae: 0.0512 - mse: 0.0036 - root_mean_squared_error: 0.0597 - val_loss: 0.0035 - val_mae: 0.0510 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0590 - lr: 0.0262
Epoch 2/150
152/162 [===========================>..] - ETA: 0s - loss: 0.0035 - mae: 0.0509 - mse: 0.0035 - root_mean_squared_error: 0.0589
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
162/162 [==============================] - 2s 13ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0035 - root_mean_squared_error: 0.0588 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0262
Epoch 3/150
155/162 [===========================>..] - ETA: 0s - loss: 0.0035 - mae: 0.0508 - mse: 0.0035 - root_mean_squared_error: 0.0589
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
162/162 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0035 - root_mean_squared_error: 0.0589 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0262
Epoch 4/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0035 - root_mean_squared_error: 0.0589 - val_loss: 0.0034 - val_mae: 0.0507 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0585 - lr: 0.0262
Epoch 5/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0035 - mae: 0.0510 - mse: 0.0035 - root_mean_squared_error: 0.0591 - val_loss: 0.0039 - val_mae: 0.0527 - val_mse: 0.0039 - val_root_mean_squared_error: 0.0622 - lr: 0.0262
Epoch 6/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0035 - mae: 0.0513 - mse: 0.0035 - root_mean_squared_error: 0.0596 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0262
Epoch 7/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0035 - mae: 0.0510 - mse: 0.0035 - root_mean_squared_error: 0.0590 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0585 - lr: 0.0262
Epoch 8/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0035 - root_mean_squared_error: 0.0589 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0262
Epoch 9/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0035 - mae: 0.0510 - mse: 0.0035 - root_mean_squared_error: 0.0592 - val_loss: 0.0035 - val_mae: 0.0509 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0589 - lr: 0.0262
Epoch 10/150
156/162 [===========================>..] - ETA: 0s - loss: 0.0035 - mae: 0.0510 - mse: 0.0035 - root_mean_squared_error: 0.0592
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
162/162 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0510 - mse: 0.0035 - root_mean_squared_error: 0.0591 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0262
Epoch 11/150
161/162 [============================>.] - ETA: 0s - loss: 0.0035 - mae: 0.0512 - mse: 0.0035 - root_mean_squared_error: 0.0594
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.013119589537382126.
162/162 [==============================] - 1s 6ms/step - loss: 0.0035 - mae: 0.0512 - mse: 0.0035 - root_mean_squared_error: 0.0594 - val_loss: 0.0034 - val_mae: 0.0508 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0587 - lr: 0.0262
Epoch 12/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0035 - val_mae: 0.0509 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0589 - lr: 0.0131
Epoch 13/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0035 - root_mean_squared_error: 0.0589 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0131
Epoch 14/150

159/162 [============================>.] - ETA: 0s - loss: 0.0035 - mae: 0.0508 - mse: 0.0035 - root_mean_squared_error: 0.0587
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
162/162 [==============================] - 2s 13ms/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0035 - root_mean_squared_error: 0.0588 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0131
Epoch 15/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0035 - root_mean_squared_error: 0.0590 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0131
Epoch 16/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0035 - val_mae: 0.0511 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0592 - lr: 0.0131
Epoch 17/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0037 - val_mae: 0.0518 - val_mse: 0.0037 - val_root_mean_squared_error: 0.0606 - lr: 0.0131
Epoch 18/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0035 - root_mean_squared_error: 0.0588 - val_loss: 0.0034 - val_mae: 0.0507 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0586 - lr: 0.0131
Epoch 19/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0035 - mae: 0.0509 - mse: 0.0035 - root_mean_squared_error: 0.0589 - val_loss: 0.0036 - val_mae: 0.0515 - val_mse: 0.0036 - val_root_mean_squared_error: 0.0600 - lr: 0.0131
Epoch 20/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0035 - root_mean_squared_error: 0.0587 - val_loss: 0.0034 - val_mae: 0.0507 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0587 - lr: 0.0131
Epoch 21/150
153/162 [===========================>..] - ETA: 0s - loss: 0.0035 - mae: 0.0511 - mse: 0.0035 - root_mean_squared_error: 0.0592
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.006559794768691063.
162/162 [==============================] - 1s 6ms/step - loss: 0.0035 - mae: 0.0510 - mse: 0.0035 - root_mean_squared_error: 0.0592 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0131
Epoch 22/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0035 - val_mae: 0.0509 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0589 - lr: 0.0066
Epoch 23/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0066
Epoch 24/150
162/162 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0508 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0587 - lr: 0.0066
Epoch 25/150
162/162 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0034 - val_mae: 0.0507 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0585 - lr: 0.0066
Epoch 26/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0066
Epoch 27/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0507 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0585 - lr: 0.0066
Epoch 28/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0035 - val_mae: 0.0511 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0591 - lr: 0.0066
Epoch 29/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - root_mean_squared_error: 0.0587 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0066
Epoch 30/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0066
Epoch 31/150
159/162 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0032798973843455315.
162/162 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0066
Epoch 32/150

160/162 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
162/162 [==============================] - 2s 11ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0033
Epoch 33/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0033
Epoch 34/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0033
Epoch 35/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0033
Epoch 36/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0033
Epoch 37/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0033
Epoch 38/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0033
Epoch 39/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0035 - val_mae: 0.0509 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0589 - lr: 0.0033
Epoch 40/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0033
Epoch 41/150
157/162 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0016399486921727657.
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0033
Epoch 42/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0016
Epoch 43/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0016
Epoch 44/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0016
Epoch 45/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0016
Epoch 46/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0016
Epoch 47/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0016
Epoch 48/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0016
Epoch 49/150
162/162 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0016
Epoch 50/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0016
Epoch 51/150
 61/162 [==========>...................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.0034 - root_mean_squared_error: 0.0580
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0008199743460863829.
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0016
Epoch 52/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 8.1997e-04
Epoch 53/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 8.1997e-04
Epoch 54/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 8.1997e-04
Epoch 55/150
 91/162 [===============>..............] - ETA: 0s - loss: 0.0035 - mae: 0.0511 - mse: 0.0035 - root_mean_squared_error: 0.0590
162/162 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 8.1997e-04
Epoch 57/150
144/162 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0503 - mse: 0.0034 - root_mean_squared_error: 0.0581
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 8.1997e-04
Epoch 60/150
  1/162 [..............................] - ETA: 0s - loss: 0.0028 - mae: 0.0462 - mse: 0.0028 - root_mean_squared_error: 0.0532
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 8.1997e-04
Epoch 62/150
 26/162 [===>..........................] - ETA: 0s - loss: 0.0034 - mae: 0.0508 - mse: 0.0034 - root_mean_squared_error: 0.0586
 96/162 [================>.............] - ETA: 0s - loss: 0.0035 - mae: 0.0510 - mse: 0.0035 - root_mean_squared_error: 0.05870584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 8.1997e-04
162/162 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 4.0999e-04
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 4.0999e-04
154/162 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.05840583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 4.0999e-04
161/162 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.05830583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 4.0999e-04
 36/162 [=====>........................] - ETA: 0s - loss: 0.0033 - mae: 0.0499 - mse: 0.0033 - root_mean_squared_error: 0.05780583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.0499e-04
158/162 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.05820583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.0499e-04
158/162 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.05820583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.0499e-04
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
157/162 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.05830583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.0499e-044
157/162 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.05830583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.0499e-044
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
 25/162 [===>..........................] - ETA: 0s - loss: 0.0034 - mae: 0.0508 - mse: 0.0034 - root_mean_squared_error: 0.05870583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0250e-044
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0250e-044
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0250e-044
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0250e-044
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 5.1248e-054
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 5.1248e-054
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 5.1248e-054
162/162 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 5.1248e-054
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.5624e-054
159/162 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.05840583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.5624e-054
 13/162 [=>............................] - ETA: 0s - loss: 0.0034 - mae: 0.0500 - mse: 0.0034 - root_mean_squared_error: 0.05810583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.5624e-054
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.5624e-054
156/162 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.05820583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.5624e-054
162/162 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.2812e-054
160/162 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.05830583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.2812e-054
 38/162 [======>.......................] - ETA: 0s - loss: 0.0034 - mae: 0.0503 - mse: 0.0034 - root_mean_squared_error: 0.05830583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.2812e-054
162/162 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.2812e-054
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.2812e-054
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-054
 61/162 [==========>...................] - ETA: 0s - loss: 0.0033 - mae: 0.0495 - mse: 0.0033 - root_mean_squared_error: 0.05750583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-054
162/162 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-054
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-054
157/162 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.05830583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-054
 13/162 [=>............................] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.05800583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-054
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-054
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-054
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-054
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-054
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-054
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-054
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-054
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-054
 56/242 [=====>........................] - ETA: 0s - loss: 0.0079 - mae: 0.0762 - mse: 0.0079 - root_mean_squared_error: 0.0887r']) - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-054
242/242 [==============================] - 1s 6ms/step - loss: 0.0078 - mae: 0.0760 - mse: 0.0078 - root_mean_squared_error: 0.0882 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0262e-054
 58/242 [======>.......................] - ETA: 0s - loss: 0.0077 - mae: 0.0751 - mse: 0.0077 - root_mean_squared_error: 0.08790882 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0262e-054
242/242 [==============================] - 1s 6ms/step - loss: 0.0077 - mae: 0.0755 - mse: 0.0077 - root_mean_squared_error: 0.0877 - val_loss: 0.0079 - val_mae: 0.0769 - val_mse: 0.0079 - val_root_mean_squared_error: 0.0889 - lr: 0.0262e-054
 24/242 [=>............................] - ETA: 1s - loss: 0.0074 - mae: 0.0737 - mse: 0.0074 - root_mean_squared_error: 0.08630877 - val_loss: 0.0079 - val_mae: 0.0769 - val_mse: 0.0079 - val_root_mean_squared_error: 0.0889 - lr: 0.0262e-054
242/242 [==============================] - 1s 6ms/step - loss: 0.0078 - mae: 0.0757 - mse: 0.0078 - root_mean_squared_error: 0.0880 - val_loss: 0.0078 - val_mae: 0.0767 - val_mse: 0.0078 - val_root_mean_squared_error: 0.0884 - lr: 0.0262e-054
242/242 [==============================] - 1s 6ms/step - loss: 0.0078 - mae: 0.0757 - mse: 0.0078 - root_mean_squared_error: 0.0880 - val_loss: 0.0078 - val_mae: 0.0767 - val_mse: 0.0078 - val_root_mean_squared_error: 0.0884 - lr: 0.0262e-054
242/242 [==============================] - 1s 6ms/step - loss: 0.0078 - mae: 0.0759 - mse: 0.0078 - root_mean_squared_error: 0.0882 - val_loss: 0.0078 - val_mae: 0.0764 - val_mse: 0.0078 - val_root_mean_squared_error: 0.0881 - lr: 0.0262e-054
183/242 [=====================>........] - ETA: 0s - loss: 0.0077 - mae: 0.0756 - mse: 0.0077 - root_mean_squared_error: 0.08760882 - val_loss: 0.0078 - val_mae: 0.0764 - val_mse: 0.0078 - val_root_mean_squared_error: 0.0881 - lr: 0.0262e-054
242/242 [==============================] - 1s 5ms/step - loss: 0.0076 - mae: 0.0754 - mse: 0.0076 - root_mean_squared_error: 0.0875 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0131e-054
178/242 [=====================>........] - ETA: 0s - loss: 0.0078 - mae: 0.0763 - mse: 0.0078 - root_mean_squared_error: 0.08820875 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0131e-054
242/242 [==============================] - 1s 6ms/step - loss: 0.0077 - mae: 0.0757 - mse: 0.0077 - root_mean_squared_error: 0.0877 - val_loss: 0.0078 - val_mae: 0.0764 - val_mse: 0.0078 - val_root_mean_squared_error: 0.0882 - lr: 0.0131e-054
159/242 [==================>...........] - ETA: 0s - loss: 0.0078 - mae: 0.0761 - mse: 0.0078 - root_mean_squared_error: 0.08800877 - val_loss: 0.0078 - val_mae: 0.0764 - val_mse: 0.0078 - val_root_mean_squared_error: 0.0882 - lr: 0.0131e-054
 12/242 [>.............................] - ETA: 1s - loss: 0.0073 - mae: 0.0731 - mse: 0.0073 - root_mean_squared_error: 0.08550874 - val_loss: 0.0080 - val_mae: 0.0772 - val_mse: 0.0080 - val_root_mean_squared_error: 0.0894 - lr: 0.0131e-054
242/242 [==============================] - 1s 6ms/step - loss: 0.0077 - mae: 0.0756 - mse: 0.0077 - root_mean_squared_error: 0.0875 - val_loss: 0.0078 - val_mae: 0.0766 - val_mse: 0.0078 - val_root_mean_squared_error: 0.0884 - lr: 0.0066e-054
242/242 [==============================] - 1s 6ms/step - loss: 0.0077 - mae: 0.0756 - mse: 0.0077 - root_mean_squared_error: 0.0875 - val_loss: 0.0078 - val_mae: 0.0766 - val_mse: 0.0078 - val_root_mean_squared_error: 0.0884 - lr: 0.0066e-054
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 28/150===========================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 28/150===========================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 28/150===========================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0032798973843455315. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0032798973843455315. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0032798973843455315. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 36/150duceLROnPlateau reducing learning rate to 0.0032798973843455315. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 36/150duceLROnPlateau reducing learning rate to 0.0032798973843455315. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 39/150duceLROnPlateau reducing learning rate to 0.0032798973843455315. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 39/150duceLROnPlateau reducing learning rate to 0.0032798973843455315. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 45/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 45/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 48/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 48/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 51/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 52/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 54/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 54/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 54/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 58/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 58/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 61/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 62/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 64/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 64/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 67/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 67/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 70/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 70/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 76/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 76/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 76/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 80/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 80/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 82/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 82/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0016399486921727657. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 91: ReduceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 91: ReduceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 91: ReduceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 91: ReduceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 97/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 97/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 100/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 100/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 102/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 102/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 106/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 106/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 109/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 109/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 109/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 112/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 114/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 114/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 117/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 117/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 120/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 120/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 122/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 122/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 126/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 126/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 129/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 129/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 129/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 133/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 133/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 136/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 136/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 139/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 139/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 142/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 142/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 145/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 145/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 145/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 149/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 149/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 149/150uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_train_batch_end` time: 0.0044s). Check your callbacks.
Epoch 1/15050uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 1/15050uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 4/15050uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 4/15050uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 7/15050uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 7/15050uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 10/1500uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 10/1500uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 12/1500uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 14/1500uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 14/1500uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 17/1500uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 17/1500uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 20/1500uceLROnPlateau reducing learning rate to 5.124839663039893e-05. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.006559794768691063.. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.006559794768691063.. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 25/150duceLROnPlateau reducing learning rate to 0.006559794768691063.. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 25/150duceLROnPlateau reducing learning rate to 0.006559794768691063.. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 28/150duceLROnPlateau reducing learning rate to 0.006559794768691063.. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 28/150duceLROnPlateau reducing learning rate to 0.006559794768691063.. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 28/150duceLROnPlateau reducing learning rate to 0.006559794768691063.. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0032798973843455315. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 34/150duceLROnPlateau reducing learning rate to 0.0032798973843455315. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 34/150duceLROnPlateau reducing learning rate to 0.0032798973843455315. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 37/150duceLROnPlateau reducing learning rate to 0.0032798973843455315. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 37/150duceLROnPlateau reducing learning rate to 0.0032798973843455315. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 40/150duceLROnPlateau reducing learning rate to 0.0032798973843455315. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 40/150duceLROnPlateau reducing learning rate to 0.0032798973843455315. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 42/150duceLROnPlateau reducing learning rate to 0.0032798973843455315. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 42/150duceLROnPlateau reducing learning rate to 0.0032798973843455315. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 42/150duceLROnPlateau reducing learning rate to 0.0032798973843455315. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 47/150duceLROnPlateau reducing learning rate to 0.0032798973843455315. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 49/150duceLROnPlateau reducing learning rate to 0.0032798973843455315. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 49/150duceLROnPlateau reducing learning rate to 0.0032798973843455315. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0008199743460863829. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0008199743460863829. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 55/150duceLROnPlateau reducing learning rate to 0.0008199743460863829. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 55/150duceLROnPlateau reducing learning rate to 0.0008199743460863829. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 58/150duceLROnPlateau reducing learning rate to 0.0008199743460863829. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 58/150duceLROnPlateau reducing learning rate to 0.0008199743460863829. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 61/150duceLROnPlateau reducing learning rate to 0.0008199743460863829. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 62/150duceLROnPlateau reducing learning rate to 0.0008199743460863829. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 64/150duceLROnPlateau reducing learning rate to 0.0008199743460863829. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 64/150duceLROnPlateau reducing learning rate to 0.0008199743460863829. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 67/150duceLROnPlateau reducing learning rate to 0.0008199743460863829. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 67/150duceLROnPlateau reducing learning rate to 0.0008199743460863829. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 70/150duceLROnPlateau reducing learning rate to 0.0008199743460863829. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 70/150duceLROnPlateau reducing learning rate to 0.0008199743460863829. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0008199743460863829. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0008199743460863829. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 76/150duceLROnPlateau reducing learning rate to 0.0008199743460863829. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 76/150duceLROnPlateau reducing learning rate to 0.0008199743460863829. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 79/150duceLROnPlateau reducing learning rate to 0.0008199743460863829. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 79/150duceLROnPlateau reducing learning rate to 0.0008199743460863829. 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 81: ReduceLROnPlateau reducing learning rate to 0.00010249679326079786.0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 81: ReduceLROnPlateau reducing learning rate to 0.00010249679326079786.0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 85/150duceLROnPlateau reducing learning rate to 0.00010249679326079786.0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 85/150duceLROnPlateau reducing learning rate to 0.00010249679326079786.0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 88/150duceLROnPlateau reducing learning rate to 0.00010249679326079786.0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 88/150duceLROnPlateau reducing learning rate to 0.00010249679326079786.0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 91/150duceLROnPlateau reducing learning rate to 0.00010249679326079786.0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 92/150duceLROnPlateau reducing learning rate to 0.00010249679326079786.0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 94/150duceLROnPlateau reducing learning rate to 0.00010249679326079786.0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 94/150duceLROnPlateau reducing learning rate to 0.00010249679326079786.0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 97/150duceLROnPlateau reducing learning rate to 0.00010249679326079786.0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 97/150duceLROnPlateau reducing learning rate to 0.00010249679326079786.0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 100/150uceLROnPlateau reducing learning rate to 0.00010249679326079786.0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 100/150uceLROnPlateau reducing learning rate to 0.00010249679326079786.0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 102/150uceLROnPlateau reducing learning rate to 0.00010249679326079786.0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 102/150uceLROnPlateau reducing learning rate to 0.00010249679326079786.0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 106/150uceLROnPlateau reducing learning rate to 0.00010249679326079786.0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 106/150uceLROnPlateau reducing learning rate to 0.00010249679326079786.0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 109/150uceLROnPlateau reducing learning rate to 0.00010249679326079786.0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 109/150uceLROnPlateau reducing learning rate to 0.00010249679326079786.0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 111: ReduceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 111: ReduceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 115/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 115/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 118/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 118/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 121/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 122/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 124/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 124/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 127/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 127/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 130/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 130/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 133/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 133/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 136/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 136/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 139/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 139/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 142/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 142/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 145/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 147/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 147/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 147/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05..0753 - mse: 0.0076 - root_mean_squared_error: 0.0873 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 4/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 4/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 7/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 7/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 10/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 10/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 12/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 12/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 16/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 16/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 16/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 20/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 20/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 22/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 22/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 26/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 26/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 29/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 29/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 29/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 32/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 32/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 36/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 36/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 39/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 39/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 39/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 42/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 42/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 46/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 46/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 49/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 49/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 49/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 52/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 52/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 56/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 56/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 59/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 59/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00040998717304319143.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00040998717304319143.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 65/150duceLROnPlateau reducing learning rate to 0.00040998717304319143.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 65/150duceLROnPlateau reducing learning rate to 0.00040998717304319143.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 65/150duceLROnPlateau reducing learning rate to 0.00040998717304319143.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 69/150duceLROnPlateau reducing learning rate to 0.00040998717304319143.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 69/150duceLROnPlateau reducing learning rate to 0.00040998717304319143.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 71: ReduceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 71: ReduceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 75/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 75/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 78/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 78/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 81/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 82/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 84/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 84/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 84/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 88/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 88/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 91/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 92/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 94/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 96/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 96/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 96/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 100/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 100/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 102/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 102/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 102/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 107/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 107/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 110/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 110/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 112/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 112/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 116/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 116/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 119/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 119/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 119/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 122/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 122/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 126/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 126/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 129/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 129/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 132/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 134/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 134/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 137/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 137/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 137/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 137/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 142/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 142/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 145/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 147/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 147/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 147/150uceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_3.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 3/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 3/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 3/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 5/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 5/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 8/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 8/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 10/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 13/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 13/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 15/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 18/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 20/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 20/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 23/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 24/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 24/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 26/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 29/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 29/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 29/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 31/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 31/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 34/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 36/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 38/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 38/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 41/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 41/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 41/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0032798973843455315.7905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0032798973843455315.7905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 48/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.7905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 48/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.7905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 51/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.7905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 51/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.7905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 54/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.7905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 55/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.7905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 57/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.7905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 57/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.7905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 60/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.7905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 60/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.7905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 63/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.7905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 63/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.7905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 65/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.7905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 65/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.7905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 69/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.7905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 69/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.7905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.7905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.7905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 74: ReduceLROnPlateau reducing learning rate to 0.00040998717304319143.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 74: ReduceLROnPlateau reducing learning rate to 0.00040998717304319143.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 74: ReduceLROnPlateau reducing learning rate to 0.00040998717304319143.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 79/150duceLROnPlateau reducing learning rate to 0.00040998717304319143.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 79/150duceLROnPlateau reducing learning rate to 0.00040998717304319143.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 82/150duceLROnPlateau reducing learning rate to 0.00040998717304319143.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 82/150duceLROnPlateau reducing learning rate to 0.00040998717304319143.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 84: ReduceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 84: ReduceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 88/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 88/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 91/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 91/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 91/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 94: ReduceLROnPlateau reducing learning rate to 0.00010249679326079786.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 94: ReduceLROnPlateau reducing learning rate to 0.00010249679326079786.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 98/150duceLROnPlateau reducing learning rate to 0.00010249679326079786.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 98/150duceLROnPlateau reducing learning rate to 0.00010249679326079786.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 98/150duceLROnPlateau reducing learning rate to 0.00010249679326079786.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 102/150uceLROnPlateau reducing learning rate to 0.00010249679326079786.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 102/150uceLROnPlateau reducing learning rate to 0.00010249679326079786.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 104: ReduceLROnPlateau reducing learning rate to 5.124839663039893e-05.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 104: ReduceLROnPlateau reducing learning rate to 5.124839663039893e-05.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 104: ReduceLROnPlateau reducing learning rate to 5.124839663039893e-05.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 109/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 109/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 112/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 112/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 114: ReduceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 114: ReduceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 118/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 118/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 121/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 121/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 124/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 125/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 127/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 127/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 130/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 130/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 133/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 133/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 135/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 135/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 135/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 140/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 140/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 143/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 143/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 146/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 146/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 149/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 149/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 1/15050duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 1/15050duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0040s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0040s). Check your callbacks.
Epoch 4/15050duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 4/15050duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 7/15050duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 7/15050duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 7/15050duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 11/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 11/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 14/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 14/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 17/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 17/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 17/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 17/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 21/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 21/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 21/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 26/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 26/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 29/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 30/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 30/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 32/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 32/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 32/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 35/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 38/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 38/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 38/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 42/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 42/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 44/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 44/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 44/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 44/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 49/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 52/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 52/1500duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 58/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 58/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 58/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 62/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 62/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 64/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 64/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 64/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 64/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 64/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 69/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 69/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 74/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 74/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 74/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 77/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 77/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 80/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 80/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 80/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 80/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 87: ReduceLROnPlateau reducing learning rate to 0.00040998717304319143..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 87: ReduceLROnPlateau reducing learning rate to 0.00040998717304319143..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 89/150duceLROnPlateau reducing learning rate to 0.00040998717304319143..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 89/150duceLROnPlateau reducing learning rate to 0.00040998717304319143..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 89/150duceLROnPlateau reducing learning rate to 0.00040998717304319143..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 89/150duceLROnPlateau reducing learning rate to 0.00040998717304319143..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 89/150duceLROnPlateau reducing learning rate to 0.00040998717304319143..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 89/150duceLROnPlateau reducing learning rate to 0.00040998717304319143..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 95/150duceLROnPlateau reducing learning rate to 0.00040998717304319143..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 95/150duceLROnPlateau reducing learning rate to 0.00040998717304319143..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 97: ReduceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 97: ReduceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 100/150uceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 103/150uceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 103/150uceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 103/150uceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 105/150uceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 105/150uceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 107/150uceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 107/150uceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 109/150uceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 109/150uceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 111/150uceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 114/150uceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 114/150uceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 114/150uceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 117/150uceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 119/150uceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 121/150uceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 121/150uceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 121/150uceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 121/150uceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 125/150uceLROnPlateau reducing learning rate to 0.00020499358652159572..05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 127: ReduceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 127: ReduceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 127: ReduceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 130/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 130/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 130/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 130/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 136/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 138/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 140/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 140/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 140/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 144/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 144/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 144/150duceLROnPlateau reducing learning rate to 2.5624198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 147: ReduceLROnPlateau reducing learning rate to 1e-05.198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 150/150duceLROnPlateau reducing learning rate to 1e-05.198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 1/15050duceLROnPlateau reducing learning rate to 1e-05.198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 1/15050duceLROnPlateau reducing learning rate to 1e-05.198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 4/15050duceLROnPlateau reducing learning rate to 1e-05.198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 4/15050duceLROnPlateau reducing learning rate to 1e-05.198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 4/15050duceLROnPlateau reducing learning rate to 1e-05.198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 8/15050duceLROnPlateau reducing learning rate to 1e-05.198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 8/15050duceLROnPlateau reducing learning rate to 1e-05.198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 11/1500duceLROnPlateau reducing learning rate to 1e-05.198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 11/1500duceLROnPlateau reducing learning rate to 1e-05.198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 14/1500duceLROnPlateau reducing learning rate to 1e-05.198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 14/1500duceLROnPlateau reducing learning rate to 1e-05.198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 17/1500duceLROnPlateau reducing learning rate to 1e-05.198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 17/1500duceLROnPlateau reducing learning rate to 1e-05.198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 17/1500duceLROnPlateau reducing learning rate to 1e-05.198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 21/1500duceLROnPlateau reducing learning rate to 1e-05.198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 21/1500duceLROnPlateau reducing learning rate to 1e-05.198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 24/1500duceLROnPlateau reducing learning rate to 1e-05.198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 24/1500duceLROnPlateau reducing learning rate to 1e-05.198315199465e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 30/150duceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 30/150duceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 33/150duceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 33/150duceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 33/150duceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 37/150duceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 37/150duceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 39/150duceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 39/150duceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 43/150duceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 43/150duceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 46/150duceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 46/150duceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 46/150duceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 53/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 53/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 56/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 56/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 59/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 59/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 62/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 62/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 62/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 66/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 66/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0016399486921727657.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0016399486921727657.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0016399486921727657.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0016399486921727657.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 75/150duceLROnPlateau reducing learning rate to 0.0016399486921727657.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 75/150duceLROnPlateau reducing learning rate to 0.0016399486921727657.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 75/150duceLROnPlateau reducing learning rate to 0.0016399486921727657.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 82/150duceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 82/150duceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 114/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 114/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 117/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 117/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 119/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 119/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 123/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 123/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 126/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 126/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 126/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 129/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 129/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 133/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 133/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 136/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 136/150uceLROnPlateau reducing learning rate to 0.0008199743460863829.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 138: ReduceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 138: ReduceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 138: ReduceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 143/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 143/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 146/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 146/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 148: ReduceLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 148: ReduceLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 1/150ReduceLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 1/150ReduceLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0053s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0053s). Check your callbacks.
Epoch 4/150ReduceLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 4/150ReduceLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 4/150ReduceLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 8/150ReduceLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 8/150ReduceLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 11/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 11/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 14/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 14/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 17/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 17/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 20/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 20/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 20/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 24/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 24/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 27/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 27/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 30/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 30/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 33/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 33/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 36/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 36/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 36/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 40/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 40/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 43/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 43/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 45/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 45/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 49/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 49/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 49/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 53/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 53/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 55/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 55/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 55/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 58/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 58/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 58/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 62/150educeLROnPlateau reducing learning rate to 1e-05.099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 67/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 67/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 67/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 70/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 73/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 75/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 76/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 76/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 76/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 76/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 80/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 80/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 80/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 80/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0032798973843455315.5.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 105: ReduceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 105: ReduceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 105: ReduceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 105: ReduceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 112/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 112/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 115/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 116/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 116/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 118/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 121/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 121/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 121/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 121/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 125/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 125/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 125/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 128/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 128/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 130/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 133/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 133/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 133/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 137/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 137/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 137/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 137/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 137/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 137/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_065533-7tls0sd6\files\model-best)... Done. 0.0s
Epoch 143/150duceLROnPlateau reducing learning rate to 0.00020499358652159572.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 145: ReduceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 145: ReduceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 145: ReduceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 150/150duceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 1/15050duceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 1/15050duceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 1/15050duceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 5/15050duceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 5/15050duceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 8/15050duceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 8/15050duceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 11/1500duceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 11/1500duceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 14/1500duceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 14/1500duceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 17/1500duceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 17/1500duceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 17/1500duceLROnPlateau reducing learning rate to 1.2812099157599732e-05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 24/150duceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 24/150duceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 24/150duceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 28/150duceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 28/150duceLROnPlateau reducing learning rate to 0.013119589537382126.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 30: ReduceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 30: ReduceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 34/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 34/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 37/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 37/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 40/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 40/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 43/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 44/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 46/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 46/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 49/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 49/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 49/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 53/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 54/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 56/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 56/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 56/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 60/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 60/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 63/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 64/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 66/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 66/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 66/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 70/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 70/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 73/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 74/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 76/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 76/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 79/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 79/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 82/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 82/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 84/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 86/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 86/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 89/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 89/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 92/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 92/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 94/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 94/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 94/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 99/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 99/150duceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 102/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 102/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 104/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 106/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 106/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 109/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 109/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 112/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 112/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 114/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 116/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 116/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 119/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 119/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 122/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 122/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 124/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 124/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 128/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 128/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 131/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 131/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 131/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 134/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 134/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 138/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 138/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 141/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 141/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 144/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 144/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 144/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 148/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 148/150uceLROnPlateau reducing learning rate to 0.006559794768691063.05.05121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_4.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
 56/162 [=========>....................] - ETA: 0s - loss: 0.0026 - mae: 0.0421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
 56/162 [=========>....................] - ETA: 0s - loss: 0.0026 - mae: 0.0421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0040s). Check your callbacks.
Epoch 4/150=======>....................] - ETA: 0s - loss: 0.0026 - mae: 0.0421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 4/150=======>....................] - ETA: 0s - loss: 0.0026 - mae: 0.0421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 13/150======>....................] - ETA: 0s - loss: 0.0026 - mae: 0.0421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 13/150======>....................] - ETA: 0s - loss: 0.0026 - mae: 0.0421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 16/150======>....................] - ETA: 0s - loss: 0.0026 - mae: 0.0421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 19/150======>....................] - ETA: 0s - loss: 0.0026 - mae: 0.0421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 21/150======>....................] - ETA: 0s - loss: 0.0026 - mae: 0.0421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 24/150======>....................] - ETA: 0s - loss: 0.0026 - mae: 0.0421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 24/150======>....................] - ETA: 0s - loss: 0.0026 - mae: 0.0421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 27/150======>....................] - ETA: 0s - loss: 0.0026 - mae: 0.0421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 30/150======>....................] - ETA: 0s - loss: 0.0026 - mae: 0.0421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 31/150======>....................] - ETA: 0s - loss: 0.0026 - mae: 0.0421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 34/150======>....................] - ETA: 0s - loss: 0.0026 - mae: 0.0421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 37/150======>....................] - ETA: 0s - loss: 0.0026 - mae: 0.0421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 39/150======>....................] - ETA: 0s - loss: 0.0026 - mae: 0.0421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 41/150======>....................] - ETA: 0s - loss: 0.0026 - mae: 0.0421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0032798973843455315.421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 45/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 47/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 50/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 52/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 53/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 56/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 58/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 61/150duceLROnPlateau reducing learning rate to 0.0032798973843455315.421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0008199743460863829.421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 65/150duceLROnPlateau reducing learning rate to 0.0008199743460863829.421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 67/150duceLROnPlateau reducing learning rate to 0.0008199743460863829.421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 69/150duceLROnPlateau reducing learning rate to 0.0008199743460863829.421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 71/150duceLROnPlateau reducing learning rate to 0.0008199743460863829.421 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 72: ReduceLROnPlateau reducing learning rate to 0.00040998717304319143.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 75/150duceLROnPlateau reducing learning rate to 0.00040998717304319143.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 78/150duceLROnPlateau reducing learning rate to 0.00040998717304319143.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 80/150duceLROnPlateau reducing learning rate to 0.00040998717304319143.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 82/150duceLROnPlateau reducing learning rate to 0.00040998717304319143.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 84/150duceLROnPlateau reducing learning rate to 0.00040998717304319143.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 87/150duceLROnPlateau reducing learning rate to 0.00040998717304319143.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 89/150duceLROnPlateau reducing learning rate to 0.00040998717304319143.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 91/150duceLROnPlateau reducing learning rate to 0.00040998717304319143.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 92: ReduceLROnPlateau reducing learning rate to 0.00010249679326079786.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 92: ReduceLROnPlateau reducing learning rate to 0.00010249679326079786.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 96/150duceLROnPlateau reducing learning rate to 0.00010249679326079786.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 99/150duceLROnPlateau reducing learning rate to 0.00010249679326079786.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 101/150uceLROnPlateau reducing learning rate to 0.00010249679326079786.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 102: ReduceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 105/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 107/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 109/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 111/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 113/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 116/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 118/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 120/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 122/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 123/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 126/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 128/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 130/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 132/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 134/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 137/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 139/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 141/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 141/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 144/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 147/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
Epoch 149/150duceLROnPlateau reducing learning rate to 5.124839663039893e-05.21 - mse: 0.0026 - root_mean_squared_error: 0.0511M_150epochs/model_9.h57 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_10.h5 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.02623917905121828LR_[22]CHN_100CNNI_32BS_40DU_10P_val_lossM_150epochs/model_10.h5 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0066e-054