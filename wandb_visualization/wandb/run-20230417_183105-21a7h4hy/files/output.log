Epoch 1/30
72/98 [=====================>........] - ETA: 0s - loss: 0.0990 - mae: 0.0512 - mse: 0.0060
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0014s). Check your callbacks.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183105-21a7h4hy\files\model-best)... Done. 0.0s
98/98 [==============================] - 1s 8ms/step - loss: 0.0751 - mae: 0.0512 - mse: 0.0055 - val_loss: 0.0031 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 0.0936
Epoch 2/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0423 - mse: 0.0027 - val_loss: 0.0034 - val_mae: 0.0358 - val_mse: 0.0017 - lr: 0.0936
Epoch 3/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0027 - mae: 0.0366 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0351 - val_mse: 0.0018 - lr: 0.0936
Epoch 4/30
69/98 [====================>.........] - ETA: 0s - loss: 0.0020 - mae: 0.0344 - mse: 0.0017
98/98 [==============================] - 2s 18ms/step - loss: 0.0019 - mae: 0.0335 - mse: 0.0016 - val_loss: 0.0016 - val_mae: 0.0311 - val_mse: 0.0014 - lr: 0.0936
Epoch 5/30
98/98 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0311 - mse: 0.0015 - val_loss: 0.0016 - val_mae: 0.0292 - val_mse: 0.0013 - lr: 0.0936
Epoch 6/30
70/98 [====================>.........] - ETA: 0s - loss: 0.0016 - mae: 0.0287 - mse: 0.0013
98/98 [==============================] - 1s 8ms/step - loss: 0.0015 - mae: 0.0282 - mse: 0.0012 - val_loss: 0.0015 - val_mae: 0.0290 - val_mse: 0.0013 - lr: 0.0936
Epoch 7/30
60/98 [=================>............] - ETA: 0s - loss: 0.0014 - mae: 0.0268 - mse: 0.0011
98/98 [==============================] - 1s 9ms/step - loss: 0.0014 - mae: 0.0267 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0247 - val_mse: 9.9782e-04 - lr: 0.0936
Epoch 8/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0267 - mse: 0.0011 - val_loss: 0.0027 - val_mae: 0.0393 - val_mse: 0.0022 - lr: 0.0936
Epoch 9/30
79/98 [=======================>......] - ETA: 0s - loss: 0.0016 - mae: 0.0275 - mse: 0.0012
98/98 [==============================] - 1s 8ms/step - loss: 0.0015 - mae: 0.0270 - mse: 0.0012 - val_loss: 0.0011 - val_mae: 0.0238 - val_mse: 9.2246e-04 - lr: 0.0936
Epoch 10/30
40/98 [===========>..................] - ETA: 0s - loss: 0.0014 - mae: 0.0256 - mse: 0.0010
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.046785250306129456.
98/98 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0247 - mse: 9.9530e-04 - val_loss: 0.0014 - val_mae: 0.0279 - val_mse: 0.0012 - lr: 0.0936
Epoch 11/30
77/98 [======================>.......] - ETA: 0s - loss: 0.0011 - mae: 0.0237 - mse: 9.2532e-04
98/98 [==============================] - 1s 8ms/step - loss: 0.0011 - mae: 0.0237 - mse: 9.2243e-04 - val_loss: 0.0011 - val_mae: 0.0246 - val_mse: 9.6378e-04 - lr: 0.0468
Epoch 12/30
74/98 [=====================>........] - ETA: 0s - loss: 0.0011 - mae: 0.0241 - mse: 9.6402e-04
98/98 [==============================] - 1s 9ms/step - loss: 0.0011 - mae: 0.0238 - mse: 9.5101e-04 - val_loss: 0.0010 - val_mae: 0.0231 - val_mse: 8.6773e-04 - lr: 0.0468
Epoch 13/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0237 - mse: 9.2042e-04 - val_loss: 0.0016 - val_mae: 0.0304 - val_mse: 0.0015 - lr: 0.0468
Epoch 14/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0237 - mse: 9.2455e-04 - val_loss: 0.0015 - val_mae: 0.0278 - val_mse: 0.0012 - lr: 0.0468
Epoch 15/30
73/98 [=====================>........] - ETA: 0s - loss: 0.0011 - mae: 0.0237 - mse: 9.1832e-04
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.023392625153064728.
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0236 - mse: 9.0916e-04 - val_loss: 0.0011 - val_mae: 0.0241 - val_mse: 9.2494e-04 - lr: 0.0468
Epoch 16/30
78/98 [======================>.......] - ETA: 0s - loss: 9.5841e-04 - mae: 0.0223 - mse: 8.2537e-04
98/98 [==============================] - 1s 8ms/step - loss: 9.5820e-04 - mae: 0.0222 - mse: 8.2345e-04 - val_loss: 9.8778e-04 - val_mae: 0.0235 - val_mse: 8.7477e-04 - lr: 0.0234
Epoch 17/30
70/98 [====================>.........] - ETA: 0s - loss: 0.0010 - mae: 0.0229 - mse: 8.6647e-04
98/98 [==============================] - 1s 8ms/step - loss: 9.7918e-04 - mae: 0.0226 - mse: 8.4550e-04 - val_loss: 9.7597e-04 - val_mae: 0.0224 - val_mse: 8.1665e-04 - lr: 0.0234
Epoch 18/30
71/98 [====================>.........] - ETA: 0s - loss: 9.6662e-04 - mae: 0.0227 - mse: 8.2492e-04
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.011696312576532364.
98/98 [==============================] - 0s 1ms/step - loss: 9.8763e-04 - mae: 0.0228 - mse: 8.4493e-04 - val_loss: 0.0014 - val_mae: 0.0277 - val_mse: 0.0012 - lr: 0.0234
Epoch 19/30
77/98 [======================>.......] - ETA: 0s - loss: 9.4480e-04 - mae: 0.0222 - mse: 8.1902e-04
98/98 [==============================] - 1s 9ms/step - loss: 9.5075e-04 - mae: 0.0223 - mse: 8.2761e-04 - val_loss: 9.2895e-04 - val_mae: 0.0223 - val_mse: 8.1113e-04 - lr: 0.0117
Epoch 20/30
73/98 [=====================>........] - ETA: 0s - loss: 8.8708e-04 - mae: 0.0216 - mse: 7.7242e-04
98/98 [==============================] - 1s 8ms/step - loss: 9.1028e-04 - mae: 0.0219 - mse: 7.9672e-04 - val_loss: 9.2072e-04 - val_mae: 0.0225 - val_mse: 8.1376e-04 - lr: 0.0117
Epoch 21/30
73/98 [=====================>........] - ETA: 0s - loss: 9.3776e-04 - mae: 0.0224 - mse: 8.1979e-04
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.005848156288266182.
98/98 [==============================] - 0s 1ms/step - loss: 9.3347e-04 - mae: 0.0222 - mse: 8.1502e-04 - val_loss: 9.2881e-04 - val_mae: 0.0222 - val_mse: 8.0856e-04 - lr: 0.0117
Epoch 22/30
77/98 [======================>.......] - ETA: 0s - loss: 8.7904e-04 - mae: 0.0215 - mse: 7.7337e-04
98/98 [==============================] - 1s 8ms/step - loss: 8.9098e-04 - mae: 0.0217 - mse: 7.8643e-04 - val_loss: 9.1626e-04 - val_mae: 0.0223 - val_mse: 8.0896e-04 - lr: 0.0058
Epoch 23/30
98/98 [==============================] - 0s 1ms/step - loss: 8.9265e-04 - mae: 0.0217 - mse: 7.8857e-04 - val_loss: 0.0011 - val_mae: 0.0248 - val_mse: 9.7208e-04 - lr: 0.0058
Epoch 24/30
77/98 [======================>.......] - ETA: 0s - loss: 9.2836e-04 - mae: 0.0220 - mse: 8.1551e-04
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.002924078144133091.
98/98 [==============================] - 0s 1ms/step - loss: 9.1647e-04 - mae: 0.0220 - mse: 8.0618e-04 - val_loss: 9.3114e-04 - val_mae: 0.0229 - val_mse: 8.3801e-04 - lr: 0.0058
Epoch 25/30
57/98 [================>.............] - ETA: 0s - loss: 9.0996e-04 - mae: 0.0220 - mse: 8.0738e-04
98/98 [==============================] - 1s 8ms/step - loss: 8.8858e-04 - mae: 0.0217 - mse: 7.8568e-04 - val_loss: 9.1566e-04 - val_mae: 0.0223 - val_mse: 8.1689e-04 - lr: 0.0029
Epoch 26/30
98/98 [==============================] - 0s 1ms/step - loss: 8.8259e-04 - mae: 0.0216 - mse: 7.7955e-04 - val_loss: 9.4606e-04 - val_mae: 0.0233 - val_mse: 8.6610e-04 - lr: 0.0029
Epoch 27/30
79/98 [=======================>......] - ETA: 0s - loss: 9.0070e-04 - mae: 0.0218 - mse: 8.0120e-04
Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0014620390720665455.
98/98 [==============================] - 0s 1ms/step - loss: 8.9277e-04 - mae: 0.0218 - mse: 7.9385e-04 - val_loss: 9.5213e-04 - val_mae: 0.0227 - val_mse: 8.3956e-04 - lr: 0.0029
Epoch 28/30
74/98 [=====================>........] - ETA: 0s - loss: 8.8481e-04 - mae: 0.0217 - mse: 7.8461e-04
98/98 [==============================] - 1s 8ms/step - loss: 8.7819e-04 - mae: 0.0215 - mse: 7.7800e-04 - val_loss: 9.0759e-04 - val_mae: 0.0222 - val_mse: 8.0410e-04 - lr: 0.0015
Epoch 29/30
98/98 [==============================] - 0s 1ms/step - loss: 8.7493e-04 - mae: 0.0215 - mse: 7.7663e-04 - val_loss: 9.2004e-04 - val_mae: 0.0223 - val_mse: 8.1409e-04 - lr: 0.0015
Epoch 30/30
80/98 [=======================>......] - ETA: 0s - loss: 8.8299e-04 - mae: 0.0214 - mse: 7.7830e-04
Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0007310195360332727.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183105-21a7h4hy\files\model-best)... Done. 0.0s
98/98 [==============================] - 1s 8ms/step - loss: 8.7669e-04 - mae: 0.0214 - mse: 7.7302e-04 - val_loss: 9.0047e-04 - val_mae: 0.0224 - val_mse: 8.0862e-04 - lr: 0.0015
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_adam_0.09357049888244956_70_40_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
130/130 [==============================] - 0s 2ms/step - loss: 0.0546 - mae: 0.0562 - mse: 0.0049 - val_loss: 0.0035 - val_mae: 0.0489 - val_mse: 0.0032 - lr: 0.0936
Epoch 2/30
130/130 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0496 - mse: 0.0033 - val_loss: 0.0065 - val_mae: 0.0617 - val_mse: 0.0057 - lr: 0.0936
Epoch 3/30
130/130 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0479 - mse: 0.0032 - val_loss: 0.0075 - val_mae: 0.0674 - val_mse: 0.0067 - lr: 0.0936
Epoch 4/30
 80/130 [=================>............] - ETA: 0s - loss: 0.0036 - mae: 0.0435 - mse: 0.0028
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.046785250306129456.
130/130 [==============================] - 0s 978us/step - loss: 0.0033 - mae: 0.0414 - mse: 0.0026 - val_loss: 0.0082 - val_mae: 0.0726 - val_mse: 0.0076 - lr: 0.0936
Epoch 5/30
130/130 [==============================] - 0s 1ms/step - loss: 0.0027 - mae: 0.0367 - mse: 0.0021 - val_loss: 0.0055 - val_mae: 0.0595 - val_mse: 0.0052 - lr: 0.0468
Epoch 6/30
130/130 [==============================] - 0s 1ms/step - loss: 0.0024 - mae: 0.0359 - mse: 0.0020 - val_loss: 0.0044 - val_mae: 0.0520 - val_mse: 0.0038 - lr: 0.0468
Epoch 7/30
130/130 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0337 - mse: 0.0018 - val_loss: 0.0019 - val_mae: 0.0316 - val_mse: 0.0017 - lr: 0.0468
Epoch 8/30
130/130 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0324 - mse: 0.0017 - val_loss: 0.0022 - val_mae: 0.0360 - val_mse: 0.0020 - lr: 0.0468
Epoch 9/30
130/130 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0326 - mse: 0.0017 - val_loss: 0.0034 - val_mae: 0.0447 - val_mse: 0.0028 - lr: 0.0468
Epoch 10/30
 77/130 [================>.............] - ETA: 0s - loss: 0.0021 - mae: 0.0333 - mse: 0.0018
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.023392625153064728.
130/130 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0059 - val_mae: 0.0635 - val_mse: 0.0058 - lr: 0.0468
Epoch 11/30
130/130 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0322 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0324 - val_mse: 0.0017 - lr: 0.0234
Epoch 12/30
130/130 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0296 - mse: 0.0015 - val_loss: 0.0020 - val_mae: 0.0328 - val_mse: 0.0017 - lr: 0.0234
Epoch 13/30
 79/130 [=================>............] - ETA: 0s - loss: 0.0017 - mae: 0.0296 - mse: 0.0015
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.011696312576532364.
130/130 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0296 - mse: 0.0015 - val_loss: 0.0019 - val_mae: 0.0322 - val_mse: 0.0017 - lr: 0.0234
Epoch 14/30
130/130 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0290 - mse: 0.0014 - val_loss: 0.0016 - val_mae: 0.0289 - val_mse: 0.0014 - lr: 0.0117
Epoch 15/30
130/130 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0290 - mse: 0.0014 - val_loss: 0.0020 - val_mae: 0.0328 - val_mse: 0.0017 - lr: 0.0117
Epoch 16/30
130/130 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0293 - mse: 0.0014 - val_loss: 0.0016 - val_mae: 0.0284 - val_mse: 0.0014 - lr: 0.0117
Epoch 17/30
126/130 [============================>.] - ETA: 0s - loss: 0.0016 - mae: 0.0284 - mse: 0.0014
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.005848156288266182.
130/130 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0283 - mse: 0.0014 - val_loss: 0.0016 - val_mae: 0.0287 - val_mse: 0.0014 - lr: 0.0117
Epoch 18/30
130/130 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0284 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0274 - val_mse: 0.0013 - lr: 0.0058
Epoch 19/30
130/130 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0278 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0283 - val_mse: 0.0014 - lr: 0.0058
Epoch 20/30
130/130 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0279 - mse: 0.0013 - val_loss: 0.0017 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0058
Epoch 21/30
 78/130 [=================>............] - ETA: 0s - loss: 0.0015 - mae: 0.0280 - mse: 0.0013
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.002924078144133091.
130/130 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0281 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0269 - val_mse: 0.0013 - lr: 0.0058
Epoch 22/30
130/130 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0274 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0278 - val_mse: 0.0013 - lr: 0.0029
Epoch 23/30
130/130 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0274 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0271 - val_mse: 0.0013 - lr: 0.0029
Epoch 24/30
119/130 [==========================>...] - ETA: 0s - loss: 0.0015 - mae: 0.0275 - mse: 0.0013
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0014620390720665455.
130/130 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0277 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0273 - val_mse: 0.0013 - lr: 0.0029
Epoch 25/30
130/130 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0272 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0268 - val_mse: 0.0013 - lr: 0.0015
Epoch 26/30
130/130 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0274 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0267 - val_mse: 0.0013 - lr: 0.0015
Epoch 27/30
 81/130 [=================>............] - ETA: 0s - loss: 0.0015 - mae: 0.0273 - mse: 0.0013
Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0007310195360332727.
130/130 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0272 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0268 - val_mse: 0.0013 - lr: 0.0015
Epoch 28/30
130/130 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0270 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0268 - val_mse: 0.0013 - lr: 7.3102e-04
Epoch 29/30
130/130 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0270 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0269 - val_mse: 0.0013 - lr: 7.3102e-04
Epoch 30/30
 78/130 [=================>............] - ETA: 0s - loss: 0.0015 - mae: 0.0276 - mse: 0.0013
Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00036550976801663637.
130/130 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0272 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0267 - val_mse: 0.0013 - lr: 7.3102e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_adam_0.09357049888244956_70_40_30epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
98/98 [==============================] - 0s 2ms/step - loss: 0.0626 - mae: 0.0405 - mse: 0.0024 - val_loss: 0.0021 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0936
Epoch 2/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0403 - val_mse: 0.0023 - lr: 0.0936
Epoch 3/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0936
Epoch 4/30
71/98 [====================>.........] - ETA: 0s - loss: 0.0020 - mae: 0.0380 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.046785250306129456.
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0936
Epoch 5/30
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0468
Epoch 6/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0382 - val_mse: 0.0019 - lr: 0.0468
Epoch 7/30
76/98 [======================>.......] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.023392625153064728.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0394 - val_mse: 0.0021 - lr: 0.0468
Epoch 8/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0234
Epoch 9/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0234
Epoch 10/30
56/98 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.011696312576532364.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0234
Epoch 11/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0117
Epoch 12/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0117
Epoch 13/30
75/98 [=====================>........] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.005848156288266182.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0117
Epoch 14/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0058
Epoch 15/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0058
Epoch 16/30
70/98 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.002924078144133091.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0058
Epoch 17/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 18/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 19/30
97/98 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0014620390720665455.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 20/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0015
Epoch 21/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 22/30
77/98 [======================>.......] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0007310195360332727.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0015
Epoch 23/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.3102e-04
Epoch 24/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.3102e-04
Epoch 25/30
77/98 [======================>.......] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00036550976801663637.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.3102e-04
Epoch 26/30
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.6551e-04
Epoch 27/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.6551e-04
Epoch 28/30
77/98 [======================>.......] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00018275488400831819.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.6551e-04
Epoch 29/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.8275e-04
Epoch 30/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.8275e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_adam_0.09357049888244956_70_40_30epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
98/98 [==============================] - 0s 2ms/step - loss: 0.0647 - mae: 0.0397 - mse: 0.0022 - val_loss: 0.0023 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0936
Epoch 2/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0397 - val_mse: 0.0022 - lr: 0.0936
Epoch 3/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0936
Epoch 4/30
76/98 [======================>.......] - ETA: 0s - loss: 0.0021 - mae: 0.0378 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.046785250306129456.
98/98 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0936
Epoch 5/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0381 - val_mse: 0.0020 - lr: 0.0468
Epoch 6/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0336 - mse: 0.0016 - val_loss: 0.0025 - val_mae: 0.0387 - val_mse: 0.0022 - lr: 0.0468
Epoch 7/30
77/98 [======================>.......] - ETA: 0s - loss: 0.0015 - mae: 0.0291 - mse: 0.0013
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.023392625153064728.
98/98 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0286 - mse: 0.0012 - val_loss: 0.0021 - val_mae: 0.0370 - val_mse: 0.0020 - lr: 0.0468
Epoch 8/30
98/98 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0266 - mse: 0.0011 - val_loss: 0.0015 - val_mae: 0.0295 - val_mse: 0.0013 - lr: 0.0234
Epoch 9/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0255 - mse: 0.0010 - val_loss: 0.0013 - val_mae: 0.0276 - val_mse: 0.0012 - lr: 0.0234
Epoch 10/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0246 - mse: 9.7930e-04 - val_loss: 0.0018 - val_mae: 0.0329 - val_mse: 0.0016 - lr: 0.0234
Epoch 11/30
98/98 [==============================] - 0s 3ms/step - loss: 0.0012 - mae: 0.0257 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0258 - val_mse: 0.0010 - lr: 0.0234
Epoch 12/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0242 - mse: 9.4328e-04 - val_loss: 0.0011 - val_mae: 0.0242 - val_mse: 9.5138e-04 - lr: 0.0234
Epoch 13/30
98/98 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0241 - mse: 9.3117e-04 - val_loss: 0.0011 - val_mae: 0.0246 - val_mse: 9.8792e-04 - lr: 0.0234
Epoch 14/30
70/98 [====================>.........] - ETA: 0s - loss: 0.0010 - mae: 0.0243 - mse: 9.4240e-04
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.011696312576532364.
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0242 - mse: 9.3599e-04 - val_loss: 0.0012 - val_mae: 0.0273 - val_mse: 0.0011 - lr: 0.0234
Epoch 15/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0239 - mse: 9.1723e-04 - val_loss: 0.0010 - val_mae: 0.0244 - val_mse: 9.3739e-04 - lr: 0.0117
Epoch 16/30
98/98 [==============================] - 0s 1ms/step - loss: 9.8032e-04 - mae: 0.0233 - mse: 8.8482e-04 - val_loss: 0.0010 - val_mae: 0.0238 - val_mse: 9.1828e-04 - lr: 0.0117
Epoch 17/30
98/98 [==============================] - 0s 1ms/step - loss: 9.7265e-04 - mae: 0.0232 - mse: 8.8273e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4029e-04 - lr: 0.0117
Epoch 18/30
98/98 [==============================] - 0s 1ms/step - loss: 9.8552e-04 - mae: 0.0236 - mse: 8.9674e-04 - val_loss: 0.0010 - val_mae: 0.0237 - val_mse: 9.2432e-04 - lr: 0.0117
Epoch 19/30
76/98 [======================>.......] - ETA: 0s - loss: 0.0010 - mae: 0.0237 - mse: 9.1539e-04
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.005848156288266182.
98/98 [==============================] - 0s 1ms/step - loss: 9.9901e-04 - mae: 0.0237 - mse: 9.0756e-04 - val_loss: 0.0010 - val_mae: 0.0241 - val_mse: 9.5162e-04 - lr: 0.0117
Epoch 20/30
98/98 [==============================] - 0s 1ms/step - loss: 9.5834e-04 - mae: 0.0231 - mse: 8.6947e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4368e-04 - lr: 0.0058
Epoch 21/30
98/98 [==============================] - 0s 1ms/step - loss: 9.4457e-04 - mae: 0.0230 - mse: 8.5971e-04 - val_loss: 0.0010 - val_mae: 0.0245 - val_mse: 9.3971e-04 - lr: 0.0058
Epoch 22/30
76/98 [======================>.......] - ETA: 0s - loss: 9.5624e-04 - mae: 0.0233 - mse: 8.7259e-04
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.002924078144133091.
98/98 [==============================] - 0s 1ms/step - loss: 9.5823e-04 - mae: 0.0233 - mse: 8.7209e-04 - val_loss: 9.7870e-04 - val_mae: 0.0235 - val_mse: 8.9117e-04 - lr: 0.0058
Epoch 23/30
98/98 [==============================] - 0s 1ms/step - loss: 9.3436e-04 - mae: 0.0228 - mse: 8.5215e-04 - val_loss: 9.7882e-04 - val_mae: 0.0235 - val_mse: 8.9883e-04 - lr: 0.0029
Epoch 24/30
98/98 [==============================] - 0s 1ms/step - loss: 9.2538e-04 - mae: 0.0227 - mse: 8.4387e-04 - val_loss: 9.8905e-04 - val_mae: 0.0235 - val_mse: 9.0812e-04 - lr: 0.0029
Epoch 25/30
76/98 [======================>.......] - ETA: 0s - loss: 9.3383e-04 - mae: 0.0231 - mse: 8.5568e-04
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0014620390720665455.
98/98 [==============================] - 0s 1ms/step - loss: 9.4320e-04 - mae: 0.0231 - mse: 8.6347e-04 - val_loss: 9.7468e-04 - val_mae: 0.0236 - val_mse: 8.9020e-04 - lr: 0.0029
Epoch 26/30
98/98 [==============================] - 0s 1ms/step - loss: 9.2471e-04 - mae: 0.0227 - mse: 8.4190e-04 - val_loss: 9.8004e-04 - val_mae: 0.0234 - val_mse: 8.9888e-04 - lr: 0.0015
Epoch 27/30
98/98 [==============================] - 0s 1ms/step - loss: 9.2389e-04 - mae: 0.0227 - mse: 8.4383e-04 - val_loss: 9.7213e-04 - val_mae: 0.0235 - val_mse: 8.9325e-04 - lr: 0.0015
Epoch 28/30
77/98 [======================>.......] - ETA: 0s - loss: 9.2316e-04 - mae: 0.0226 - mse: 8.4470e-04
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0007310195360332727.
98/98 [==============================] - 0s 1ms/step - loss: 9.2479e-04 - mae: 0.0227 - mse: 8.4619e-04 - val_loss: 9.7118e-04 - val_mae: 0.0235 - val_mse: 8.9317e-04 - lr: 0.0015
Epoch 29/30
98/98 [==============================] - 0s 1ms/step - loss: 9.1891e-04 - mae: 0.0226 - mse: 8.3959e-04 - val_loss: 9.7100e-04 - val_mae: 0.0235 - val_mse: 8.9428e-04 - lr: 7.3102e-04
Epoch 30/30
98/98 [==============================] - 0s 1ms/step - loss: 9.1809e-04 - mae: 0.0226 - mse: 8.3935e-04 - val_loss: 9.8909e-04 - val_mae: 0.0235 - val_mse: 9.0905e-04 - lr: 7.3102e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_adam_0.09357049888244956_70_40_30epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
98/98 [==============================] - 0s 2ms/step - loss: 0.0585 - mae: 0.0402 - mse: 0.0023 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0936
Epoch 2/30
98/98 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0936
Epoch 3/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0936
Epoch 4/30
66/98 [===================>..........] - ETA: 0s - loss: 0.0020 - mae: 0.0382 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.046785250306129456.
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0936
Epoch 5/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0468
Epoch 6/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0468
Epoch 7/30
68/98 [===================>..........] - ETA: 0s - loss: 0.0020 - mae: 0.0379 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.023392625153064728.
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0468
Epoch 8/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0234
Epoch 9/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0234
Epoch 10/30
66/98 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.011696312576532364.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0234
Epoch 11/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0117
Epoch 12/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0117
Epoch 13/30
60/98 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.005848156288266182.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0117
Epoch 14/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0058
Epoch 15/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0058
Epoch 16/30
66/98 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.002924078144133091.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0058
Epoch 17/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 18/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0029
Epoch 19/30
74/98 [=====================>........] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0014620390720665455.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 20/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0015
Epoch 21/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 22/30
80/98 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.0019
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0007310195360332727.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 23/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.3102e-04
Epoch 24/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.3102e-04
Epoch 25/30
75/98 [=====================>........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00036550976801663637.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.3102e-04
Epoch 26/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.6551e-04
Epoch 27/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.6551e-04
Epoch 28/30
78/98 [======================>.......] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.0019
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00018275488400831819.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.6551e-04
Epoch 29/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.8275e-04
Epoch 30/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.8275e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_adam_0.09357049888244956_70_40_30epochs/model_5.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
98/98 [==============================] - 0s 2ms/step - loss: 0.0611 - mae: 0.0409 - mse: 0.0025 - val_loss: 0.0021 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0936
Epoch 2/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0936
Epoch 3/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0936
Epoch 4/30
67/98 [===================>..........] - ETA: 0s - loss: 0.0021 - mae: 0.0380 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.046785250306129456.
98/98 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 0.0936
Epoch 5/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0468
Epoch 6/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0468
Epoch 7/30
78/98 [======================>.......] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.023392625153064728.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0468
Epoch 8/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0234
Epoch 9/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0234
Epoch 10/30
78/98 [======================>.......] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.011696312576532364.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0234
Epoch 11/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0117
Epoch 12/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0117
Epoch 13/30
77/98 [======================>.......] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.005848156288266182.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0117
Epoch 14/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0058
Epoch 15/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0058
Epoch 16/30
61/98 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.002924078144133091.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0058
Epoch 17/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 18/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 19/30
79/98 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0014620390720665455.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 20/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 21/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 22/30
55/98 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0007310195360332727.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 23/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.3102e-04
Epoch 24/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.3102e-04
Epoch 25/30
63/98 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00036550976801663637.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.3102e-04
Epoch 26/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.6551e-04
Epoch 27/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.6551e-04
Epoch 28/30
73/98 [=====================>........] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0020
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00018275488400831819.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.6551e-04
Epoch 29/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.8275e-04
Epoch 30/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.8275e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_adam_0.09357049888244956_70_40_30epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
98/98 [==============================] - 0s 2ms/step - loss: 0.0624 - mae: 0.0438 - mse: 0.0031 - val_loss: 0.0021 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 0.0936
Epoch 2/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 0.0936
Epoch 3/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0373 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 0.0936
Epoch 4/30
56/98 [================>.............] - ETA: 0s - loss: 0.0021 - mae: 0.0371 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.046785250306129456.
98/98 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0362 - mse: 0.0018 - val_loss: 0.0032 - val_mae: 0.0374 - val_mse: 0.0020 - lr: 0.0936
Epoch 5/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0320 - mse: 0.0015 - val_loss: 0.0032 - val_mae: 0.0453 - val_mse: 0.0030 - lr: 0.0468
Epoch 6/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0298 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0278 - val_mse: 0.0012 - lr: 0.0468
Epoch 7/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0279 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.0468
Epoch 8/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0270 - val_mse: 0.0011 - lr: 0.0468
Epoch 9/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0270 - mse: 0.0011 - val_loss: 0.0017 - val_mae: 0.0322 - val_mse: 0.0015 - lr: 0.0468
Epoch 10/30
77/98 [======================>.......] - ETA: 0s - loss: 0.0014 - mae: 0.0275 - mse: 0.0012
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.023392625153064728.
98/98 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0270 - mse: 0.0012 - val_loss: 0.0028 - val_mae: 0.0428 - val_mse: 0.0026 - lr: 0.0468
Epoch 11/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0010 - lr: 0.0234
Epoch 12/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0251 - mse: 0.0010 - val_loss: 0.0014 - val_mae: 0.0287 - val_mse: 0.0013 - lr: 0.0234
Epoch 13/30
79/98 [=======================>......] - ETA: 0s - loss: 0.0011 - mae: 0.0254 - mse: 0.0010
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.011696312576532364.
98/98 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0255 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0249 - val_mse: 9.8763e-04 - lr: 0.0234
Epoch 14/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0245 - mse: 9.5498e-04 - val_loss: 0.0012 - val_mae: 0.0264 - val_mse: 0.0011 - lr: 0.0117
Epoch 15/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0248 - mse: 9.7381e-04 - val_loss: 0.0011 - val_mae: 0.0250 - val_mse: 9.8627e-04 - lr: 0.0117
Epoch 16/30
86/98 [=========================>....] - ETA: 0s - loss: 0.0011 - mae: 0.0247 - mse: 9.7299e-04
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.005848156288266182.
98/98 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0249 - mse: 9.8324e-04 - val_loss: 0.0011 - val_mae: 0.0252 - val_mse: 9.9496e-04 - lr: 0.0117
Epoch 17/30
98/98 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0242 - mse: 9.3584e-04 - val_loss: 0.0011 - val_mae: 0.0251 - val_mse: 9.9356e-04 - lr: 0.0058
Epoch 18/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0241 - mse: 9.3441e-04 - val_loss: 0.0011 - val_mae: 0.0247 - val_mse: 9.6891e-04 - lr: 0.0058
Epoch 19/30
77/98 [======================>.......] - ETA: 0s - loss: 0.0010 - mae: 0.0243 - mse: 9.4617e-04
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.002924078144133091.
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0243 - mse: 9.4200e-04 - val_loss: 0.0011 - val_mae: 0.0247 - val_mse: 9.6320e-04 - lr: 0.0058
Epoch 20/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0241 - mse: 9.3116e-04 - val_loss: 0.0011 - val_mae: 0.0249 - val_mse: 9.7587e-04 - lr: 0.0029
Epoch 21/30
74/98 [=====================>........] - ETA: 0s - loss: 0.0010 - mae: 0.0240 - mse: 9.2305e-04
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0240 - mse: 9.2226e-04 - val_loss: 0.0010 - val_mae: 0.0245 - val_mse: 9.6218e-04 - lr: 0.0029
Epoch 22/30
72/98 [=====================>........] - ETA: 0s - loss: 0.0010 - mae: 0.0243 - mse: 9.4726e-04
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0014620390720665455.
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0241 - mse: 9.3068e-04 - val_loss: 0.0011 - val_mae: 0.0247 - val_mse: 9.6397e-04 - lr: 0.0029
Epoch 23/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0241 - mse: 9.2639e-04 - val_loss: 0.0010 - val_mae: 0.0245 - val_mse: 9.5658e-04 - lr: 0.0015
Epoch 24/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0240 - mse: 9.2026e-04 - val_loss: 0.0011 - val_mae: 0.0249 - val_mse: 9.7760e-04 - lr: 0.0015
Epoch 25/30
73/98 [=====================>........] - ETA: 0s - loss: 0.0010 - mae: 0.0241 - mse: 9.3039e-04
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0007310195360332727.
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0240 - mse: 9.1931e-04 - val_loss: 0.0010 - val_mae: 0.0245 - val_mse: 9.5557e-04 - lr: 0.0015
Epoch 26/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0240 - mse: 9.2102e-04 - val_loss: 0.0010 - val_mae: 0.0247 - val_mse: 9.6642e-04 - lr: 7.3102e-04
Epoch 27/30
98/98 [==============================] - 0s 1ms/step - loss: 9.9606e-04 - mae: 0.0239 - mse: 9.1323e-04 - val_loss: 0.0010 - val_mae: 0.0246 - val_mse: 9.5998e-04 - lr: 7.3102e-04
Epoch 28/30
98/98 [==============================] - 0s 1ms/step - loss: 9.9881e-04 - mae: 0.0240 - mse: 9.1912e-04 - val_loss: 0.0010 - val_mae: 0.0244 - val_mse: 9.5231e-04 - lr: 7.3102e-04
Epoch 29/30
98/98 [==============================] - 0s 1ms/step - loss: 9.9985e-04 - mae: 0.0239 - mse: 9.1713e-04 - val_loss: 0.0010 - val_mae: 0.0245 - val_mse: 9.5361e-04 - lr: 7.3102e-04
Epoch 30/30
98/98 [==============================] - 0s 1ms/step - loss: 9.9756e-04 - mae: 0.0240 - mse: 9.2054e-04 - val_loss: 0.0010 - val_mae: 0.0246 - val_mse: 9.5866e-04 - lr: 7.3102e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_adam_0.09357049888244956_70_40_30epochs/model_7.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
98/98 [==============================] - 0s 2ms/step - loss: 0.0649 - mae: 0.0464 - mse: 0.0039 - val_loss: 0.0039 - val_mae: 0.0495 - val_mse: 0.0037 - lr: 0.0936
Epoch 2/30
98/98 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0371 - mse: 0.0020 - val_loss: 0.0031 - val_mae: 0.0416 - val_mse: 0.0025 - lr: 0.0936
Epoch 3/30
80/98 [=======================>......] - ETA: 0s - loss: 0.0023 - mae: 0.0378 - mse: 0.0020
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0240 - mse: 9.2226e-04 - val_loss: 0.0010 - val_mae: 0.0245 - val_mse: 9.6218e-04 - lr: 0.0029
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0240 - mse: 9.2226e-04 - val_loss: 0.0010 - val_mae: 0.0245 - val_mse: 9.6218e-04 - lr: 0.0029
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0240 - mse: 9.2226e-04 - val_loss: 0.0010 - val_mae: 0.0245 - val_mse: 9.6218e-04 - lr: 0.0029
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0240 - mse: 9.2226e-04 - val_loss: 0.0010 - val_mae: 0.0245 - val_mse: 9.6218e-04 - lr: 0.0029
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0240 - mse: 9.2226e-04 - val_loss: 0.0010 - val_mae: 0.0245 - val_mse: 9.6218e-04 - lr: 0.0029