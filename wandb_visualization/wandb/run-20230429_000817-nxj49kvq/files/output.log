Epoch 1/150
81/81 [==============================] - ETA: 0s - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
81/81 [==============================] - 3s 24ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0645
Epoch 2/150
81/81 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0645
Epoch 3/150
81/81 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0645
Epoch 4/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0645
Epoch 5/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0645
Epoch 6/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0645
Epoch 7/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0645
Epoch 8/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0645
Epoch 9/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0645
Epoch 10/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0645
Epoch 11/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0645
Epoch 12/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0645
Epoch 13/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0645
Epoch 14/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0645
Epoch 15/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0645
Epoch 16/150
73/81 [==========================>...] - ETA: 0s - loss: 0.0044 - mae: 0.0540 - mse: 0.0044 - root_mean_squared_error: 0.0662
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.03224178031086922.
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0645
Epoch 17/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0322
Epoch 18/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0322
Epoch 19/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0322
Epoch 20/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0322
Epoch 21/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0322
Epoch 22/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0322
Epoch 23/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0322
Epoch 24/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0322
Epoch 25/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0322
Epoch 26/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0322
Epoch 27/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0322
Epoch 28/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0322
Epoch 29/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0322
Epoch 30/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0322
Epoch 31/150
73/81 [==========================>...] - ETA: 0s - loss: 0.0044 - mae: 0.0543 - mse: 0.0044 - root_mean_squared_error: 0.0664
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.01612089015543461.
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0322
Epoch 32/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0161
Epoch 33/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0161
Epoch 34/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0161
Epoch 35/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0161
Epoch 36/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0161
Epoch 37/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0161
Epoch 38/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0161
Epoch 39/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0161
Epoch 40/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0161
Epoch 41/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0161
Epoch 42/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0161
Epoch 43/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0161
Epoch 44/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0161
Epoch 45/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0161
Epoch 46/150
81/81 [==============================] - ETA: 0s - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663
Epoch 46: ReduceLROnPlateau reducing learning rate to 0.008060445077717304.
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0161
Epoch 47/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0081
Epoch 48/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0081
Epoch 49/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0081
Epoch 50/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0081
Epoch 51/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0081
Epoch 52/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0081
Epoch 53/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0081
Epoch 54/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0081
Epoch 55/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0081
Epoch 56/150
72/81 [=========================>....] - ETA: 0s - loss: 0.0044 - mae: 0.0544 - mse: 0.0044 - root_mean_squared_error: 0.0665
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0081
Epoch 58/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0081
Epoch 59/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0081
Epoch 60/150
50/81 [=================>............] - ETA: 0s - loss: 0.0044 - mae: 0.0540 - mse: 0.0044 - root_mean_squared_error: 0.0661
12/81 [===>..........................] - ETA: 0s - loss: 0.0042 - mae: 0.0530 - mse: 0.0042 - root_mean_squared_error: 0.06490663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0081
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.004030222538858652.
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0081
Epoch 62/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0040
Epoch 63/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0040
Epoch 64/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0040
Epoch 65/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0040
Epoch 66/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0040
Epoch 67/150
81/81 [==============================] - ETA: 0s - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0040
Epoch 69/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0040
Epoch 70/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0040
Epoch 71/150
30/81 [==========>...................] - ETA: 0s - loss: 0.0043 - mae: 0.0534 - mse: 0.0043 - root_mean_squared_error: 0.0655
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0040
Epoch 73/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0040
Epoch 74/150
80/81 [============================>.] - ETA: 0s - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663
73/81 [==========================>...] - ETA: 0s - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.06620663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0040
Epoch 76: ReduceLROnPlateau reducing learning rate to 0.002015111269429326.
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0040
Epoch 77/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0020
Epoch 78/150
48/81 [================>.............] - ETA: 0s - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0664
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0020
Epoch 80/150
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0020
Epoch 81/150
 9/81 [==>...........................] - ETA: 0s - loss: 0.0045 - mae: 0.0547 - mse: 0.0045 - root_mean_squared_error: 0.0672
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0020
Epoch 84/150
60/81 [=====================>........] - ETA: 0s - loss: 0.0044 - mae: 0.0543 - mse: 0.0044 - root_mean_squared_error: 0.0664
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0020
Epoch 88/150
22/81 [=======>......................] - ETA: 0s - loss: 0.0044 - mae: 0.0539 - mse: 0.0044 - root_mean_squared_error: 0.0660
81/81 [==============================] - ETA: 0s - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.06630663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0020
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0010
Epoch 95/150
38/81 [=============>................] - ETA: 0s - loss: 0.0044 - mae: 0.0545 - mse: 0.0044 - root_mean_squared_error: 0.0665
78/81 [===========================>..] - ETA: 0s - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.06630663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0010
61/81 [=====================>........] - ETA: 0s - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.06620663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0010
 9/81 [==>...........................] - ETA: 0s - loss: 0.0046 - mae: 0.0564 - mse: 0.0046 - root_mean_squared_error: 0.06800663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0010
81/81 [==============================] - ETA: 0s - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.06630663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 0.0010
31/81 [==========>...................] - ETA: 0s - loss: 0.0043 - mae: 0.0532 - mse: 0.0043 - root_mean_squared_error: 0.06570663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 5.0378e-04
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 5.0378e-04
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 5.0378e-04
80/81 [============================>.] - ETA: 0s - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.06620663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 5.0378e-04
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 2.5189e-04
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 2.5189e-04
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 2.5189e-04
78/81 [===========================>..] - ETA: 0s - loss: 0.0044 - mae: 0.0541 - mse: 0.0044 - root_mean_squared_error: 0.06610663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 2.5189e-04
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.2594e-04
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.2594e-04
81/81 [==============================] - 1s 7ms/step - loss: 0.0044 - mae: 0.0542 - mse: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.2594e-04
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.2594e-04
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0670 - lr: 1.2594e-04
108/108 [==============================] - 1s 5ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.064504
 94/108 [=========================>....] - ETA: 0s - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.18471846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.064504
108/108 [==============================] - 1s 6ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.064504
108/108 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.064504
 99/108 [==========================>...] - ETA: 0s - loss: 0.0340 - mae: 0.1749 - mse: 0.0340 - root_mean_squared_error: 0.18431846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.064504
108/108 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.032204
108/108 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.032204
108/108 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.032204
108/108 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.032204
 11/108 [==>...........................] - ETA: 0s - loss: 0.0350 - mae: 0.1778 - mse: 0.0350 - root_mean_squared_error: 0.18701846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.032204
102/108 [===========================>..] - ETA: 0s - loss: 0.0340 - mae: 0.1749 - mse: 0.0340 - root_mean_squared_error: 0.18441846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.032204
108/108 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.016104
108/108 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.016104
108/108 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.016104
108/108 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.016104
 99/108 [==========================>...] - ETA: 0s - loss: 0.0340 - mae: 0.1748 - mse: 0.0340 - root_mean_squared_error: 0.18431846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.016104
103/108 [===========================>..] - ETA: 0s - loss: 0.0342 - mae: 0.1755 - mse: 0.0342 - root_mean_squared_error: 0.18491846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.016104
108/108 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.008104
108/108 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.008104
108/108 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.008104
108/108 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.008104
100/108 [==========================>...] - ETA: 0s - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.18471846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.008104
108/108 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.004004
 31/108 [=======>......................] - ETA: 0s - loss: 0.0340 - mae: 0.1753 - mse: 0.0340 - root_mean_squared_error: 0.18441846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.004004
108/108 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.004004
108/108 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.004004
 83/108 [======================>.......] - ETA: 0s - loss: 0.0339 - mae: 0.1748 - mse: 0.0339 - root_mean_squared_error: 0.18421846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.004004
 42/108 [==========>...................] - ETA: 0s - loss: 0.0336 - mae: 0.1736 - mse: 0.0336 - root_mean_squared_error: 0.18341846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.004004
108/108 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.002004
108/108 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.002004
 92/108 [========================>.....] - ETA: 0s - loss: 0.0341 - mae: 0.1753 - mse: 0.0341 - root_mean_squared_error: 0.18481846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.002004
108/108 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.002004
 99/108 [==========================>...] - ETA: 0s - loss: 0.0342 - mae: 0.1754 - mse: 0.0342 - root_mean_squared_error: 0.18481846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.002004
108/108 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
 11/108 [==>...........................] - ETA: 0s - loss: 0.0341 - mae: 0.1751 - mse: 0.0341 - root_mean_squared_error: 0.18461846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
108/108 [==============================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 102/150==========================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 105/150==========================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 107/150==========================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 111/150==========================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 113/150==========================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 116/150==========================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 119/150==========================] - 1s 7ms/step - loss: 0.0341 - mae: 0.1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 121: ReduceLROnPlateau reducing learning rate to 0.00025188890867866576..1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 124/150duceLROnPlateau reducing learning rate to 0.00025188890867866576..1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 127/150duceLROnPlateau reducing learning rate to 0.00025188890867866576..1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 129/150duceLROnPlateau reducing learning rate to 0.00025188890867866576..1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 132/150duceLROnPlateau reducing learning rate to 0.00025188890867866576..1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 135/150duceLROnPlateau reducing learning rate to 0.00025188890867866576..1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 136: ReduceLROnPlateau reducing learning rate to 0.00012594445433933288..1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 140/150duceLROnPlateau reducing learning rate to 0.00012594445433933288..1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 143/150duceLROnPlateau reducing learning rate to 0.00012594445433933288..1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 145/150duceLROnPlateau reducing learning rate to 0.00012594445433933288..1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 148/150duceLROnPlateau reducing learning rate to 0.00012594445433933288..1752 - mse: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
>Saved ../trained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_2.h5: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 3/150rained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_2.h5: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 5/150rained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_2.h5: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 8/150rained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_2.h5: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 12/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_2.h5: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 15/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_2.h5: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 17/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_2.h5: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 21/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_2.h5: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
Epoch 25/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_2.h5: 0.0339 - val_mae: 0.1745 - val_mse: 0.0339 - val_root_mean_squared_error: 0.1840 - lr: 0.001004
81/81 [==============================] - 1s 7ms/step - loss: 0.0918 - mae: 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.01612089015543461. 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 35/150duceLROnPlateau reducing learning rate to 0.01612089015543461. 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 39/150duceLROnPlateau reducing learning rate to 0.01612089015543461. 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 43/150duceLROnPlateau reducing learning rate to 0.01612089015543461. 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 46/150duceLROnPlateau reducing learning rate to 0.01612089015543461. 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 49/150duceLROnPlateau reducing learning rate to 0.01612089015543461. 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 52/150duceLROnPlateau reducing learning rate to 0.01612089015543461. 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 56/150duceLROnPlateau reducing learning rate to 0.01612089015543461. 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 59/150duceLROnPlateau reducing learning rate to 0.01612089015543461. 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 62/150duceLROnPlateau reducing learning rate to 0.01612089015543461. 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 66/150duceLROnPlateau reducing learning rate to 0.01612089015543461. 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 70/150duceLROnPlateau reducing learning rate to 0.01612089015543461. 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 73/150duceLROnPlateau reducing learning rate to 0.01612089015543461. 0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 76: ReduceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 80/150duceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 84/150duceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 88/150duceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 90/150duceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 93/150duceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 97/150duceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 101/150uceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 105/150uceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 107/150uceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 111/150uceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 115/150uceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 119/150uceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 122/150uceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 126/150uceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 130/150uceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 132/150uceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 136/150uceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 139/150uceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 143/150uceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 146/150uceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 149/150uceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 2/15050uceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 4/15050uceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 8/15050uceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 11/1500uceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 14/1500uceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.03224178031086922..0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 20/150duceLROnPlateau reducing learning rate to 0.03224178031086922..0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 24/150duceLROnPlateau reducing learning rate to 0.03224178031086922..0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 28/150duceLROnPlateau reducing learning rate to 0.03224178031086922..0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.01612089015543461..0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 35/150duceLROnPlateau reducing learning rate to 0.01612089015543461..0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 39/150duceLROnPlateau reducing learning rate to 0.01612089015543461..0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 42/150duceLROnPlateau reducing learning rate to 0.01612089015543461..0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 46/150duceLROnPlateau reducing learning rate to 0.01612089015543461..0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 49/150duceLROnPlateau reducing learning rate to 0.01612089015543461..0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 53/150duceLROnPlateau reducing learning rate to 0.01612089015543461..0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 55/150duceLROnPlateau reducing learning rate to 0.01612089015543461..0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 59/150duceLROnPlateau reducing learning rate to 0.01612089015543461..0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 62/150duceLROnPlateau reducing learning rate to 0.01612089015543461..0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 66/150duceLROnPlateau reducing learning rate to 0.01612089015543461..0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 70/150duceLROnPlateau reducing learning rate to 0.01612089015543461..0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 73/150duceLROnPlateau reducing learning rate to 0.01612089015543461..0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 76: ReduceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 80/150duceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
Epoch 84/150duceLROnPlateau reducing learning rate to 0.002015111269429326.0.2998 - mse: 0.0918 - root_mean_squared_error: 0.3030 - val_loss: 0.0922 - val_mae: 0.3004 - val_mse: 0.0922 - val_root_mean_squared_error: 0.3037 - lr: 0.03221004
81/81 [==============================] - 1s 7ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 91/150=========================] - 1s 7ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 94/150=========================] - 1s 7ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 97/150=========================] - 1s 7ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 101/150========================] - 1s 7ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 104/150========================] - 1s 7ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 107/150========================] - 1s 7ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 111/150========================] - 1s 7ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 115/150========================] - 1s 7ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 118/150========================] - 1s 7ms/step - loss: 0.1618 - mae: 0.3998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 121: ReduceLROnPlateau reducing learning rate to 0.00025188890867866576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 125/150duceLROnPlateau reducing learning rate to 0.00025188890867866576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 129/150duceLROnPlateau reducing learning rate to 0.00025188890867866576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 133/150duceLROnPlateau reducing learning rate to 0.00025188890867866576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 135/150duceLROnPlateau reducing learning rate to 0.00025188890867866576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 138/150duceLROnPlateau reducing learning rate to 0.00025188890867866576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 142/150duceLROnPlateau reducing learning rate to 0.00025188890867866576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 146/150duceLROnPlateau reducing learning rate to 0.00025188890867866576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 149/150duceLROnPlateau reducing learning rate to 0.00025188890867866576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 149/150duceLROnPlateau reducing learning rate to 0.00025188890867866576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0045s vs `on_train_batch_end` time: 0.0046s). Check your callbacks.
Epoch 2/15050duceLROnPlateau reducing learning rate to 0.00025188890867866576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 4/15050duceLROnPlateau reducing learning rate to 0.00025188890867866576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 8/15050duceLROnPlateau reducing learning rate to 0.00025188890867866576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 11/1500duceLROnPlateau reducing learning rate to 0.00025188890867866576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 15/1500duceLROnPlateau reducing learning rate to 0.00025188890867866576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 18/1500duceLROnPlateau reducing learning rate to 0.00025188890867866576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 21/1500duceLROnPlateau reducing learning rate to 0.00025188890867866576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 25/1500duceLROnPlateau reducing learning rate to 0.00025188890867866576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 29/1500duceLROnPlateau reducing learning rate to 0.00025188890867866576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.01612089015543461.576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 35/150duceLROnPlateau reducing learning rate to 0.01612089015543461.576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 39/150duceLROnPlateau reducing learning rate to 0.01612089015543461.576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 43/150duceLROnPlateau reducing learning rate to 0.01612089015543461.576.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 46: ReduceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 50/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 71/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 75/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 78/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 82/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 86/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 90/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 92/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 96/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 100/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 104/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 107/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 110/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 114/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 118/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 121/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 124/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 128/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 132/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 136/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 139/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 143/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 146/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 149/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 2/15050uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 4/15050uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 8/15050uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 12/1500uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 15/1500uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 18/1500uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 22/1500uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 26/1500uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 30/1500uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 32/1500uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 36/1500uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 40/1500uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 43/1500uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 46: ReduceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 50/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 72/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 76/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 79/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 82/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 86/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 90/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 92/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 96/150duceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 100/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 104/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 107/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 111/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 115/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 119/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 121/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 124/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 128/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 132/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 136/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 139/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 143/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 147/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 150/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 150/150uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0056s vs `on_train_batch_end` time: 0.0065s). Check your callbacks.
Epoch 3/15050uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 5/15050uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 8/15050uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 11/1500uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 15/1500uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 17/1500uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 21/1500uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 25/1500uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 29/1500uceLROnPlateau reducing learning rate to 0.008060445077717304.76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 35/150duceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 39/150duceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 43/150duceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 46/150duceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 49/150duceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 52/150duceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 56/150duceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 59/150duceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 62/150duceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 66/150duceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 69/150duceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 73/150duceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 76/150duceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 79/150duceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 83/150duceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 86/150duceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 89/150duceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 92/150duceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 96/150duceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 100/150uceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 103/150uceLROnPlateau reducing learning rate to 0.01612089015543461..76.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 106: ReduceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 110/150duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 1/15050duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 3/15050duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 7/15050duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 9/15050duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 13/1500duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 16/1500duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 19/1500duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 23/1500duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 27/1500duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 30/1500duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 33/1500duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 37/1500duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 41/1500duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 44/1500duceLROnPlateau reducing learning rate to 0.0005037778173573315..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 46: ReduceLROnPlateau reducing learning rate to 0.008060445077717304.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 50/150duceLROnPlateau reducing learning rate to 0.008060445077717304.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008060445077717304.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008060445077717304.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008060445077717304.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008060445077717304.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008060445077717304.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 72/150duceLROnPlateau reducing learning rate to 0.008060445077717304.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 75/150duceLROnPlateau reducing learning rate to 0.008060445077717304.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 78/150duceLROnPlateau reducing learning rate to 0.008060445077717304.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 82/150duceLROnPlateau reducing learning rate to 0.008060445077717304.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 85/150duceLROnPlateau reducing learning rate to 0.008060445077717304.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 89/150duceLROnPlateau reducing learning rate to 0.008060445077717304.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 91: ReduceLROnPlateau reducing learning rate to 0.001007555634714663.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 95/150duceLROnPlateau reducing learning rate to 0.001007555634714663.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 99/150duceLROnPlateau reducing learning rate to 0.001007555634714663.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 103/150uceLROnPlateau reducing learning rate to 0.001007555634714663.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 106/150uceLROnPlateau reducing learning rate to 0.001007555634714663.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 109/150uceLROnPlateau reducing learning rate to 0.001007555634714663.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 113/150uceLROnPlateau reducing learning rate to 0.001007555634714663.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 117/150uceLROnPlateau reducing learning rate to 0.001007555634714663.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 120/150uceLROnPlateau reducing learning rate to 0.001007555634714663.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 122/150uceLROnPlateau reducing learning rate to 0.001007555634714663.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 126/150uceLROnPlateau reducing learning rate to 0.001007555634714663.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 130/150uceLROnPlateau reducing learning rate to 0.001007555634714663.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 133/150uceLROnPlateau reducing learning rate to 0.001007555634714663.5..998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 136: ReduceLROnPlateau reducing learning rate to 0.00012594445433933288.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 140/150duceLROnPlateau reducing learning rate to 0.00012594445433933288.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
Epoch 144/150duceLROnPlateau reducing learning rate to 0.00012594445433933288.998 - mse: 0.1618 - root_mean_squared_error: 0.4022 - val_loss: 0.1623 - val_mae: 0.4004 - val_mse: 0.1623 - val_root_mean_squared_error: 0.4029 - lr: 0.00201004
81/81 [==============================] - 1s 7ms/step - loss: 0.6416 - mae: 0.7998 - mse: 0.6416 - root_mean_squared_error: 0.8010 - val_loss: 0.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
>Saved ../trained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 3/150rained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 6/150rained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 9/150rained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 12/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 16/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 19/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 23/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 26/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 30/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 32/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 36/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 40/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 44/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 46/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 49/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 53/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 57/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 61/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 64/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 68/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 71/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 75/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 77/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 81/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 85/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 88/150ained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 91: ReduceLROnPlateau reducing learning rate to 0.001007555634714663.558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 95/150duceLROnPlateau reducing learning rate to 0.001007555634714663.558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 99/150duceLROnPlateau reducing learning rate to 0.001007555634714663.558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 102/150uceLROnPlateau reducing learning rate to 0.001007555634714663.558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 106/150uceLROnPlateau reducing learning rate to 0.001007555634714663.558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 109/150uceLROnPlateau reducing learning rate to 0.001007555634714663.558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 113/150uceLROnPlateau reducing learning rate to 0.001007555634714663.558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 116/150uceLROnPlateau reducing learning rate to 0.001007555634714663.558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 120/150uceLROnPlateau reducing learning rate to 0.001007555634714663.558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 122/150uceLROnPlateau reducing learning rate to 0.001007555634714663.558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 126/150uceLROnPlateau reducing learning rate to 0.001007555634714663.558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 130/150uceLROnPlateau reducing learning rate to 0.001007555634714663.558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 133/150uceLROnPlateau reducing learning rate to 0.001007555634714663.558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 136: ReduceLROnPlateau reducing learning rate to 0.00012594445433933288.499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 140/150duceLROnPlateau reducing learning rate to 0.00012594445433933288.499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 144/150duceLROnPlateau reducing learning rate to 0.00012594445433933288.499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
Epoch 147/150duceLROnPlateau reducing learning rate to 0.00012594445433933288.499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_8.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
>Saved ../trained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_9.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04
>Saved ../trained_models/CNN/models_segments_overlap-cnn_adam_0.06448355821558499LR_[39]CHN_20CNNI_48BS_40DU_15P_val_mseM_150epochs/model_9.h50.6426 - val_mae: 0.8004 - val_mse: 0.6426 - val_root_mean_squared_error: 0.8016 - lr: 1.2594e-04