[[3.53506187e-06 7.85384079e-05 3.16658876e-04 ... 9.82961325e-05
  9.05030065e-06 2.12761417e-04]
 [4.85922918e-06 1.07957410e-04 4.35273300e-04 ... 1.35116004e-04
  1.24403721e-05 2.92457819e-04]
 [8.73413522e-06 1.94046130e-04 7.82374267e-04 ... 2.42861863e-04
  2.23607259e-05 5.25673116e-04]
 ...
 [2.81195597e-09 1.05684711e-07 7.95720129e-07 ... 1.63653769e-05
  3.05162050e-05 5.16527118e-05]
 [3.76663712e-09 1.41565501e-07 1.06587337e-06 ... 2.19215511e-05
  4.08766965e-05 6.91892136e-05]
 [4.92131791e-09 1.84963089e-07 1.39262199e-06 ... 2.86417083e-05
  5.34076451e-05 9.03995009e-05]]
[[0.8  ]
 [0.8  ]
 [0.8  ]
 ...
 [0.981]
 [0.981]
 [0.981]]
(5904, 8)
(1476, 8)
(5904, 8, 1)
(5904, 1)
(1476, 8, 1)
(1476, 1)
Epoch 1/150
WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
 63/738 [=>............................] - ETA: 21s - loss: 0.0238 - mae: 0.1073 - mse: 0.0238











737/738 [============================>.] - ETA: 0s - loss: 0.0131 - mae: 0.0945 - mse: 0.0131
738/738 [==============================] - 32s 42ms/step - loss: 0.0130 - mae: 0.0944 - mse: 0.0130 - val_loss: 0.0037 - val_mae: 0.0516 - val_mse: 0.0037 - lr: 0.0690
Epoch 2/150







737/738 [============================>.] - ETA: 0s - loss: 0.0036 - mae: 0.0514 - mse: 0.0036
738/738 [==============================] - 30s 40ms/step - loss: 0.0036 - mae: 0.0514 - mse: 0.0036 - val_loss: 0.0034 - val_mae: 0.0499 - val_mse: 0.0034 - lr: 0.0690
Epoch 3/150

736/738 [============================>.] - ETA: 0s - loss: 0.0035 - mae: 0.0514 - mse: 0.0035
738/738 [==============================] - 25s 34ms/step - loss: 0.0035 - mae: 0.0514 - mse: 0.0035 - val_loss: 0.0033 - val_mae: 0.0495 - val_mse: 0.0033 - lr: 0.0690
Epoch 4/150
737/738 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034
738/738 [==============================] - 24s 33ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - val_loss: 0.0029 - val_mae: 0.0465 - val_mse: 0.0029 - lr: 0.0690
Epoch 5/150








737/738 [============================>.] - ETA: 0s - loss: 0.0022 - mae: 0.0370 - mse: 0.0022
738/738 [==============================] - 32s 43ms/step - loss: 0.0022 - mae: 0.0370 - mse: 0.0022 - val_loss: 0.0015 - val_mae: 0.0278 - val_mse: 0.0015 - lr: 0.0690
Epoch 6/150

738/738 [==============================] - ETA: 0s - loss: 0.0015 - mae: 0.0297 - mse: 0.0015
738/738 [==============================] - 28s 38ms/step - loss: 0.0015 - mae: 0.0297 - mse: 0.0015 - val_loss: 0.0013 - val_mae: 0.0280 - val_mse: 0.0013 - lr: 0.0690
Epoch 7/150








738/738 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0271 - mse: 0.0013
738/738 [==============================] - 28s 38ms/step - loss: 0.0013 - mae: 0.0271 - mse: 0.0013 - val_loss: 0.0013 - val_mae: 0.0260 - val_mse: 0.0013 - lr: 0.0690
Epoch 8/150








738/738 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0254 - mse: 0.0012
738/738 [==============================] - 26s 36ms/step - loss: 0.0012 - mae: 0.0254 - mse: 0.0012 - val_loss: 0.0010 - val_mae: 0.0226 - val_mse: 0.0010 - lr: 0.0690
Epoch 9/150








738/738 [==============================] - 22s 30ms/step - loss: 0.0010 - mae: 0.0235 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0264 - val_mse: 0.0012 - lr: 0.0690
Epoch 10/150











738/738 [==============================] - ETA: 0s - loss: 9.8208e-04 - mae: 0.0231 - mse: 9.8208e-04
738/738 [==============================] - 27s 37ms/step - loss: 9.8208e-04 - mae: 0.0231 - mse: 9.8208e-04 - val_loss: 9.6882e-04 - val_mae: 0.0249 - val_mse: 9.6882e-04 - lr: 0.0690
Epoch 11/150









737/738 [============================>.] - ETA: 0s - loss: 9.2233e-04 - mae: 0.0226 - mse: 9.2233e-04
738/738 [==============================] - 29s 39ms/step - loss: 9.2181e-04 - mae: 0.0226 - mse: 9.2181e-04 - val_loss: 8.1278e-04 - val_mae: 0.0213 - val_mse: 8.1278e-04 - lr: 0.0690
Epoch 12/150








737/738 [============================>.] - ETA: 0s - loss: 8.5331e-04 - mae: 0.0216 - mse: 8.5331e-04
738/738 [==============================] - 24s 33ms/step - loss: 8.5290e-04 - mae: 0.0216 - mse: 8.5290e-04 - val_loss: 7.2647e-04 - val_mae: 0.0203 - val_mse: 7.2647e-04 - lr: 0.0690
Epoch 13/150








738/738 [==============================] - 21s 29ms/step - loss: 8.3711e-04 - mae: 0.0212 - mse: 8.3711e-04 - val_loss: 9.1011e-04 - val_mae: 0.0236 - val_mse: 9.1011e-04 - lr: 0.0690
Epoch 14/150









738/738 [==============================] - 21s 29ms/step - loss: 8.5179e-04 - mae: 0.0212 - mse: 8.5179e-04 - val_loss: 7.3741e-04 - val_mae: 0.0206 - val_mse: 7.3741e-04 - lr: 0.0690
Epoch 15/150









738/738 [==============================] - 21s 28ms/step - loss: 7.4642e-04 - mae: 0.0199 - mse: 7.4642e-04 - val_loss: 0.0013 - val_mae: 0.0319 - val_mse: 0.0013 - lr: 0.0690
Epoch 16/150










736/738 [============================>.] - ETA: 0s - loss: 6.6610e-04 - mae: 0.0185 - mse: 6.6610e-04
738/738 [==============================] - 23s 31ms/step - loss: 6.6591e-04 - mae: 0.0185 - mse: 6.6591e-04 - val_loss: 5.3144e-04 - val_mae: 0.0161 - val_mse: 5.3144e-04 - lr: 0.0690
Epoch 17/150








738/738 [==============================] - 20s 27ms/step - loss: 6.4945e-04 - mae: 0.0186 - mse: 6.4945e-04 - val_loss: 5.9606e-04 - val_mae: 0.0195 - val_mse: 5.9606e-04 - lr: 0.0690
Epoch 18/150









738/738 [==============================] - 21s 28ms/step - loss: 6.0670e-04 - mae: 0.0180 - mse: 6.0670e-04 - val_loss: 7.0607e-04 - val_mae: 0.0211 - val_mse: 7.0607e-04 - lr: 0.0690
Epoch 19/150










738/738 [==============================] - 21s 28ms/step - loss: 5.9277e-04 - mae: 0.0175 - mse: 5.9277e-04 - val_loss: 7.3481e-04 - val_mae: 0.0192 - val_mse: 7.3481e-04 - lr: 0.0690
Epoch 20/150









738/738 [==============================] - 20s 28ms/step - loss: 5.4704e-04 - mae: 0.0168 - mse: 5.4704e-04 - val_loss: 5.8055e-04 - val_mae: 0.0149 - val_mse: 5.8055e-04 - lr: 0.0690
Epoch 21/150









738/738 [==============================] - ETA: 0s - loss: 4.7601e-04 - mae: 0.0157 - mse: 4.7601e-04
738/738 [==============================] - 24s 33ms/step - loss: 4.7601e-04 - mae: 0.0157 - mse: 4.7601e-04 - val_loss: 5.1676e-04 - val_mae: 0.0155 - val_mse: 5.1676e-04 - lr: 0.0690
Epoch 22/150








737/738 [============================>.] - ETA: 0s - loss: 4.4652e-04 - mae: 0.0150 - mse: 4.4652e-04
738/738 [==============================] - 24s 32ms/step - loss: 4.4637e-04 - mae: 0.0150 - mse: 4.4637e-04 - val_loss: 3.4518e-04 - val_mae: 0.0137 - val_mse: 3.4518e-04 - lr: 0.0690
Epoch 23/150








738/738 [==============================] - 20s 28ms/step - loss: 0.0011 - mae: 0.0229 - mse: 0.0011 - val_loss: 4.7265e-04 - val_mae: 0.0145 - val_mse: 4.7265e-04 - lr: 0.0690
Epoch 24/150









738/738 [==============================] - 21s 28ms/step - loss: 4.5369e-04 - mae: 0.0150 - mse: 4.5369e-04 - val_loss: 4.2262e-04 - val_mae: 0.0147 - val_mse: 4.2262e-04 - lr: 0.0690
Epoch 25/150










738/738 [==============================] - 21s 28ms/step - loss: 4.0793e-04 - mae: 0.0142 - mse: 4.0793e-04 - val_loss: 5.4537e-04 - val_mae: 0.0162 - val_mse: 5.4537e-04 - lr: 0.0690
Epoch 26/150









738/738 [==============================] - 21s 28ms/step - loss: 5.4810e-04 - mae: 0.0157 - mse: 5.4810e-04 - val_loss: 6.0990e-04 - val_mae: 0.0181 - val_mse: 6.0990e-04 - lr: 0.0690
Epoch 27/150









737/738 [============================>.] - ETA: 0s - loss: 3.4879e-04 - mae: 0.0132 - mse: 3.4879e-04
738/738 [==============================] - 24s 33ms/step - loss: 3.4896e-04 - mae: 0.0132 - mse: 3.4896e-04 - val_loss: 2.5243e-04 - val_mae: 0.0114 - val_mse: 2.5243e-04 - lr: 0.0690
Epoch 28/150







738/738 [==============================] - 20s 28ms/step - loss: 3.2007e-04 - mae: 0.0128 - mse: 3.2007e-04 - val_loss: 3.5961e-04 - val_mae: 0.0152 - val_mse: 3.5961e-04 - lr: 0.0690
Epoch 29/150









738/738 [==============================] - 20s 27ms/step - loss: 3.4645e-04 - mae: 0.0132 - mse: 3.4645e-04 - val_loss: 2.6179e-04 - val_mae: 0.0108 - val_mse: 2.6179e-04 - lr: 0.0690
Epoch 30/150









738/738 [==============================] - 20s 27ms/step - loss: 4.0713e-04 - mae: 0.0140 - mse: 4.0713e-04 - val_loss: 8.6375e-04 - val_mae: 0.0191 - val_mse: 8.6375e-04 - lr: 0.0690
Epoch 31/150










738/738 [==============================] - 21s 29ms/step - loss: 3.0093e-04 - mae: 0.0122 - mse: 3.0093e-04 - val_loss: 4.8049e-04 - val_mae: 0.0148 - val_mse: 4.8049e-04 - lr: 0.0690
Epoch 32/150









738/738 [==============================] - 20s 27ms/step - loss: 3.3056e-04 - mae: 0.0132 - mse: 3.3056e-04 - val_loss: 2.7423e-04 - val_mae: 0.0116 - val_mse: 2.7423e-04 - lr: 0.0690
Epoch 33/150









738/738 [==============================] - 20s 28ms/step - loss: 2.6328e-04 - mae: 0.0117 - mse: 2.6328e-04 - val_loss: 8.4008e-04 - val_mae: 0.0245 - val_mse: 8.4008e-04 - lr: 0.0690
Epoch 34/150









738/738 [==============================] - 21s 28ms/step - loss: 2.4305e-04 - mae: 0.0113 - mse: 2.4305e-04 - val_loss: 3.0166e-04 - val_mae: 0.0124 - val_mse: 3.0166e-04 - lr: 0.0690
Epoch 35/150










737/738 [============================>.] - ETA: 0s - loss: 2.8917e-04 - mae: 0.0124 - mse: 2.8917e-04
738/738 [==============================] - 24s 32ms/step - loss: 2.8896e-04 - mae: 0.0124 - mse: 2.8896e-04 - val_loss: 2.0808e-04 - val_mae: 0.0111 - val_mse: 2.0808e-04 - lr: 0.0690
Epoch 36/150








738/738 [==============================] - 21s 28ms/step - loss: 3.6401e-04 - mae: 0.0133 - mse: 3.6401e-04 - val_loss: 2.6145e-04 - val_mae: 0.0109 - val_mse: 2.6145e-04 - lr: 0.0690
Epoch 37/150










738/738 [==============================] - ETA: 0s - loss: 2.3244e-04 - mae: 0.0110 - mse: 2.3244e-04
738/738 [==============================] - 24s 33ms/step - loss: 2.3244e-04 - mae: 0.0110 - mse: 2.3244e-04 - val_loss: 1.4675e-04 - val_mae: 0.0091 - val_mse: 1.4675e-04 - lr: 0.0690
Epoch 38/150
248/738 [=========>....................] - ETA: 12s - loss: 2.2610e-04 - mae: 0.0108 - mse: 2.2610e-04
327/738 [============>.................] - ETA: 10s - loss: 2.1793e-04 - mae: 0.0106 - mse: 2.1793e-04
406/738 [===============>..............] - ETA: 8s - loss: 2.3842e-04 - mae: 0.0111 - mse: 2.3842e-04
488/738 [==================>...........] - ETA: 6s - loss: 2.3133e-04 - mae: 0.0109 - mse: 2.3133e-04
569/738 [======================>.......] - ETA: 4s - loss: 2.2915e-04 - mae: 0.0108 - mse: 2.2915e-04
647/738 [=========================>....] - ETA: 2s - loss: 2.3524e-04 - mae: 0.0108 - mse: 2.3524e-04
726/738 [============================>.] - ETA: 0s - loss: 2.3320e-04 - mae: 0.0108 - mse: 2.3320e-04
738/738 [==============================] - 21s 28ms/step - loss: 2.3317e-04 - mae: 0.0108 - mse: 2.3317e-04 - val_loss: 1.5403e-04 - val_mae: 0.0083 - val_mse: 1.5403e-04 - lr: 0.0690
 73/738 [=>............................] - ETA: 18s - loss: 1.9842e-04 - mae: 0.0104 - mse: 1.9842e-047e-04 - val_loss: 1.5403e-04 - val_mae: 0.0083 - val_mse: 1.5403e-04 - lr: 0.0690
151/738 [=====>........................] - ETA: 15s - loss: 0.0015 - mae: 0.0199 - mse: 0.0015        7e-04 - val_loss: 1.5403e-04 - val_mae: 0.0083 - val_mse: 1.5403e-04 - lr: 0.0690
231/738 [========>.....................] - ETA: 13s - loss: 0.0058 - mae: 0.0486 - mse: 0.0058        7e-04 - val_loss: 1.5403e-04 - val_mae: 0.0083 - val_mse: 1.5403e-04 - lr: 0.0690
313/738 [===========>..................] - ETA: 11s - loss: 0.0079 - mae: 0.0620 - mse: 0.0079        7e-04 - val_loss: 1.5403e-04 - val_mae: 0.0083 - val_mse: 1.5403e-04 - lr: 0.0690
374/738 [==============>...............] - ETA: 9s - loss: 0.0088 - mae: 0.0684 - mse: 0.0088         7e-04 - val_loss: 1.5403e-04 - val_mae: 0.0083 - val_mse: 1.5403e-04 - lr: 0.0690
454/738 [=================>............] - ETA: 7s - loss: 0.0097 - mae: 0.0742 - mse: 0.0097         7e-04 - val_loss: 1.5403e-04 - val_mae: 0.0083 - val_mse: 1.5403e-04 - lr: 0.0690
537/738 [====================>.........] - ETA: 5s - loss: 0.0101 - mae: 0.0775 - mse: 0.0101         7e-04 - val_loss: 1.5403e-04 - val_mae: 0.0083 - val_mse: 1.5403e-04 - lr: 0.0690
619/738 [========================>.....] - ETA: 3s - loss: 0.0105 - mae: 0.0805 - mse: 0.0105         7e-04 - val_loss: 1.5403e-04 - val_mae: 0.0083 - val_mse: 1.5403e-04 - lr: 0.0690
700/738 [===========================>..] - ETA: 0s - loss: 0.0108 - mae: 0.0825 - mse: 0.0108         7e-04 - val_loss: 1.5403e-04 - val_mae: 0.0083 - val_mse: 1.5403e-04 - lr: 0.0690
737/738 [============================>.] - ETA: 0s - loss: 0.0109 - mae: 0.0833 - mse: 0.0109         7e-04 - val_loss: 1.5403e-04 - val_mae: 0.0083 - val_mse: 1.5403e-04 - lr: 0.0690
 54/738 [=>............................] - ETA: 17s - loss: 0.0139 - mae: 0.1013 - mse: 0.0139.0109 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
135/738 [====>.........................] - ETA: 15s - loss: 0.0135 - mae: 0.1000 - mse: 0.0135.0109 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
216/738 [=======>......................] - ETA: 13s - loss: 0.0132 - mae: 0.0990 - mse: 0.0132.0109 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
298/738 [===========>..................] - ETA: 11s - loss: 0.0132 - mae: 0.0990 - mse: 0.0132.0109 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
382/738 [==============>...............] - ETA: 8s - loss: 0.0134 - mae: 0.0999 - mse: 0.0134 .0109 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
464/738 [=================>............] - ETA: 6s - loss: 0.0134 - mae: 0.1000 - mse: 0.0134 .0109 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
544/738 [=====================>........] - ETA: 4s - loss: 0.0135 - mae: 0.1005 - mse: 0.0135 .0109 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
603/738 [=======================>......] - ETA: 3s - loss: 0.0135 - mae: 0.1004 - mse: 0.0135 .0109 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
669/738 [==========================>...] - ETA: 1s - loss: 0.0134 - mae: 0.1001 - mse: 0.0134 .0109 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
737/738 [============================>.] - ETA: 0s - loss: 0.0134 - mae: 0.1000 - mse: 0.0134 .0109 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
 11/738 [..............................] - ETA: 18s - loss: 0.0137 - mae: 0.0997 - mse: 0.0137.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
 92/738 [==>...........................] - ETA: 16s - loss: 0.0134 - mae: 0.0995 - mse: 0.0134.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
175/738 [======>.......................] - ETA: 14s - loss: 0.0137 - mae: 0.1012 - mse: 0.0137.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
256/738 [=========>....................] - ETA: 12s - loss: 0.0135 - mae: 0.1000 - mse: 0.0135.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
338/738 [============>.................] - ETA: 10s - loss: 0.0137 - mae: 0.1015 - mse: 0.0137.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
420/738 [================>.............] - ETA: 7s - loss: 0.0137 - mae: 0.1013 - mse: 0.0137 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
500/738 [===================>..........] - ETA: 5s - loss: 0.0136 - mae: 0.1009 - mse: 0.0136 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
579/738 [======================>.......] - ETA: 4s - loss: 0.0135 - mae: 0.1004 - mse: 0.0135 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
656/738 [=========================>....] - ETA: 2s - loss: 0.0135 - mae: 0.1002 - mse: 0.0135 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
708/738 [===========================>..] - ETA: 0s - loss: 0.0134 - mae: 0.0999 - mse: 0.0134 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
737/738 [============================>.] - ETA: 0s - loss: 0.0134 - mae: 0.1000 - mse: 0.0134 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
 59/738 [=>............................] - ETA: 17s - loss: 0.0133 - mae: 0.1000 - mse: 0.0133.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
138/738 [====>.........................] - ETA: 15s - loss: 0.0131 - mae: 0.0989 - mse: 0.0131.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
219/738 [=======>......................] - ETA: 13s - loss: 0.0131 - mae: 0.0987 - mse: 0.0131.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
301/738 [===========>..................] - ETA: 11s - loss: 0.0132 - mae: 0.0991 - mse: 0.0132.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
382/738 [==============>...............] - ETA: 9s - loss: 0.0131 - mae: 0.0985 - mse: 0.0131 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
459/738 [=================>............] - ETA: 7s - loss: 0.0132 - mae: 0.0992 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
536/738 [====================>.........] - ETA: 5s - loss: 0.0133 - mae: 0.0993 - mse: 0.0133 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
615/738 [========================>.....] - ETA: 3s - loss: 0.0133 - mae: 0.0997 - mse: 0.0133 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
697/738 [===========================>..] - ETA: 1s - loss: 0.0134 - mae: 0.0997 - mse: 0.0134 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
736/738 [============================>.] - ETA: 0s - loss: 0.0134 - mae: 0.0999 - mse: 0.0134 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
 57/738 [=>............................] - ETA: 16s - loss: 0.0134 - mae: 0.1001 - mse: 0.0134.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
118/738 [===>..........................] - ETA: 15s - loss: 0.0132 - mae: 0.0986 - mse: 0.0132.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
196/738 [======>.......................] - ETA: 13s - loss: 0.0136 - mae: 0.1007 - mse: 0.0136.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
272/738 [==========>...................] - ETA: 11s - loss: 0.0133 - mae: 0.0992 - mse: 0.0133.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
356/738 [=============>................] - ETA: 9s - loss: 0.0132 - mae: 0.0987 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
437/738 [================>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
437/738 [================>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
437/738 [================>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
437/738 [================>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
437/738 [================>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 44/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 44/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 44/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 44/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 44/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 44/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 44/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 44/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 44/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 44/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 45/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 45/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 45/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 45/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 45/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 45/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 45/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 45/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 45/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 45/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 45/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 46/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 46/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 46/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 46/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 46/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 46/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 46/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 46/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 46/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 46/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 47/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 47/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 47/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 47/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 47/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 47/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 47/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 47/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 47/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 47/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 47/150=============>.............] - ETA: 7s - loss: 0.0132 - mae: 0.0989 - mse: 0.0132 .0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
 72/738 [=>............................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
 72/738 [=>............................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
 72/738 [=>............................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
 72/738 [=>............................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
 72/738 [=>............................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
 72/738 [=>............................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
 72/738 [=>............................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
 72/738 [=>............................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
 72/738 [=>............................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
 72/738 [=>............................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 49/150...........................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 49/150...........................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 49/150...........................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 49/150...........................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 49/150...........................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 49/150...........................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 49/150...........................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 49/150...........................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 49/150...........................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 49/150...........................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 50/150...........................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 50/150...........................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 50/150...........................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 50/150...........................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 50/150...........................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 50/150...........................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 50/150...........................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 50/150...........................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 50/150...........................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 50/150...........................] - ETA: 18s - loss: 0.0140 - mae: 0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 51/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 51/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 51/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 51/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 51/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 51/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 51/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 51/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 51/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 51/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 52/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 52/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 52/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 52/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 52/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 52/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 52/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 52/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 52/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 52/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 53/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 53/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 53/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 53/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 53/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 53/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 53/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 53/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 53/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 53/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 53/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 54/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 54/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 54/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 54/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 54/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 54/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 54/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 54/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 54/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 54/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 55/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 55/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 55/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 55/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 55/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 55/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 55/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 55/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 55/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 55/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 56/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 56/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 56/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 56/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 56/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 56/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 56/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 56/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 56/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 56/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 56/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 57/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 57/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 57/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 57/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 57/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 57/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 57/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 57/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 57/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 57/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 57/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 57/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 58/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 58/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 58/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 58/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 58/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 58/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 58/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 58/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 58/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 58/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 58/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 58/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 59/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 59/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 59/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 59/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 59/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 59/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 59/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 59/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 59/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 59/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 59/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 60/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 60/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 60/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 60/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 60/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 60/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 60/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 60/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 60/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 60/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 61/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 61/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 61/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 61/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 61/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 61/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 61/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 61/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 61/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 61/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 62/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 62/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 62/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 62/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 62/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 62/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 62/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 62/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 62/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 62/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 62/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 63/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 63/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 63/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 63/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 63/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 63/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 63/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 63/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 63/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 63/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 63/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 64/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 64/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 64/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 64/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 64/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 64/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 64/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 64/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 64/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 64/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 65/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 65/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 65/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 65/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 65/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 65/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 65/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 65/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 65/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 65/150duceLROnPlateau reducing learning rate to 0.03448000177741051.0.1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 66/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 66/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 66/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 66/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 66/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 66/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 66/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 66/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 66/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 66/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 67/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 67/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 67/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 67/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 67/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 67/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 67/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 67/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 67/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 67/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 68/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 68/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 68/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 68/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 68/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 68/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 68/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 68/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 68/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 68/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 68/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 68/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 69/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 69/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 69/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 69/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 69/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 69/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 69/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 69/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 69/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 69/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 69/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 70/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 70/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 70/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 70/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 70/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 70/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 70/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 70/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 70/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 70/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 71/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 71/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 71/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 71/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 71/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 71/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 71/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 71/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 71/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 71/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 71/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 72/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 72/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 72/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 72/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 72/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 72/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 72/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 72/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 72/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 72/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 73/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 73/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 73/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 73/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 73/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 73/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 73/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 73/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 73/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 73/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 73/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 74/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 74/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 74/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 74/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 74/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 74/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 74/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 74/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 74/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 74/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 74/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 75/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 75/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 75/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 75/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 75/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 75/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 75/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 75/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 75/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 75/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 76/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 76/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 76/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 76/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 76/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 76/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 76/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 76/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 76/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 76/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 77/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 77/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 77/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 77/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 77/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 77/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 77/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 77/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 77/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 77/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 78/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 78/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 78/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 78/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 78/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 78/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 78/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 78/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 78/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 78/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 78/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 79/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 79/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 79/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 79/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 79/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 79/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 79/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 79/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 79/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 79/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 79/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 80/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 80/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 80/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 80/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 80/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 80/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 80/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 80/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 80/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 80/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 80/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 80/150duceLROnPlateau reducing learning rate to 0.017240000888705254..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 81/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 81/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 81/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 81/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 81/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 81/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 81/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 81/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 81/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 81/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 81/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 81/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 82/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 82/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 82/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 82/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 82/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 82/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 82/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 82/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 82/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 82/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 82/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 83/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 83/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 83/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 83/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 83/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 83/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 83/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 83/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 83/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 83/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 83/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 83/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 84/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 84/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 84/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 84/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 84/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 84/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 84/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 84/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 84/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 84/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 84/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 85/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 85/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 85/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 85/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 85/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 85/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 85/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 85/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 85/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 85/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 85/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 85/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 86/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 86/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 86/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 86/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 86/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 86/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 86/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 86/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 86/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 86/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 86/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 86/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 86/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 87/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 87/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 87/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 87/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 87/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 87/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 87/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 87/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 87/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 87/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 88/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 88/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 88/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 88/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 88/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 88/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 88/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 88/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 88/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 88/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 88/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 88/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 89/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 89/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 89/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 89/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 89/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 89/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 89/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 89/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 89/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 89/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 89/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 89/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 90/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 90/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 90/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 90/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 90/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 90/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 90/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 90/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 90/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 90/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 90/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 90/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 91/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 91/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 91/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 91/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 91/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 91/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 91/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 91/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 91/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 91/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 91/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 91/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 91/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 92/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 92/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 92/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 92/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 92/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 92/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 92/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 92/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 92/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 92/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 92/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 92/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 92/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 92/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 93/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 93/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 93/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 93/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 93/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 93/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 93/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 93/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 93/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 93/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 93/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 93/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 93/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 93/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 94/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 94/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 94/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 94/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 94/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 94/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 94/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 94/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 94/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 94/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 94/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 94/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 94/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 94/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 95/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 95/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 95/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 95/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 95/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 95/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 95/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 95/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 95/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 95/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 95/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 95/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 95/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 95/150duceLROnPlateau reducing learning rate to 0.008620000444352627..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 96/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 96/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 96/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 96/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 96/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 96/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 96/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 96/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 96/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 96/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 96/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 96/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 96/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 96/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 97/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 97/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 97/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 97/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 97/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 97/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 97/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 97/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 97/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 97/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 97/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 97/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 97/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 97/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 98/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 98/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 98/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 98/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 98/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 98/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 98/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 98/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 98/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 98/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 98/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 98/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 98/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 98/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 99/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 99/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 99/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 99/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 99/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 99/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 99/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 99/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 99/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 99/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 99/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 99/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 99/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 99/150duceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 100/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 100/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 100/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 100/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 100/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 100/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 100/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 100/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 100/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 100/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 100/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 100/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 100/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 101/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 101/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 101/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 101/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 101/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 101/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 101/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 101/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 101/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 101/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 101/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 101/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 101/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 102/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 102/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 102/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 102/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 102/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 102/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 102/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 102/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 102/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 102/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 102/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 103/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 103/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 103/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 103/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 103/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 103/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 103/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 103/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 103/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 103/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 104/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 104/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 104/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 104/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 104/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 104/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 104/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 104/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 104/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 104/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 105/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 105/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 105/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 105/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 105/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 105/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 105/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 105/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 105/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 105/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 105/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 105/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 106/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 106/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 106/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 106/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 106/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 106/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 106/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 106/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 106/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 106/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 106/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 106/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 106/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 107/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 107/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 107/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 107/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 107/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 107/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 107/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 107/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 107/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 107/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 107/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 107/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 108/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 108/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 108/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 108/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 108/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 108/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 108/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 108/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 108/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 108/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 108/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 108/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 109/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 109/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 109/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 109/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 109/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 109/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 109/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 109/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 109/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 109/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 109/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 109/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 110/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 110/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 110/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 110/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 110/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 110/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 110/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 110/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 110/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 110/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 110/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 110/150uceLROnPlateau reducing learning rate to 0.004310000222176313..1030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 111/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 111/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 111/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 111/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 111/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 111/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 111/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 111/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 111/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 111/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 111/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 112/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 112/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 112/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 112/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 112/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 112/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 112/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 112/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 112/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 112/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 112/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 112/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 113/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 113/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 113/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 113/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 113/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 113/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 113/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 113/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 113/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 113/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 113/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0021550001110881567.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0010775000555440784.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.030 - mse: 0.0140.0134 - val_loss: 0.0133 - val_mae: 0.0998 - val_mse: 0.0133 - lr: 0.0690-04 - lr: 0.0690
>Saved ../../trained_models/RNN/models_segments_overlap-14-LSTM-BI_adam_0.06896LR_[10]HL8DU_8BS_['sigmoid', 'tanh', 'tanh']_15P_val_mseM_8DU_150epochs/model_12.h5.0690-04 - lr: 0.0690
>Saved ../../trained_models/RNN/models_segments_overlap-14-LSTM-BI_adam_0.06896LR_[10]HL8DU_8BS_['sigmoid', 'tanh', 'tanh']_15P_val_mseM_8DU_150epochs/model_12.h5.0690-04 - lr: 0.0690