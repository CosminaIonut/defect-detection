Epoch 1/30
215/243 [=========================>....] - ETA: 0s - loss: 0.1345 - mae: 0.0517 - mse: 0.0059
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
243/243 [==============================] - 2s 8ms/step - loss: 0.1195 - mae: 0.0502 - mse: 0.0055 - val_loss: 0.0040 - val_mae: 0.0437 - val_mse: 0.0029 - lr: 0.0099
Epoch 2/30
215/243 [=========================>....] - ETA: 0s - loss: 0.0029 - mae: 0.0396 - mse: 0.0023
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_155308-k7hwqa6e\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 7ms/step - loss: 0.0029 - mae: 0.0394 - mse: 0.0023 - val_loss: 0.0031 - val_mae: 0.0401 - val_mse: 0.0024 - lr: 0.0099
Epoch 3/30
243/243 [==============================] - 1s 6ms/step - loss: 0.0026 - mae: 0.0386 - mse: 0.0021 - val_loss: 0.0023 - val_mae: 0.0373 - val_mse: 0.0019 - lr: 0.0099
Epoch 4/30
238/243 [============================>.] - ETA: 0s - loss: 0.0023 - mae: 0.0369 - mse: 0.0019
243/243 [==============================] - 2s 6ms/step - loss: 0.0023 - mae: 0.0369 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0353 - val_mse: 0.0017 - lr: 0.0099
Epoch 5/30
227/243 [===========================>..] - ETA: 0s - loss: 0.0021 - mae: 0.0357 - mse: 0.0018
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_155308-k7hwqa6e\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 7ms/step - loss: 0.0021 - mae: 0.0355 - mse: 0.0018 - val_loss: 0.0020 - val_mae: 0.0344 - val_mse: 0.0016 - lr: 0.0099
Epoch 6/30
243/243 [==============================] - 1s 6ms/step - loss: 0.0021 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0333 - val_mse: 0.0016 - lr: 0.0099
Epoch 7/30
243/243 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0335 - mse: 0.0016 - val_loss: 0.0020 - val_mae: 0.0349 - val_mse: 0.0017 - lr: 0.0099
Epoch 8/30
213/243 [=========================>....] - ETA: 0s - loss: 0.0018 - mae: 0.0318 - mse: 0.0015
243/243 [==============================] - 2s 6ms/step - loss: 0.0018 - mae: 0.0317 - mse: 0.0015 - val_loss: 0.0017 - val_mae: 0.0314 - val_mse: 0.0015 - lr: 0.0099
Epoch 9/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0298 - mse: 0.0014 - val_loss: 0.0018 - val_mae: 0.0308 - val_mse: 0.0014 - lr: 0.0099
Epoch 10/30
230/243 [===========================>..] - ETA: 0s - loss: 0.0017 - mae: 0.0293 - mse: 0.0013
243/243 [==============================] - 2s 6ms/step - loss: 0.0017 - mae: 0.0291 - mse: 0.0013 - val_loss: 0.0016 - val_mae: 0.0277 - val_mse: 0.0012 - lr: 0.0099
Epoch 11/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0281 - mse: 0.0012 - val_loss: 0.0020 - val_mae: 0.0335 - val_mse: 0.0017 - lr: 0.0099
Epoch 12/30
218/243 [=========================>....] - ETA: 0s - loss: 0.0016 - mae: 0.0277 - mse: 0.0012
243/243 [==============================] - 1s 6ms/step - loss: 0.0016 - mae: 0.0277 - mse: 0.0012 - val_loss: 0.0015 - val_mae: 0.0271 - val_mse: 0.0012 - lr: 0.0099
Epoch 13/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0265 - mse: 0.0011 - val_loss: 0.0016 - val_mae: 0.0290 - val_mse: 0.0013 - lr: 0.0099
Epoch 14/30
233/243 [===========================>..] - ETA: 0s - loss: 0.0015 - mae: 0.0265 - mse: 0.0011
243/243 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0265 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0240 - val_mse: 9.3611e-04 - lr: 0.0099
Epoch 15/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0017 - val_mae: 0.0294 - val_mse: 0.0014 - lr: 0.0099
Epoch 16/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0258 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0251 - val_mse: 0.0010 - lr: 0.0099
Epoch 17/30
240/243 [============================>.] - ETA: 0s - loss: 0.0014 - mae: 0.0256 - mse: 0.0011
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_155308-k7hwqa6e\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0255 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0238 - val_mse: 9.2623e-04 - lr: 0.0099
Epoch 18/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0255 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0242 - val_mse: 9.4559e-04 - lr: 0.0099
Epoch 19/30
184/243 [=====================>........] - ETA: 0s - loss: 0.0013 - mae: 0.0251 - mse: 0.0010
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.004933531861752272.
243/243 [==============================] - 1s 2ms/step - loss: 0.0013 - mae: 0.0249 - mse: 0.0010 - val_loss: 0.0019 - val_mae: 0.0324 - val_mse: 0.0017 - lr: 0.0099
Epoch 20/30
243/243 [==============================] - 2s 6ms/step - loss: 0.0011 - mae: 0.0237 - mse: 9.3175e-04 - val_loss: 0.0011 - val_mae: 0.0238 - val_mse: 9.2000e-04 - lr: 0.0049
Epoch 21/30
216/243 [=========================>....] - ETA: 0s - loss: 0.0010 - mae: 0.0232 - mse: 8.8491e-04
243/243 [==============================] - 2s 8ms/step - loss: 0.0011 - mae: 0.0235 - mse: 9.1041e-04 - val_loss: 0.0010 - val_mae: 0.0231 - val_mse: 8.7090e-04 - lr: 0.0049
Epoch 22/30
243/243 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0232 - mse: 8.8986e-04 - val_loss: 0.0013 - val_mae: 0.0266 - val_mse: 0.0011 - lr: 0.0049
Epoch 23/30
243/243 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0233 - mse: 8.9301e-04 - val_loss: 0.0010 - val_mae: 0.0232 - val_mse: 8.7707e-04 - lr: 0.0049
Epoch 24/30
203/243 [========================>.....] - ETA: 0s - loss: 0.0010 - mae: 0.0232 - mse: 8.9670e-04
243/243 [==============================] - 1s 5ms/step - loss: 0.0010 - mae: 0.0233 - mse: 8.9482e-04 - val_loss: 9.9871e-04 - val_mae: 0.0231 - val_mse: 8.7466e-04 - lr: 0.0049
Epoch 25/30
233/243 [===========================>..] - ETA: 0s - loss: 0.0010 - mae: 0.0230 - mse: 8.8318e-04
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.002466765930876136.
243/243 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0230 - mse: 8.8154e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.0463e-04 - lr: 0.0049
Epoch 26/30
202/243 [=======================>......] - ETA: 0s - loss: 9.7248e-04 - mae: 0.0227 - mse: 8.5136e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_155308-k7hwqa6e\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 5ms/step - loss: 9.5475e-04 - mae: 0.0224 - mse: 8.3498e-04 - val_loss: 9.8100e-04 - val_mae: 0.0235 - val_mse: 8.7564e-04 - lr: 0.0025
Epoch 27/30
211/243 [=========================>....] - ETA: 0s - loss: 9.2957e-04 - mae: 0.0222 - mse: 8.1410e-04
243/243 [==============================] - 1s 6ms/step - loss: 9.4233e-04 - mae: 0.0223 - mse: 8.2682e-04 - val_loss: 9.6873e-04 - val_mae: 0.0235 - val_mse: 8.7535e-04 - lr: 0.0025
Epoch 28/30
243/243 [==============================] - 0s 2ms/step - loss: 9.3927e-04 - mae: 0.0224 - mse: 8.2905e-04 - val_loss: 0.0010 - val_mae: 0.0234 - val_mse: 8.8822e-04 - lr: 0.0025
Epoch 29/30
243/243 [==============================] - 0s 2ms/step - loss: 9.3555e-04 - mae: 0.0224 - mse: 8.2755e-04 - val_loss: 0.0011 - val_mae: 0.0242 - val_mse: 9.3745e-04 - lr: 0.0025
Epoch 30/30
243/243 [==============================] - 2s 6ms/step - loss: 9.2791e-04 - mae: 0.0223 - mse: 8.2158e-04 - val_loss: 9.1790e-04 - val_mae: 0.0225 - val_mse: 8.0597e-04 - lr: 0.0025
>Saved ../trained_models/models_segments_overlap_rmsprop_0.0098670635193028LR_[70]HN_16BS_5P_val_lossM_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0851 - mae: 0.0558 - mse: 0.0047 - val_loss: 0.0039 - val_mae: 0.0489 - val_mse: 0.0032 - lr: 0.0099
Epoch 2/30
323/323 [==============================] - 1s 2ms/step - loss: 0.0041 - mae: 0.0514 - mse: 0.0036 - val_loss: 0.0036 - val_mae: 0.0483 - val_mse: 0.0032 - lr: 0.0099
Epoch 3/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0479 - mse: 0.0032 - val_loss: 0.0032 - val_mae: 0.0438 - val_mse: 0.0028 - lr: 0.0099
Epoch 4/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0033 - mae: 0.0438 - mse: 0.0028 - val_loss: 0.0028 - val_mae: 0.0389 - val_mse: 0.0023 - lr: 0.0099
Epoch 5/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0403 - mse: 0.0025 - val_loss: 0.0038 - val_mae: 0.0461 - val_mse: 0.0030 - lr: 0.0099
Epoch 6/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0027 - mae: 0.0379 - mse: 0.0022 - val_loss: 0.0026 - val_mae: 0.0366 - val_mse: 0.0021 - lr: 0.0099
Epoch 7/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0363 - mse: 0.0021 - val_loss: 0.0023 - val_mae: 0.0334 - val_mse: 0.0018 - lr: 0.0099
Epoch 8/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0361 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0313 - val_mse: 0.0016 - lr: 0.0099
Epoch 9/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0025 - mae: 0.0353 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0389 - val_mse: 0.0023 - lr: 0.0099
Epoch 10/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0353 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0309 - val_mse: 0.0016 - lr: 0.0099
Epoch 11/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0345 - mse: 0.0019 - val_loss: 0.0029 - val_mae: 0.0391 - val_mse: 0.0023 - lr: 0.0099
Epoch 12/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0339 - mse: 0.0018 - val_loss: 0.0019 - val_mae: 0.0298 - val_mse: 0.0015 - lr: 0.0099
Epoch 13/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0337 - mse: 0.0018 - val_loss: 0.0020 - val_mae: 0.0318 - val_mse: 0.0016 - lr: 0.0099
Epoch 14/30
323/323 [==============================] - 1s 2ms/step - loss: 0.0022 - mae: 0.0333 - mse: 0.0018 - val_loss: 0.0019 - val_mae: 0.0288 - val_mse: 0.0014 - lr: 0.0099
Epoch 15/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0326 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0289 - val_mse: 0.0014 - lr: 0.0099
Epoch 16/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0329 - mse: 0.0018 - val_loss: 0.0020 - val_mae: 0.0286 - val_mse: 0.0014 - lr: 0.0099
Epoch 17/30
299/323 [==========================>...] - ETA: 0s - loss: 0.0021 - mae: 0.0320 - mse: 0.0017
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.004933531861752272.
323/323 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0319 - mse: 0.0017 - val_loss: 0.0022 - val_mae: 0.0318 - val_mse: 0.0017 - lr: 0.0099
Epoch 18/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0290 - mse: 0.0014 - val_loss: 0.0017 - val_mae: 0.0285 - val_mse: 0.0014 - lr: 0.0049
Epoch 19/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0293 - mse: 0.0015 - val_loss: 0.0016 - val_mae: 0.0271 - val_mse: 0.0013 - lr: 0.0049
Epoch 20/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0290 - mse: 0.0014 - val_loss: 0.0017 - val_mae: 0.0285 - val_mse: 0.0014 - lr: 0.0049
Epoch 21/30
323/323 [==============================] - 1s 2ms/step - loss: 0.0017 - mae: 0.0288 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0264 - val_mse: 0.0013 - lr: 0.0049
Epoch 22/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0286 - mse: 0.0014 - val_loss: 0.0020 - val_mae: 0.0325 - val_mse: 0.0017 - lr: 0.0049
Epoch 23/30
238/323 [=====================>........] - ETA: 0s - loss: 0.0016 - mae: 0.0283 - mse: 0.0014
323/323 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0281 - mse: 0.0014 - val_loss: 0.0014 - val_mae: 0.0254 - val_mse: 0.0012 - lr: 0.0049
Epoch 25/30
305/323 [===========================>..] - ETA: 0s - loss: 0.0016 - mae: 0.0279 - mse: 0.0014
323/323 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0277 - mse: 0.0013 - val_loss: 0.0026 - val_mae: 0.0402 - val_mse: 0.0024 - lr: 0.0049
Epoch 28/30
126/323 [==========>...................] - ETA: 0s - loss: 0.0016 - mae: 0.0278 - mse: 0.0013
323/323 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0274 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0250 - val_mse: 0.0012 - lr: 0.0049
Epoch 30/30
323/323 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0259 - mse: 0.0012 - val_loss: 0.0014 - val_mae: 0.0248 - val_mse: 0.0012 - lr: 0.0025
>Saved ../trained_models/models_segments_overlap_rmsprop_0.0098670635193028LR_[70]HN_16BS_5P_val_lossM_30epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
243/243 [==============================] - 1s 2ms/step - loss: 0.1027 - mae: 0.0407 - mse: 0.0024 - val_loss: 0.0022 - val_mae: 0.0382 - val_mse: 0.0019 - lr: 0.0099
Epoch 2/30
202/243 [=======================>......] - ETA: 0s - loss: 0.0022 - mae: 0.0386 - mse: 0.0020
243/243 [==============================] - 1s 2ms/step - loss: 0.1027 - mae: 0.0407 - mse: 0.0024 - val_loss: 0.0022 - val_mae: 0.0382 - val_mse: 0.0019 - lr: 0.0099
 60/243 [======>.......................] - ETA: 0s - loss: 0.0018 - mae: 0.0307 - mse: 0.00140019 - val_loss: 0.0021 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 0.0099
Epoch 5/30
243/243 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0367 - mse: 0.0018 - val_loss: 0.0020 - val_mae: 0.0353 - val_mse: 0.0017 - lr: 0.0099
Epoch 6/30
243/243 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0331 - mse: 0.0016 - val_loss: 0.0018 - val_mae: 0.0318 - val_mse: 0.0015 - lr: 0.0099
Epoch 7/30
129/243 [==============>...............] - ETA: 0s - loss: 0.0015 - mae: 0.0275 - mse: 0.0012     - val_loss: 0.0016 - val_mae: 0.0282 - val_mse: 0.0013 - lr: 0.0099
Epoch 8/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0281 - mse: 0.0012 - val_loss: 0.0016 - val_mae: 0.0280 - val_mse: 0.0012 - lr: 0.0099
Epoch 9/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0271 - mse: 0.0012 - val_loss: 0.0016 - val_mae: 0.0270 - val_mse: 0.0012 - lr: 0.0099
Epoch 10/30
171/243 [====================>.........] - ETA: 0s - loss: 0.0014 - mae: 0.0264 - mse: 0.00110011 - val_loss: 0.0017 - val_mae: 0.0295 - val_mse: 0.0013 - lr: 0.0099
Epoch 11/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0268 - mse: 0.0011 - val_loss: 0.0014 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.0099
Epoch 12/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0021 - val_mae: 0.0339 - val_mse: 0.0017 - lr: 0.0099
Epoch 13/30
210/243 [========================>.....] - ETA: 0s - loss: 0.0013 - mae: 0.0258 - mse: 0.00110011 - val_loss: 0.0014 - val_mae: 0.0267 - val_mse: 0.0011 - lr: 0.0099
Epoch 14/30
243/243 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0014 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0099
Epoch 15/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0015 - val_mae: 0.0274 - val_mse: 0.0011 - lr: 0.0099
Epoch 16/30
243/243 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0248 - mse: 9.7979e-04 - val_loss: 0.0011 - val_mae: 0.0247 - val_mse: 9.9962e-04 - lr: 0.0049
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.004933531861752272.
243/243 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0258 - mse: 0.0011 - val_loss: 0.0017 - val_mae: 0.0280 - val_mse: 0.0013 - lr: 0.0099
Epoch 17/30
243/243 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0246 - mse: 9.6564e-04 - val_loss: 0.0012 - val_mae: 0.0252 - val_mse: 0.0010 - lr: 0.0049
Epoch 18/30
243/243 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0248 - mse: 9.7979e-04 - val_loss: 0.0011 - val_mae: 0.0247 - val_mse: 9.9962e-04 - lr: 0.0049
Epoch 19/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0246 - mse: 9.7785e-04 - val_loss: 0.0011 - val_mae: 0.0248 - val_mse: 9.7878e-04 - lr: 0.0049
Epoch 20/30
243/243 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0246 - mse: 9.6259e-04 - val_loss: 0.0011 - val_mae: 0.0246 - val_mse: 9.8711e-04 - lr: 0.0049
Epoch 21/30
243/243 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0246 - mse: 9.6297e-04 - val_loss: 0.0011 - val_mae: 0.0260 - val_mse: 0.0010 - lr: 0.0049
Epoch 22/30
219/243 [==========================>...] - ETA: 0s - loss: 0.0011 - mae: 0.0247 - mse: 9.6021e-04
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.002466765930876136.
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0248 - mse: 9.6613e-04 - val_loss: 0.0011 - val_mae: 0.0249 - val_mse: 0.0010 - lr: 0.0049
Epoch 23/30
 36/243 [===>..........................] - ETA: 0s - loss: 9.6882e-04 - mae: 0.0235 - mse: 8.8506e-04
243/243 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0241 - mse: 9.2126e-04 - val_loss: 0.0011 - val_mae: 0.0247 - val_mse: 0.0010 - lr: 0.00250049
Epoch 25/30
243/243 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0241 - mse: 9.2592e-04 - val_loss: 0.0011 - val_mae: 0.0245 - val_mse: 9.8818e-04 - lr: 0.0025
Epoch 26/30
228/243 [===========================>..] - ETA: 0s - loss: 0.0010 - mae: 0.0240 - mse: 9.2174e-04
239/243 [============================>.] - ETA: 0s - loss: 9.9016e-04 - mae: 0.0238 - mse: 9.1218e-04 - val_loss: 0.0011 - val_mae: 0.0247 - val_mse: 0.0010 - lr: 0.00250049
243/243 [==============================] - 1s 3ms/step - loss: 9.8905e-04 - mae: 0.0238 - mse: 9.1118e-04 - val_loss: 0.0012 - val_mae: 0.0277 - val_mse: 0.0011 - lr: 0.0025
243/243 [==============================] - 1s 3ms/step - loss: 9.8905e-04 - mae: 0.0238 - mse: 9.1118e-04 - val_loss: 0.0012 - val_mae: 0.0277 - val_mse: 0.0011 - lr: 0.0025
243/243 [==============================] - 1s 2ms/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0099: 0.0025
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.0018 - val_mae: 0.0359 - val_mse: 0.0018 - lr: 0.0049: 0.0025
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.0018 - val_mae: 0.0359 - val_mse: 0.0018 - lr: 0.0049: 0.0025
243/243 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0276 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0265 - val_mse: 0.0011 - lr: 0.0049: 0.0025
243/243 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0261 - val_mse: 0.0011 - lr: 0.0049: 0.0025
112/243 [============>.................] - ETA: 0s - loss: 0.0011 - mae: 0.0249 - mse: 9.8903e-04 - val_loss: 0.0013 - val_mae: 0.0261 - val_mse: 0.0011 - lr: 0.0049: 0.0025
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0246 - mse: 9.8037e-04 - val_loss: 0.0012 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.00250025
200/243 [=======================>......] - ETA: 0s - loss: 0.0011 - mae: 0.0245 - mse: 9.6636e-04e-04 - val_loss: 0.0012 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.00250025
172/243 [====================>.........] - ETA: 0s - loss: 0.0010 - mae: 0.0236 - mse: 9.0152e-04     - val_loss: 0.0011 - val_mae: 0.0256 - val_mse: 0.0010 - lr: 0.00250025
243/243 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0238 - mse: 9.1076e-04 - val_loss: 0.0011 - val_mae: 0.0263 - val_mse: 0.0011 - lr: 0.00120025
243/243 [==============================] - 1s 2ms/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.009900120025
175/243 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.00190019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.009900120025
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.004900120025
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.004900120025
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.004900120025
243/243 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.001200120025
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.1669e-040025
 64/243 [======>.......................] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.1669e-040025
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.0835e-040025
 42/243 [====>.........................] - ETA: 0s - loss: 0.0021 - mae: 0.0384 - mse: 0.00200019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.0835e-040025
 42/243 [====>.........................] - ETA: 0s - loss: 0.0021 - mae: 0.0384 - mse: 0.00200019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.0835e-040025
243/243 [==============================] - 1s 2ms/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0099e-040025
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0049e-040025
243/243 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0288 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0299 - val_mse: 0.0013 - lr: 0.0049e-040025
243/243 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0288 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0299 - val_mse: 0.0013 - lr: 0.0049e-040025
243/243 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0268 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0264 - val_mse: 0.0011 - lr: 0.0049e-040025
222/243 [==========================>...] - ETA: 0s - loss: 0.0012 - mae: 0.0257 - mse: 0.0011        al_loss: 0.0013 - val_mae: 0.0264 - val_mse: 0.0011 - lr: 0.0049e-040025
243/243 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0255 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0254 - val_mse: 0.0010 - lr: 0.0025e-040025
243/243 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0252 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0251 - val_mse: 0.0010 - lr: 0.0025e-040025
243/243 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0247 - mse: 9.8130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
100/243 [===========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
100/243 [===========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
100/243 [===========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 15/30=========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 15/30=========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 15/30=========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 15/30=========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 15/30=========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 15/30=========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 15/30=========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 15/30=========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 15/30=========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 15/30=========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 15/30=========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 15/30=========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 15/30=========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 15/30=========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 15/30=========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 15/30=========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 15/30=========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 15/30=========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 15/30=========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 15/30=========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 16/30=========>..................] - ETA: 0s - loss: 0.0022 - mae: 0.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.002466765930876136.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 25/30educeLROnPlateau reducing learning rate to 0.002466765930876136.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 30/30educeLROnPlateau reducing learning rate to 0.002466765930876136.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 30/30educeLROnPlateau reducing learning rate to 0.002466765930876136.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025
Epoch 30/30educeLROnPlateau reducing learning rate to 0.002466765930876136.0378 - mse: 0.00198130e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.00120025