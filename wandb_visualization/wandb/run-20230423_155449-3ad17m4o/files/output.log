Epoch 1/30
40/49 [=======================>......] - ETA: 0s - loss: 0.8588 - mae: 0.9257 - mse: 0.8588
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
49/49 [==============================] - 2s 27ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0879
Epoch 2/30
49/49 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0879
Epoch 3/30
49/49 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0879
Epoch 4/30
49/49 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0879
Epoch 5/30
49/49 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0879
Epoch 6/30
48/49 [============================>.] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.04395103454589844.
49/49 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0879
Epoch 7/30
49/49 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0440
Epoch 8/30
49/49 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0440
Epoch 9/30
49/49 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0440
Epoch 10/30
49/49 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0440
Epoch 11/30
45/49 [==========================>...] - ETA: 0s - loss: 0.8576 - mae: 0.9250 - mse: 0.8576
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.02197551727294922.
49/49 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0440
Epoch 12/30
49/49 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0220
Epoch 13/30
49/49 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0220
Epoch 14/30
49/49 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0220
Epoch 15/30
49/49 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0220
Epoch 16/30
27/49 [===============>..............] - ETA: 0s - loss: 0.8572 - mae: 0.9248 - mse: 0.8572
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.01098775863647461.
49/49 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0220
Epoch 17/30
49/49 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0110
Epoch 18/30
49/49 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0110
Epoch 19/30
49/49 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0110
Epoch 20/30
49/49 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0110
Epoch 21/30
46/49 [===========================>..] - ETA: 0s - loss: 0.8580 - mae: 0.9253 - mse: 0.8580
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.005493879318237305.
49/49 [==============================] - 0s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0110
Epoch 22/30
49/49 [==============================] - 0s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0055
Epoch 23/30
49/49 [==============================] - 0s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0055
Epoch 24/30
49/49 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0055
Epoch 25/30
49/49 [==============================] - 0s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0055
Epoch 26/30
46/49 [===========================>..] - ETA: 0s - loss: 0.8580 - mae: 0.9252 - mse: 0.8580
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0027469396591186523.
49/49 [==============================] - 0s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0055
Epoch 27/30
49/49 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0027
Epoch 28/30
49/49 [==============================] - 0s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0027
Epoch 29/30
49/49 [==============================] - 0s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0027
Epoch 30/30
49/49 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0027
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.08790206972906581LR_[35]CHN_20CNNI_80BS_5P_val_lossM_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230423_155449-3ad17m4o\files\model-best)... Done. 0.0s
65/65 [==============================] - 2s 18ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0879
Epoch 2/30
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0879
Epoch 3/30
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0879
Epoch 4/30
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0879
Epoch 5/30
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0879
Epoch 6/30
49/65 [=====================>........] - ETA: 0s - loss: 0.6439 - mae: 0.8003 - mse: 0.6439
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.04395103454589844.
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0879
Epoch 7/30
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0440
Epoch 8/30
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0440
Epoch 9/30
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0440
Epoch 10/30
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0440
Epoch 11/30
48/65 [=====================>........] - ETA: 0s - loss: 0.6415 - mae: 0.7988 - mse: 0.6415
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.02197551727294922.
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0440
Epoch 12/30
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0220
Epoch 13/30
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0220
Epoch 14/30
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0220
Epoch 15/30
65/65 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0220
Epoch 16/30
35/65 [===============>..............] - ETA: 0s - loss: 0.6444 - mae: 0.8006 - mse: 0.6444
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.01098775863647461.
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0220
Epoch 17/30
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0110
Epoch 18/30
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0110
Epoch 19/30
65/65 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0110
Epoch 20/30
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0110
Epoch 21/30
32/65 [=============>................] - ETA: 0s - loss: 0.6398 - mae: 0.7977 - mse: 0.6398
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.005493879318237305.
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0110
Epoch 22/30
65/65 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0055
Epoch 23/30
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0055
Epoch 24/30
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0055
Epoch 25/30
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0055
Epoch 26/30
43/65 [==================>...........] - ETA: 0s - loss: 0.6439 - mae: 0.8003 - mse: 0.6439
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0027469396591186523.
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0055
Epoch 27/30
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0027
Epoch 28/30
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0027
Epoch 29/30
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0027
Epoch 30/30
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0027
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.08790206972906581LR_[35]CHN_20CNNI_80BS_5P_val_lossM_30epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
28/49 [================>.............] - ETA: 0s - loss: 0.4576 - mae: 0.6751 - mse: 0.4576
65/65 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0055
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
49/49 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0220
Epoch 5/30
49/49 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0879
Epoch 6/30
49/49 [==============================] - ETA: 0s - loss: 0.4578 - mae: 0.6752 - mse: 0.4578
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.04395103454589844.
49/49 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0879
Epoch 7/30
49/49 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0440
Epoch 8/30
49/49 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0440
Epoch 9/30
49/49 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0440
Epoch 10/30
49/49 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0440
Epoch 11/30
26/49 [==============>...............] - ETA: 0s - loss: 0.4581 - mae: 0.6754 - mse: 0.4581
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.02197551727294922.
49/49 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0440
Epoch 12/30
49/49 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0220
Epoch 13/30
49/49 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0220
Epoch 14/30
49/49 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0220
Epoch 15/30
49/49 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0220
Epoch 16/30
30/49 [=================>............] - ETA: 0s - loss: 0.4585 - mae: 0.6757 - mse: 0.4585
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.01098775863647461.
49/49 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0220
Epoch 17/30
49/49 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0110
Epoch 18/30
49/49 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0110
Epoch 19/30
49/49 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0110
Epoch 20/30
49/49 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0110
Epoch 21/30
38/49 [======================>.......] - ETA: 0s - loss: 0.4581 - mae: 0.6754 - mse: 0.4581
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.005493879318237305.
49/49 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0110
Epoch 22/30
49/49 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0055
Epoch 23/30
49/49 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0055
Epoch 24/30
49/49 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0055
Epoch 25/30
49/49 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0055
Epoch 26/30
47/49 [===========================>..] - ETA: 0s - loss: 0.4579 - mae: 0.6753 - mse: 0.4579
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0027469396591186523.
49/49 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0055
Epoch 27/30
49/49 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0027
Epoch 28/30
49/49 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0027
Epoch 29/30
49/49 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0027
Epoch 30/30
49/49 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0027
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.08790206972906581LR_[35]CHN_20CNNI_80BS_5P_val_lossM_30epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230423_155449-3ad17m4o\files\model-best)... Done. 0.0s
49/49 [==============================] - 1s 22ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0879
Epoch 2/30
49/49 [==============================] - 0s 2ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0879
Epoch 3/30
49/49 [==============================] - 0s 2ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0879
Epoch 4/30
49/49 [==============================] - 0s 2ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0879
Epoch 5/30
49/49 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0879
Epoch 6/30
47/49 [===========================>..] - ETA: 0s - loss: 0.3329 - mae: 0.5753 - mse: 0.3329
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.04395103454589844.
49/49 [==============================] - 0s 2ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0879
Epoch 7/30
49/49 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0440
Epoch 8/30
49/49 [==============================] - 0s 2ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0440
Epoch 9/30
49/49 [==============================] - 0s 2ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0440
Epoch 10/30
49/49 [==============================] - 0s 2ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0440
Epoch 11/30
43/49 [=========================>....] - ETA: 0s - loss: 0.3331 - mae: 0.5755 - mse: 0.3331
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.02197551727294922.
49/49 [==============================] - 0s 2ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0440
Epoch 12/30
49/49 [==============================] - 0s 2ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0220
Epoch 13/30
49/49 [==============================] - 0s 2ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0220
Epoch 14/30
49/49 [==============================] - 0s 2ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0220
Epoch 15/30
49/49 [==============================] - 0s 2ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0220
Epoch 16/30
48/49 [============================>.] - ETA: 0s - loss: 0.3326 - mae: 0.5751 - mse: 0.3326
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.01098775863647461.
49/49 [==============================] - 0s 2ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0220
Epoch 17/30
49/49 [==============================] - 0s 2ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0110
Epoch 18/30
49/49 [==============================] - 0s 2ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0110
Epoch 19/30
49/49 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0110
Epoch 20/30
49/49 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0110
Epoch 21/30
37/49 [=====================>........] - ETA: 0s - loss: 0.3326 - mae: 0.5751 - mse: 0.3326
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.005493879318237305.
49/49 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0110
Epoch 22/30
49/49 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0055
Epoch 23/30
49/49 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0055
Epoch 24/30
49/49 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0055
Epoch 25/30
49/49 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0055
Epoch 26/30
40/49 [=======================>......] - ETA: 0s - loss: 0.3332 - mae: 0.5756 - mse: 0.3332
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0027469396591186523.
49/49 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0055
Epoch 27/30
49/49 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0027
Epoch 28/30
49/49 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0027
Epoch 29/30
49/49 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0027
Epoch 30/30
49/49 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0027
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.08790206972906581LR_[35]CHN_20CNNI_80BS_5P_val_lossM_30epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 1/30
49/49 [==============================] - ETA: 0s - loss: 0.2277 - mae: 0.4752 - mse: 0.2277
49/49 [==============================] - 2s 27ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0879
Epoch 2/30
49/49 [==============================] - 0s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0879
Epoch 3/30
49/49 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0879
Epoch 4/30
49/49 [==============================] - 0s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0879
Epoch 5/30
49/49 [==============================] - 0s 5ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0879
Epoch 6/30
37/49 [=====================>........] - ETA: 0s - loss: 0.2280 - mae: 0.4755 - mse: 0.2280
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.04395103454589844.
49/49 [==============================] - 0s 5ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0879
Epoch 7/30
49/49 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0440
Epoch 8/30
49/49 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0440
Epoch 9/30
49/49 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0440
Epoch 10/30
49/49 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0440
Epoch 11/30
47/49 [===========================>..] - ETA: 0s - loss: 0.2276 - mae: 0.4750 - mse: 0.2276
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.02197551727294922.
49/49 [==============================] - 0s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0440
Epoch 12/30
49/49 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0220
Epoch 13/30
49/49 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0220
Epoch 14/30
49/49 [==============================] - 0s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0220
Epoch 15/30
49/49 [==============================] - 0s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0220
Epoch 16/30
43/49 [=========================>....] - ETA: 0s - loss: 0.2279 - mae: 0.4753 - mse: 0.2279
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.01098775863647461.
49/49 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0220
Epoch 17/30
49/49 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0110
Epoch 18/30
49/49 [==============================] - 0s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0110
Epoch 19/30
49/49 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0110
Epoch 20/30
49/49 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0110
Epoch 21/30
26/49 [==============>...............] - ETA: 0s - loss: 0.2280 - mae: 0.4755 - mse: 0.2280
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.005493879318237305.
49/49 [==============================] - 0s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0110
Epoch 22/30
49/49 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0055
Epoch 23/30
49/49 [==============================] - 0s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0055
Epoch 24/30
49/49 [==============================] - 0s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0055
Epoch 25/30
49/49 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0055
Epoch 26/30
40/49 [=======================>......] - ETA: 0s - loss: 0.2282 - mae: 0.4758 - mse: 0.2282
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0027469396591186523.
49/49 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0055
Epoch 27/30
49/49 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0027
Epoch 28/30
49/49 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0027
Epoch 29/30
49/49 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0027
Epoch 30/30
49/49 [==============================] - 0s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.0027
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.08790206972906581LR_[35]CHN_20CNNI_80BS_5P_val_lossM_30epochs/model_5.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230423_155449-3ad17m4o\files\model-best)... Done. 0.0s
49/49 [==============================] - 2s 28ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0879
Epoch 2/30
49/49 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0879
Epoch 3/30
49/49 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0879
Epoch 4/30
49/49 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0879
Epoch 5/30
49/49 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0879
Epoch 6/30
45/49 [==========================>...] - ETA: 0s - loss: 0.1427 - mae: 0.3752 - mse: 0.1427
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.04395103454589844.
49/49 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0879
Epoch 7/30
49/49 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0440
Epoch 8/30
49/49 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0440
Epoch 9/30
49/49 [==============================] - 0s 5ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0440
Epoch 10/30
49/49 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0440
Epoch 11/30
44/49 [=========================>....] - ETA: 0s - loss: 0.1426 - mae: 0.3751 - mse: 0.1426
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.02197551727294922.
49/49 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0440
Epoch 12/30
49/49 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0220
Epoch 13/30
49/49 [==============================] - 0s 2ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0220
Epoch 14/30
49/49 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0220
Epoch 15/30
49/49 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0220
Epoch 16/30
36/49 [=====================>........] - ETA: 0s - loss: 0.1425 - mae: 0.3750 - mse: 0.1425
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.01098775863647461.
49/49 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0220
Epoch 17/30
49/49 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0110
Epoch 18/30
49/49 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0110
Epoch 19/30
49/49 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0110
Epoch 20/30
49/49 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0110
Epoch 21/30
43/49 [=========================>....] - ETA: 0s - loss: 0.1428 - mae: 0.3753 - mse: 0.1428
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.005493879318237305.
49/49 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0110
Epoch 22/30
49/49 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0055
Epoch 23/30
49/49 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0055
Epoch 24/30
49/49 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0055
Epoch 25/30
49/49 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0055
Epoch 26/30
39/49 [======================>.......] - ETA: 0s - loss: 0.1428 - mae: 0.3754 - mse: 0.1428
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0027469396591186523.
49/49 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0055
Epoch 27/30
49/49 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0027
Epoch 28/30
49/49 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0027
Epoch 29/30
49/49 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0027
Epoch 30/30
49/49 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0027
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.08790206972906581LR_[35]CHN_20CNNI_80BS_5P_val_lossM_30epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
49/49 [==============================] - ETA: 0s - loss: 0.0776 - mae: 0.2752 - mse: 0.0776
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
49/49 [==============================] - 2s 28ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0879
Epoch 2/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0879
Epoch 3/30
49/49 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0879
Epoch 4/30
49/49 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0879
Epoch 5/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0879
Epoch 6/30
26/49 [==============>...............] - ETA: 0s - loss: 0.0779 - mae: 0.2757 - mse: 0.0779
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.04395103454589844.
49/49 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0879
Epoch 7/30
49/49 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0440
Epoch 8/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0440
Epoch 9/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0440
Epoch 10/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0440
Epoch 11/30
26/49 [==============>...............] - ETA: 0s - loss: 0.0777 - mae: 0.2753 - mse: 0.0777
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.02197551727294922.
49/49 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0440
Epoch 12/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0220
Epoch 13/30
49/49 [==============================] - 0s 6ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0220
Epoch 14/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0220
Epoch 15/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0220
Epoch 16/30
35/49 [====================>.........] - ETA: 0s - loss: 0.0775 - mae: 0.2749 - mse: 0.0775
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.01098775863647461.
49/49 [==============================] - 0s 5ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0220
Epoch 17/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0110
Epoch 18/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0110
Epoch 19/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0110
Epoch 20/30
49/49 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0110
Epoch 21/30
35/49 [====================>.........] - ETA: 0s - loss: 0.0779 - mae: 0.2757 - mse: 0.0779
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.005493879318237305.
49/49 [==============================] - 0s 5ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0110
Epoch 22/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0055
Epoch 23/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0055
Epoch 24/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0055
Epoch 25/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0055
Epoch 26/30
32/49 [==================>...........] - ETA: 0s - loss: 0.0777 - mae: 0.2753 - mse: 0.0777
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0027469396591186523.
49/49 [==============================] - 0s 5ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0055
Epoch 27/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0027
Epoch 28/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0027
Epoch 29/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0027
Epoch 30/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0027
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.08790206972906581LR_[35]CHN_20CNNI_80BS_5P_val_lossM_30epochs/model_7.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
47/49 [===========================>..] - ETA: 0s - loss: 0.0326 - mae: 0.1752 - mse: 0.0326
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
49/49 [==============================] - 2s 30ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0879
Epoch 2/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0879
Epoch 3/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0879
Epoch 4/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0879
Epoch 5/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0879
Epoch 6/30
43/49 [=========================>....] - ETA: 0s - loss: 0.0328 - mae: 0.1756 - mse: 0.0328
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.04395103454589844.
49/49 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0879
Epoch 7/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0440
Epoch 8/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0440
Epoch 9/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0440
Epoch 10/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0440
Epoch 11/30
33/49 [===================>..........] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.0325
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.02197551727294922.
49/49 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0440
Epoch 12/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0220
Epoch 13/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0220
Epoch 14/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0220
Epoch 15/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0220
Epoch 16/30
38/49 [======================>.......] - ETA: 0s - loss: 0.0326 - mae: 0.1751 - mse: 0.0326
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.01098775863647461.
49/49 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0220
Epoch 17/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0110
Epoch 18/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0110
Epoch 19/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0110
Epoch 20/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0110
Epoch 21/30
36/49 [=====================>........] - ETA: 0s - loss: 0.0325 - mae: 0.1749 - mse: 0.0325
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.005493879318237305.
49/49 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0110
Epoch 22/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0055
Epoch 23/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0055
Epoch 24/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0055
Epoch 25/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0055
Epoch 26/30
43/49 [=========================>....] - ETA: 0s - loss: 0.0326 - mae: 0.1753 - mse: 0.0326
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0027469396591186523.
49/49 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0055
Epoch 27/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0027
Epoch 28/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0027
Epoch 29/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0027
Epoch 30/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0027
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.08790206972906581LR_[35]CHN_20CNNI_80BS_5P_val_lossM_30epochs/model_8.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
41/49 [========================>.....] - ETA: 0s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
49/49 [==============================] - 2s 25ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0879
Epoch 2/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0879
Epoch 3/30
49/49 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0879
Epoch 4/30
49/49 [==============================] - 0s 8ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0879
Epoch 5/30
49/49 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0879
Epoch 6/30
30/49 [=================>............] - ETA: 0s - loss: 0.0076 - mae: 0.0754 - mse: 0.0076
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.04395103454589844.
49/49 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0879
Epoch 7/30
49/49 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0440
Epoch 8/30
49/49 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0440
Epoch 9/30
49/49 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0440
Epoch 10/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0440
Epoch 11/30
32/49 [==================>...........] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.02197551727294922.
49/49 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0440
Epoch 12/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0220
Epoch 13/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0220
Epoch 14/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0220
Epoch 15/30
49/49 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0220
Epoch 16/30
36/49 [=====================>........] - ETA: 0s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.01098775863647461.
49/49 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0220
Epoch 17/30
49/49 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0110
Epoch 18/30
49/49 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0110
Epoch 19/30
49/49 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0110
Epoch 20/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0110
Epoch 21/30
30/49 [=================>............] - ETA: 0s - loss: 0.0077 - mae: 0.0758 - mse: 0.0077
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.005493879318237305.
49/49 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0110
Epoch 22/30
49/49 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0055
Epoch 23/30
49/49 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0055
Epoch 24/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0055
Epoch 25/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0055
Epoch 26/30
38/49 [======================>.......] - ETA: 0s - loss: 0.0075 - mae: 0.0749 - mse: 0.0075
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0027469396591186523.
49/49 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0055
Epoch 27/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0027
Epoch 28/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0027
Epoch 29/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0027
Epoch 30/30
49/49 [==============================] - 0s 4ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - val_loss: 0.0075 - val_mae: 0.0746 - val_mse: 0.0075 - lr: 0.0027
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.08790206972906581LR_[35]CHN_20CNNI_80BS_5P_val_lossM_30epochs/model_9.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])