Epoch 1/200
88/98 [=========================>....] - ETA: 0s - loss: 0.0069 - mae: 0.0628 - mse: 0.0069 - root_mean_squared_error: 0.0830 - R2: -29.0696
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
98/98 [==============================] - 2s 14ms/step - loss: 0.0067 - mae: 0.0620 - mse: 0.0067 - root_mean_squared_error: 0.0816 - R2: -28.0450 - val_loss: 0.0047 - val_mae: 0.0559 - val_mse: 0.0047 - val_root_mean_squared_error: 0.0684 - val_R2: -19.0117 - lr: 0.0710
Epoch 2/200
87/98 [=========================>....] - ETA: 0s - loss: 0.0039 - mae: 0.0509 - mse: 0.0039 - root_mean_squared_error: 0.0621 - R2: -15.8820
98/98 [==============================] - 1s 12ms/step - loss: 0.0038 - mae: 0.0504 - mse: 0.0038 - root_mean_squared_error: 0.0616 - R2: -15.4355 - val_loss: 0.0022 - val_mae: 0.0400 - val_mse: 0.0022 - val_root_mean_squared_error: 0.0469 - val_R2: -8.3001 - lr: 0.0710
Epoch 3/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0465 - mse: 0.0033 - root_mean_squared_error: 0.0570 - R2: -13.4637 - val_loss: 0.0066 - val_mae: 0.0684 - val_mse: 0.0066 - val_root_mean_squared_error: 0.0812 - val_R2: -27.2739 - lr: 0.0710
Epoch 4/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0447 - mse: 0.0030 - root_mean_squared_error: 0.0547 - R2: -11.9861 - val_loss: 0.0042 - val_mae: 0.0527 - val_mse: 0.0042 - val_root_mean_squared_error: 0.0644 - val_R2: -16.5445 - lr: 0.0710
Epoch 5/200
55/98 [===============>..............] - ETA: 0s - loss: 0.0033 - mae: 0.0471 - mse: 0.0033 - root_mean_squared_error: 0.0576 - R2: -13.3057
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.03548482432961464.
98/98 [==============================] - 0s 2ms/step - loss: 0.0033 - mae: 0.0468 - mse: 0.0033 - root_mean_squared_error: 0.0571 - R2: -13.4681 - val_loss: 0.0026 - val_mae: 0.0422 - val_mse: 0.0026 - val_root_mean_squared_error: 0.0507 - val_R2: -9.8000 - lr: 0.0710
Epoch 6/200
42/98 [===========>..................] - ETA: 0s - loss: 0.0021 - mae: 0.0392 - mse: 0.0021 - root_mean_squared_error: 0.0463 - R2: -8.3511
98/98 [==============================] - 1s 14ms/step - loss: 0.0022 - mae: 0.0401 - mse: 0.0022 - root_mean_squared_error: 0.0471 - R2: -8.5548 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2453 - lr: 0.0355
Epoch 7/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0398 - mse: 0.0022 - root_mean_squared_error: 0.0474 - R2: -8.7123 - val_loss: 0.0033 - val_mae: 0.0474 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0578 - val_R2: -13.1057 - lr: 0.0355
Epoch 8/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0400 - mse: 0.0023 - root_mean_squared_error: 0.0475 - R2: -8.6964 - val_loss: 0.0024 - val_mae: 0.0410 - val_mse: 0.0024 - val_root_mean_squared_error: 0.0485 - val_R2: -8.9781 - lr: 0.0355
Epoch 9/200
47/98 [=============>................] - ETA: 0s - loss: 0.0023 - mae: 0.0404 - mse: 0.0023 - root_mean_squared_error: 0.0478 - R2: -8.8723
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.01774241216480732.
98/98 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0403 - mse: 0.0023 - root_mean_squared_error: 0.0476 - R2: -8.7078 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0444 - val_R2: -7.3020 - lr: 0.0355
Epoch 10/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0387 - mse: 0.0020 - root_mean_squared_error: 0.0451 - R2: -7.7184 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0443 - val_R2: -7.2746 - lr: 0.0177
Epoch 11/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0384 - mse: 0.0020 - root_mean_squared_error: 0.0448 - R2: -7.6193 - val_loss: 0.0028 - val_mae: 0.0438 - val_mse: 0.0028 - val_root_mean_squared_error: 0.0528 - val_R2: -10.8788 - lr: 0.0177
Epoch 12/200
91/98 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0388 - mse: 0.0020 - root_mean_squared_error: 0.0452 - R2: -7.7003
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00887120608240366.
98/98 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0388 - mse: 0.0020 - root_mean_squared_error: 0.0452 - R2: -7.7257 - val_loss: 0.0022 - val_mae: 0.0396 - val_mse: 0.0022 - val_root_mean_squared_error: 0.0465 - val_R2: -8.1066 - lr: 0.0177
Epoch 13/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - root_mean_squared_error: 0.0443 - R2: -7.4888 - val_loss: 0.0021 - val_mae: 0.0391 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0455 - val_R2: -7.7403 - lr: 0.0089
Epoch 14/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - root_mean_squared_error: 0.0441 - R2: -7.3400 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0446 - val_R2: -7.4065 - lr: 0.0089
Epoch 15/200
51/98 [==============>...............] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0020 - root_mean_squared_error: 0.0443 - R2: -7.4412
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00443560304120183.
98/98 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0020 - root_mean_squared_error: 0.0442 - R2: -7.3865 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0446 - val_R2: -7.3547 - lr: 0.0089
Epoch 16/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0440 - R2: -7.5887 - val_loss: 0.0022 - val_mae: 0.0398 - val_mse: 0.0022 - val_root_mean_squared_error: 0.0469 - val_R2: -8.2490 - lr: 0.0044
Epoch 17/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0439 - R2: -7.3018 - val_loss: 0.0020 - val_mae: 0.0387 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0447 - val_R2: -7.4361 - lr: 0.0044
Epoch 18/200
88/98 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2791
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.002217801520600915.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0440 - R2: -7.2776 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0444 - val_R2: -7.3198 - lr: 0.0044
Epoch 19/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2590 - val_loss: 0.0020 - val_mae: 0.0388 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0450 - val_R2: -7.5433 - lr: 0.0022
Epoch 20/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0439 - R2: -7.9282 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0445 - val_R2: -7.3403 - lr: 0.0022
Epoch 21/200
89/98 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0440 - R2: -7.2730
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0011089007603004575.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0439 - R2: -7.2857 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0444 - val_R2: -7.3002 - lr: 0.0022
Epoch 22/200
47/98 [=============>................] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - root_mean_squared_error: 0.0440 - R2: -7.2438
98/98 [==============================] - 2s 26ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2727 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2155 - lr: 0.0011
Epoch 23/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2912 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2386 - lr: 0.0011
Epoch 24/200
45/98 [============>.................] - ETA: 0s - loss: 0.0020 - mae: 0.0385 - mse: 0.0020 - root_mean_squared_error: 0.0443 - R2: -7.2122
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005544503801502287.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2857 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0443 - val_R2: -7.2627 - lr: 0.0011
Epoch 25/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -8.6146 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2356 - lr: 5.5445e-04
Epoch 26/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2750 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2329 - lr: 5.5445e-04
Epoch 27/200
98/98 [==============================] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2238
Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00027722519007511437.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230425_155039-k5scp13g\files\model-best)... Done. 0.0s
98/98 [==============================] - 1s 13ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2238 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2151 - lr: 5.5445e-04
Epoch 28/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.3012 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2117 - lr: 2.7723e-04
Epoch 29/200
98/98 [==============================] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.3518
98/98 [==============================] - 2s 23ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.3518 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2099 - lr: 2.7723e-04
Epoch 30/200
83/98 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019 - root_mean_squared_error: 0.0436 - R2: -7.2593
Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00013861259503755718.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2385 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2156 - lr: 2.7723e-04
Epoch 31/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2489 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2103 - lr: 1.3861e-04
Epoch 32/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2574 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2100 - lr: 1.3861e-04
Epoch 33/200
45/98 [============>.................] - ETA: 0s - loss: 0.0020 - mae: 0.0386 - mse: 0.0020 - root_mean_squared_error: 0.0445 - R2: -7.2446
Epoch 33: ReduceLROnPlateau reducing learning rate to 6.930629751877859e-05.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.3042 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2114 - lr: 1.3861e-04
Epoch 34/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2307 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2110 - lr: 6.9306e-05
Epoch 35/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2395 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2110 - lr: 6.9306e-05
Epoch 36/200
83/98 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.1775
Epoch 36: ReduceLROnPlateau reducing learning rate to 3.4653148759389296e-05.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2717 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2102 - lr: 6.9306e-05
Epoch 37/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -19.0739 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2101 - lr: 3.4653e-05
Epoch 38/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2386 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2104 - lr: 3.4653e-05
Epoch 39/200
86/98 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2261
Epoch 39: ReduceLROnPlateau reducing learning rate to 1.7326574379694648e-05.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2479 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2104 - lr: 3.4653e-05
Epoch 40/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.1703 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2103 - lr: 1.7327e-05
Epoch 41/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2342 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2103 - lr: 1.7327e-05
Epoch 42/200
92/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0437 - R2: -7.2270
Epoch 42: ReduceLROnPlateau reducing learning rate to 1e-05.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.4267 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2105 - lr: 1.7327e-05
Epoch 43/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.1737 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2106 - lr: 1.0000e-05
Epoch 44/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.4129 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2105 - lr: 1.0000e-05
Epoch 45/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2250 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2104 - lr: 1.0000e-05
Epoch 46/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2397 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2104 - lr: 1.0000e-05
Epoch 47/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2110 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2104 - lr: 1.0000e-05
Epoch 48/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -8.8584 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2102 - lr: 1.0000e-05
Epoch 49/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2639 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2102 - lr: 1.0000e-05
Epoch 50/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.4500 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2102 - lr: 1.0000e-05
Epoch 51/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2802 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2103 - lr: 1.0000e-05
Epoch 52/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2563 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2102 - lr: 1.0000e-05
Epoch 53/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.3719 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2101 - lr: 1.0000e-05
Epoch 54/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -10.5234 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2101 - lr: 1.0000e-05
Epoch 55/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2586 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2102 - lr: 1.0000e-05
Epoch 56/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2834 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2102 - lr: 1.0000e-05
Epoch 57/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2725 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2102 - lr: 1.0000e-05
Epoch 58/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2201 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2103 - lr: 1.0000e-05
Epoch 59/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2128 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2102 - lr: 1.0000e-05
Epoch 60/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2452 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2104 - lr: 1.0000e-05
Epoch 61/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.3850 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2104 - lr: 1.0000e-05
Epoch 62/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2175 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2106 - lr: 1.0000e-05
Epoch 63/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.8521 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2105 - lr: 1.0000e-05
Epoch 64/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.4465 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2105 - lr: 1.0000e-05
Epoch 65/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -9.2005 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2105 - lr: 1.0000e-05
Epoch 66/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.3094 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2106 - lr: 1.0000e-05
Epoch 67/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -10.2833 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2105 - lr: 1.0000e-05
Epoch 68/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -18.4682 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2105 - lr: 1.0000e-05
Epoch 69/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2767 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2104 - lr: 1.0000e-05
Epoch 70/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.2575 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2105 - lr: 1.0000e-05
Epoch 71/200
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.1863 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2105 - lr: 1.0000e-05
Epoch 72/200
81/98 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0439 - R2: -7.2174
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.3850 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2104 - lr: 1.0000e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.3097 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2106 - lr: 1.0000e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.3097 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2106 - lr: 1.0000e-05
Epoch 106/200========================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.3097 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2106 - lr: 1.0000e-05
Epoch 117/200========================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.3097 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2106 - lr: 1.0000e-05
Epoch 129/200========================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.3097 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2106 - lr: 1.0000e-05
Epoch 140/200========================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.3097 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2106 - lr: 1.0000e-05
Epoch 152/200========================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.3097 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2106 - lr: 1.0000e-05
Epoch 163/200========================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.3097 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2106 - lr: 1.0000e-05
Epoch 175/200========================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.3097 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2106 - lr: 1.0000e-05
Epoch 186/200========================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.3097 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2106 - lr: 1.0000e-05
Epoch 198/200========================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.3097 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2106 - lr: 1.0000e-05
Epoch 198/200========================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - R2: -7.3097 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -7.2106 - lr: 1.0000e-05