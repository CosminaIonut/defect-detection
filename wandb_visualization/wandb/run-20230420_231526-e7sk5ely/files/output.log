Epoch 1/150
224/243 [==========================>...] - ETA: 0s - loss: 0.0314 - mae: 0.0478 - mse: 0.0053
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_231526-e7sk5ely\files\model-best)... Done. 0.0s
243/243 [==============================] - 7s 26ms/step - loss: 0.0292 - mae: 0.0469 - mse: 0.0050 - val_loss: 0.0022 - val_mae: 0.0364 - val_mse: 0.0018 - lr: 0.0301
Epoch 2/150
214/243 [=========================>....] - ETA: 0s - loss: 0.0024 - mae: 0.0374 - mse: 0.0020
243/243 [==============================] - 2s 10ms/step - loss: 0.0024 - mae: 0.0371 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0350 - val_mse: 0.0017 - lr: 0.0301
Epoch 3/150
232/243 [===========================>..] - ETA: 0s - loss: 0.0023 - mae: 0.0357 - mse: 0.0019
243/243 [==============================] - 2s 7ms/step - loss: 0.0023 - mae: 0.0356 - mse: 0.0019 - val_loss: 0.0018 - val_mae: 0.0314 - val_mse: 0.0014 - lr: 0.0301
Epoch 4/150
243/243 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0320 - mse: 0.0016 - val_loss: 0.0023 - val_mae: 0.0344 - val_mse: 0.0018 - lr: 0.0301
Epoch 5/150
243/243 [==============================] - 2s 7ms/step - loss: 0.0016 - mae: 0.0286 - mse: 0.0013 - val_loss: 0.0016 - val_mae: 0.0300 - val_mse: 0.0014 - lr: 0.0301
Epoch 6/150
229/243 [===========================>..] - ETA: 0s - loss: 0.0015 - mae: 0.0273 - mse: 0.0012
243/243 [==============================] - 2s 8ms/step - loss: 0.0015 - mae: 0.0273 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0253 - val_mse: 0.0010 - lr: 0.0301
Epoch 7/150
243/243 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0269 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0301
Epoch 8/150
236/243 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0256 - mse: 0.0011
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_231526-e7sk5ely\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 8ms/step - loss: 0.0013 - mae: 0.0256 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0238 - val_mse: 9.0414e-04 - lr: 0.0301
Epoch 9/150
243/243 [==============================] - 1s 2ms/step - loss: 0.0013 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0014 - val_mae: 0.0274 - val_mse: 0.0012 - lr: 0.0301
Epoch 10/150
215/243 [=========================>....] - ETA: 0s - loss: 0.0012 - mae: 0.0252 - mse: 0.0010
243/243 [==============================] - 2s 8ms/step - loss: 0.0012 - mae: 0.0253 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0242 - val_mse: 9.5704e-04 - lr: 0.0301
Epoch 11/150
243/243 [==============================] - 2s 8ms/step - loss: 0.0013 - mae: 0.0251 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0233 - val_mse: 8.9203e-04 - lr: 0.0301
Epoch 12/150
243/243 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0241 - mse: 9.4978e-04 - val_loss: 0.0013 - val_mae: 0.0273 - val_mse: 0.0011 - lr: 0.0301
Epoch 13/150
243/243 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0247 - mse: 9.9651e-04 - val_loss: 0.0011 - val_mae: 0.0230 - val_mse: 8.6270e-04 - lr: 0.0301
Epoch 14/150
243/243 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0248 - mse: 9.9925e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.0301
Epoch 15/150
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0232 - mse: 8.8209e-04 - val_loss: 0.0011 - val_mae: 0.0221 - val_mse: 7.9665e-04 - lr: 0.0301
Epoch 16/150
235/243 [============================>.] - ETA: 0s - loss: 0.0011 - mae: 0.0235 - mse: 9.1887e-04
243/243 [==============================] - 2s 8ms/step - loss: 0.0011 - mae: 0.0235 - mse: 9.2179e-04 - val_loss: 9.9057e-04 - val_mae: 0.0221 - val_mse: 8.0467e-04 - lr: 0.0301
Epoch 17/150
243/243 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0230 - mse: 8.8213e-04 - val_loss: 0.0010 - val_mae: 0.0236 - val_mse: 8.7680e-04 - lr: 0.0301
Epoch 18/150
243/243 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0225 - mse: 8.5065e-04 - val_loss: 9.9131e-04 - val_mae: 0.0230 - val_mse: 8.7519e-04 - lr: 0.0301
Epoch 19/150
238/243 [============================>.] - ETA: 0s - loss: 0.0010 - mae: 0.0229 - mse: 8.6045e-04
243/243 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0229 - mse: 8.6188e-04 - val_loss: 8.7916e-04 - val_mae: 0.0213 - val_mse: 7.3527e-04 - lr: 0.0301
Epoch 20/150
155/243 [==================>...........] - ETA: 0s - loss: 0.0010 - mae: 0.0224 - mse: 8.2390e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0225 - mse: 8.3306e-04 - val_loss: 9.1991e-04 - val_mae: 0.0226 - val_mse: 8.2380e-04 - lr: 0.0301
Epoch 21/150
243/243 [==============================] - 1s 2ms/step - loss: 9.8926e-04 - mae: 0.0221 - mse: 8.0820e-04 - val_loss: 0.0011 - val_mae: 0.0239 - val_mse: 9.0127e-04 - lr: 0.0301
Epoch 22/150
243/243 [==============================] - 1s 3ms/step - loss: 9.5480e-04 - mae: 0.0215 - mse: 7.8049e-04 - val_loss: 8.9803e-04 - val_mae: 0.0206 - val_mse: 7.1833e-04 - lr: 0.0301
Epoch 23/150
243/243 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0222 - mse: 8.1591e-04 - val_loss: 9.3986e-04 - val_mae: 0.0211 - val_mse: 7.6772e-04 - lr: 0.0301
Epoch 24/150
243/243 [==============================] - 1s 2ms/step - loss: 8.9146e-04 - mae: 0.0210 - mse: 7.3931e-04 - val_loss: 0.0011 - val_mae: 0.0256 - val_mse: 0.0010 - lr: 0.0301
Epoch 25/150
197/243 [=======================>......] - ETA: 0s - loss: 9.2349e-04 - mae: 0.0217 - mse: 7.7780e-04
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.015042871236801147.
243/243 [==============================] - 1s 3ms/step - loss: 9.0143e-04 - mae: 0.0214 - mse: 7.5915e-04 - val_loss: 0.0011 - val_mae: 0.0236 - val_mse: 9.0851e-04 - lr: 0.0301
Epoch 26/150
243/243 [==============================] - 2s 8ms/step - loss: 7.7719e-04 - mae: 0.0197 - mse: 6.7225e-04 - val_loss: 8.3034e-04 - val_mae: 0.0198 - val_mse: 6.8055e-04 - lr: 0.0150
Epoch 27/150
228/243 [===========================>..] - ETA: 0s - loss: 7.6966e-04 - mae: 0.0197 - mse: 6.6423e-04
243/243 [==============================] - 2s 6ms/step - loss: 7.7388e-04 - mae: 0.0197 - mse: 6.6858e-04 - val_loss: 7.5695e-04 - val_mae: 0.0196 - val_mse: 6.1960e-04 - lr: 0.0150
Epoch 28/150
243/243 [==============================] - 1s 2ms/step - loss: 7.7696e-04 - mae: 0.0198 - mse: 6.7231e-04 - val_loss: 9.5231e-04 - val_mae: 0.0238 - val_mse: 8.5098e-04 - lr: 0.0150
Epoch 29/150
243/243 [==============================] - 0s 2ms/step - loss: 7.8613e-04 - mae: 0.0199 - mse: 6.7971e-04 - val_loss: 7.7831e-04 - val_mae: 0.0198 - val_mse: 6.7953e-04 - lr: 0.0150
Epoch 30/150
243/243 [==============================] - 1s 3ms/step - loss: 7.7672e-04 - mae: 0.0197 - mse: 6.6779e-04 - val_loss: 0.0010 - val_mae: 0.0248 - val_mse: 9.1853e-04 - lr: 0.0150
Epoch 31/150
208/243 [========================>.....] - ETA: 0s - loss: 7.6960e-04 - mae: 0.0196 - mse: 6.6037e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_231526-e7sk5ely\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 8ms/step - loss: 7.6095e-04 - mae: 0.0195 - mse: 6.5286e-04 - val_loss: 7.4778e-04 - val_mae: 0.0207 - val_mse: 6.7828e-04 - lr: 0.0150
Epoch 32/150
243/243 [==============================] - 2s 6ms/step - loss: 7.5202e-04 - mae: 0.0193 - mse: 6.4487e-04 - val_loss: 7.1098e-04 - val_mae: 0.0191 - val_mse: 6.2895e-04 - lr: 0.0150
Epoch 33/150
243/243 [==============================] - 1s 3ms/step - loss: 7.3167e-04 - mae: 0.0192 - mse: 6.3409e-04 - val_loss: 7.8561e-04 - val_mae: 0.0214 - val_mse: 6.8365e-04 - lr: 0.0150
Epoch 34/150
243/243 [==============================] - 1s 3ms/step - loss: 7.8303e-04 - mae: 0.0198 - mse: 6.6278e-04 - val_loss: 7.2750e-04 - val_mae: 0.0187 - val_mse: 6.0742e-04 - lr: 0.0150
Epoch 35/150
243/243 [==============================] - 1s 2ms/step - loss: 7.5940e-04 - mae: 0.0195 - mse: 6.4628e-04 - val_loss: 7.1676e-04 - val_mae: 0.0185 - val_mse: 5.6859e-04 - lr: 0.0150
Epoch 36/150
243/243 [==============================] - 1s 3ms/step - loss: 7.3550e-04 - mae: 0.0191 - mse: 6.2548e-04 - val_loss: 0.0011 - val_mae: 0.0237 - val_mse: 9.4877e-04 - lr: 0.0150
Epoch 37/150
225/243 [==========================>...] - ETA: 0s - loss: 7.2845e-04 - mae: 0.0190 - mse: 6.2626e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_231526-e7sk5ely\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 8ms/step - loss: 7.3028e-04 - mae: 0.0191 - mse: 6.2798e-04 - val_loss: 7.0569e-04 - val_mae: 0.0181 - val_mse: 5.9147e-04 - lr: 0.0150
Epoch 38/150
234/243 [===========================>..] - ETA: 0s - loss: 7.0600e-04 - mae: 0.0187 - mse: 6.0200e-04
243/243 [==============================] - 2s 8ms/step - loss: 7.0651e-04 - mae: 0.0187 - mse: 6.0247e-04 - val_loss: 7.0492e-04 - val_mae: 0.0202 - val_mse: 6.3170e-04 - lr: 0.0150
Epoch 39/150
243/243 [==============================] - 1s 2ms/step - loss: 7.1583e-04 - mae: 0.0190 - mse: 6.1348e-04 - val_loss: 8.1823e-04 - val_mae: 0.0204 - val_mse: 7.3932e-04 - lr: 0.0150
Epoch 40/150
243/243 [==============================] - 2s 7ms/step - loss: 7.0613e-04 - mae: 0.0188 - mse: 6.0924e-04 - val_loss: 6.4495e-04 - val_mae: 0.0181 - val_mse: 5.5890e-04 - lr: 0.0150
Epoch 41/150
243/243 [==============================] - 1s 3ms/step - loss: 7.2772e-04 - mae: 0.0189 - mse: 6.1582e-04 - val_loss: 7.0245e-04 - val_mae: 0.0175 - val_mse: 5.6702e-04 - lr: 0.0150
Epoch 42/150
243/243 [==============================] - 1s 3ms/step - loss: 7.1236e-04 - mae: 0.0188 - mse: 6.0567e-04 - val_loss: 6.5922e-04 - val_mae: 0.0190 - val_mse: 5.7945e-04 - lr: 0.0150
Epoch 43/150
243/243 [==============================] - 1s 2ms/step - loss: 6.7700e-04 - mae: 0.0184 - mse: 5.8221e-04 - val_loss: 9.7868e-04 - val_mae: 0.0228 - val_mse: 8.6280e-04 - lr: 0.0150
Epoch 44/150
243/243 [==============================] - 1s 3ms/step - loss: 7.3070e-04 - mae: 0.0191 - mse: 6.1945e-04 - val_loss: 6.5351e-04 - val_mae: 0.0179 - val_mse: 5.5973e-04 - lr: 0.0150
Epoch 45/150
231/243 [===========================>..] - ETA: 0s - loss: 6.9123e-04 - mae: 0.0185 - mse: 5.8892e-04
Epoch 45: ReduceLROnPlateau reducing learning rate to 0.007521435618400574.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_231526-e7sk5ely\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 8ms/step - loss: 6.8857e-04 - mae: 0.0185 - mse: 5.8490e-04 - val_loss: 6.4242e-04 - val_mae: 0.0177 - val_mse: 5.3668e-04 - lr: 0.0150
Epoch 46/150
231/243 [===========================>..] - ETA: 0s - loss: 6.3564e-04 - mae: 0.0177 - mse: 5.5094e-04
243/243 [==============================] - 2s 8ms/step - loss: 6.3460e-04 - mae: 0.0177 - mse: 5.5014e-04 - val_loss: 6.2403e-04 - val_mae: 0.0181 - val_mse: 5.4663e-04 - lr: 0.0075
Epoch 47/150
243/243 [==============================] - 1s 3ms/step - loss: 6.4402e-04 - mae: 0.0179 - mse: 5.5537e-04 - val_loss: 6.4041e-04 - val_mae: 0.0189 - val_mse: 5.6276e-04 - lr: 0.0075
Epoch 48/150
243/243 [==============================] - 1s 2ms/step - loss: 6.2638e-04 - mae: 0.0177 - mse: 5.4541e-04 - val_loss: 6.3356e-04 - val_mae: 0.0170 - val_mse: 5.3279e-04 - lr: 0.0075
Epoch 49/150
243/243 [==============================] - 1s 2ms/step - loss: 6.4090e-04 - mae: 0.0178 - mse: 5.5362e-04 - val_loss: 9.8493e-04 - val_mae: 0.0223 - val_mse: 8.5906e-04 - lr: 0.0075
Epoch 50/150
220/243 [==========================>...] - ETA: 0s - loss: 6.3213e-04 - mae: 0.0176 - mse: 5.4528e-04
243/243 [==============================] - 1s 3ms/step - loss: 6.2017e-04 - mae: 0.0174 - mse: 5.3699e-04 - val_loss: 6.7501e-04 - val_mae: 0.0198 - val_mse: 6.1893e-04 - lr: 0.0075
Epoch 51/150
243/243 [==============================] - 1s 2ms/step - loss: 6.2056e-04 - mae: 0.0174 - mse: 5.3904e-04 - val_loss: 6.5119e-04 - val_mae: 0.0193 - val_mse: 5.8475e-04 - lr: 0.0075
Epoch 52/150
243/243 [==============================] - 1s 3ms/step - loss: 6.2017e-04 - mae: 0.0174 - mse: 5.3699e-04 - val_loss: 6.7501e-04 - val_mae: 0.0198 - val_mse: 6.1893e-04 - lr: 0.0075
Epoch 53/150
226/243 [==========================>...] - ETA: 0s - loss: 6.2226e-04 - mae: 0.0175 - mse: 5.3807e-04
243/243 [==============================] - 2s 7ms/step - loss: 6.2512e-04 - mae: 0.0176 - mse: 5.4214e-04 - val_loss: 6.0658e-04 - val_mae: 0.0175 - val_mse: 5.4280e-04 - lr: 0.0075
Epoch 54/150
223/243 [==========================>...] - ETA: 0s - loss: 6.5183e-04 - mae: 0.0180 - mse: 5.6839e-04
243/243 [==============================] - 2s 7ms/step - loss: 6.2512e-04 - mae: 0.0176 - mse: 5.4214e-04 - val_loss: 6.0658e-04 - val_mae: 0.0175 - val_mse: 5.4280e-04 - lr: 0.0075
243/243 [==============================] - 1s 2ms/step - loss: 5.8116e-04 - mae: 0.0168 - mse: 5.0790e-04 - val_loss: 6.5522e-04 - val_mae: 0.0175 - val_mse: 5.7221e-04 - lr: 0.0038
Epoch 56/150
243/243 [==============================] - 1s 3ms/step - loss: 5.8911e-04 - mae: 0.0171 - mse: 5.1250e-04 - val_loss: 6.4705e-04 - val_mae: 0.0175 - val_mse: 5.7076e-04 - lr: 0.0038
Epoch 57/150
243/243 [==============================] - 0s 2ms/step - loss: 5.9123e-04 - mae: 0.0171 - mse: 5.1655e-04 - val_loss: 6.1246e-04 - val_mae: 0.0169 - val_mse: 5.3043e-04 - lr: 0.0038
Epoch 58/150
243/243 [==============================] - 1s 2ms/step - loss: 5.8116e-04 - mae: 0.0168 - mse: 5.0790e-04 - val_loss: 6.5522e-04 - val_mae: 0.0175 - val_mse: 5.7221e-04 - lr: 0.0038
Epoch 59/150
233/243 [===========================>..] - ETA: 0s - loss: 5.9167e-04 - mae: 0.0171 - mse: 5.1446e-04
243/243 [==============================] - 2s 7ms/step - loss: 5.9156e-04 - mae: 0.0171 - mse: 5.1518e-04 - val_loss: 5.8966e-04 - val_mae: 0.0174 - val_mse: 5.3157e-04 - lr: 0.0038
Epoch 60/150
243/243 [==============================] - 1s 3ms/step - loss: 5.7304e-04 - mae: 0.0167 - mse: 5.0010e-04 - val_loss: 6.0407e-04 - val_mae: 0.0182 - val_mse: 5.3327e-04 - lr: 0.0038
Epoch 61/150
222/243 [==========================>...] - ETA: 0s - loss: 5.9057e-04 - mae: 0.0170 - mse: 5.1548e-04
243/243 [==============================] - 2s 7ms/step - loss: 5.9156e-04 - mae: 0.0171 - mse: 5.1518e-04 - val_loss: 5.8966e-04 - val_mae: 0.0174 - val_mse: 5.3157e-04 - lr: 0.0038
231/243 [===========================>..] - ETA: 0s - loss: 5.8423e-04 - mae: 0.0170 - mse: 5.1044e-04e-04 - val_loss: 5.8966e-04 - val_mae: 0.0174 - val_mse: 5.3157e-04 - lr: 0.0038
231/243 [===========================>..] - ETA: 0s - loss: 5.8423e-04 - mae: 0.0170 - mse: 5.1044e-04e-04 - val_loss: 5.8966e-04 - val_mae: 0.0174 - val_mse: 5.3157e-04 - lr: 0.0038
243/243 [==============================] - 1s 3ms/step - loss: 5.6142e-04 - mae: 0.0165 - mse: 4.9040e-04 - val_loss: 5.8211e-04 - val_mae: 0.0171 - val_mse: 5.2272e-04 - lr: 0.0019
Epoch 67/150
225/243 [==========================>...] - ETA: 0s - loss: 5.6870e-04 - mae: 0.0166 - mse: 4.9817e-04
243/243 [==============================] - 1s 3ms/step - loss: 5.6142e-04 - mae: 0.0165 - mse: 4.9040e-04 - val_loss: 5.8211e-04 - val_mae: 0.0171 - val_mse: 5.2272e-04 - lr: 0.0019
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_231526-e7sk5ely\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 3ms/step - loss: 5.6142e-04 - mae: 0.0165 - mse: 4.9040e-04 - val_loss: 5.8211e-04 - val_mae: 0.0171 - val_mse: 5.2272e-04 - lr: 0.0019
243/243 [==============================] - 0s 1ms/step - loss: 5.6336e-04 - mae: 0.0166 - mse: 4.9175e-04 - val_loss: 5.9777e-04 - val_mae: 0.0167 - val_mse: 5.2441e-04 - lr: 0.0019
243/243 [==============================] - 0s 1ms/step - loss: 5.6336e-04 - mae: 0.0166 - mse: 4.9175e-04 - val_loss: 5.9777e-04 - val_mae: 0.0167 - val_mse: 5.2441e-04 - lr: 0.0019
215/243 [=========================>....] - ETA: 0s - loss: 5.5140e-04 - mae: 0.0164 - mse: 4.8244e-04e-04 - val_loss: 5.8870e-04 - val_mae: 0.0167 - val_mse: 5.2063e-04 - lr: 0.0019
215/243 [=========================>....] - ETA: 0s - loss: 5.5140e-04 - mae: 0.0164 - mse: 4.8244e-04e-04 - val_loss: 5.8870e-04 - val_mae: 0.0167 - val_mse: 5.2063e-04 - lr: 0.0019
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_231526-e7sk5ely\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 7ms/step - loss: 5.4891e-04 - mae: 0.0163 - mse: 4.7993e-04 - val_loss: 5.6536e-04 - val_mae: 0.0167 - val_mse: 4.9897e-04 - lr: 9.4018e-04
243/243 [==============================] - 2s 7ms/step - loss: 5.4891e-04 - mae: 0.0163 - mse: 4.7993e-04 - val_loss: 5.6536e-04 - val_mae: 0.0167 - val_mse: 4.9897e-04 - lr: 9.4018e-04
234/243 [===========================>..] - ETA: 0s - loss: 5.4331e-04 - mae: 0.0162 - mse: 4.7582e-04e-04 - val_loss: 5.6536e-04 - val_mae: 0.0167 - val_mse: 4.9897e-04 - lr: 9.4018e-04
243/243 [==============================] - 2s 7ms/step - loss: 5.4501e-04 - mae: 0.0163 - mse: 4.7772e-04 - val_loss: 5.6148e-04 - val_mae: 0.0169 - val_mse: 4.9847e-04 - lr: 9.4018e-04
243/243 [==============================] - 2s 7ms/step - loss: 5.4501e-04 - mae: 0.0163 - mse: 4.7772e-04 - val_loss: 5.6148e-04 - val_mae: 0.0169 - val_mse: 4.9847e-04 - lr: 9.4018e-04
243/243 [==============================] - 1s 3ms/step - loss: 5.4284e-04 - mae: 0.0162 - mse: 4.7534e-04 - val_loss: 5.5952e-04 - val_mae: 0.0167 - val_mse: 4.9878e-04 - lr: 4.7009e-04
243/243 [==============================] - 1s 3ms/step - loss: 5.4284e-04 - mae: 0.0162 - mse: 4.7534e-04 - val_loss: 5.5952e-04 - val_mae: 0.0167 - val_mse: 4.9878e-04 - lr: 4.7009e-04
243/243 [==============================] - 1s 2ms/step - loss: 5.4135e-04 - mae: 0.0162 - mse: 4.7592e-04 - val_loss: 5.6551e-04 - val_mae: 0.0164 - val_mse: 4.9676e-04 - lr: 4.7009e-04
  1/243 [..............................] - ETA: 0s - loss: 7.3517e-04 - mae: 0.0187 - mse: 6.6965e-04e-04 - val_loss: 5.5929e-04 - val_mae: 0.0165 - val_mse: 4.9430e-04 - lr: 4.7009e-04
243/243 [==============================] - 1s 3ms/step - loss: 5.3824e-04 - mae: 0.0161 - mse: 4.7303e-04 - val_loss: 5.6384e-04 - val_mae: 0.0165 - val_mse: 4.9794e-04 - lr: 2.3504e-04
243/243 [==============================] - 1s 3ms/step - loss: 5.3824e-04 - mae: 0.0161 - mse: 4.7303e-04 - val_loss: 5.6384e-04 - val_mae: 0.0165 - val_mse: 4.9794e-04 - lr: 2.3504e-04
243/243 [==============================] - 1s 3ms/step - loss: 5.3897e-04 - mae: 0.0162 - mse: 4.7432e-04 - val_loss: 5.5768e-04 - val_mae: 0.0165 - val_mse: 4.9205e-04 - lr: 2.3504e-04
243/243 [==============================] - 1s 3ms/step - loss: 5.3897e-04 - mae: 0.0162 - mse: 4.7432e-04 - val_loss: 5.5768e-04 - val_mae: 0.0165 - val_mse: 4.9205e-04 - lr: 2.3504e-04
 65/243 [=======>......................] - ETA: 0s - loss: 5.2860e-04 - mae: 0.0161 - mse: 4.6383e-04e-04 - val_loss: 5.5558e-04 - val_mae: 0.0167 - val_mse: 4.9094e-04 - lr: 1.1752e-04
243/243 [==============================] - 1s 3ms/step - loss: 5.3718e-04 - mae: 0.0162 - mse: 4.7219e-04 - val_loss: 5.5735e-04 - val_mae: 0.0165 - val_mse: 4.9245e-04 - lr: 1.1752e-04
243/243 [==============================] - 1s 3ms/step - loss: 5.3675e-04 - mae: 0.0161 - mse: 4.7103e-04 - val_loss: 5.5871e-04 - val_mae: 0.0165 - val_mse: 4.9339e-04 - lr: 1.1752e-04
243/243 [==============================] - 1s 3ms/step - loss: 5.3595e-04 - mae: 0.0161 - mse: 4.7141e-04 - val_loss: 5.5671e-04 - val_mae: 0.0165 - val_mse: 4.9194e-04 - lr: 5.8761e-05
243/243 [==============================] - 1s 3ms/step - loss: 5.3595e-04 - mae: 0.0161 - mse: 4.7141e-04 - val_loss: 5.5671e-04 - val_mae: 0.0165 - val_mse: 4.9194e-04 - lr: 5.8761e-05
243/243 [==============================] - 1s 3ms/step - loss: 5.3595e-04 - mae: 0.0161 - mse: 4.7141e-04 - val_loss: 5.5671e-04 - val_mae: 0.0165 - val_mse: 4.9194e-04 - lr: 5.8761e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_231526-e7sk5ely\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_231526-e7sk5ely\files\model-best)... Done. 0.0s
221/243 [==========================>...] - ETA: 0s - loss: 5.3837e-04 - mae: 0.0162 - mse: 4.7332e-04e-04 - val_loss: 5.5642e-04 - val_mae: 0.0165 - val_mse: 4.9166e-04 - lr: 5.8761e-05
243/243 [==============================] - 1s 2ms/step - loss: 5.3539e-04 - mae: 0.0161 - mse: 4.7034e-04 - val_loss: 5.5596e-04 - val_mae: 0.0165 - val_mse: 4.9140e-04 - lr: 2.9381e-05
243/243 [==============================] - 0s 2ms/step - loss: 5.3531e-04 - mae: 0.0161 - mse: 4.7043e-04 - val_loss: 5.5735e-04 - val_mae: 0.0165 - val_mse: 4.9237e-04 - lr: 2.9381e-05
243/243 [==============================] - 0s 1ms/step - loss: 5.3500e-04 - mae: 0.0161 - mse: 4.6993e-04 - val_loss: 5.5676e-04 - val_mae: 0.0165 - val_mse: 4.9178e-04 - lr: 1.4690e-05
191/243 [======================>.......] - ETA: 0s - loss: 5.4915e-04 - mae: 0.0163 - mse: 4.8444e-04e-04 - val_loss: 5.5749e-04 - val_mae: 0.0165 - val_mse: 4.9247e-04 - lr: 1.4690e-05
243/243 [==============================] - 0s 2ms/step - loss: 5.3489e-04 - mae: 0.0161 - mse: 4.6982e-04 - val_loss: 5.5671e-04 - val_mae: 0.0165 - val_mse: 4.9183e-04 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_adam_0.03008574251538143LR_[33]HN_16BS_10P_val_mseM_150epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
243/243 [==============================] - 0s 2ms/step - loss: 5.3489e-04 - mae: 0.0161 - mse: 4.6982e-04 - val_loss: 5.5671e-04 - val_mae: 0.0165 - val_mse: 4.9183e-04 - lr: 1.0000e-05
243/243 [==============================] - 0s 2ms/step - loss: 5.3489e-04 - mae: 0.0161 - mse: 4.6982e-04 - val_loss: 5.5671e-04 - val_mae: 0.0165 - val_mse: 4.9183e-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0028 - mae: 0.0396 - mse: 0.0024 - val_loss: 0.0035 - val_mae: 0.0446 - val_mse: 0.0029 - lr: 0.0301-04 - lr: 1.0000e-05
108/323 [=========>....................] - ETA: 0s - loss: 0.0020 - mae: 0.0323 - mse: 0.00170024 - val_loss: 0.0035 - val_mae: 0.0446 - val_mse: 0.0029 - lr: 0.0301-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0322 - mse: 0.0017 - val_loss: 0.0018 - val_mae: 0.0289 - val_mse: 0.0014 - lr: 0.0301-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0017 - mae: 0.0288 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0279 - val_mse: 0.0013 - lr: 0.0301-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0017 - mae: 0.0288 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0279 - val_mse: 0.0013 - lr: 0.0301-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0270 - mse: 0.0013 - val_loss: 0.0017 - val_mae: 0.0291 - val_mse: 0.0014 - lr: 0.0301-04 - lr: 1.0000e-05
270/323 [========================>.....] - ETA: 0s - loss: 0.0015 - mae: 0.0264 - mse: 0.00120013 - val_loss: 0.0017 - val_mae: 0.0291 - val_mse: 0.0014 - lr: 0.0301-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0261 - mse: 0.0012 - val_loss: 0.0017 - val_mae: 0.0314 - val_mse: 0.0016 - lr: 0.0301-04 - lr: 1.0000e-05
319/323 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0247 - mse: 0.0011     - val_loss: 0.0017 - val_mae: 0.0314 - val_mse: 0.0016 - lr: 0.0301-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0247 - mse: 0.0011 - val_loss: 0.0016 - val_mae: 0.0305 - val_mse: 0.0014 - lr: 0.0301-04 - lr: 1.0000e-05
312/323 [===========================>..] - ETA: 0s - loss: 0.0014 - mae: 0.0249 - mse: 0.0011        al_loss: 0.0016 - val_mae: 0.0305 - val_mse: 0.0014 - lr: 0.0301-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0249 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0252 - val_mse: 0.0011 - lr: 0.0301-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0013 - mae: 0.0247 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0237 - val_mse: 9.5290e-04 - lr: 0.0301- lr: 1.0000e-05
311/323 [===========================>..] - ETA: 0s - loss: 0.0013 - mae: 0.0244 - mse: 0.0010     - val_loss: 0.0012 - val_mae: 0.0237 - val_mse: 9.5290e-04 - lr: 0.0301- lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0246 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0253 - val_mse: 0.0011 - lr: 0.03010301- lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0217 - mse: 8.8630e-04 - val_loss: 0.0012 - val_mae: 0.0255 - val_mse: 0.0011 - lr: 0.0150- lr: 1.0000e-05
162/323 [==============>...............] - ETA: 0s - loss: 0.0011 - mae: 0.0220 - mse: 8.8841e-04e-04 - val_loss: 0.0012 - val_mae: 0.0255 - val_mse: 0.0011 - lr: 0.0150- lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0217 - mse: 8.7390e-04 - val_loss: 0.0010 - val_mae: 0.0219 - val_mse: 8.5110e-04 - lr: 0.0150: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0220 - mse: 8.7933e-04 - val_loss: 8.9720e-04 - val_mae: 0.0182 - val_mse: 6.9538e-04 - lr: 0.01500000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0220 - mse: 8.7933e-04 - val_loss: 8.9720e-04 - val_mae: 0.0182 - val_mse: 6.9538e-04 - lr: 0.01500000e-05
308/323 [===========================>..] - ETA: 0s - loss: 0.0010 - mae: 0.0216 - mse: 8.4727e-04     - val_loss: 8.9720e-04 - val_mae: 0.0182 - val_mse: 6.9538e-04 - lr: 0.01500000e-05
303/323 [===========================>..] - ETA: 0s - loss: 9.1963e-04 - mae: 0.0202 - mse: 7.5687e-04 - val_loss: 8.9720e-04 - val_mae: 0.0182 - val_mse: 6.9538e-04 - lr: 0.01500000e-05
323/323 [==============================] - 1s 3ms/step - loss: 9.2423e-04 - mae: 0.0202 - mse: 7.6114e-04 - val_loss: 8.4969e-04 - val_mae: 0.0185 - val_mse: 6.7647e-04 - lr: 0.0075e-05
323/323 [==============================] - 1s 3ms/step - loss: 8.7968e-04 - mae: 0.0193 - mse: 7.1653e-04 - val_loss: 8.6600e-04 - val_mae: 0.0192 - val_mse: 7.0395e-04 - lr: 0.0075e-05
323/323 [==============================] - 1s 3ms/step - loss: 8.7968e-04 - mae: 0.0193 - mse: 7.1653e-04 - val_loss: 8.6600e-04 - val_mae: 0.0192 - val_mse: 7.0395e-04 - lr: 0.0075e-05
323/323 [==============================] - 1s 3ms/step - loss: 8.7222e-04 - mae: 0.0194 - mse: 7.1542e-04 - val_loss: 0.0010 - val_mae: 0.0225 - val_mse: 8.6272e-04 - lr: 0.00750075e-05
323/323 [==============================] - 1s 3ms/step - loss: 8.7222e-04 - mae: 0.0194 - mse: 7.1542e-04 - val_loss: 0.0010 - val_mae: 0.0225 - val_mse: 8.6272e-04 - lr: 0.00750075e-05
323/323 [==============================] - 1s 3ms/step - loss: 8.4706e-04 - mae: 0.0190 - mse: 7.0067e-04 - val_loss: 7.9024e-04 - val_mae: 0.0177 - val_mse: 6.5345e-04 - lr: 0.0075e-05
323/323 [==============================] - 1s 2ms/step - loss: 8.0571e-04 - mae: 0.0185 - mse: 6.6243e-04 - val_loss: 7.6527e-04 - val_mae: 0.0176 - val_mse: 6.2642e-04 - lr: 0.0038e-05
323/323 [==============================] - 1s 2ms/step - loss: 7.8704e-04 - mae: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 75/150===========================] - 1s 2ms/step - loss: 7.8704e-04 - mae: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 78/150===========================] - 1s 2ms/step - loss: 7.8704e-04 - mae: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 81/150===========================] - 1s 2ms/step - loss: 7.8704e-04 - mae: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 84/150===========================] - 1s 2ms/step - loss: 7.8704e-04 - mae: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 85/150===========================] - 1s 2ms/step - loss: 7.8704e-04 - mae: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 88/150===========================] - 1s 2ms/step - loss: 7.8704e-04 - mae: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 91/150===========================] - 1s 2ms/step - loss: 7.8704e-04 - mae: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 93/150===========================] - 1s 2ms/step - loss: 7.8704e-04 - mae: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 94: ReduceLROnPlateau reducing learning rate to 0.00047008972615003586.ae: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 97/150duceLROnPlateau reducing learning rate to 0.00047008972615003586.ae: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 99/150duceLROnPlateau reducing learning rate to 0.00047008972615003586.ae: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 101/150uceLROnPlateau reducing learning rate to 0.00047008972615003586.ae: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 103/150uceLROnPlateau reducing learning rate to 0.00047008972615003586.ae: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 104: ReduceLROnPlateau reducing learning rate to 0.00023504486307501793.e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 107/150duceLROnPlateau reducing learning rate to 0.00023504486307501793.e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 109/150duceLROnPlateau reducing learning rate to 0.00023504486307501793.e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 111/150duceLROnPlateau reducing learning rate to 0.00023504486307501793.e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 113/150duceLROnPlateau reducing learning rate to 0.00023504486307501793.e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 114: ReduceLROnPlateau reducing learning rate to 0.00011752243153750896.e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 117/150duceLROnPlateau reducing learning rate to 0.00011752243153750896.e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 119/150duceLROnPlateau reducing learning rate to 0.00011752243153750896.e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 121/150duceLROnPlateau reducing learning rate to 0.00011752243153750896.e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 123/150duceLROnPlateau reducing learning rate to 0.00011752243153750896.e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 124: ReduceLROnPlateau reducing learning rate to 5.876121576875448e-05..e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 127/150duceLROnPlateau reducing learning rate to 5.876121576875448e-05..e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 129/150duceLROnPlateau reducing learning rate to 5.876121576875448e-05..e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 131/150duceLROnPlateau reducing learning rate to 5.876121576875448e-05..e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 133/150duceLROnPlateau reducing learning rate to 5.876121576875448e-05..e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 134: ReduceLROnPlateau reducing learning rate to 2.938060788437724e-05..e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 138/150duceLROnPlateau reducing learning rate to 2.938060788437724e-05..e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 140/150duceLROnPlateau reducing learning rate to 2.938060788437724e-05..e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 142/150duceLROnPlateau reducing learning rate to 2.938060788437724e-05..e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 144: ReduceLROnPlateau reducing learning rate to 1.469030394218862e-05..e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 147/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05..e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 147/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05..e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 150/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05..e: 0.0182 - mse: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
241/243 [============================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
241/243 [============================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 4/150==========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 7/150==========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 10/150=========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 13/150=========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 17/150=========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 21/150=========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 24/150=========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 27/150=========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 30/150=========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 33/150=========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 35/150=========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 38/150=========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 41/150=========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 44/150=========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 46/150=========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 50/150=========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 54/150=========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 57/150=========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 61/150=========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 64/150=========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 66/150=========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 70/150=========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 73/150=========================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 79/150duceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 82/150duceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 115/150uceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 118/150uceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 122/150uceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 126/150uceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 129/150uceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 132/150uceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 135/150uceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 138/150uceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 142/150uceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 144/150uceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 146: ReduceLROnPlateau reducing learning rate to 1e-05.01794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 150/150duceLROnPlateau reducing learning rate to 1e-05.01794523000717.381 - mse: 0.0019: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
 75/243 [========>.....................] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 4/150======>.....................] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 7/150======>.....................] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 11/150=====>.....................] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 14/150=====>.....................] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 18/150=====>.....................] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 21/150=====>.....................] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 24/150=====>.....................] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 27/150=====>.....................] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 31/150=====>.....................] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 34/150=====>.....................] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 38/150=====>.....................] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0018803589046001434.383 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 45/150duceLROnPlateau reducing learning rate to 0.0018803589046001434.383 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 52/150duceLROnPlateau reducing learning rate to 0.0018803589046001434.383 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 52/150duceLROnPlateau reducing learning rate to 0.0018803589046001434.383 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 56/150duceLROnPlateau reducing learning rate to 0.0018803589046001434.383 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 59/150duceLROnPlateau reducing learning rate to 0.0018803589046001434.383 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00047008972615003586.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 64/150duceLROnPlateau reducing learning rate to 0.00047008972615003586.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 68/150duceLROnPlateau reducing learning rate to 0.00047008972615003586.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 71: ReduceLROnPlateau reducing learning rate to 0.00023504486307501793.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 75/150duceLROnPlateau reducing learning rate to 0.00023504486307501793.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 78/150duceLROnPlateau reducing learning rate to 0.00023504486307501793.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 81/150duceLROnPlateau reducing learning rate to 0.00023504486307501793.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 84/150duceLROnPlateau reducing learning rate to 0.00023504486307501793.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 87/150duceLROnPlateau reducing learning rate to 0.00023504486307501793.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 90/150duceLROnPlateau reducing learning rate to 0.00023504486307501793.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 92/150duceLROnPlateau reducing learning rate to 0.00023504486307501793.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 96/150duceLROnPlateau reducing learning rate to 0.00023504486307501793.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 100/150uceLROnPlateau reducing learning rate to 0.00023504486307501793.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 102/150uceLROnPlateau reducing learning rate to 0.00023504486307501793.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 106/150uceLROnPlateau reducing learning rate to 0.00023504486307501793.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 109/150uceLROnPlateau reducing learning rate to 0.00023504486307501793.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 111: ReduceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 114/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 117/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 119/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 121/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 124/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 127/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 130/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 133/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 136/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 139/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 142/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 144/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 147/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 150/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 150/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 1/15050duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 3/15050duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 6/15050duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 8/15050duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 11/1500duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 14/1500duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 17/1500duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 19/1500duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 23/1500duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 27/1500duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 31/1500duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 34/1500duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 36: ReduceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 40/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 43/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 46/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 49/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 51/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 55/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 57/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 61/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 65/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 68/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 76/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 79/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 82/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 85/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 87/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 91/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 93/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 96: ReduceLROnPlateau reducing learning rate to 0.00011752243153750896.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 100/150uceLROnPlateau reducing learning rate to 0.00011752243153750896.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 104/150uceLROnPlateau reducing learning rate to 0.00011752243153750896.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 107/150uceLROnPlateau reducing learning rate to 0.00011752243153750896.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 111/150uceLROnPlateau reducing learning rate to 0.00011752243153750896.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 114/150uceLROnPlateau reducing learning rate to 0.00011752243153750896.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 116/150uceLROnPlateau reducing learning rate to 0.00011752243153750896.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 119/150uceLROnPlateau reducing learning rate to 0.00011752243153750896.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 122/150uceLROnPlateau reducing learning rate to 0.00011752243153750896.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 125/150uceLROnPlateau reducing learning rate to 0.00011752243153750896.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 126: ReduceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 130/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 133/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 136/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 139/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 143/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 147/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 149/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 1/15050duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 1/15050duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 3/15050duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 5/15050duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 8/15050duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 11/1500duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 14/1500duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 17/1500duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 19/1500duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 25/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 27/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 30/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 32/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 36/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 39/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 41/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 44/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 47/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 50/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 53/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 56/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 59/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 63/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 67/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 70/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 73/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 77/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 79/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 82/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 85/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 88/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 90/150duceLROnPlateau reducing learning rate to 0.007521435618400574.5.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 114/150uceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 118/150uceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 120/150uceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 124/150uceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 126/150uceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 129/150uceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 132/150uceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 134/150uceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 137/150uceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 139: ReduceLROnPlateau reducing learning rate to 5.876121576875448e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 143/150duceLROnPlateau reducing learning rate to 5.876121576875448e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 145/150duceLROnPlateau reducing learning rate to 5.876121576875448e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 148/150duceLROnPlateau reducing learning rate to 5.876121576875448e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 149: ReduceLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 149: ReduceLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 1/150ReduceLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 3/150ReduceLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 6/150ReduceLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 9/150ReduceLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 12/150educeLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 15/150educeLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 17/150educeLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 20/150educeLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 22/150educeLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 25/150educeLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 28/150educeLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 31/150educeLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 34/150educeLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 38/150educeLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 42/150educeLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 45/150educeLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 48/150educeLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 51/150educeLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 55/150duceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 58/150duceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 61/150duceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 63/150duceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 66/150duceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 69/150duceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 75/150duceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 79/150duceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 81/150duceLROnPlateau reducing learning rate to 0.0009401794523000717..83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 82: ReduceLROnPlateau reducing learning rate to 0.00011752243153750896.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 86/150duceLROnPlateau reducing learning rate to 0.00011752243153750896.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 89/150duceLROnPlateau reducing learning rate to 0.00011752243153750896.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 92/150duceLROnPlateau reducing learning rate to 0.00011752243153750896.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 95/150duceLROnPlateau reducing learning rate to 0.00011752243153750896.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 97/150duceLROnPlateau reducing learning rate to 0.00011752243153750896.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 100/150uceLROnPlateau reducing learning rate to 0.00011752243153750896.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 102: ReduceLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 105/150duceLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 109/150duceLROnPlateau reducing learning rate to 2.938060788437724e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 112: ReduceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 116/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 120/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 123/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 127/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 130/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 133/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 135/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 138/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 141/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 144/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 147/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 150/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 150/150duceLROnPlateau reducing learning rate to 1.469030394218862e-05.83 - mse: 0.0020: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
223/243 [==========================>...] - ETA: 0s - loss: 0.0025 - mae: 0.0381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 4/150========================>...] - ETA: 0s - loss: 0.0025 - mae: 0.0381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 7/150========================>...] - ETA: 0s - loss: 0.0025 - mae: 0.0381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 10/150=======================>...] - ETA: 0s - loss: 0.0025 - mae: 0.0381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 13/150=======================>...] - ETA: 0s - loss: 0.0025 - mae: 0.0381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 16/150=======================>...] - ETA: 0s - loss: 0.0025 - mae: 0.0381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 19/150=======================>...] - ETA: 0s - loss: 0.0025 - mae: 0.0381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 21/150=======================>...] - ETA: 0s - loss: 0.0025 - mae: 0.0381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 24/150=======================>...] - ETA: 0s - loss: 0.0025 - mae: 0.0381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 27/150=======================>...] - ETA: 0s - loss: 0.0025 - mae: 0.0381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 30/150=======================>...] - ETA: 0s - loss: 0.0025 - mae: 0.0381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 33/150=======================>...] - ETA: 0s - loss: 0.0025 - mae: 0.0381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 36/150=======================>...] - ETA: 0s - loss: 0.0025 - mae: 0.0381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 39/150=======================>...] - ETA: 0s - loss: 0.0025 - mae: 0.0381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 42/150=======================>...] - ETA: 0s - loss: 0.0025 - mae: 0.0381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 44/150=======================>...] - ETA: 0s - loss: 0.0025 - mae: 0.0381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 46: ReduceLROnPlateau reducing learning rate to 0.003760717809200287.0381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 50/150duceLROnPlateau reducing learning rate to 0.003760717809200287.0381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 54/150duceLROnPlateau reducing learning rate to 0.003760717809200287.0381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0018803589046001434.381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 60/150duceLROnPlateau reducing learning rate to 0.0018803589046001434.381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 64/150duceLROnPlateau reducing learning rate to 0.0018803589046001434.381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 70/150duceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 73/150duceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 76/150duceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 77/150duceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 81/150duceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0009401794523000717.381 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 86: ReduceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 90/150duceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 93/150duceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 96/150duceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 99/150duceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 102/150uceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 105/150uceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 107/150uceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 113/150uceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 116/150uceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 118/150uceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 122/150uceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 125/150uceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 127/150uceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 130/150uceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 133/150uceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 136/150uceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 138/150uceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 142/150uceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 145/150uceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 148/150uceLROnPlateau reducing learning rate to 0.00023504486307501793.81 - mse: 0.0021: 6.4780e-04 - val_loss: 7.6261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
>Saved ../trained_models/models_segments_overlap_adam_0.03008574251538143LR_[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
>Saved ../trained_models/models_segments_overlap_adam_0.03008574251538143LR_[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 3/150rained_models/models_segments_overlap_adam_0.03008574251538143LR_[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 5/150rained_models/models_segments_overlap_adam_0.03008574251538143LR_[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 8/150rained_models/models_segments_overlap_adam_0.03008574251538143LR_[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 11/150ained_models/models_segments_overlap_adam_0.03008574251538143LR_[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 14/150ained_models/models_segments_overlap_adam_0.03008574251538143LR_[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 17/150ained_models/models_segments_overlap_adam_0.03008574251538143LR_[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 20/150ained_models/models_segments_overlap_adam_0.03008574251538143LR_[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 23/150ained_models/models_segments_overlap_adam_0.03008574251538143LR_[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 26/150ained_models/models_segments_overlap_adam_0.03008574251538143LR_[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 29/150ained_models/models_segments_overlap_adam_0.03008574251538143LR_[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 32/150ained_models/models_segments_overlap_adam_0.03008574251538143LR_[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 35/150ained_models/models_segments_overlap_adam_0.03008574251538143LR_[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 38/150ained_models/models_segments_overlap_adam_0.03008574251538143LR_[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 41/150ained_models/models_segments_overlap_adam_0.03008574251538143LR_[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 44/150ained_models/models_segments_overlap_adam_0.03008574251538143LR_[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 45: ReduceLROnPlateau reducing learning rate to 0.015042871236801147._[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 49/150duceLROnPlateau reducing learning rate to 0.015042871236801147._[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 53/150duceLROnPlateau reducing learning rate to 0.015042871236801147._[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 56/150duceLROnPlateau reducing learning rate to 0.015042871236801147._[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 59/150duceLROnPlateau reducing learning rate to 0.015042871236801147._[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 63/150duceLROnPlateau reducing learning rate to 0.015042871236801147._[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 66/150duceLROnPlateau reducing learning rate to 0.015042871236801147._[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 70/150duceLROnPlateau reducing learning rate to 0.015042871236801147._[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 73/150duceLROnPlateau reducing learning rate to 0.015042871236801147._[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 76/150duceLROnPlateau reducing learning rate to 0.015042871236801147._[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 80/150duceLROnPlateau reducing learning rate to 0.015042871236801147._[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0018803589046001434.[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0018803589046001434.[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0018803589046001434.[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0018803589046001434.[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0018803589046001434.[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0018803589046001434.[33]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 103: ReduceLROnPlateau reducing learning rate to 0.00047008972615003586.3]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 107/150duceLROnPlateau reducing learning rate to 0.00047008972615003586.3]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 110/150duceLROnPlateau reducing learning rate to 0.00047008972615003586.3]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 113/150duceLROnPlateau reducing learning rate to 0.00047008972615003586.3]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 116/150duceLROnPlateau reducing learning rate to 0.00047008972615003586.3]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 120/150duceLROnPlateau reducing learning rate to 0.00047008972615003586.3]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 123/150duceLROnPlateau reducing learning rate to 0.00047008972615003586.3]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 126/150duceLROnPlateau reducing learning rate to 0.00047008972615003586.3]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 129/150duceLROnPlateau reducing learning rate to 0.00047008972615003586.3]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 132/150duceLROnPlateau reducing learning rate to 0.00047008972615003586.3]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 134/150duceLROnPlateau reducing learning rate to 0.00047008972615003586.3]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 137/150duceLROnPlateau reducing learning rate to 0.00047008972615003586.3]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 140/150duceLROnPlateau reducing learning rate to 0.00047008972615003586.3]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 143/150duceLROnPlateau reducing learning rate to 0.00047008972615003586.3]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 146/150duceLROnPlateau reducing learning rate to 0.00047008972615003586.3]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
Epoch 149/150duceLROnPlateau reducing learning rate to 0.00047008972615003586.3]HN_16BS_10P_val_mseM_150epochs/model_8.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
>Saved ../trained_models/models_segments_overlap_adam_0.03008574251538143LR_[33]HN_16BS_10P_val_mseM_150epochs/model_9.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05
>Saved ../trained_models/models_segments_overlap_adam_0.03008574251538143LR_[33]HN_16BS_10P_val_mseM_150epochs/model_9.h5261e-04 - val_mae: 0.0172 - val_mse: 6.2260e-04 - lr: 0.0038e-05