Epoch 1/200
37/45 [=======================>......] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
45/45 [==============================] - 2s 38ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0892
Epoch 2/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0892
Epoch 3/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0892
Epoch 4/200
45/45 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0892
Epoch 5/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0892
Epoch 6/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0892
Epoch 7/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0892
Epoch 8/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0892
Epoch 9/200
45/45 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0892
Epoch 10/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0892
Epoch 11/200
31/45 [===================>..........] - ETA: 0s - loss: 0.8595 - mae: 0.9260 - mse: 0.8595
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.04458273574709892.
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0892
Epoch 12/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0446
Epoch 13/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0446
Epoch 14/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0446
Epoch 15/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0446
Epoch 16/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0446
Epoch 17/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0446
Epoch 18/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0446
Epoch 19/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0446
Epoch 20/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0446
Epoch 21/200
32/45 [====================>.........] - ETA: 0s - loss: 0.8577 - mae: 0.9251 - mse: 0.8577
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.02229136787354946.
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0446
Epoch 22/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0223
Epoch 23/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0223
Epoch 24/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0223
Epoch 25/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0223
Epoch 26/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0223
Epoch 27/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0223
Epoch 28/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0223
Epoch 29/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0223
Epoch 30/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0223
Epoch 31/200
30/45 [===================>..........] - ETA: 0s - loss: 0.8573 - mae: 0.9249 - mse: 0.8573
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.01114568393677473.
45/45 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0223
Epoch 32/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0111
Epoch 33/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0111
Epoch 34/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0111
Epoch 35/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0111
Epoch 36/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0111
Epoch 37/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0111
Epoch 38/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0111
Epoch 39/200
45/45 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0111
Epoch 40/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0111
Epoch 41/200
35/45 [======================>.......] - ETA: 0s - loss: 0.8585 - mae: 0.9255 - mse: 0.8585
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.005572841968387365.
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0111
Epoch 42/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0056
Epoch 43/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0056
Epoch 44/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0056
Epoch 45/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0056
Epoch 46/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0056
Epoch 47/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0056
Epoch 48/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0056
Epoch 49/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0056
Epoch 50/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0056
Epoch 51/200
36/45 [=======================>......] - ETA: 0s - loss: 0.8586 - mae: 0.9256 - mse: 0.8586
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0027864209841936827.
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0056
Epoch 52/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0028
Epoch 53/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0028
Epoch 54/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0028
Epoch 55/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0028
Epoch 56/200
38/45 [========================>.....] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.85798579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0028
Epoch 57/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0028
Epoch 58/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0028
Epoch 59/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0028
Epoch 60/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0028
Epoch 61/200
34/45 [=====================>........] - ETA: 0s - loss: 0.8583 - mae: 0.9254 - mse: 0.8583
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0013932104920968413.
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0028
Epoch 62/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
Epoch 63/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
Epoch 64/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
Epoch 65/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
Epoch 66/200
 1/45 [..............................] - ETA: 0s - loss: 0.8604 - mae: 0.9266 - mse: 0.86048579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
Epoch 67/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
Epoch 68/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
Epoch 69/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
Epoch 70/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
Epoch 71/200
38/45 [========================>.....] - ETA: 0s - loss: 0.8590 - mae: 0.9258 - mse: 0.8590
Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0006966052460484207.
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
Epoch 72/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.9661e-04
Epoch 73/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.9661e-04
Epoch 74/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.9661e-04
Epoch 75/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.9661e-04
Epoch 76/200
 1/45 [..............................] - ETA: 0s - loss: 0.8614 - mae: 0.9272 - mse: 0.86148579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.9661e-04
Epoch 77/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.9661e-04
Epoch 78/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.9661e-04
Epoch 79/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.9661e-04
Epoch 80/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.9661e-04
Epoch 81/200
36/45 [=======================>......] - ETA: 0s - loss: 0.8586 - mae: 0.9256 - mse: 0.8586
Epoch 81: ReduceLROnPlateau reducing learning rate to 0.00034830262302421033.
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.9661e-04
Epoch 82/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 3.4830e-04
Epoch 83/200
45/45 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 3.4830e-04
Epoch 84/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 3.4830e-04
Epoch 85/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 3.4830e-04
Epoch 86/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 3.4830e-04
Epoch 87/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 3.4830e-04
Epoch 88/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 3.4830e-04
Epoch 89/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 3.4830e-04
Epoch 90/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 3.4830e-04
Epoch 91/200
38/45 [========================>.....] - ETA: 0s - loss: 0.8572 - mae: 0.9248 - mse: 0.8572
Epoch 91: ReduceLROnPlateau reducing learning rate to 0.00017415131151210517.
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 3.4830e-04
Epoch 92/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.7415e-04
Epoch 93/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.7415e-04
Epoch 94/200
45/45 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.7415e-04
Epoch 95/200
32/45 [====================>.........] - ETA: 0s - loss: 0.8584 - mae: 0.9255 - mse: 0.8584
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.7415e-04
Epoch 97/200
45/45 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.7415e-04
Epoch 98/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.7415e-04
Epoch 99/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.7415e-04
Epoch 100/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.7415e-04
Epoch 101/200
32/45 [====================>.........] - ETA: 0s - loss: 0.8574 - mae: 0.9249 - mse: 0.8574
Epoch 101: ReduceLROnPlateau reducing learning rate to 8.707565575605258e-05.
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.7415e-04
Epoch 102/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 8.7076e-05
Epoch 103/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 8.7076e-05
Epoch 104/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 8.7076e-05
Epoch 105/200
 1/45 [..............................] - ETA: 0s - loss: 0.8572 - mae: 0.9248 - mse: 0.8572
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 8.7076e-05
Epoch 107/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 8.7076e-05
Epoch 108/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 8.7076e-05
Epoch 109/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 8.7076e-05
Epoch 110/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 8.7076e-05
Epoch 111/200
30/45 [===================>..........] - ETA: 0s - loss: 0.8577 - mae: 0.9251 - mse: 0.8577
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 4.3538e-05
Epoch 117/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 4.3538e-05
Epoch 118/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 4.3538e-05
Epoch 119/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 4.3538e-05
Epoch 120/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 4.3538e-05
Epoch 121/200
16/45 [=========>....................] - ETA: 0s - loss: 0.8565 - mae: 0.9245 - mse: 0.8565
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 2.1769e-05
Epoch 127/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 2.1769e-05
Epoch 128/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 2.1769e-05
Epoch 129/200
39/45 [=========================>....] - ETA: 0s - loss: 0.8576 - mae: 0.9250 - mse: 0.8576
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0884e-05
Epoch 137/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0884e-05
Epoch 138/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0884e-05
Epoch 139/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0884e-05
Epoch 140/200
34/45 [=====================>........] - ETA: 0s - loss: 0.8569 - mae: 0.9247 - mse: 0.8569
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 147/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 148/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 149/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 150/200
34/45 [=====================>........] - ETA: 0s - loss: 0.8586 - mae: 0.9256 - mse: 0.8586
45/45 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 158/200
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 159/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 160/200
35/45 [======================>.......] - ETA: 0s - loss: 0.8575 - mae: 0.9250 - mse: 0.8575
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 169/200
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 170/200
16/45 [=========>....................] - ETA: 0s - loss: 0.8577 - mae: 0.9251 - mse: 0.8577
45/45 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 180/200
 1/45 [..............................] - ETA: 0s - loss: 0.8449 - mae: 0.9183 - mse: 0.8449
 1/45 [..............................] - ETA: 0s - loss: 0.8526 - mae: 0.9224 - mse: 0.85268579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
45/45 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr']): 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr']): 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr']): 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
46/59 [======================>.......] - ETA: 0s - loss: 0.6432 - mae: 0.7999 - mse: 0.64328579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
50/59 [========================>.....] - ETA: 0s - loss: 0.6435 - mae: 0.8001 - mse: 0.64358579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
49/59 [=======================>......] - ETA: 0s - loss: 0.6427 - mae: 0.7996 - mse: 0.64278579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
49/59 [=======================>......] - ETA: 0s - loss: 0.6427 - mae: 0.7996 - mse: 0.64278579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
56/59 [===========================>..] - ETA: 0s - loss: 0.6429 - mae: 0.7997 - mse: 0.64298579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
58/59 [============================>.] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.64318579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
15/59 [======>.......................] - ETA: 0s - loss: 0.6409 - mae: 0.7985 - mse: 0.64098579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
47/59 [======================>.......] - ETA: 0s - loss: 0.6425 - mae: 0.7995 - mse: 0.64258579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
47/59 [======================>.......] - ETA: 0s - loss: 0.6428 - mae: 0.7996 - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 80/200=================>.......] - ETA: 0s - loss: 0.6428 - mae: 0.7996 - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 88/200=================>.......] - ETA: 0s - loss: 0.6428 - mae: 0.7996 - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 94/200=================>.......] - ETA: 0s - loss: 0.6428 - mae: 0.7996 - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 101: ReduceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 109/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 115/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 122/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 129/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 134/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 142/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 151/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 158/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 165/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 172/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 179/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 186/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 193/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 193/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 193/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 193/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.0034s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.0034s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 7/20000duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 17/2000duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 27/2000duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 37/2000duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 47/2000duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 57/2000duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 67/2000duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 77/2000duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 84/2000duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 94/2000duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 103/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 113/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 123/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 133/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 143/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 154/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 164/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 175/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 182/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 193/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 193/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 193/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_train_batch_end` time: 0.0032s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_train_batch_end` time: 0.0032s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 193/200duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 7/20000duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 17/2000duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 27/2000duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 36/2000duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 45/2000duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 54/2000duceLROnPlateau reducing learning rate to 8.707565575605258e-05. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0013932104920968413.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 81/200duceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 91/200duceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 101/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 111/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 121/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 131/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 139/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 149/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 158/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 167/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 177/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 186/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 195/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 195/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 195/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_end` time: 0.0027s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_end` time: 0.0027s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 7/20000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 17/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 27/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 37/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 47/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 57/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 67/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 77/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 87/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 97/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 107/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 117/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 127/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 137/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 147/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 158/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 169/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 180/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 191/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 200/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 200/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 200/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 17/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 27/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 37/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 47/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 57/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 67/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 77/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 77/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 87/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 97/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 107/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 116/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 125/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 134/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 143/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 153/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 162/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 170/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 179/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 189/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 199/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 199/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.0033s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.0033s). Check your callbacks.
Epoch 199/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 17/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 27/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 37/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 47/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 47/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 57/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 67/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 77/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 87/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 97/2000uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 107/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 115/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 125/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 134/200uceLROnPlateau reducing learning rate to 0.0006966052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 141: ReduceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 151/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 160/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 169/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 179/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 188/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 197/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 197/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 197/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.0029s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.0029s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 7/20000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 17/2000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 27/2000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 37/2000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 47/2000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 57/2000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 67/2000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 77/2000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 87/2000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 97/2000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 107/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 115/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 125/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 135/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 145/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 156/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 167/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 176/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 185/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 191/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 1/20000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 1/20000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 1/20000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 17/2000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 27/2000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 37/2000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 37/2000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 47/2000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 57/2000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 67/2000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 77/2000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 86/2000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 95/2000duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 105/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 115/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 125/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 135/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 145/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 155/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 166/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 175/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 186/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 196/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 196/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 196/200duceLROnPlateau reducing learning rate to 1e-05.66052460484207.. - mse: 0.64288579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05