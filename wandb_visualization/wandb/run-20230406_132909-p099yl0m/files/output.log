Y [[0.096]
 [0.014]
 [0.026]
 ...
 [0.02 ]
 [0.074]
 [0.086]]
X [[0.00293123 0.00242012 0.00202833 ... 0.00123472 0.00110405 0.0010347 ]
 [0.01003065 0.00520174 0.00222913 ... 0.00047567 0.00160212 0.00299861]
 [0.0651209  0.0624661  0.06012098 ... 0.0531939  0.05098064 0.04881471]
 ...
 [0.0141577  0.00361839 0.00010273 ... 0.00797822 0.00888544 0.00702019]
 [0.01199593 0.00969102 0.00783776 ... 0.00348408 0.0024832  0.00170184]
 [0.02677437 0.00450759 0.00090166 ... 0.01828678 0.01288733 0.00463391]]
Epoch 1/10
86/86 [==============================] - 1s 3ms/step - loss: 14.5420 - mae: 0.0258 - mse: 9.2449e-04 - val_loss: 13.8351 - val_mae: 0.0251 - val_mse: 8.4854e-04 - lr: 1.0000e-04
Epoch 2/10
86/86 [==============================] - 0s 2ms/step - loss: 13.2273 - mae: 0.0243 - mse: 7.9926e-04 - val_loss: 12.6225 - val_mae: 0.0251 - val_mse: 8.4574e-04 - lr: 1.0000e-04
Epoch 3/10
86/86 [==============================] - 0s 2ms/step - loss: 12.0958 - mae: 0.0243 - mse: 7.9674e-04 - val_loss: 11.5729 - val_mae: 0.0255 - val_mse: 8.5333e-04 - lr: 1.0000e-04
Epoch 4/10
84/86 [============================>.] - ETA: 0s - loss: 11.1259 - mae: 0.0243 - mse: 7.9740e-04
Epoch 4: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.
86/86 [==============================] - 0s 2ms/step - loss: 11.1199 - mae: 0.0243 - mse: 7.9751e-04 - val_loss: 10.6715 - val_mae: 0.0254 - val_mse: 8.4581e-04 - lr: 1.0000e-04
Epoch 5/10
86/86 [==============================] - 0s 2ms/step - loss: 10.4719 - mae: 0.0242 - mse: 7.9287e-04 - val_loss: 10.2692 - val_mae: 0.0255 - val_mse: 8.5164e-04 - lr: 5.0000e-05
Epoch 6/10
86/86 [==============================] - 0s 2ms/step - loss: 10.0853 - mae: 0.0242 - mse: 7.9333e-04 - val_loss: 9.8988 - val_mae: 0.0252 - val_mse: 8.3300e-04 - lr: 5.0000e-05
Epoch 7/10
44/86 [==============>...............] - ETA: 0s - loss: 9.8112 - mae: 0.0242 - mse: 7.8992e-04
Epoch 7: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.
86/86 [==============================] - 0s 2ms/step - loss: 9.7298 - mae: 0.0242 - mse: 7.9431e-04 - val_loss: 9.5586 - val_mae: 0.0252 - val_mse: 8.3504e-04 - lr: 5.0000e-05
Epoch 8/10
86/86 [==============================] - 0s 2ms/step - loss: 9.4798 - mae: 0.0242 - mse: 7.9344e-04 - val_loss: 9.3987 - val_mae: 0.0250 - val_mse: 8.3900e-04 - lr: 2.5000e-05
Epoch 9/10
86/86 [==============================] - 0s 2ms/step - loss: 9.3232 - mae: 0.0242 - mse: 7.9463e-04 - val_loss: 9.2457 - val_mae: 0.0252 - val_mse: 8.3941e-04 - lr: 2.5000e-05
Epoch 10/10
82/86 [===========================>..] - ETA: 0s - loss: 9.1762 - mae: 0.0243 - mse: 7.9900e-04
Epoch 10: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.
86/86 [==============================] - 0s 2ms/step - loss: 9.1735 - mae: 0.0243 - mse: 7.9553e-04 - val_loss: 9.0993 - val_mae: 0.0251 - val_mse: 8.3698e-04 - lr: 2.5000e-05
>Saved models_no_overlap_30.0_10epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Y [[0.196]
 [0.114]
 [0.126]
 ...
 [0.12 ]
 [0.174]
 [0.186]]
X [[0.02748851 0.00039159 0.00726006 ... 0.0061901  0.00020034 0.01068299]
 [0.04808978 0.01491017 0.00209172 ... 0.02369569 0.02969262 0.02770941]
 [0.03573033 0.00888656 0.00066304 ... 0.02158401 0.02246699 0.01629257]
 ...
 [0.00124297 0.0006329  0.00042122 ... 0.00086485 0.00093282 0.0008421 ]
 [0.00653011 0.00134035 0.00166156 ... 0.00377469 0.00158575 0.00118001]
 [0.00629538 0.00118206 0.00202483 ... 0.00288299 0.00107985 0.00197787]]
Epoch 1/10
86/86 [==============================] - 1s 3ms/step - loss: 14.5575 - mae: 0.0549 - mse: 0.0049 - val_loss: 13.8475 - val_mae: 0.0209 - val_mse: 6.6209e-04 - lr: 1.0000e-04
Epoch 2/10
86/86 [==============================] - 0s 2ms/step - loss: 13.2409 - mae: 0.0181 - mse: 5.1181e-04 - val_loss: 12.6372 - val_mae: 0.0186 - val_mse: 5.2469e-04 - lr: 1.0000e-04
Epoch 3/10
86/86 [==============================] - 0s 2ms/step - loss: 12.1116 - mae: 0.0170 - mse: 4.6483e-04 - val_loss: 11.5899 - val_mae: 0.0200 - val_mse: 6.0868e-04 - lr: 1.0000e-04
Epoch 4/10
86/86 [==============================] - 0s 2ms/step - loss: 11.1378 - mae: 0.0171 - mse: 4.6919e-04 - val_loss: 10.6904 - val_mae: 0.0189 - val_mse: 5.4697e-04 - lr: 1.0000e-04
Epoch 5/10
46/86 [===============>..............] - ETA: 0s - loss: 10.4792 - mae: 0.0172 - mse: 4.7310e-04
Epoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.
86/86 [==============================] - 0s 2ms/step - loss: 10.3048 - mae: 0.0174 - mse: 4.7543e-04 - val_loss: 9.9242 - val_mae: 0.0200 - val_mse: 6.0155e-04 - lr: 1.0000e-04
Epoch 6/10
86/86 [==============================] - 0s 2ms/step - loss: 9.7553 - mae: 0.0175 - mse: 4.8249e-04 - val_loss: 9.5840 - val_mae: 0.0189 - val_mse: 5.4256e-04 - lr: 5.0000e-05
Epoch 7/10
86/86 [==============================] - 0s 2ms/step - loss: 9.4289 - mae: 0.0177 - mse: 4.9027e-04 - val_loss: 9.2718 - val_mae: 0.0190 - val_mse: 5.4645e-04 - lr: 5.0000e-05
Epoch 8/10
42/86 [=============>................] - ETA: 0s - loss: 9.2016 - mae: 0.0174 - mse: 4.7868e-04
Epoch 8: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.
86/86 [==============================] - 0s 2ms/step - loss: 9.1298 - mae: 0.0179 - mse: 4.9672e-04 - val_loss: 8.9861 - val_mae: 0.0199 - val_mse: 5.8590e-04 - lr: 5.0000e-05
Epoch 9/10
86/86 [==============================] - 0s 2ms/step - loss: 8.9199 - mae: 0.0181 - mse: 5.0421e-04 - val_loss: 8.8520 - val_mae: 0.0194 - val_mse: 5.6474e-04 - lr: 2.5000e-05
Epoch 10/10
86/86 [==============================] - 0s 2ms/step - loss: 8.7887 - mae: 0.0182 - mse: 5.0836e-04 - val_loss: 8.7238 - val_mae: 0.0194 - val_mse: 5.6285e-04 - lr: 2.5000e-05
>Saved models_no_overlap_30.0_10epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Y [[0.296]
 [0.214]
 [0.226]
 ...
 [0.22 ]
 [0.274]
 [0.286]]
X [[0.0182882  0.00473865 0.02211658 ... 0.0223316  0.01884855 0.00023106]
 [0.03406256 0.00102707 0.01487339 ... 0.00247679 0.00735794 0.02798943]
 [0.02507582 0.00064567 0.01368136 ... 0.00056875 0.01117072 0.02570779]
 ...
 [0.00099347 0.00041288 0.00068923 ... 0.00041979 0.00058872 0.00095584]
 [0.0047433  0.00150399 0.00482519 ... 0.00354627 0.00575795 0.00259891]
 [0.00455493 0.00170686 0.00501392 ... 0.00449312 0.00525996 0.00152137]]
Epoch 1/10
86/86 [==============================] - 1s 3ms/step - loss: 14.3649 - mae: 0.1210 - mse: 0.0192 - val_loss: 13.6419 - val_mae: 0.0284 - val_mse: 0.0013 - lr: 1.0000e-04
Epoch 2/10
86/86 [==============================] - 0s 2ms/step - loss: 13.0345 - mae: 0.0198 - mse: 6.2309e-04 - val_loss: 12.4309 - val_mae: 0.0166 - val_mse: 4.4851e-04 - lr: 1.0000e-04
Epoch 3/10
86/86 [==============================] - 0s 2ms/step - loss: 11.9056 - mae: 0.0150 - mse: 3.7288e-04 - val_loss: 11.3844 - val_mae: 0.0157 - val_mse: 3.9692e-04 - lr: 1.0000e-04
Epoch 4/10
86/86 [==============================] - 0s 2ms/step - loss: 10.9331 - mae: 0.0143 - mse: 3.5038e-04 - val_loss: 10.4865 - val_mae: 0.0154 - val_mse: 4.0136e-04 - lr: 1.0000e-04
Epoch 5/10
78/86 [==========================>...] - ETA: 0s - loss: 10.1330 - mae: 0.0146 - mse: 3.6021e-04
Epoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.
86/86 [==============================] - 0s 2ms/step - loss: 10.1018 - mae: 0.0147 - mse: 3.6592e-04 - val_loss: 9.7222 - val_mae: 0.0167 - val_mse: 4.5997e-04 - lr: 1.0000e-04
Epoch 6/10
86/86 [==============================] - 0s 2ms/step - loss: 9.5538 - mae: 0.0149 - mse: 3.7238e-04 - val_loss: 9.3830 - val_mae: 0.0160 - val_mse: 4.2073e-04 - lr: 5.0000e-05
Epoch 7/10
86/86 [==============================] - 0s 2ms/step - loss: 9.2285 - mae: 0.0150 - mse: 3.8197e-04 - val_loss: 9.0722 - val_mae: 0.0176 - val_mse: 4.8960e-04 - lr: 5.0000e-05
Epoch 8/10
69/86 [=======================>......] - ETA: 0s - loss: 8.9572 - mae: 0.0154 - mse: 3.9276e-04
Epoch 8: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.
86/86 [==============================] - 0s 2ms/step - loss: 8.9307 - mae: 0.0153 - mse: 3.9089e-04 - val_loss: 8.7876 - val_mae: 0.0168 - val_mse: 4.4134e-04 - lr: 5.0000e-05
Epoch 9/10
86/86 [==============================] - 0s 2ms/step - loss: 8.7218 - mae: 0.0155 - mse: 3.9744e-04 - val_loss: 8.6542 - val_mae: 0.0167 - val_mse: 4.5479e-04 - lr: 2.5000e-05
Epoch 10/10
86/86 [==============================] - 0s 2ms/step - loss: 8.5913 - mae: 0.0156 - mse: 4.0357e-04 - val_loss: 8.5267 - val_mae: 0.0172 - val_mse: 4.6086e-04 - lr: 2.5000e-05
>Saved models_no_overlap_30.0_10epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Y [[0.396]
 [0.314]
 [0.326]
 ...
 [0.32 ]
 [0.374]
 [0.386]]
X [[0.01118243 0.01738499 0.01228667 ... 0.00130245 0.01862108 0.01527098]
 [0.02270906 0.0097482  0.02967412 ... 0.03415757 0.01340192 0.0044837 ]
 [0.01650482 0.00882636 0.0223758  ... 0.02595569 0.00470275 0.00906345]
 ...
 [0.00079213 0.00058654 0.0009241  ... 0.00101096 0.00056759 0.00053519]
 [0.00334416 0.00371257 0.0040112  ... 0.00257067 0.00239752 0.00563637]
 [0.00320211 0.00400127 0.00362818 ... 0.00174091 0.00353137 0.00485635]]
Epoch 1/10
86/86 [==============================] - 1s 3ms/step - loss: 14.6537 - mae: 0.2027 - mse: 0.0487 - val_loss: 13.9066 - val_mae: 0.0742 - val_mse: 0.0067 - lr: 1.0000e-04
Epoch 2/10
86/86 [==============================] - 0s 2ms/step - loss: 13.2910 - mae: 0.0329 - mse: 0.0018 - val_loss: 12.6822 - val_mae: 0.0202 - val_mse: 5.8802e-04 - lr: 1.0000e-04
Epoch 3/10
86/86 [==============================] - 0s 2ms/step - loss: 12.1536 - mae: 0.0171 - mse: 4.6507e-04 - val_loss: 11.6292 - val_mae: 0.0194 - val_mse: 5.3029e-04 - lr: 1.0000e-04
Epoch 4/10
86/86 [==============================] - 0s 2ms/step - loss: 11.1749 - mae: 0.0157 - mse: 4.1233e-04 - val_loss: 10.7254 - val_mae: 0.0178 - val_mse: 4.6658e-04 - lr: 1.0000e-04
Epoch 5/10
86/86 [==============================] - 0s 2ms/step - loss: 10.3379 - mae: 0.0156 - mse: 4.1080e-04 - val_loss: 9.9555 - val_mae: 0.0187 - val_mse: 4.9861e-04 - lr: 1.0000e-04
Epoch 6/10
86/86 [==============================] - 0s 2ms/step - loss: 9.6274 - mae: 0.0162 - mse: 4.3059e-04 - val_loss: 9.3043 - val_mae: 0.0188 - val_mse: 5.7250e-04 - lr: 1.0000e-04
Epoch 7/10
44/86 [==============>...............] - ETA: 0s - loss: 9.1593 - mae: 0.0160 - mse: 4.2453e-04
Epoch 7: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.
86/86 [==============================] - 0s 2ms/step - loss: 9.0282 - mae: 0.0164 - mse: 4.3937e-04 - val_loss: 8.7568 - val_mae: 0.0184 - val_mse: 4.8479e-04 - lr: 1.0000e-04
Epoch 8/10
86/86 [==============================] - 0s 2ms/step - loss: 8.6369 - mae: 0.0163 - mse: 4.3011e-04 - val_loss: 8.5156 - val_mae: 0.0176 - val_mse: 5.1401e-04 - lr: 5.0000e-05
Epoch 9/10
86/86 [==============================] - 0s 2ms/step - loss: 8.4060 - mae: 0.0164 - mse: 4.4077e-04 - val_loss: 8.2952 - val_mae: 0.0207 - val_mse: 5.8055e-04 - lr: 5.0000e-05
Epoch 10/10
44/86 [==============>...............] - ETA: 0s - loss: 8.2432 - mae: 0.0165 - mse: 4.3710e-04
Epoch 10: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.
86/86 [==============================] - 0s 2ms/step - loss: 8.1950 - mae: 0.0166 - mse: 4.4668e-04 - val_loss: 8.0936 - val_mae: 0.0170 - val_mse: 4.8857e-04 - lr: 5.0000e-05
>Saved models_no_overlap_30.0_10epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Y [[0.496]
 [0.414]
 [0.426]
 ...
 [0.42 ]
 [0.474]
 [0.486]]
X [[6.09523062e-03 2.60635719e-02 3.23428795e-07 ... 2.56026743e-02
  1.71041837e-04 2.54984670e-02]
 [1.40446918e-02 2.61646829e-02 1.25673051e-02 ... 1.25419787e-03
  3.29900489e-02 7.42571154e-03]
 [1.00183570e-02 2.14339205e-02 7.42171361e-03 ... 2.69533320e-03
  2.61955631e-02 1.32740317e-03]
 ...
 [6.39117437e-04 8.80646365e-04 5.95484829e-04 ... 4.33446885e-04
  1.00569413e-03 4.69498592e-04]
 [2.32347860e-03 5.63694251e-03 1.16408700e-03 ... 4.87953571e-03
  2.23918923e-03 4.20476051e-03]
 [2.22512691e-03 5.76013101e-03 1.05127168e-03 ... 5.50438660e-03
  1.39780310e-03 5.27877300e-03]]
Epoch 1/10
86/86 [==============================] - 1s 3ms/step - loss: 14.5174 - mae: 0.2703 - mse: 0.0841 - val_loss: 13.7484 - val_mae: 0.1122 - val_mse: 0.0149 - lr: 1.0000e-04
Epoch 2/10
86/86 [==============================] - 0s 2ms/step - loss: 13.1268 - mae: 0.0504 - mse: 0.0041 - val_loss: 12.5161 - val_mae: 0.0253 - val_mse: 9.7290e-04 - lr: 1.0000e-04
Epoch 3/10
86/86 [==============================] - 0s 2ms/step - loss: 11.9878 - mae: 0.0208 - mse: 6.6363e-04 - val_loss: 11.4637 - val_mae: 0.0185 - val_mse: 5.1874e-04 - lr: 1.0000e-04
Epoch 4/10
86/86 [==============================] - 0s 2ms/step - loss: 11.0103 - mae: 0.0170 - mse: 4.5818e-04 - val_loss: 10.5617 - val_mae: 0.0194 - val_mse: 5.6133e-04 - lr: 1.0000e-04
Epoch 5/10
86/86 [==============================] - 0s 2ms/step - loss: 10.1754 - mae: 0.0165 - mse: 4.4267e-04 - val_loss: 9.7943 - val_mae: 0.0182 - val_mse: 5.0930e-04 - lr: 1.0000e-04
Epoch 6/10
85/86 [============================>.] - ETA: 0s - loss: 9.4683 - mae: 0.0170 - mse: 4.5611e-04
Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.
86/86 [==============================] - 0s 2ms/step - loss: 9.4676 - mae: 0.0170 - mse: 4.5607e-04 - val_loss: 9.1460 - val_mae: 0.0178 - val_mse: 4.9200e-04 - lr: 1.0000e-04
Epoch 7/10
86/86 [==============================] - 0s 2ms/step - loss: 9.0038 - mae: 0.0166 - mse: 4.4376e-04 - val_loss: 8.8597 - val_mae: 0.0182 - val_mse: 5.0656e-04 - lr: 5.0000e-05
Epoch 8/10
86/86 [==============================] - 0s 2ms/step - loss: 8.7296 - mae: 0.0167 - mse: 4.5099e-04 - val_loss: 8.5981 - val_mae: 0.0206 - val_mse: 6.2132e-04 - lr: 5.0000e-05
Epoch 9/10
44/86 [==============>...............] - ETA: 0s - loss: 8.5363 - mae: 0.0164 - mse: 4.3283e-04
Epoch 9: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.
86/86 [==============================] - 0s 2ms/step - loss: 8.4791 - mae: 0.0169 - mse: 4.5643e-04 - val_loss: 8.3589 - val_mae: 0.0175 - val_mse: 4.8731e-04 - lr: 5.0000e-05
Epoch 10/10
86/86 [==============================] - 0s 2ms/step - loss: 8.3037 - mae: 0.0167 - mse: 4.5059e-04 - val_loss: 8.2469 - val_mae: 0.0181 - val_mse: 5.0851e-04 - lr: 2.5000e-05
>Saved models_no_overlap_30.0_10epochs/model_5.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Y [[0.596]
 [0.514]
 [0.526]
 ...
 [0.52 ]
 [0.574]
 [0.586]]
X [[0.00281704 0.02431304 0.01335414 ... 0.0001957  0.02202468 0.01045449]
 [0.00794252 0.03519745 0.00164735 ... 0.03222877 0.00365329 0.03065086]
 [0.0055022  0.02725266 0.00194181 ... 0.02144673 0.00716432 0.01778728]
 ...
 [0.00053196 0.00102944 0.00043293 ... 0.00093997 0.0005066  0.00088545]
 [0.00164814 0.00575309 0.00262877 ... 0.00141542 0.00576226 0.00116022]
 [0.00158778 0.00563416 0.00308913 ... 0.0010541  0.00561785 0.00194067]]
Epoch 1/10
86/86 [==============================] - 1s 3ms/step - loss: 14.7945 - mae: 0.3641 - mse: 0.1463 - val_loss: 13.9891 - val_mae: 0.1754 - val_mse: 0.0346 - lr: 1.0000e-04
Epoch 2/10
86/86 [==============================] - 0s 2ms/step - loss: 13.3504 - mae: 0.0815 - mse: 0.0102 - val_loss: 12.7295 - val_mae: 0.0358 - val_mse: 0.0020 - lr: 1.0000e-04
Epoch 3/10
86/86 [==============================] - 0s 2ms/step - loss: 12.1959 - mae: 0.0287 - mse: 0.0013 - val_loss: 11.6670 - val_mae: 0.0243 - val_mse: 0.0010 - lr: 1.0000e-04
Epoch 4/10
86/86 [==============================] - 0s 2ms/step - loss: 11.2092 - mae: 0.0208 - mse: 6.6347e-04 - val_loss: 10.7564 - val_mae: 0.0224 - val_mse: 6.6124e-04 - lr: 1.0000e-04
Epoch 5/10
86/86 [==============================] - 0s 2ms/step - loss: 10.3663 - mae: 0.0184 - mse: 5.3079e-04 - val_loss: 9.9814 - val_mae: 0.0179 - val_mse: 5.2787e-04 - lr: 1.0000e-04
Epoch 6/10
86/86 [==============================] - 0s 2ms/step - loss: 9.6515 - mae: 0.0178 - mse: 5.0780e-04 - val_loss: 9.3268 - val_mae: 0.0208 - val_mse: 7.5377e-04 - lr: 1.0000e-04
Epoch 7/10
86/86 [==============================] - 0s 2ms/step - loss: 9.0492 - mae: 0.0180 - mse: 5.1255e-04 - val_loss: 8.7766 - val_mae: 0.0209 - val_mse: 5.8063e-04 - lr: 1.0000e-04
Epoch 8/10
72/86 [========================>.....] - ETA: 0s - loss: 8.5790 - mae: 0.0186 - mse: 5.4030e-04
Epoch 8: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.
86/86 [==============================] - 0s 2ms/step - loss: 8.5444 - mae: 0.0187 - mse: 5.4967e-04 - val_loss: 8.3165 - val_mae: 0.0226 - val_mse: 6.6799e-04 - lr: 1.0000e-04
Epoch 9/10
86/86 [==============================] - 0s 2ms/step - loss: 8.2155 - mae: 0.0180 - mse: 5.0329e-04 - val_loss: 8.1135 - val_mae: 0.0189 - val_mse: 6.2056e-04 - lr: 5.0000e-05
Epoch 10/10
86/86 [==============================] - 0s 4ms/step - loss: 8.0212 - mae: 0.0182 - mse: 5.1460e-04 - val_loss: 7.9280 - val_mae: 0.0210 - val_mse: 7.4291e-04 - lr: 5.0000e-05
>Saved models_no_overlap_30.0_10epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Y [[0.696]
 [0.614]
 [0.626]
 ...
 [0.62 ]
 [0.674]
 [0.686]]
X [[0.00100632 0.01468389 0.02928995 ... 0.02402802 0.01473997 0.0002305 ]
 [0.00410087 0.03056912 0.02327682 ... 0.00599302 0.01852052 0.02772186]
 [0.00270548 0.02250158 0.02040663 ... 0.00888944 0.00803623 0.02553832]
 ...
 [0.00046505 0.00093261 0.00084285 ... 0.0005503  0.00065485 0.00095144]
 [0.00125998 0.00418219 0.00613691 ... 0.00566793 0.00177753 0.00259461]
 [0.00122914 0.00393944 0.00633418 ... 0.00572376 0.00278586 0.00152013]]
Epoch 1/10
86/86 [==============================] - 1s 5ms/step - loss: 14.7487 - mae: 0.5001 - mse: 0.2603 - val_loss: 13.9055 - val_mae: 0.3133 - val_mse: 0.1000 - lr: 1.0000e-04
Epoch 2/10
86/86 [==============================] - 0s 4ms/step - loss: 13.2327 - mae: 0.1461 - mse: 0.0299 - val_loss: 12.5962 - val_mae: 0.0456 - val_mse: 0.0029 - lr: 1.0000e-04
Epoch 3/10
86/86 [==============================] - 0s 3ms/step - loss: 12.0626 - mae: 0.0374 - mse: 0.0020 - val_loss: 11.5340 - val_mae: 0.0338 - val_mse: 0.0016 - lr: 1.0000e-04
Epoch 4/10
86/86 [==============================] - 0s 4ms/step - loss: 11.0770 - mae: 0.0328 - mse: 0.0015 - val_loss: 10.6248 - val_mae: 0.0315 - val_mse: 0.0014 - lr: 1.0000e-04
Epoch 5/10
86/86 [==============================] - 1s 6ms/step - loss: 10.2354 - mae: 0.0309 - mse: 0.0013 - val_loss: 9.8513 - val_mae: 0.0305 - val_mse: 0.0013 - lr: 1.0000e-04
Epoch 6/10
86/86 [==============================] - 0s 4ms/step - loss: 9.5220 - mae: 0.0293 - mse: 0.0012 - val_loss: 9.1979 - val_mae: 0.0298 - val_mse: 0.0012 - lr: 1.0000e-04
Epoch 7/10
86/86 [==============================] - 0s 4ms/step - loss: 8.9214 - mae: 0.0291 - mse: 0.0012 - val_loss: 8.6498 - val_mae: 0.0299 - val_mse: 0.0013 - lr: 1.0000e-04
Epoch 8/10
86/86 [==============================] - 0s 3ms/step - loss: 8.4186 - mae: 0.0287 - mse: 0.0011 - val_loss: 8.1915 - val_mae: 0.0294 - val_mse: 0.0012 - lr: 1.0000e-04
Epoch 9/10
86/86 [==============================] - 0s 4ms/step - loss: 7.9976 - mae: 0.0283 - mse: 0.0011 - val_loss: 7.8069 - val_mae: 0.0290 - val_mse: 0.0012 - lr: 1.0000e-04
Epoch 10/10
86/86 [==============================] - 0s 4ms/step - loss: 7.6434 - mae: 0.0282 - mse: 0.0011 - val_loss: 7.4821 - val_mae: 0.0322 - val_mse: 0.0015 - lr: 1.0000e-04
>Saved models_no_overlap_30.0_10epochs/model_7.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Y [[0.796]
 [0.714]
 [0.726]
 ...
 [0.72 ]
 [0.774]
 [0.786]]
X [[0.00022629 0.00495616 0.01957348 ... 0.00437114 0.00130849 0.01504514]
 [0.00205337 0.01737347 0.03898619 ... 0.02461781 0.03026386 0.00447503]
 [0.00125259 0.01198549 0.0296546  ... 0.013766   0.02591585 0.00904026]
 ...
 [0.00042983 0.00069183 0.00109211 ... 0.00077923 0.00097717 0.00053487]
 [0.00108117 0.00226479 0.0053754  ... 0.00102576 0.00289618 0.00560514]
 [0.00106969 0.00207929 0.00498671 ... 0.0013048  0.00185761 0.00481809]]
Epoch 1/10
86/86 [==============================] - 1s 5ms/step - loss: 15.0768 - mae: 0.4893 - mse: 0.2654 - val_loss: 14.1959 - val_mae: 0.2304 - val_mse: 0.0623 - lr: 1.0000e-04
Epoch 2/10
86/86 [==============================] - 0s 2ms/step - loss: 13.5396 - mae: 0.1197 - mse: 0.0203 - val_loss: 12.9101 - val_mae: 0.0668 - val_mse: 0.0063 - lr: 1.0000e-04
Epoch 3/10
86/86 [==============================] - 0s 3ms/step - loss: 12.3725 - mae: 0.0550 - mse: 0.0045 - val_loss: 11.8389 - val_mae: 0.0417 - val_mse: 0.0029 - lr: 1.0000e-04
Epoch 4/10
86/86 [==============================] - 0s 3ms/step - loss: 11.3775 - mae: 0.0389 - mse: 0.0023 - val_loss: 10.9204 - val_mae: 0.0337 - val_mse: 0.0017 - lr: 1.0000e-04
Epoch 5/10
86/86 [==============================] - 0s 3ms/step - loss: 10.5268 - mae: 0.0306 - mse: 0.0014 - val_loss: 10.1380 - val_mae: 0.0273 - val_mse: 0.0011 - lr: 1.0000e-04
Epoch 6/10
86/86 [==============================] - 0s 3ms/step - loss: 9.8049 - mae: 0.0261 - mse: 0.0010 - val_loss: 9.4769 - val_mae: 0.0266 - val_mse: 0.0012 - lr: 1.0000e-04
Epoch 7/10
86/86 [==============================] - 0s 4ms/step - loss: 9.1966 - mae: 0.0242 - mse: 8.7179e-04 - val_loss: 8.9215 - val_mae: 0.0267 - val_mse: 9.7533e-04 - lr: 1.0000e-04
Epoch 8/10
86/86 [==============================] - 0s 4ms/step - loss: 8.6867 - mae: 0.0236 - mse: 8.2481e-04 - val_loss: 8.4558 - val_mae: 0.0233 - val_mse: 7.7291e-04 - lr: 1.0000e-04
Epoch 9/10
86/86 [==============================] - 0s 4ms/step - loss: 8.2590 - mae: 0.0230 - mse: 7.8472e-04 - val_loss: 8.0650 - val_mae: 0.0225 - val_mse: 7.2507e-04 - lr: 1.0000e-04
Epoch 10/10
86/86 [==============================] - 0s 3ms/step - loss: 7.8986 - mae: 0.0230 - mse: 7.8815e-04 - val_loss: 7.7340 - val_mae: 0.0259 - val_mse: 8.9039e-04 - lr: 1.0000e-04
>Saved models_no_overlap_30.0_10epochs/model_8.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Y [[0.896]
 [0.814]
 [0.826]
 ...
 [0.82 ]
 [0.874]
 [0.886]]
X [[1.68700350e-05 5.08684465e-04 3.04420353e-03 ... 2.39526770e-02
  2.87784802e-02 2.87183658e-02]
 [1.22442942e-03 5.80032512e-03 2.16794600e-02 ... 1.64463190e-02
  1.70881136e-03 7.17214544e-03]
 [6.90631753e-04 3.56631514e-03 1.42720027e-02 ... 1.83272921e-02
  4.38938646e-03 1.22751731e-03]
 ...
 [4.15892437e-04 4.90099039e-04 7.56990916e-04 ... 7.57091876e-04
  4.54970753e-04 4.65827606e-04]
 [1.02609682e-03 1.20563218e-03 2.05233827e-03 ... 6.40833769e-03
  6.07325777e-03 4.49378265e-03]
 [1.02397732e-03 1.15023685e-03 1.77614442e-03 ... 6.01792407e-03
  6.45268516e-03 5.72367207e-03]]
Epoch 1/10
86/86 [==============================] - 1s 5ms/step - loss: 15.0737 - mae: 0.5687 - mse: 0.3601 - val_loss: 14.1541 - val_mae: 0.3025 - val_mse: 0.1091 - lr: 1.0000e-04
Epoch 2/10
86/86 [==============================] - 0s 3ms/step - loss: 13.4803 - mae: 0.1825 - mse: 0.0444 - val_loss: 12.8420 - val_mae: 0.1138 - val_mse: 0.0186 - lr: 1.0000e-04
Epoch 3/10
86/86 [==============================] - 0s 3ms/step - loss: 12.3015 - mae: 0.0926 - mse: 0.0125 - val_loss: 11.7643 - val_mae: 0.0725 - val_mse: 0.0073 - lr: 1.0000e-04
Epoch 4/10
86/86 [==============================] - 0s 4ms/step - loss: 11.3007 - mae: 0.0589 - mse: 0.0053 - val_loss: 10.8416 - val_mae: 0.0459 - val_mse: 0.0037 - lr: 1.0000e-04
Epoch 5/10
86/86 [==============================] - 0s 5ms/step - loss: 10.4461 - mae: 0.0422 - mse: 0.0028 - val_loss: 10.0558 - val_mae: 0.0410 - val_mse: 0.0025 - lr: 1.0000e-04
Epoch 6/10
86/86 [==============================] - 0s 5ms/step - loss: 9.7214 - mae: 0.0350 - mse: 0.0019 - val_loss: 9.3923 - val_mae: 0.0345 - val_mse: 0.0019 - lr: 1.0000e-04
Epoch 7/10
86/86 [==============================] - 0s 3ms/step - loss: 9.1112 - mae: 0.0310 - mse: 0.0015 - val_loss: 8.8350 - val_mae: 0.0291 - val_mse: 0.0013 - lr: 1.0000e-04
Epoch 8/10
86/86 [==============================] - 0s 2ms/step - loss: 8.6002 - mae: 0.0294 - mse: 0.0013 - val_loss: 8.3696 - val_mae: 0.0285 - val_mse: 0.0013 - lr: 1.0000e-04
Epoch 9/10
86/86 [==============================] - 0s 3ms/step - loss: 8.1730 - mae: 0.0282 - mse: 0.0012 - val_loss: 7.9800 - val_mae: 0.0301 - val_mse: 0.0015 - lr: 1.0000e-04
Epoch 10/10
86/86 [==============================] - ETA: 0s - loss: 7.8134 - mae: 0.0270 - mse: 0.0011
Epoch 10: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.
86/86 [==============================] - 0s 3ms/step - loss: 7.8134 - mae: 0.0270 - mse: 0.0011 - val_loss: 7.6494 - val_mae: 0.0323 - val_mse: 0.0015 - lr: 1.0000e-04
>Saved models_no_overlap_30.0_10epochs/model_9.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Y [[0.972]
 [0.94 ]
 [0.948]
 ...
 [1.   ]
 [0.986]
 [0.944]]
X [[0.00041265 0.00041287 0.00041432 ... 0.00044489 0.00047125 0.00050919]
 [0.00056971 0.0006524  0.00114772 ... 0.00882494 0.01385096 0.01967764]
 [0.00056777 0.00058678 0.00070343 ... 0.00267332 0.00407844 0.00582863]
 ...
 [0.00041264 0.00041264 0.00041264 ... 0.00041264 0.00041264 0.00041264]
 [0.00056721 0.00056735 0.00056832 ... 0.00059086 0.00061189 0.00064387]
 [0.00101958 0.00102164 0.00103412 ... 0.00123619 0.00137453 0.00154112]]
Epoch 1/10
87/87 [==============================] - 1s 5ms/step - loss: 14.8734 - mae: 0.7059 - mse: 0.5247 - val_loss: 13.8657 - val_mae: 0.4108 - val_mse: 0.1737 - lr: 1.0000e-04
Epoch 2/10
87/87 [==============================] - 0s 2ms/step - loss: 13.1294 - mae: 0.1718 - mse: 0.0446 - val_loss: 12.4791 - val_mae: 0.0581 - val_mse: 0.0052 - lr: 1.0000e-04
Epoch 3/10
87/87 [==============================] - 0s 3ms/step - loss: 11.9341 - mae: 0.0489 - mse: 0.0038 - val_loss: 11.4030 - val_mae: 0.0444 - val_mse: 0.0030 - lr: 1.0000e-04
Epoch 4/10
87/87 [==============================] - 0s 4ms/step - loss: 10.9369 - mae: 0.0407 - mse: 0.0025 - val_loss: 10.4835 - val_mae: 0.0388 - val_mse: 0.0021 - lr: 1.0000e-04
Epoch 5/10
87/87 [==============================] - 0s 4ms/step - loss: 10.0875 - mae: 0.0360 - mse: 0.0019 - val_loss: 9.7033 - val_mae: 0.0355 - val_mse: 0.0017 - lr: 1.0000e-04
Epoch 6/10
87/87 [==============================] - 0s 5ms/step - loss: 9.3691 - mae: 0.0329 - mse: 0.0015 - val_loss: 9.0458 - val_mae: 0.0317 - val_mse: 0.0014 - lr: 1.0000e-04
Epoch 7/10
87/87 [==============================] - 0s 3ms/step - loss: 8.7661 - mae: 0.0306 - mse: 0.0013 - val_loss: 8.4958 - val_mae: 0.0304 - val_mse: 0.0012 - lr: 1.0000e-04
Epoch 8/10
87/87 [==============================] - 0s 3ms/step - loss: 8.2626 - mae: 0.0293 - mse: 0.0012 - val_loss: 8.0373 - val_mae: 0.0287 - val_mse: 0.0011 - lr: 1.0000e-04
Epoch 9/10
87/87 [==============================] - 0s 3ms/step - loss: 7.8428 - mae: 0.0287 - mse: 0.0011 - val_loss: 7.6545 - val_mae: 0.0281 - val_mse: 0.0010 - lr: 1.0000e-04
Epoch 10/10
87/87 [==============================] - 0s 3ms/step - loss: 7.4906 - mae: 0.0277 - mse: 0.0011 - val_loss: 7.3316 - val_mae: 0.0303 - val_mse: 0.0013 - lr: 1.0000e-04
>Saved models_no_overlap_30.0_10epochs/model_10.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])