Epoch 1/150
153/162 [===========================>..] - ETA: 0s - loss: 0.0036 - mae: 0.0514 - mse: 0.0036 - root_mean_squared_error: 0.0599
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
162/162 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0514 - mse: 0.0036 - root_mean_squared_error: 0.0598 - val_loss: 0.0034 - val_mae: 0.0507 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0586 - lr: 0.0153
Epoch 2/150
161/162 [============================>.] - ETA: 0s - loss: 0.0035 - mae: 0.0509 - mse: 0.0035 - root_mean_squared_error: 0.0589
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
162/162 [==============================] - 2s 13ms/step - loss: 0.0035 - mae: 0.0509 - mse: 0.0035 - root_mean_squared_error: 0.0589 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0153
Epoch 3/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0034 - val_mae: 0.0508 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0586 - lr: 0.0153
Epoch 4/150
156/162 [===========================>..] - ETA: 0s - loss: 0.0035 - mae: 0.0511 - mse: 0.0035 - root_mean_squared_error: 0.0593
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
162/162 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0510 - mse: 0.0035 - root_mean_squared_error: 0.0591 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0153
Epoch 5/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0035 - mae: 0.0509 - mse: 0.0035 - root_mean_squared_error: 0.0589 - val_loss: 0.0036 - val_mae: 0.0515 - val_mse: 0.0036 - val_root_mean_squared_error: 0.0599 - lr: 0.0153
Epoch 6/150
162/162 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0035 - root_mean_squared_error: 0.0589 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0153
Epoch 7/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0035 - root_mean_squared_error: 0.0588 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0153
Epoch 8/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0035 - val_mae: 0.0512 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0594 - lr: 0.0153
Epoch 9/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0035 - root_mean_squared_error: 0.0588 - val_loss: 0.0034 - val_mae: 0.0507 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0586 - lr: 0.0153
Epoch 10/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0587 - val_loss: 0.0036 - val_mae: 0.0516 - val_mse: 0.0036 - val_root_mean_squared_error: 0.0601 - lr: 0.0153
Epoch 11/150
162/162 [==============================] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - root_mean_squared_error: 0.0586
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.007658619899302721.
162/162 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0035 - val_mae: 0.0510 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0591 - lr: 0.0153
Epoch 12/150
162/162 [==============================] - 1s 5ms/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0035 - root_mean_squared_error: 0.0588 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0077
Epoch 13/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0077
Epoch 14/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0035 - val_mae: 0.0509 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0589 - lr: 0.0077
Epoch 15/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0077
Epoch 16/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0034 - val_mae: 0.0508 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0586 - lr: 0.0077
Epoch 17/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0035 - val_mae: 0.0511 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0594 - lr: 0.0077
Epoch 18/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0035 - val_mae: 0.0508 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0587 - lr: 0.0077
Epoch 19/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0035 - root_mean_squared_error: 0.0589 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0077
Epoch 20/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - root_mean_squared_error: 0.0587 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0077
Epoch 21/150
155/162 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0584
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0038293099496513605.
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0035 - val_mae: 0.0513 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0594 - lr: 0.0077
Epoch 22/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0038
Epoch 23/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0507 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0586 - lr: 0.0038
Epoch 24/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0035 - val_mae: 0.0508 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0588 - lr: 0.0038
Epoch 25/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0038
Epoch 26/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0038
Epoch 27/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0038
Epoch 28/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0038
Epoch 29/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0035 - val_mae: 0.0509 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0588 - lr: 0.0038
Epoch 30/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0507 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0585 - lr: 0.0038
Epoch 31/150
157/162 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - root_mean_squared_error: 0.0587
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0019146549748256803.
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0038
Epoch 32/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0585 - lr: 0.0019
Epoch 33/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0019
Epoch 34/150
162/162 [==============================] - 1s 7ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0019
Epoch 35/150
162/162 [==============================] - 1s 7ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0019
Epoch 36/150
162/162 [==============================] - 1s 7ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0019
Epoch 37/150
162/162 [==============================] - 1s 7ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0019
Epoch 38/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0019
Epoch 39/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0019
Epoch 40/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0019
Epoch 41/150
153/162 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0009573274874128401.
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0585 - lr: 0.0019
Epoch 42/150
155/162 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0583
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
162/162 [==============================] - 2s 12ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 9.5733e-04
Epoch 43/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 9.5733e-04
Epoch 44/150
162/162 [==============================] - 1s 7ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 9.5733e-04
Epoch 45/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 9.5733e-04
Epoch 46/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 9.5733e-04
Epoch 47/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 9.5733e-04
Epoch 48/150
 11/162 [=>............................] - ETA: 0s - loss: 0.0035 - mae: 0.0519 - mse: 0.0035 - root_mean_squared_error: 0.05930583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 9.5733e-04
Epoch 49/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 9.5733e-04
Epoch 50/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 9.5733e-04
Epoch 51/150
150/162 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0582
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00047866374370642006.
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 9.5733e-04
Epoch 52/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 4.7866e-04
Epoch 53/150
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 4.7866e-04
Epoch 54/150
 38/162 [======>.......................] - ETA: 0s - loss: 0.0035 - mae: 0.0513 - mse: 0.0035 - root_mean_squared_error: 0.0589
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 4.7866e-04
Epoch 56/150
 51/162 [========>.....................] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0580
 63/162 [==========>...................] - ETA: 0s - loss: 0.0034 - mae: 0.0503 - mse: 0.0034 - root_mean_squared_error: 0.05800583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 4.7866e-04
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 4.7866e-04
162/162 [==============================] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.05830583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 4.7866e-04
162/162 [==============================] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.05830583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 4.7866e-04
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.3933e-04
 38/162 [======>.......................] - ETA: 0s - loss: 0.0033 - mae: 0.0499 - mse: 0.0033 - root_mean_squared_error: 0.05780583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.3933e-04
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.3933e-04
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.3933e-04
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.1967e-04
 75/162 [============>.................] - ETA: 0s - loss: 0.0034 - mae: 0.0502 - mse: 0.0034 - root_mean_squared_error: 0.05810583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.1967e-04
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.1967e-04
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.1967e-04
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 5.9833e-05
 97/162 [================>.............] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.05830583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 5.9833e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 5.9833e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 5.9833e-05
 50/162 [========>.....................] - ETA: 0s - loss: 0.0034 - mae: 0.0509 - mse: 0.0034 - root_mean_squared_error: 0.05870583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 5.9833e-05
 62/162 [==========>...................] - ETA: 0s - loss: 0.0034 - mae: 0.0508 - mse: 0.0034 - root_mean_squared_error: 0.05860583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 5.9833e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.9916e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.9916e-05
102/162 [=================>............] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.05820583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.9916e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.9916e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.9916e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.4958e-05
131/162 [=======================>......] - ETA: 0s - loss: 0.0034 - mae: 0.0508 - mse: 0.0034 - root_mean_squared_error: 0.05860583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.4958e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.4958e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.4958e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
153/162 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.05830583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
100/162 [=================>............] - ETA: 0s - loss: 0.0033 - mae: 0.0497 - mse: 0.0033 - root_mean_squared_error: 0.05770583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
137/162 [========================>.....] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.05840583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
155/162 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.05830583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
 88/162 [===============>..............] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.05820583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
149/162 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.05820583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
234/242 [============================>.] - ETA: 0s - loss: 0.0031 - mae: 0.0418 - mse: 0.0031 - root_mean_squared_error: 0.0554r']) - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.0000e-05
242/242 [==============================] - 3s 11ms/step - loss: 0.0031 - mae: 0.0417 - mse: 0.0031 - root_mean_squared_error: 0.0553 - val_loss: 0.0028 - val_mae: 0.0409 - val_mse: 0.0028 - val_root_mean_squared_error: 0.0533 - lr: 0.0153-05
242/242 [==============================] - 3s 11ms/step - loss: 0.0031 - mae: 0.0417 - mse: 0.0031 - root_mean_squared_error: 0.0553 - val_loss: 0.0028 - val_mae: 0.0409 - val_mse: 0.0028 - val_root_mean_squared_error: 0.0533 - lr: 0.0153-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
242/242 [==============================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
242/242 [==============================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 10/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 13/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 13/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 13/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 13/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 13/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 13/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 13/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 20/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 20/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 20/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 24/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 24/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 28/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 30/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 30/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 32/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 32/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 34/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 36/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 36/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 36/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 36/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 36/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 40/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 40/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 44/150===========================] - 2s 6ms/step - loss: 0.0025 - mae: 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0038293099496513605. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0038293099496513605. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 50/150duceLROnPlateau reducing learning rate to 0.0038293099496513605. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 50/150duceLROnPlateau reducing learning rate to 0.0038293099496513605. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 50/150duceLROnPlateau reducing learning rate to 0.0038293099496513605. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 50/150duceLROnPlateau reducing learning rate to 0.0038293099496513605. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 54/150duceLROnPlateau reducing learning rate to 0.0038293099496513605. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 54/150duceLROnPlateau reducing learning rate to 0.0038293099496513605. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 59/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 62/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 62/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 65/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 65/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 67/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 69/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 69/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 69/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 75/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 77/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 79/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 79/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 82/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 82/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 82/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 82/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 82/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 86: ReduceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 86: ReduceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 89/150duceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 92/150duceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 92/150duceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 92/150duceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 96/150duceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 98/150duceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 98/150duceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 102/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 102/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 105/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 105/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 107/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 109/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 109/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 112/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 112/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 115/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 115/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 117/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 119/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 119/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 122/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 122/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 122/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 126/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 127/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 129/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 129/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 132/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 132/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 135/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 135/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 137/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 137/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 141/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 141/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 141/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 145/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 145/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 148/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 148/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0380 - mse: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0057 - val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 4/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 4/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 4/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 7/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 9/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 9/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 9/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 12/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 12/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 12/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 15/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 15/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 18/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 18/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 20/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 20/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 20/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 23/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 23/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 23/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 27/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 27/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 27/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 27/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 35/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 38/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 38/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 38/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 38/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 45/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 45/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 45/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 50/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 52/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 52/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 52/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 55/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 55/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 55/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 55/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 62/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 62/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 62/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 65/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 65/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 65/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 65/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 69/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 69/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 75/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 75/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 75/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 78/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 81/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 82/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 82/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 82/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 82/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 82/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 111: ReduceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 111: ReduceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 113/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 113/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 116/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 116/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 116/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 120/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 122/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 122/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 126/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 126/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 126/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 129/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 131/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 131/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 131/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 131/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 134/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 136/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 139/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 139/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 139/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 142/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 142/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 142/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 145/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 145/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 145/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 148/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 148/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230509_235739-97wv9tvc\files\model-best)... Done. 0.0s
Epoch 148/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_2.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0049s). Check your callbacks.
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 3/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 3/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 6/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 6/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 9/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 9/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 9/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 13/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 13/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 16/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 16/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 16/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 20/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 20/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 23/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 23/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 26/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 26/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 26/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 30/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 30/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 33/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 34/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 34/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 37/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 37/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 40/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 40/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 43/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 43/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 46/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 46/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 46/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 50/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 50/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 52/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 52/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 56/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 56/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 59/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 59/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 66/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 66/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 69/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 69/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 73/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 75/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 75/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 75/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 79/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 79/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 82/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 83/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 83/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 102: ReduceLROnPlateau reducing learning rate to 0.00011966593592660502.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 102: ReduceLROnPlateau reducing learning rate to 0.00011966593592660502.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 102: ReduceLROnPlateau reducing learning rate to 0.00011966593592660502.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
135/242 [===============>..............] - ETA: 0s - loss: 6.6844e-05 - mae: 0.0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
135/242 [===============>..............] - ETA: 0s - loss: 6.6844e-05 - mae: 0.0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 110/150===========>..............] - ETA: 0s - loss: 6.6844e-05 - mae: 0.0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 110/150===========>..............] - ETA: 0s - loss: 6.6844e-05 - mae: 0.0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 112: ReduceLROnPlateau reducing learning rate to 5.983296796330251e-05.0.0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 112: ReduceLROnPlateau reducing learning rate to 5.983296796330251e-05.0.0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 112: ReduceLROnPlateau reducing learning rate to 5.983296796330251e-05.0.0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 117/150duceLROnPlateau reducing learning rate to 5.983296796330251e-05.0.0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 117/150duceLROnPlateau reducing learning rate to 5.983296796330251e-05.0.0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 120/150duceLROnPlateau reducing learning rate to 5.983296796330251e-05.0.0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 120/150duceLROnPlateau reducing learning rate to 5.983296796330251e-05.0.0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 122: ReduceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 122: ReduceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 126/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 126/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 126/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 130/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 130/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 130/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 133/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 133/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 137/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 137/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 140/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 140/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 140/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 143/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 143/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 147/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 147/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 147/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0061 - mse: 6.6844e-05 - root_mean_squared_error: 0.0082pochs/model_3.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 3/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 3/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 6/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 6/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 6/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 10/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 10/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 13/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 13/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 16/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 16/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 16/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 20/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 20/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 20/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 24/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 24/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 27/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 27/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 30/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 30/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 30/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 34/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 35/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 37/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 37/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 37/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 41/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 41/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
Epoch 41/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_4.h5- val_mae: 0.0573 - val_mse: 0.0057 - val_root_mean_squared_error: 0.0756 - lr: 0.01533-05
242/242 [==============================] - 1s 6ms/step - loss: 0.0011 - mae: 0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
242/242 [==============================] - 1s 6ms/step - loss: 0.0011 - mae: 0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 48/150===========================] - 1s 6ms/step - loss: 0.0011 - mae: 0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 48/150===========================] - 1s 6ms/step - loss: 0.0011 - mae: 0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 51/150===========================] - 1s 6ms/step - loss: 0.0011 - mae: 0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 51/150===========================] - 1s 6ms/step - loss: 0.0011 - mae: 0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 51/150===========================] - 1s 6ms/step - loss: 0.0011 - mae: 0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 59/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 59/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 62/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 62/150duceLROnPlateau reducing learning rate to 0.0019146549748256803. 0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0009573274874128401. 0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0009573274874128401. 0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 68/150duceLROnPlateau reducing learning rate to 0.0009573274874128401. 0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 68/150duceLROnPlateau reducing learning rate to 0.0009573274874128401. 0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 68/150duceLROnPlateau reducing learning rate to 0.0009573274874128401. 0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0009573274874128401. 0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0009573274874128401. 0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 74: ReduceLROnPlateau reducing learning rate to 0.00047866374370642006.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 74: ReduceLROnPlateau reducing learning rate to 0.00047866374370642006.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 78/150duceLROnPlateau reducing learning rate to 0.00047866374370642006.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 78/150duceLROnPlateau reducing learning rate to 0.00047866374370642006.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 78/150duceLROnPlateau reducing learning rate to 0.00047866374370642006.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 82/150duceLROnPlateau reducing learning rate to 0.00047866374370642006.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 82/150duceLROnPlateau reducing learning rate to 0.00047866374370642006.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 85/150duceLROnPlateau reducing learning rate to 0.00047866374370642006.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 85/150duceLROnPlateau reducing learning rate to 0.00047866374370642006.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 85/150duceLROnPlateau reducing learning rate to 0.00047866374370642006.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 89/150duceLROnPlateau reducing learning rate to 0.00047866374370642006.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 89/150duceLROnPlateau reducing learning rate to 0.00047866374370642006.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 92/150duceLROnPlateau reducing learning rate to 0.00047866374370642006.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 92/150duceLROnPlateau reducing learning rate to 0.00047866374370642006.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 94: ReduceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 94: ReduceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 94: ReduceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 99/150duceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 99/150duceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 102/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 102/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 102/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 105/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 105/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 109/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 109/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 112/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 112/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 114: ReduceLROnPlateau reducing learning rate to 5.983296796330251e-05.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 114: ReduceLROnPlateau reducing learning rate to 5.983296796330251e-05.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 118/150duceLROnPlateau reducing learning rate to 5.983296796330251e-05.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 118/150duceLROnPlateau reducing learning rate to 5.983296796330251e-05.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 118/150duceLROnPlateau reducing learning rate to 5.983296796330251e-05.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 122/150duceLROnPlateau reducing learning rate to 5.983296796330251e-05.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 122/150duceLROnPlateau reducing learning rate to 5.983296796330251e-05.0.0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 124: ReduceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 124: ReduceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 124: ReduceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 129/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 129/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 132/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 132/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 134: ReduceLROnPlateau reducing learning rate to 1.4958241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 134: ReduceLROnPlateau reducing learning rate to 1.4958241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 138/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 138/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 138/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 142/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 142/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 144: ReduceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 144: ReduceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 144: ReduceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 149/150duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 149/150duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 1/15050duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 1/15050duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 4/15050duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 4/15050duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 4/15050duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 8/15050duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 8/15050duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 8/15050duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 12/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 12/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 15/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 15/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 18/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 18/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 18/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 22/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 22/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 25/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 25/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 25/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 29/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 29/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 32/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 32/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 35/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 35/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 38/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 38/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 38/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 41/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 41/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 45/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 45/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 48/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 48/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 51/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 51/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 54/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 54/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 54/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 58/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 58/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 60/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 60/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 64/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 64/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 67/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 67/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 70/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 70/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 70/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 74/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 74/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 80/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 80/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 83/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 83/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 116/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 117/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 119/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 119/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 119/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 123/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 123/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 126/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 127/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 129/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 129/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 129/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 133/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 133/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 136/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 137/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 139/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 139/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 139/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 143/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 143/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 146/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 147/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 149/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 149/150uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 1/15050uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 1/15050uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0042s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0042s). Check your callbacks.
Epoch 1/15050uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 5/15050uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 5/15050uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 5/15050uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 9/15050uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 9/15050uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 12/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 12/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 15/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 15/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 18/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 18/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 21/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 21/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 21/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 25/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 25/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 25/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 29/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 29/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 32/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 32/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 35/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 35/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 38/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 39/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 39/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 42/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 42/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 45/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 45/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 48/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 49/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 51/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 51/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 54/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 54/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 54/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 58/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 59/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 59/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 62/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 62/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 65/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 65/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 68/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 69/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 71/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 71/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 71/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 75/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 75/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 78/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 79/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 79/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 82/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 82/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 85/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 85/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 85/1500uceLROnPlateau reducing learning rate to 0.0019146549748256803.5..0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 88: ReduceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 88: ReduceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 92/150duceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 92/150duceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 95/150duceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 95/150duceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 98/150duceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 99/150duceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 101/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 101/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 101/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 105/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 105/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 108/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 109/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 111/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 111/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 114/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 114/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 117/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 117/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 119/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 121/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 121/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 124/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 124/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 124/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 128/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 129/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 131/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 131/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 131/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 135/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 135/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 138/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 139/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 141/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 141/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 144/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 144/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 144/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 148/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 148/150uceLROnPlateau reducing learning rate to 0.00023933187185321003...0268 - mse: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 4/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 4/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 7/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 7/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 7/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 11/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 11/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 11/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 15/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 15/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 18/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 18/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 21/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 21/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 21/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 25/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 25/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 25/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 29/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 29/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 32/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 32/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 35/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 35/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 38/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 38/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 38/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.007658619899302721.23976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.007658619899302721.23976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.007658619899302721.23976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 46/150duceLROnPlateau reducing learning rate to 0.007658619899302721.23976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 46/150duceLROnPlateau reducing learning rate to 0.007658619899302721.23976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 49/150duceLROnPlateau reducing learning rate to 0.007658619899302721.23976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 49/150duceLROnPlateau reducing learning rate to 0.007658619899302721.23976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 56/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 56/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 59/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 59/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 59/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 63/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 64/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 66/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 66/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 69/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 69/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 74/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 74/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 74/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 79/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 79/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 79/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 83/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.3976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 93: ReduceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 93: ReduceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 97/150duceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 97/150duceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 100/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 100/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 103/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 104/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 106/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 106/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 106/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 110/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 110/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 113/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 114/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 116/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 116/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 119/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 119/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 119/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 123/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 124/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 124/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 127/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 127/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 130/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 130/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 130/150uceLROnPlateau reducing learning rate to 0.00023933187185321003.976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 133: ReduceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 133: ReduceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 137/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 137/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 140/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 140/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 140/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 143: ReduceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 143: ReduceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 143: ReduceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 148/150duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 148/150duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_7.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 3/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 3/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 3/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 7/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 7/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 7/150rained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 11/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 11/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 14/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 14/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 17/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 17/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 20/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 20/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 20/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 24/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 24/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 27/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 27/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 27/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 31/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 31/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 34/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 35/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 37/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 37/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 37/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 41/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 41/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 44/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 44/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 46/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 46/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 50/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 50/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 53/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 53/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 53/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 56/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 58/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 58/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 61/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 61/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 64/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 64/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 66/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 66/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 70/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 70/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 70/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 74/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 74/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 76/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 76/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 80/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 80/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 80/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 84/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 84/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 86/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 88/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 88/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 91/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 91/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 94/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 94/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 97/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 97/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 97/150ained_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 100/150ined_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 100/150ined_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 100/150ined_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 105/150ined_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 105/150ined_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 108/150ined_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 108/150ined_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 110/150ined_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 110/150ined_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 114/150ined_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 114/150ined_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 117/150ined_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 117/150ined_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 117/150ined_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 120/150ined_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 120/150ined_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 124/150ined_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 124/150ined_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 127/150ined_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 127/150ined_models/CNN/models_segments_overlap-cnn-more_adam_0.01531723976585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 129: ReduceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 129: ReduceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 129: ReduceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 134/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 134/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 137/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 137/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 139: ReduceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 139: ReduceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 139: ReduceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 144/150duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 144/150duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 147/150duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 147/150duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 150/150duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 1/15050duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 3/15050duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 3/15050duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 6/15050duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 8/15050duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 10/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 12/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 14/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 16/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 18/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 21/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 23/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 25/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 27/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 29/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 31/1500duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 32: ReduceLROnPlateau reducing learning rate to 0.007658619899302721.05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 35/150duceLROnPlateau reducing learning rate to 0.007658619899302721.05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 37/150duceLROnPlateau reducing learning rate to 0.007658619899302721.05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 39/150duceLROnPlateau reducing learning rate to 0.007658619899302721.05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 41/150duceLROnPlateau reducing learning rate to 0.007658619899302721.05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0038293099496513605.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 45/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 47/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 49/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 51/150duceLROnPlateau reducing learning rate to 0.0038293099496513605.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0019146549748256803.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 55/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 57/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 59/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 61/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 63/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 64/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 67/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 69/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 71/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 73/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 75/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 75/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 79/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 81/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 83/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0019146549748256803.5.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 93: ReduceLROnPlateau reducing learning rate to 0.00011966593592660502..76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 96/150duceLROnPlateau reducing learning rate to 0.00011966593592660502..76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 98/150duceLROnPlateau reducing learning rate to 0.00011966593592660502..76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 100/150uceLROnPlateau reducing learning rate to 0.00011966593592660502..76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 102/150uceLROnPlateau reducing learning rate to 0.00011966593592660502..76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 103: ReduceLROnPlateau reducing learning rate to 5.983296796330251e-05..76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 106/150duceLROnPlateau reducing learning rate to 5.983296796330251e-05..76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 108/150duceLROnPlateau reducing learning rate to 5.983296796330251e-05..76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 110/150duceLROnPlateau reducing learning rate to 5.983296796330251e-05..76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 112/150duceLROnPlateau reducing learning rate to 5.983296796330251e-05..76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 113: ReduceLROnPlateau reducing learning rate to 2.9916483981651254e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 116/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 118/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 120/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 122/150duceLROnPlateau reducing learning rate to 2.9916483981651254e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 123: ReduceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 126/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 128/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 130/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 132/150duceLROnPlateau reducing learning rate to 1.4958241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 133: ReduceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 136/150duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 138/150duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 140/150duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 142/150duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 144/150duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 146/150duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
Epoch 148/150duceLROnPlateau reducing learning rate to 1e-05.241990825627e-05.76585724LR_[34]CHN_100CNNI_32BS_1000DU_10P_val_lossM_150epochs/model_8.h5- val_mae: 0.0280 - val_mse: 0.0012 - val_root_mean_squared_error: 0.0344 - lr: 0.00773-05
162/162 [==============================] - 1s 6ms/step - loss: 6.1794e-05 - mae: 0.0057 - mse: 6.1794e-05 - root_mean_squared_error: 0.0079 - val_loss: 6.6768e-05 - val_mae: 0.0059 - val_mse: 6.6768e-05 - val_root_mean_squared_error: 0.0082 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 6.1794e-05 - mae: 0.0057 - mse: 6.1794e-05 - root_mean_squared_error: 0.0079 - val_loss: 6.6768e-05 - val_mae: 0.0059 - val_mse: 6.6768e-05 - val_root_mean_squared_error: 0.0082 - lr: 1.0000e-05