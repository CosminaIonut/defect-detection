Epoch 1/150
230/243 [===========================>..] - ETA: 0s - loss: 0.8585 - mae: 0.9255 - mse: 0.8585
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0023s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0023s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
243/243 [==============================] - 3s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0999
Epoch 2/150
224/243 [==========================>...] - ETA: 0s - loss: 0.8580 - mae: 0.9253 - mse: 0.8580
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.049969978630542755.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0999
Epoch 3/150
224/243 [==========================>...] - ETA: 0s - loss: 0.8580 - mae: 0.9252 - mse: 0.8580
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.024984989315271378.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0500
Epoch 4/150
224/243 [==========================>...] - ETA: 0s - loss: 0.8583 - mae: 0.9254 - mse: 0.8583
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.012492494657635689.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0250
Epoch 5/150
236/243 [============================>.] - ETA: 0s - loss: 0.8578 - mae: 0.9252 - mse: 0.8578
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.006246247328817844.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0125
Epoch 6/150
233/243 [===========================>..] - ETA: 0s - loss: 0.8578 - mae: 0.9252 - mse: 0.8578
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.003123123664408922.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0062
Epoch 7/150
237/243 [============================>.] - ETA: 0s - loss: 0.8578 - mae: 0.9251 - mse: 0.8578
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.001561561832204461.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0031
Epoch 8/150
229/243 [===========================>..] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0007807809161022305.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0016
Epoch 9/150
230/243 [===========================>..] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003903904580511153.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 7.8078e-04
Epoch 10/150
205/243 [========================>.....] - ETA: 0s - loss: 0.8585 - mae: 0.9255 - mse: 0.8585
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00019519522902555764.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 3.9039e-04
Epoch 11/150
234/243 [===========================>..] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579
Epoch 11: ReduceLROnPlateau reducing learning rate to 9.759761451277882e-05.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.9520e-04
Epoch 12/150
231/243 [===========================>..] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579
Epoch 12: ReduceLROnPlateau reducing learning rate to 4.879880725638941e-05.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 9.7598e-05
Epoch 13/150
235/243 [============================>.] - ETA: 0s - loss: 0.8581 - mae: 0.9253 - mse: 0.8581
Epoch 13: ReduceLROnPlateau reducing learning rate to 2.4399403628194705e-05.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 4.8799e-05
Epoch 14/150
228/243 [===========================>..] - ETA: 0s - loss: 0.8582 - mae: 0.9253 - mse: 0.8582
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.2199701814097352e-05.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 2.4399e-05
Epoch 15/150
232/243 [===========================>..] - ETA: 0s - loss: 0.8583 - mae: 0.9254 - mse: 0.8583
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.2200e-05
Epoch 16/150
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 17/150
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 18/150
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 19/150
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 20/150
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 21/150
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 22/150
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 23/150
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 24/150
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 25/150
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 26/150
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 27/150
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 28/150
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 29/150
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 30/150
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 31/150
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 32/150
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 33/150
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 34/150
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 35/150
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 36/150
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 37/150
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 38/150
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 39/150
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 40/150
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 41/150
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 42/150
231/243 [===========================>..] - ETA: 0s - loss: 0.8576 - mae: 0.9251 - mse: 0.8576
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 44/150
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 45/150
174/243 [====================>.........] - ETA: 0s - loss: 0.8581 - mae: 0.9253 - mse: 0.8581
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 47/150
227/243 [===========================>..] - ETA: 0s - loss: 0.8573 - mae: 0.9249 - mse: 0.8573
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 50/150
163/243 [===================>..........] - ETA: 0s - loss: 0.8573 - mae: 0.9249 - mse: 0.8573
226/243 [==========================>...] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.85798579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
158/243 [==================>...........] - ETA: 0s - loss: 0.8571 - mae: 0.9248 - mse: 0.85718579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
204/243 [========================>.....] - ETA: 0s - loss: 0.8589 - mae: 0.9257 - mse: 0.85898579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
 99/243 [===========>..................] - ETA: 0s - loss: 0.8594 - mae: 0.9260 - mse: 0.85948579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
183/243 [=====================>........] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.85798579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
159/243 [==================>...........] - ETA: 0s - loss: 0.8576 - mae: 0.9250 - mse: 0.85768579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
206/243 [========================>.....] - ETA: 0s - loss: 0.8575 - mae: 0.9250 - mse: 0.85758579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
208/243 [========================>.....] - ETA: 0s - loss: 0.8591 - mae: 0.9258 - mse: 0.85918579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
 19/243 [=>............................] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.85798579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
239/243 [============================>.] - ETA: 0s - loss: 0.8578 - mae: 0.9251 - mse: 0.85788579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
197/243 [=======================>......] - ETA: 0s - loss: 0.8577 - mae: 0.9251 - mse: 0.85778579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0039s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0039s). Check your callbacks.
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
310/323 [===========================>..] - ETA: 0s - loss: 0.6432 - mae: 0.7999 - mse: 0.64326431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0999e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0125e-05
282/323 [=========================>....] - ETA: 0s - loss: 0.6432 - mae: 0.7999 - mse: 0.64326431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0125e-05
110/323 [=========>....................] - ETA: 0s - loss: 0.6419 - mae: 0.7990 - mse: 0.64196431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0016e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.9520e-04
320/323 [============================>.] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.64316431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.9520e-04
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 2.4399e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
319/323 [============================>.] - ETA: 0s - loss: 0.6430 - mae: 0.7998 - mse: 0.64306431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
196/323 [=================>............] - ETA: 0s - loss: 0.6437 - mae: 0.8002 - mse: 0.64376431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
307/323 [===========================>..] - ETA: 0s - loss: 0.6429 - mae: 0.7997 - mse: 0.64296431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
263/323 [=======================>......] - ETA: 0s - loss: 0.6428 - mae: 0.7997 - mse: 0.64286431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
127/323 [==========>...................] - ETA: 0s - loss: 0.6435 - mae: 0.8001 - mse: 0.64356431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
 82/323 [======>.......................] - ETA: 0s - loss: 0.6430 - mae: 0.7998 - mse: 0.64306431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
227/323 [====================>.........] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.64316431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
127/323 [==========>...................] - ETA: 0s - loss: 0.6419 - mae: 0.7991 - mse: 0.64196431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
 78/323 [======>.......................] - ETA: 0s - loss: 0.6381 - mae: 0.7967 - mse: 0.63816431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 67/150===========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 67/150===========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 70/150===========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 72/150===========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 74/150===========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 76/150===========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 78/150===========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 80/150===========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 82/150===========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 84/150===========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 86/150===========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 86/150===========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 89/150===========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 91/150===========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 93/150===========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 95/150===========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 97/150===========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 99/150===========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 101/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 103/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 103/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 106/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 108/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 110/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 112/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 112/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 115/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 118/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 118/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 121/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 123/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 125/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 127/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 129/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 131/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 131/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 134/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 136/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 138/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 140/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 142/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 144/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 146/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 148/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 150/150==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 1/15050==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 1/15050==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 1/15050==========================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 4/150duceLROnPlateau reducing learning rate to 0.049969978630542755.e: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 7/150duceLROnPlateau reducing learning rate to 0.006246247328817844.e: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 10/150uceLROnPlateau reducing learning rate to 0.0007807809161022305.: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 11: ReduceLROnPlateau reducing learning rate to 9.759761451277882e-05. 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 16/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 19/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 22/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 25/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 28/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 28/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 31/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 34/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 37/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 37/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 40/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 43/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 46/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 49/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 49/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 52/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 55/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 58/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 61/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 61/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 64/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 67/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 70/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 73/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 75/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 78/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 80/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 83/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 85/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 87/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 90/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 92/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 95/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 97/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 100/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 102/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 105/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 107/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 109/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 112/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 114/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 116/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 119/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 122/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 124/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 126/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 129/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 131/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 134/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 136/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 139/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 139/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 143/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 146/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 148/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.0999399547859351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.0999399547859351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.0999399547859351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0037s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0037s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 7/150duceLROnPlateau reducing learning rate to 0.006246247328817844.59351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 10/150uceLROnPlateau reducing learning rate to 0.0007807809161022305.9351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 11: ReduceLROnPlateau reducing learning rate to 9.759761451277882e-05.351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 13/150duceLROnPlateau reducing learning rate to 9.759761451277882e-05.351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 16/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 16/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 19/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 22/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 25/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 28/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 28/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 31/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 34/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 37/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 40/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 40/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 43/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 46/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 49/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 52/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 55/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 55/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 58/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 61/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 64/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 67/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 70/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 70/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 73/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 76/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 78/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 81/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 83/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 85/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 88/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 90/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 93/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 95/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 98/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 100/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 102/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 105/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 107/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 109/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 112/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 114/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 117/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 120/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 122/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 125/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 127/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 129/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 131/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 134/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 136/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 139/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 141/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 143/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 146/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 149/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_3.h5- val_mse: 0.6442 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.0999399547859351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.0999399547859351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_end` time: 0.0034s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_end` time: 0.0034s). Check your callbacks.
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.0999399547859351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.006246247328817844.59351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 7/150duceLROnPlateau reducing learning rate to 0.006246247328817844.59351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 10/150uceLROnPlateau reducing learning rate to 0.0007807809161022305.9351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 13/150duceLROnPlateau reducing learning rate to 9.759761451277882e-05.351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 16/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 16/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 19/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 22/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 25/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 28/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 28/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 31/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 34/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 37/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 40/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 43/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 46/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 46/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 49/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 52/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 55/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 58/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 58/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 61/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 64/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 67/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 70/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 73/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 73/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 76/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 79/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 82/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 85/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 87/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 89/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 92/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 94/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 97/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 99/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 102/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 104/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 107/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 109/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 112/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 114/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 116/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 119/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 121/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 124/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 126/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 129/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 131/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 134/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 136/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 139/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 141/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 143/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 146/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 148/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_4.h5- val_mse: 0.6442 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.0999399547859351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.0999399547859351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.0999399547859351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 4/150duceLROnPlateau reducing learning rate to 0.049969978630542755.59351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 7/150duceLROnPlateau reducing learning rate to 0.006246247328817844.59351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0007807809161022305.9351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 11: ReduceLROnPlateau reducing learning rate to 9.759761451277882e-05.351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 13/150duceLROnPlateau reducing learning rate to 9.759761451277882e-05.351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 16/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 19/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 22/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 22/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 25/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 28/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 31/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 34/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 34/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 37/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 40/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 43/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 46/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 49/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 49/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 52/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 55/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 58/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 61/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 64/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 64/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 67/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 70/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 73/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 75/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 78/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 80/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 83/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 85/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 87/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 90/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 92/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 94/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 96/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 98/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 101/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 103/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 106/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 108/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 111/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 113/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 116/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 118/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 120/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 122/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 125/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 127/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 130/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 132/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 135/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 137/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 140/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 142/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 145/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 147/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 149/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 1/15050uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 1/15050uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_train_batch_end` time: 0.0025s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_train_batch_end` time: 0.0025s). Check your callbacks.
Epoch 1/15050uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.006246247328817844.05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 7/150duceLROnPlateau reducing learning rate to 0.006246247328817844.05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 10/150uceLROnPlateau reducing learning rate to 0.0007807809161022305.5.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 13/150duceLROnPlateau reducing learning rate to 9.759761451277882e-05..51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 16/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 19/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 22/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 25/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 25/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 28/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 31/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 34/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 37/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 40/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 40/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 43/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 46/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 49/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 49/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 52/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 55/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 58/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 61/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 61/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 64/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 67/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 70/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 72/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 72/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 76/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 79/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 81/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 84/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 86/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 88/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 91/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 93/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 96/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 98/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 100/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 102/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 104/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 107/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 109/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 112/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 114/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 116/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 119/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 121/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 123/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 126/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 128/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 130/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 133/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 135/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 138/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 140/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 142/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 144/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 146/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 149/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_5.h5- val_mse: 0.6442 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.0999399547859351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.0999399547859351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.0999399547859351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 4/150duceLROnPlateau reducing learning rate to 0.049969978630542755.59351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 7/150duceLROnPlateau reducing learning rate to 0.006246247328817844.59351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 10/150uceLROnPlateau reducing learning rate to 0.0007807809161022305.9351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 11: ReduceLROnPlateau reducing learning rate to 9.759761451277882e-05.351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 13/150duceLROnPlateau reducing learning rate to 9.759761451277882e-05.351LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 16/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 19/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 22/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 22/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 25/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 28/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 31/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 31/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 34/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 37/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 40/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 43/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 43/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 46/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 49/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 52/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 52/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 55/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 58/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 61/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 64/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 66/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 68/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 71/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 73/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 75/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 77/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 80/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 82/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 85/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 87/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 87/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 91/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 94/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 96/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 98/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 101/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 103/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 106/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 108/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 112/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 115/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 117/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 119/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 122/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 124/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 126/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 129/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 131/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 133/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 136/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 138/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 140/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 143/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 146/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 148/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 150/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 150/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 150/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0022s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0022s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 150/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 7/150duceLROnPlateau reducing learning rate to 0.006246247328817844.05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0007807809161022305.5.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 10/150uceLROnPlateau reducing learning rate to 0.0007807809161022305.5.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 13/150duceLROnPlateau reducing learning rate to 9.759761451277882e-05..51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 16/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 16/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 19/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 22/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 25/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 28/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 28/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 31/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 34/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 37/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 40/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 40/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 43/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 46/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 49/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 49/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 52/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 55/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 58/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 61/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 61/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 64/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 67/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 70/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 72/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 75/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 77/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 79/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 82/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 84/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 86/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 89/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 91/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 93/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 96/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 98/150duceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 100/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 102/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 105/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 107/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 112/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 114/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 114/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 118/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 121/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 123/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 126/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 128/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 131/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 133/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 135/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 138/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 140/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 142/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 144/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 147/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 149/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 149/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05
Epoch 149/150uceLROnPlateau reducing learning rate to 1.2199701814097352e-05.51LR_[64]CHN_64CNNI_16BS_1P_val_lossM_150epochs/model_7.h5- val_mse: 0.6442 - lr: 1.0000e-05