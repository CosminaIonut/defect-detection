Epoch 1/20
226/243 [==========================>...] - ETA: 0s - loss: 0.0394 - mae: 0.0498 - mse: 0.0058
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0004s vs `on_train_batch_end` time: 0.0023s). Check your callbacks.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_175741-f0vlqlxj\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 4ms/step - loss: 0.0369 - mae: 0.0489 - mse: 0.0055 - val_loss: 0.0026 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0243
Epoch 2/20
243/243 [==============================] - 1s 4ms/step - loss: 0.0023 - mae: 0.0371 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0368 - val_mse: 0.0019 - lr: 0.0243
Epoch 3/20
231/243 [===========================>..] - ETA: 0s - loss: 0.0022 - mae: 0.0364 - mse: 0.0019
243/243 [==============================] - 1s 4ms/step - loss: 0.0022 - mae: 0.0363 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0336 - val_mse: 0.0016 - lr: 0.0243
Epoch 4/20
219/243 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0332 - mse: 0.0016
243/243 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0330 - mse: 0.0016 - val_loss: 0.0017 - val_mae: 0.0317 - val_mse: 0.0014 - lr: 0.0243
Epoch 5/20
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0322 - mse: 0.0016 - val_loss: 0.0029 - val_mae: 0.0400 - val_mse: 0.0024 - lr: 0.0243
Epoch 6/20
237/243 [============================>.] - ETA: 0s - loss: 0.0016 - mae: 0.0290 - mse: 0.0013
243/243 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0290 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0272 - val_mse: 0.0012 - lr: 0.0243
Epoch 7/20
243/243 [==============================] - 0s 952us/step - loss: 0.0015 - mae: 0.0279 - mse: 0.0012 - val_loss: 0.0014 - val_mae: 0.0280 - val_mse: 0.0012 - lr: 0.0243
Epoch 8/20
237/243 [============================>.] - ETA: 0s - loss: 0.0015 - mae: 0.0278 - mse: 0.0012
243/243 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0277 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0260 - val_mse: 0.0011 - lr: 0.0243
Epoch 9/20
236/243 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0264 - mse: 0.0011
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.012134233489632607.
243/243 [==============================] - 0s 927us/step - loss: 0.0014 - mae: 0.0265 - mse: 0.0011 - val_loss: 0.0014 - val_mae: 0.0272 - val_mse: 0.0011 - lr: 0.0243
Epoch 10/20
243/243 [==============================] - 0s 928us/step - loss: 0.0012 - mae: 0.0256 - mse: 0.0011 - val_loss: 0.0014 - val_mae: 0.0274 - val_mse: 0.0011 - lr: 0.0121
Epoch 11/20
243/243 [==============================] - 0s 888us/step - loss: 0.0012 - mae: 0.0255 - mse: 0.0010 - val_loss: 0.0018 - val_mae: 0.0320 - val_mse: 0.0015 - lr: 0.0121
Epoch 12/20
166/243 [===================>..........] - ETA: 0s - loss: 0.0012 - mae: 0.0252 - mse: 0.0010
243/243 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0252 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0246 - val_mse: 9.9251e-04 - lr: 0.0121
Epoch 13/20
243/243 [==============================] - 0s 934us/step - loss: 0.0012 - mae: 0.0249 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0253 - val_mse: 0.0010 - lr: 0.0121
Epoch 14/20
243/243 [==============================] - 0s 884us/step - loss: 0.0012 - mae: 0.0256 - mse: 0.0011 - val_loss: 0.0014 - val_mae: 0.0276 - val_mse: 0.0012 - lr: 0.0121
Epoch 15/20
167/243 [===================>..........] - ETA: 0s - loss: 0.0011 - mae: 0.0243 - mse: 9.6270e-04
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.006067116744816303.
243/243 [==============================] - 0s 890us/step - loss: 0.0011 - mae: 0.0244 - mse: 9.7384e-04 - val_loss: 0.0015 - val_mae: 0.0298 - val_mse: 0.0013 - lr: 0.0121
Epoch 16/20
243/243 [==============================] - 0s 906us/step - loss: 0.0011 - mae: 0.0235 - mse: 9.1391e-04 - val_loss: 0.0012 - val_mae: 0.0263 - val_mse: 0.0011 - lr: 0.0061
Epoch 17/20
165/243 [===================>..........] - ETA: 0s - loss: 0.0011 - mae: 0.0239 - mse: 9.4406e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0236 - mse: 9.2481e-04 - val_loss: 0.0011 - val_mae: 0.0238 - val_mse: 9.1552e-04 - lr: 0.0061
Epoch 18/20
214/243 [=========================>....] - ETA: 0s - loss: 0.0010 - mae: 0.0232 - mse: 8.9822e-04
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0030335583724081516.
243/243 [==============================] - 0s 981us/step - loss: 0.0011 - mae: 0.0233 - mse: 9.0253e-04 - val_loss: 0.0011 - val_mae: 0.0243 - val_mse: 9.4546e-04 - lr: 0.0061
Epoch 19/20
166/243 [===================>..........] - ETA: 0s - loss: 0.0010 - mae: 0.0226 - mse: 8.6209e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0230 - mse: 8.8392e-04 - val_loss: 0.0011 - val_mae: 0.0236 - val_mse: 9.1187e-04 - lr: 0.0030
Epoch 20/20
236/243 [============================>.] - ETA: 0s - loss: 0.0010 - mae: 0.0226 - mse: 8.6118e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_175741-f0vlqlxj\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0226 - mse: 8.6474e-04 - val_loss: 0.0010 - val_mae: 0.0233 - val_mse: 8.7511e-04 - lr: 0.0030
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_adam_0.024268467375406975_30_16_20epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
323/323 [==============================] - 1s 1ms/step - loss: 0.0243 - mae: 0.0558 - mse: 0.0051 - val_loss: 0.0035 - val_mae: 0.0469 - val_mse: 0.0030 - lr: 0.0243
Epoch 2/20
323/323 [==============================] - 0s 879us/step - loss: 0.0033 - mae: 0.0446 - mse: 0.0029 - val_loss: 0.0027 - val_mae: 0.0386 - val_mse: 0.0023 - lr: 0.0243
Epoch 3/20
323/323 [==============================] - 0s 881us/step - loss: 0.0028 - mae: 0.0394 - mse: 0.0024 - val_loss: 0.0024 - val_mae: 0.0354 - val_mse: 0.0020 - lr: 0.0243
Epoch 4/20
323/323 [==============================] - 0s 883us/step - loss: 0.0026 - mae: 0.0373 - mse: 0.0022 - val_loss: 0.0021 - val_mae: 0.0330 - val_mse: 0.0018 - lr: 0.0243
Epoch 5/20
323/323 [==============================] - 0s 904us/step - loss: 0.0023 - mae: 0.0351 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0313 - val_mse: 0.0016 - lr: 0.0243
Epoch 6/20
323/323 [==============================] - 0s 976us/step - loss: 0.0024 - mae: 0.0358 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0345 - val_mse: 0.0019 - lr: 0.0243
Epoch 7/20
323/323 [==============================] - 0s 981us/step - loss: 0.0023 - mae: 0.0349 - mse: 0.0019 - val_loss: 0.0026 - val_mae: 0.0362 - val_mse: 0.0020 - lr: 0.0243
Epoch 8/20
317/323 [============================>.] - ETA: 0s - loss: 0.0021 - mae: 0.0332 - mse: 0.0018
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.012134233489632607.
323/323 [==============================] - 0s 928us/step - loss: 0.0021 - mae: 0.0331 - mse: 0.0018 - val_loss: 0.0027 - val_mae: 0.0399 - val_mse: 0.0024 - lr: 0.0243
Epoch 9/20
323/323 [==============================] - 0s 926us/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0121
Epoch 10/20
323/323 [==============================] - 0s 942us/step - loss: 0.0019 - mae: 0.0317 - mse: 0.0016 - val_loss: 0.0017 - val_mae: 0.0293 - val_mse: 0.0015 - lr: 0.0121
Epoch 11/20
323/323 [==============================] - 0s 939us/step - loss: 0.0018 - mae: 0.0307 - mse: 0.0015 - val_loss: 0.0018 - val_mae: 0.0316 - val_mse: 0.0016 - lr: 0.0121
Epoch 12/20
323/323 [==============================] - 0s 931us/step - loss: 0.0017 - mae: 0.0309 - mse: 0.0015 - val_loss: 0.0020 - val_mae: 0.0338 - val_mse: 0.0018 - lr: 0.0121
Epoch 13/20
317/323 [============================>.] - ETA: 0s - loss: 0.0017 - mae: 0.0304 - mse: 0.0015
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.006067116744816303.
323/323 [==============================] - 0s 925us/step - loss: 0.0017 - mae: 0.0304 - mse: 0.0015 - val_loss: 0.0016 - val_mae: 0.0289 - val_mse: 0.0014 - lr: 0.0121
Epoch 14/20
323/323 [==============================] - 0s 923us/step - loss: 0.0017 - mae: 0.0301 - mse: 0.0015 - val_loss: 0.0019 - val_mae: 0.0332 - val_mse: 0.0017 - lr: 0.0061
Epoch 15/20
323/323 [==============================] - 0s 973us/step - loss: 0.0016 - mae: 0.0297 - mse: 0.0015 - val_loss: 0.0017 - val_mae: 0.0299 - val_mse: 0.0015 - lr: 0.0061
Epoch 16/20
323/323 [==============================] - 0s 896us/step - loss: 0.0016 - mae: 0.0297 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0279 - val_mse: 0.0013 - lr: 0.0061
Epoch 17/20
323/323 [==============================] - 0s 879us/step - loss: 0.0016 - mae: 0.0293 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0278 - val_mse: 0.0013 - lr: 0.0061
Epoch 18/20
323/323 [==============================] - 0s 882us/step - loss: 0.0016 - mae: 0.0293 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0286 - val_mse: 0.0014 - lr: 0.0061
Epoch 19/20
250/323 [======================>.......] - ETA: 0s - loss: 0.0016 - mae: 0.0292 - mse: 0.0014
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0030335583724081516.
323/323 [==============================] - 0s 873us/step - loss: 0.0016 - mae: 0.0292 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0283 - val_mse: 0.0014 - lr: 0.0061
Epoch 20/20
323/323 [==============================] - 0s 872us/step - loss: 0.0015 - mae: 0.0285 - mse: 0.0013 - val_loss: 0.0016 - val_mae: 0.0295 - val_mse: 0.0014 - lr: 0.0030
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_adam_0.024268467375406975_30_16_20epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
243/243 [==============================] - 1s 1ms/step - loss: 0.0270 - mae: 0.0407 - mse: 0.0024 - val_loss: 0.0021 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 0.0243
Epoch 2/20
243/243 [==============================] - 0s 931us/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0243
Epoch 3/20
243/243 [==============================] - 0s 915us/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0389 - val_mse: 0.0020 - lr: 0.0243
Epoch 4/20
165/243 [===================>..........] - ETA: 0s - loss: 0.0020 - mae: 0.0379 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.012134233489632607.
243/243 [==============================] - 0s 906us/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0243
Epoch 5/20
243/243 [==============================] - 0s 902us/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 0.0121
Epoch 6/20
243/243 [==============================] - 0s 924us/step - loss: 0.0019 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 0.0121
Epoch 7/20
243/243 [==============================] - 0s 923us/step - loss: 0.0019 - mae: 0.0369 - mse: 0.0018 - val_loss: 0.0018 - val_mae: 0.0355 - val_mse: 0.0017 - lr: 0.0121
Epoch 8/20
243/243 [==============================] - 0s 922us/step - loss: 0.0017 - mae: 0.0331 - mse: 0.0016 - val_loss: 0.0015 - val_mae: 0.0292 - val_mse: 0.0013 - lr: 0.0121
Epoch 9/20
243/243 [==============================] - 0s 906us/step - loss: 0.0015 - mae: 0.0286 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0284 - val_mse: 0.0012 - lr: 0.0121
Epoch 10/20
243/243 [==============================] - 0s 914us/step - loss: 0.0013 - mae: 0.0267 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0121
Epoch 11/20
243/243 [==============================] - 0s 903us/step - loss: 0.0013 - mae: 0.0267 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 0.0121
Epoch 12/20
243/243 [==============================] - 0s 933us/step - loss: 0.0012 - mae: 0.0257 - mse: 0.0011 - val_loss: 0.0014 - val_mae: 0.0289 - val_mse: 0.0012 - lr: 0.0121
Epoch 13/20
214/243 [=========================>....] - ETA: 0s - loss: 0.0011 - mae: 0.0252 - mse: 0.0010
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.006067116744816303.
243/243 [==============================] - 0s 1000us/step - loss: 0.0011 - mae: 0.0252 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0251 - val_mse: 9.9324e-04 - lr: 0.0121
Epoch 14/20
243/243 [==============================] - 0s 896us/step - loss: 0.0011 - mae: 0.0248 - mse: 9.8803e-04 - val_loss: 0.0012 - val_mae: 0.0249 - val_mse: 0.0010 - lr: 0.0061
Epoch 15/20
243/243 [==============================] - 0s 968us/step - loss: 0.0011 - mae: 0.0250 - mse: 9.9293e-04 - val_loss: 0.0011 - val_mae: 0.0251 - val_mse: 9.9267e-04 - lr: 0.0061
Epoch 16/20
160/243 [==================>...........] - ETA: 0s - loss: 0.0011 - mae: 0.0250 - mse: 9.9846e-04
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0030335583724081516.
243/243 [==============================] - 0s 922us/step - loss: 0.0011 - mae: 0.0248 - mse: 9.8517e-04 - val_loss: 0.0011 - val_mae: 0.0258 - val_mse: 0.0010 - lr: 0.0061
Epoch 17/20
243/243 [==============================] - 0s 908us/step - loss: 0.0010 - mae: 0.0239 - mse: 9.2036e-04 - val_loss: 0.0011 - val_mae: 0.0251 - val_mse: 9.7494e-04 - lr: 0.0030
Epoch 18/20
243/243 [==============================] - 0s 933us/step - loss: 0.0010 - mae: 0.0240 - mse: 9.2829e-04 - val_loss: 0.0011 - val_mae: 0.0248 - val_mse: 9.6861e-04 - lr: 0.0030
Epoch 19/20
165/243 [===================>..........] - ETA: 0s - loss: 0.0010 - mae: 0.0243 - mse: 9.3733e-04
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0015167791862040758.
243/243 [==============================] - 0s 918us/step - loss: 0.0010 - mae: 0.0241 - mse: 9.2298e-04 - val_loss: 0.0012 - val_mae: 0.0272 - val_mse: 0.0011 - lr: 0.0030
Epoch 20/20
243/243 [==============================] - 0s 924us/step - loss: 9.8861e-04 - mae: 0.0235 - mse: 8.9342e-04 - val_loss: 0.0011 - val_mae: 0.0250 - val_mse: 9.6768e-04 - lr: 0.0015
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_adam_0.024268467375406975_30_16_20epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
243/243 [==============================] - 1s 2ms/step - loss: 0.0283 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0243
Epoch 2/20
243/243 [==============================] - 0s 995us/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0243
Epoch 3/20
243/243 [==============================] - 0s 943us/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0243
Epoch 4/20
232/243 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.012134233489632607.
243/243 [==============================] - 0s 959us/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0243
Epoch 5/20
243/243 [==============================] - 0s 976us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0121
Epoch 6/20
243/243 [==============================] - 0s 931us/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0121
Epoch 7/20
235/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.006067116744816303.
243/243 [==============================] - 0s 947us/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0121
Epoch 8/20
243/243 [==============================] - 0s 996us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0061
Epoch 9/20
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0061
Epoch 10/20
237/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0030335583724081516.
243/243 [==============================] - 0s 931us/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0061
Epoch 11/20
243/243 [==============================] - 0s 952us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0030
Epoch 12/20
243/243 [==============================] - 0s 916us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0030
Epoch 13/20
240/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0015167791862040758.
243/243 [==============================] - 0s 931us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0030
Epoch 14/20
 84/243 [=========>....................] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0018s). Check your callbacks.
243/243 [==============================] - 0s 928us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 15/20
243/243 [==============================] - 0s 917us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 16/20
242/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0007583895931020379.
243/243 [==============================] - 0s 906us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 17/20
243/243 [==============================] - 0s 901us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.5839e-04
Epoch 18/20
243/243 [==============================] - 0s 919us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.5839e-04
Epoch 19/20
166/243 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00037919479655101895.
243/243 [==============================] - 0s 895us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.5839e-04
Epoch 20/20
243/243 [==============================] - 0s 914us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.7919e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_adam_0.024268467375406975_30_16_20epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
243/243 [==============================] - 0s 928us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0013s). Check your callbacks.
Epoch 16/20============================] - 0s 928us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 16/20============================] - 0s 928us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 16/20============================] - 0s 928us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0030335583724081516.e: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00037919479655101895.: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
  1/243 [..............................] - ETA: 0s - loss: 9.7423e-04 - mae: 0.0249 - mse: 9.6244e-04 val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
  1/243 [..............................] - ETA: 0s - loss: 9.7423e-04 - mae: 0.0249 - mse: 9.6244e-04 val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0015167791862040758. 0.0249 - mse: 9.6244e-04 val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 3/20ReduceLROnPlateau reducing learning rate to 0.0015167791862040758. 0.0249 - mse: 9.6244e-04 val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 3/20ReduceLROnPlateau reducing learning rate to 0.0015167791862040758. 0.0249 - mse: 9.6244e-04 val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 11/20educeLROnPlateau reducing learning rate to 0.0015167791862040758. 0.0249 - mse: 9.6244e-04 val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 11/20educeLROnPlateau reducing learning rate to 0.0015167791862040758. 0.0249 - mse: 9.6244e-04 val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 11/20educeLROnPlateau reducing learning rate to 0.0015167791862040758. 0.0249 - mse: 9.6244e-04 val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_175741-f0vlqlxj\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_175741-f0vlqlxj\files\model-best)... Done. 0.0s
Epoch 11/20educeLROnPlateau reducing learning rate to 0.0015167791862040758. 0.0249 - mse: 9.6244e-04 val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 11/20educeLROnPlateau reducing learning rate to 0.0015167791862040758. 0.0249 - mse: 9.6244e-04 val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_175741-f0vlqlxj\files\model-best)... Done. 0.0s
Epoch 11/20educeLROnPlateau reducing learning rate to 0.0015167791862040758. 0.0249 - mse: 9.6244e-04 val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 7/200educeLROnPlateau reducing learning rate to 0.0015167791862040758. 0.0249 - mse: 9.6244e-04 val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 7/200educeLROnPlateau reducing learning rate to 0.0015167791862040758. 0.0249 - mse: 9.6244e-04 val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.