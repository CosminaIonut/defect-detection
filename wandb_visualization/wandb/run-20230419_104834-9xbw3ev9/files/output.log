Epoch 1/150
227/243 [===========================>..] - ETA: 0s - loss: 0.1736 - mae: 0.0468 - mse: 0.0039
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
243/243 [==============================] - 2s 5ms/step - loss: 0.1625 - mae: 0.0460 - mse: 0.0038 - val_loss: 0.0024 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0432
Epoch 2/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0030 - mae: 0.0410 - mse: 0.0024 - val_loss: 0.0048 - val_mae: 0.0485 - val_mse: 0.0035 - lr: 0.0432
Epoch 3/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0395 - mse: 0.0021 - val_loss: 0.0025 - val_mae: 0.0411 - val_mse: 0.0024 - lr: 0.0432
Epoch 4/150
235/243 [============================>.] - ETA: 0s - loss: 0.0025 - mae: 0.0398 - mse: 0.0022
243/243 [==============================] - 1s 6ms/step - loss: 0.0025 - mae: 0.0396 - mse: 0.0022 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0432
Epoch 5/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0432
Epoch 6/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0432
Epoch 7/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0432
Epoch 8/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0432
Epoch 9/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0432
Epoch 10/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0432
Epoch 11/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0432
Epoch 12/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0432
Epoch 13/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0432
Epoch 14/150
240/243 [============================>.] - ETA: 0s - loss: 0.0023 - mae: 0.0381 - mse: 0.0019
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.02158670499920845.
243/243 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0432
Epoch 15/150
241/243 [============================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0380 - mse: 0.0019
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_104834-9xbw3ev9\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0216
Epoch 16/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0216
Epoch 17/150
243/243 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0216
Epoch 18/150
237/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
243/243 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0216
Epoch 19/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0216
Epoch 20/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0216
Epoch 21/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0216
Epoch 22/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0216
Epoch 23/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0216
Epoch 24/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0216
Epoch 25/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0216
Epoch 26/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0216
Epoch 27/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0216
Epoch 28/150
238/243 [============================>.] - ETA: 0s - loss: 0.0021 - mae: 0.0380 - mse: 0.0019
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.010793352499604225.
243/243 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0216
Epoch 29/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 30/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 31/150
238/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
243/243 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0108
Epoch 32/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0108
Epoch 33/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 34/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 35/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 36/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 37/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 38/150
237/243 [============================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0379 - mse: 0.0019
Epoch 38: ReduceLROnPlateau reducing learning rate to 0.005396676249802113.
243/243 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0108
Epoch 39/150
238/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
243/243 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0054
Epoch 40/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0054
Epoch 41/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 42/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 43/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 44/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0054
Epoch 45/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0054
Epoch 46/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 47/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0054
Epoch 48/150
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0026983381249010563.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0054
Epoch 49/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0027
Epoch 50/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0027
Epoch 51/150
239/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
243/243 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0027
Epoch 52/150
232/243 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
243/243 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0027
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_104834-9xbw3ev9\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0027
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0013
Epoch 61/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 62/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 63/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 64/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 65/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0013
Epoch 66/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0013
Epoch 67/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 68/150
231/243 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0006745845312252641.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0013
Epoch 69/150
232/243 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_104834-9xbw3ev9\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7458e-04
Epoch 70/150
225/243 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
243/243 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7458e-04
243/243 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7458e-04
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7458e-04
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7458e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_104834-9xbw3ev9\files\model-best)... Done. 0.0s
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7458e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_104834-9xbw3ev9\files\model-best)... Done. 0.0s
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7458e-04
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.4323e-05
243/243 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2162e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.1081e-05
  1/243 [..............................] - ETA: 0s - loss: 0.0020 - mae: 0.0412 - mse: 0.00200019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.1081e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0540e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
 59/323 [====>.........................] - ETA: 0s - loss: 0.6379 - mae: 0.0623 - mse: 0.0066  19 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
323/323 [==============================] - 1s 1ms/step - loss: 0.1208 - mae: 0.0549 - mse: 0.0044 - val_loss: 0.0035 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0432e-05
323/323 [==============================] - 0s 1ms/step - loss: 0.0042 - mae: 0.0511 - mse: 0.0035 - val_loss: 0.0038 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0432e-05
323/323 [==============================] - 0s 1ms/step - loss: 0.0042 - mae: 0.0511 - mse: 0.0035 - val_loss: 0.0038 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0432e-05
323/323 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_104834-9xbw3ev9\files\model-best)... Done. 0.0s
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_104834-9xbw3ev9\files\model-best)... Done. 0.0s
 62/323 [====>.........................] - ETA: 0s - loss: 0.0034 - mae: 0.0499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 91: ReduceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 101/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_train_batch_end` time: 0.0016s). Check your callbacks.
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0022s). Check your callbacks.
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0012s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05
Epoch 87/1500uceLROnPlateau reducing learning rate to 8.432306640315801e-05.499 - mse: 0.00330034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0216e-05