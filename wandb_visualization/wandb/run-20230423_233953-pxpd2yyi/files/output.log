Epoch 1/50
186/243 [=====================>........] - ETA: 0s - loss: 0.8569 - mae: 0.9247 - mse: 0.8569
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0915
Epoch 2/50
193/243 [======================>.......] - ETA: 0s - loss: 0.8582 - mae: 0.9254 - mse: 0.8582
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.04576149210333824.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0915
Epoch 3/50
222/243 [==========================>...] - ETA: 0s - loss: 0.8582 - mae: 0.9253 - mse: 0.8582
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.02288074605166912.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0458
Epoch 4/50
236/243 [============================>.] - ETA: 0s - loss: 0.8580 - mae: 0.9253 - mse: 0.8580
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.01144037302583456.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0229
Epoch 5/50
225/243 [==========================>...] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00572018651291728.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0114
Epoch 6/50
237/243 [============================>.] - ETA: 0s - loss: 0.8581 - mae: 0.9253 - mse: 0.8581
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00286009325645864.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0057
Epoch 7/50
159/243 [==================>...........] - ETA: 0s - loss: 0.8572 - mae: 0.9248 - mse: 0.8572
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00143004662822932.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0029
Epoch 8/50
243/243 [==============================] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00071502331411466.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
Epoch 9/50
217/243 [=========================>....] - ETA: 0s - loss: 0.8578 - mae: 0.9252 - mse: 0.8578
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00035751165705733.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 7.1502e-04
Epoch 10/50
218/243 [=========================>....] - ETA: 0s - loss: 0.8578 - mae: 0.9251 - mse: 0.8578
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.000178755828528665.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 3.5751e-04
Epoch 11/50
242/243 [============================>.] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579
Epoch 11: ReduceLROnPlateau reducing learning rate to 8.93779142643325e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.7876e-04
Epoch 12/50
238/243 [============================>.] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579
Epoch 12: ReduceLROnPlateau reducing learning rate to 4.468895713216625e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 8.9378e-05
Epoch 13/50
160/243 [==================>...........] - ETA: 0s - loss: 0.8580 - mae: 0.9252 - mse: 0.8580
Epoch 13: ReduceLROnPlateau reducing learning rate to 2.2344478566083126e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 4.4689e-05
Epoch 14/50
160/243 [==================>...........] - ETA: 0s - loss: 0.8583 - mae: 0.9254 - mse: 0.8583
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.1172239283041563e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 2.2344e-05
Epoch 15/50
240/243 [============================>.] - ETA: 0s - loss: 0.8580 - mae: 0.9253 - mse: 0.8580
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.1172e-05
Epoch 16/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 17/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 18/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 19/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 20/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 21/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 22/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 23/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 24/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 25/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 26/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 27/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 28/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 29/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 30/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 31/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 32/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 33/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 34/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 35/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 36/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 37/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 38/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 39/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 40/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 41/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 42/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 43/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 44/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 45/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 46/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 47/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 48/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 49/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 50/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.09152298567287293LR_[124]CHN_100CNNI_16BS_1P_val_lossM_50epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/50
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0021s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0021s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0114e-05
Epoch 6/50
300/323 [==========================>...] - ETA: 0s - loss: 0.6433 - mae: 0.7999 - mse: 0.6433
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00286009325645864.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0057
Epoch 7/50
309/323 [===========================>..] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00143004662822932.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0029
Epoch 8/50
295/323 [==========================>...] - ETA: 0s - loss: 0.6436 - mae: 0.8002 - mse: 0.6436
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 8.9378e-05
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00035751165705733.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 7.1502e-04
Epoch 10/50
309/323 [===========================>..] - ETA: 0s - loss: 0.6435 - mae: 0.8000 - mse: 0.6435
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.000178755828528665.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 3.5751e-04
Epoch 11/50
244/323 [=====================>........] - ETA: 0s - loss: 0.6439 - mae: 0.8003 - mse: 0.6439
Epoch 11: ReduceLROnPlateau reducing learning rate to 8.93779142643325e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.7876e-04
Epoch 12/50
323/323 [==============================] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431
Epoch 12: ReduceLROnPlateau reducing learning rate to 4.468895713216625e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 8.9378e-05
Epoch 13/50
314/323 [============================>.] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431
Epoch 13: ReduceLROnPlateau reducing learning rate to 2.2344478566083126e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 4.4689e-05
Epoch 14/50
305/323 [===========================>..] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.1172239283041563e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 2.2344e-05
Epoch 15/50
309/323 [===========================>..] - ETA: 0s - loss: 0.6430 - mae: 0.7997 - mse: 0.6430
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.1172e-05
Epoch 16/50
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 17/50
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 18/50
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 19/50
247/323 [=====================>........] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 23/50
221/323 [===================>..........] - ETA: 0s - loss: 0.6419 - mae: 0.7991 - mse: 0.6419
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
212/243 [=========================>....] - ETA: 0s - loss: 0.4577 - mae: 0.6751 - mse: 0.4577  31 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
212/243 [=========================>....] - ETA: 0s - loss: 0.4577 - mae: 0.6751 - mse: 0.4577  31 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0057e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.7876e-04
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 11: ReduceLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 17/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 17/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
Epoch 37/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00286009325645864.5.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 17/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 17/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
Epoch 37/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00286009325645864.5.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 17/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 17/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230423_233953-pxpd2yyi\files\model-best)... Done. 0.0s
Epoch 13/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 13/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 20/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 30/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 30/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 30/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 30/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 30/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 30/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00286009325645864.5.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 11: ReduceLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 17/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0021s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0021s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 11: ReduceLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 17/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 17/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 8.93779142643325e-05.: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05