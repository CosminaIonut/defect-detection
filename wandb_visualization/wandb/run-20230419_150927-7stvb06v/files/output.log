Epoch 1/30
236/243 [============================>.] - ETA: 0s - loss: 0.0160 - mae: 0.0477 - mse: 0.0042
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0028s). Check your callbacks.
243/243 [==============================] - 2s 6ms/step - loss: 0.0157 - mae: 0.0474 - mse: 0.0042 - val_loss: 0.0029 - val_mae: 0.0370 - val_mse: 0.0018 - lr: 0.0416
Epoch 2/30
218/243 [=========================>....] - ETA: 0s - loss: 0.0032 - mae: 0.0376 - mse: 0.0019
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.020808327943086624.
243/243 [==============================] - 1s 2ms/step - loss: 0.0032 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.0039 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0416
Epoch 3/30
219/243 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0341 - mse: 0.0017
243/243 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0341 - mse: 0.0016 - val_loss: 0.0018 - val_mae: 0.0310 - val_mse: 0.0014 - lr: 0.0208
Epoch 4/30
235/243 [============================>.] - ETA: 0s - loss: 0.0017 - mae: 0.0297 - mse: 0.0013
243/243 [==============================] - 2s 6ms/step - loss: 0.0017 - mae: 0.0298 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0267 - val_mse: 0.0011 - lr: 0.0208
Epoch 5/30
226/243 [==========================>...] - ETA: 0s - loss: 0.0015 - mae: 0.0270 - mse: 0.0012
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.010404163971543312.
243/243 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0270 - mse: 0.0012 - val_loss: 0.0014 - val_mae: 0.0269 - val_mse: 0.0011 - lr: 0.0208
Epoch 6/30
232/243 [===========================>..] - ETA: 0s - loss: 0.0012 - mae: 0.0245 - mse: 9.8889e-04
243/243 [==============================] - 1s 6ms/step - loss: 0.0012 - mae: 0.0246 - mse: 9.9183e-04 - val_loss: 0.0012 - val_mae: 0.0248 - val_mse: 9.8395e-04 - lr: 0.0104
Epoch 7/30
208/243 [========================>.....] - ETA: 0s - loss: 0.0011 - mae: 0.0241 - mse: 9.4998e-04
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.005202081985771656.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_150927-7stvb06v\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_150927-7stvb06v\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 6ms/step - loss: 0.0011 - mae: 0.0241 - mse: 9.4392e-04 - val_loss: 0.0011 - val_mae: 0.0237 - val_mse: 9.0769e-04 - lr: 0.0104
Epoch 8/30
243/243 [==============================] - 2s 6ms/step - loss: 0.0010 - mae: 0.0232 - mse: 8.9621e-04 - val_loss: 0.0011 - val_mae: 0.0236 - val_mse: 9.0535e-04 - lr: 0.0052
Epoch 9/30
242/243 [============================>.] - ETA: 0s - loss: 0.0010 - mae: 0.0230 - mse: 8.8216e-04
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.002601040992885828.
243/243 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0230 - mse: 8.8143e-04 - val_loss: 0.0011 - val_mae: 0.0239 - val_mse: 9.2246e-04 - lr: 0.0052
Epoch 10/30
213/243 [=========================>....] - ETA: 0s - loss: 9.9656e-04 - mae: 0.0228 - mse: 8.6736e-04
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.001300520496442914.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_150927-7stvb06v\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 6ms/step - loss: 9.8352e-04 - mae: 0.0226 - mse: 8.5439e-04 - val_loss: 0.0010 - val_mae: 0.0233 - val_mse: 8.8545e-04 - lr: 0.0026
Epoch 11/30
239/243 [============================>.] - ETA: 0s - loss: 9.7513e-04 - mae: 0.0226 - mse: 8.5640e-04
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.000650260248221457.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_150927-7stvb06v\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 6ms/step - loss: 9.7189e-04 - mae: 0.0225 - mse: 8.5308e-04 - val_loss: 9.9289e-04 - val_mae: 0.0232 - val_mse: 8.7431e-04 - lr: 0.0013
Epoch 12/30
235/243 [============================>.] - ETA: 0s - loss: 9.6759e-04 - mae: 0.0225 - mse: 8.4699e-04
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0003251301241107285.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_150927-7stvb06v\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_150927-7stvb06v\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 6ms/step - loss: 9.6309e-04 - mae: 0.0224 - mse: 8.4254e-04 - val_loss: 9.9067e-04 - val_mae: 0.0231 - val_mse: 8.7250e-04 - lr: 6.5026e-04
Epoch 13/30
219/243 [==========================>...] - ETA: 0s - loss: 9.4759e-04 - mae: 0.0221 - mse: 8.2747e-04
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00016256506205536425.
243/243 [==============================] - 1s 3ms/step - loss: 9.5964e-04 - mae: 0.0223 - mse: 8.3990e-04 - val_loss: 9.9611e-04 - val_mae: 0.0231 - val_mse: 8.7462e-04 - lr: 3.2513e-04
Epoch 14/30
225/243 [==========================>...] - ETA: 0s - loss: 9.5271e-04 - mae: 0.0222 - mse: 8.3400e-04
Epoch 14: ReduceLROnPlateau reducing learning rate to 8.128253102768213e-05.
243/243 [==============================] - 1s 3ms/step - loss: 9.5753e-04 - mae: 0.0223 - mse: 8.3893e-04 - val_loss: 9.9194e-04 - val_mae: 0.0231 - val_mse: 8.7372e-04 - lr: 1.6257e-04
Epoch 15/30
213/243 [=========================>....] - ETA: 0s - loss: 9.4786e-04 - mae: 0.0223 - mse: 8.3032e-04
Epoch 15: ReduceLROnPlateau reducing learning rate to 4.064126551384106e-05.
243/243 [==============================] - 1s 3ms/step - loss: 9.5647e-04 - mae: 0.0223 - mse: 8.3882e-04 - val_loss: 9.9149e-04 - val_mae: 0.0231 - val_mse: 8.7329e-04 - lr: 8.1283e-05
Epoch 16/30
231/243 [===========================>..] - ETA: 0s - loss: 9.5071e-04 - mae: 0.0222 - mse: 8.3293e-04
Epoch 16: ReduceLROnPlateau reducing learning rate to 2.032063275692053e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_150927-7stvb06v\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 6ms/step - loss: 9.5584e-04 - mae: 0.0223 - mse: 8.3809e-04 - val_loss: 9.8959e-04 - val_mae: 0.0231 - val_mse: 8.7269e-04 - lr: 4.0641e-05
Epoch 17/30
239/243 [============================>.] - ETA: 0s - loss: 9.5255e-04 - mae: 0.0223 - mse: 8.3554e-04
Epoch 17: ReduceLROnPlateau reducing learning rate to 1.0160316378460266e-05.
243/243 [==============================] - 1s 3ms/step - loss: 9.5563e-04 - mae: 0.0223 - mse: 8.3862e-04 - val_loss: 9.8969e-04 - val_mae: 0.0231 - val_mse: 8.7262e-04 - lr: 2.0321e-05
Epoch 18/30
241/243 [============================>.] - ETA: 0s - loss: 9.5376e-04 - mae: 0.0223 - mse: 8.3684e-04
Epoch 18: ReduceLROnPlateau reducing learning rate to 1e-05.
243/243 [==============================] - 1s 3ms/step - loss: 9.5544e-04 - mae: 0.0223 - mse: 8.3852e-04 - val_loss: 9.8982e-04 - val_mae: 0.0231 - val_mse: 8.7259e-04 - lr: 1.0160e-05
Epoch 19/30
243/243 [==============================] - 1s 3ms/step - loss: 9.5541e-04 - mae: 0.0223 - mse: 8.3812e-04 - val_loss: 9.8960e-04 - val_mae: 0.0231 - val_mse: 8.7249e-04 - lr: 1.0000e-05
Epoch 20/30
243/243 [==============================] - 2s 7ms/step - loss: 9.5536e-04 - mae: 0.0223 - mse: 8.3823e-04 - val_loss: 9.8956e-04 - val_mae: 0.0231 - val_mse: 8.7256e-04 - lr: 1.0000e-05
Epoch 21/30
216/243 [=========================>....] - ETA: 0s - loss: 9.5802e-04 - mae: 0.0223 - mse: 8.4105e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_150927-7stvb06v\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 6ms/step - loss: 9.5534e-04 - mae: 0.0223 - mse: 8.3837e-04 - val_loss: 9.8952e-04 - val_mae: 0.0231 - val_mse: 8.7251e-04 - lr: 1.0000e-05
Epoch 22/30
243/243 [==============================] - 1s 3ms/step - loss: 9.5528e-04 - mae: 0.0223 - mse: 8.3825e-04 - val_loss: 9.8955e-04 - val_mae: 0.0231 - val_mse: 8.7248e-04 - lr: 1.0000e-05
Epoch 23/30
243/243 [==============================] - 1s 3ms/step - loss: 9.5526e-04 - mae: 0.0223 - mse: 8.3826e-04 - val_loss: 9.8954e-04 - val_mae: 0.0231 - val_mse: 8.7239e-04 - lr: 1.0000e-05
Epoch 24/30
243/243 [==============================] - 2s 7ms/step - loss: 9.5522e-04 - mae: 0.0223 - mse: 8.3808e-04 - val_loss: 9.8947e-04 - val_mae: 0.0231 - val_mse: 8.7235e-04 - lr: 1.0000e-05
Epoch 25/30
219/243 [==========================>...] - ETA: 0s - loss: 9.6292e-04 - mae: 0.0224 - mse: 8.4541e-04
243/243 [==============================] - 2s 7ms/step - loss: 9.5512e-04 - mae: 0.0223 - mse: 8.3765e-04 - val_loss: 9.8925e-04 - val_mae: 0.0231 - val_mse: 8.7230e-04 - lr: 1.0000e-05
Epoch 26/30
243/243 [==============================] - 1s 3ms/step - loss: 9.5517e-04 - mae: 0.0223 - mse: 8.3794e-04 - val_loss: 9.8929e-04 - val_mae: 0.0231 - val_mse: 8.7228e-04 - lr: 1.0000e-05
Epoch 27/30
243/243 [==============================] - 1s 2ms/step - loss: 9.5512e-04 - mae: 0.0223 - mse: 8.3815e-04 - val_loss: 9.8928e-04 - val_mae: 0.0231 - val_mse: 8.7224e-04 - lr: 1.0000e-05
Epoch 28/30
243/243 [==============================] - 1s 3ms/step - loss: 9.5507e-04 - mae: 0.0223 - mse: 8.3784e-04 - val_loss: 9.8936e-04 - val_mae: 0.0231 - val_mse: 8.7225e-04 - lr: 1.0000e-05
Epoch 29/30
243/243 [==============================] - 1s 3ms/step - loss: 9.5503e-04 - mae: 0.0223 - mse: 8.3796e-04 - val_loss: 9.8943e-04 - val_mae: 0.0231 - val_mse: 8.7226e-04 - lr: 1.0000e-05
Epoch 30/30
243/243 [==============================] - 1s 3ms/step - loss: 9.5499e-04 - mae: 0.0223 - mse: 8.3777e-04 - val_loss: 9.8936e-04 - val_mae: 0.0231 - val_mse: 8.7222e-04 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.04161665638100033LR_[30]HN_16BS_1P_val_lossM_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0117 - mae: 0.0539 - mse: 0.0042 - val_loss: 0.0045 - val_mae: 0.0505 - val_mse: 0.0035 - lr: 0.0416
Epoch 2/30
310/323 [===========================>..] - ETA: 0s - loss: 0.0047 - mae: 0.0510 - mse: 0.0035
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.020808327943086624.
323/323 [==============================] - 1s 3ms/step - loss: 0.0047 - mae: 0.0511 - mse: 0.0035 - val_loss: 0.0067 - val_mae: 0.0581 - val_mse: 0.0049 - lr: 0.0416
Epoch 3/30
323/323 [==============================] - 1s 2ms/step - loss: 0.0036 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0208
Epoch 4/30
323/323 [==============================] - ETA: 0s - loss: 0.0036 - mae: 0.0506 - mse: 0.0034
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.010404163971543312.
323/323 [==============================] - 1s 2ms/step - loss: 0.0036 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0208
Epoch 5/30
320/323 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.00340034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0104
Epoch 6/30
320/323 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.00340034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0104
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.005202081985771656.
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0104
Epoch 7/30
303/323 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.002601040992885828.
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0052
Epoch 8/30
319/323 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.001300520496442914.
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0026
Epoch 9/30
300/323 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.000650260248221457.
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0013
Epoch 10/30
264/323 [=======================>......] - ETA: 0s - loss: 0.0034 - mae: 0.0508 - mse: 0.0034
278/323 [========================>.....] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.00340034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.5026e-04
Epoch 11/30
304/323 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00016256506205536425.
323/323 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.2513e-04
Epoch 12/30
282/323 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 12: ReduceLROnPlateau reducing learning rate to 8.128253102768213e-05.
323/323 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6257e-04
Epoch 13/30
278/323 [========================>.....] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.00340034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.5026e-04
Epoch 13: ReduceLROnPlateau reducing learning rate to 4.064126551384106e-05.
323/323 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.1283e-05
Epoch 14/30
316/323 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 14: ReduceLROnPlateau reducing learning rate to 2.032063275692053e-05.
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 4.0641e-05
Epoch 15/30
305/323 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 15: ReduceLROnPlateau reducing learning rate to 1.0160316378460266e-05.
323/323 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 2.0321e-05
Epoch 16/30
290/323 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 19/30
  1/323 [..............................] - ETA: 5s - loss: 0.0041 - mae: 0.0569 - mse: 0.0041
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
309/323 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.00340034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
243/243 [==============================] - ETA: 0s - loss: 0.0122 - mae: 0.0400 - mse: 0.0023  34 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0122 - mae: 0.0400 - mse: 0.0023 - val_loss: 0.0033 - val_mae: 0.0396 - val_mse: 0.0022 - lr: 0.0416e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0104e-05
242/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0104e-05
242/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0104e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6257e-04
212/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.00190019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6257e-04
149/243 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019        al_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6257e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 27/30============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 30/30============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 30/30============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 2/300============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 4/300============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.002601040992885828.e: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 14/30educeLROnPlateau reducing learning rate to 0.0003251301241107285. 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 18/30educeLROnPlateau reducing learning rate to 0.0003251301241107285. 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 18/30educeLROnPlateau reducing learning rate to 0.0003251301241107285. 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 23/30educeLROnPlateau reducing learning rate to 0.0003251301241107285. 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 0.0003251301241107285. 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 29/30educeLROnPlateau reducing learning rate to 0.0003251301241107285. 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0126 - mae: 0.0397 - mse: 0.0024 - val_loss: 0.0034 - val_mae: 0.0399 - val_mse: 0.0022 - lr: 0.0416e-05
Epoch 3/30=============================] - 1s 3ms/step - loss: 0.0126 - mae: 0.0397 - mse: 0.0024 - val_loss: 0.0034 - val_mae: 0.0399 - val_mse: 0.0022 - lr: 0.0416e-05
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.010404163971543312.e: 0.0397 - mse: 0.0024 - val_loss: 0.0034 - val_mae: 0.0399 - val_mse: 0.0022 - lr: 0.0416e-05
Epoch 9/30educeLROnPlateau reducing learning rate to 0.010404163971543312.e: 0.0397 - mse: 0.0024 - val_loss: 0.0034 - val_mae: 0.0399 - val_mse: 0.0022 - lr: 0.0416e-05
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0003251301241107285. 0.0397 - mse: 0.0024 - val_loss: 0.0034 - val_mae: 0.0399 - val_mse: 0.0022 - lr: 0.0416e-05
Epoch 14: ReduceLROnPlateau reducing learning rate to 4.064126551384106e-05. 0.0397 - mse: 0.0024 - val_loss: 0.0034 - val_mae: 0.0399 - val_mse: 0.0022 - lr: 0.0416e-05
Epoch 16: ReduceLROnPlateau reducing learning rate to 1.0160316378460266e-05.0.0397 - mse: 0.0024 - val_loss: 0.0034 - val_mae: 0.0399 - val_mse: 0.0022 - lr: 0.0416e-05
Epoch 20/30educeLROnPlateau reducing learning rate to 1.0160316378460266e-05.0.0397 - mse: 0.0024 - val_loss: 0.0034 - val_mae: 0.0399 - val_mse: 0.0022 - lr: 0.0416e-05
Epoch 23/30educeLROnPlateau reducing learning rate to 1.0160316378460266e-05.0.0397 - mse: 0.0024 - val_loss: 0.0034 - val_mae: 0.0399 - val_mse: 0.0022 - lr: 0.0416e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 1.0160316378460266e-05.0.0397 - mse: 0.0024 - val_loss: 0.0034 - val_mae: 0.0399 - val_mse: 0.0022 - lr: 0.0416e-05
Epoch 29/30educeLROnPlateau reducing learning rate to 1.0160316378460266e-05.0.0397 - mse: 0.0024 - val_loss: 0.0034 - val_mae: 0.0399 - val_mse: 0.0022 - lr: 0.0416e-05
243/243 [==============================] - 1s 4ms/step - loss: 0.0122 - mae: 0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
243/243 [==============================] - 1s 4ms/step - loss: 0.0122 - mae: 0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 3/30=============================] - 1s 4ms/step - loss: 0.0122 - mae: 0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 7/30=============================] - 1s 4ms/step - loss: 0.0122 - mae: 0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.005202081985771656.e: 0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.000650260248221457.: 0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00016256506205536425.0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 17: ReduceLROnPlateau reducing learning rate to 2.032063275692053e-05..0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 21/30educeLROnPlateau reducing learning rate to 2.032063275692053e-05..0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 24/30educeLROnPlateau reducing learning rate to 2.032063275692053e-05..0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 28/30educeLROnPlateau reducing learning rate to 2.032063275692053e-05..0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 30/30educeLROnPlateau reducing learning rate to 2.032063275692053e-05..0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 2/300educeLROnPlateau reducing learning rate to 2.032063275692053e-05..0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 2/300educeLROnPlateau reducing learning rate to 2.032063275692053e-05..0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.020808327943086624.5..0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.005202081985771656.5..0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.000650260248221457...0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 13: ReduceLROnPlateau reducing learning rate to 8.128253102768213e-05..0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 16: ReduceLROnPlateau reducing learning rate to 1.0160316378460266e-05.0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 19/30educeLROnPlateau reducing learning rate to 1.0160316378460266e-05.0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 22/30educeLROnPlateau reducing learning rate to 1.0160316378460266e-05.0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 25/30educeLROnPlateau reducing learning rate to 1.0160316378460266e-05.0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 28/30educeLROnPlateau reducing learning rate to 1.0160316378460266e-05.0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 28/30educeLROnPlateau reducing learning rate to 1.0160316378460266e-05.0.0399 - mse: 0.0022 - val_loss: 0.0033 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.04161665638100033LR_[30]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 2/30trained_models/models_segments_overlap_rmsprop_0.04161665638100033LR_[30]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.010404163971543312.33LR_[30]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.002601040992885828.33LR_[30]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0003251301241107285.LR_[30]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 17/30educeLROnPlateau reducing learning rate to 4.064126551384106e-05.LR_[30]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 17/30educeLROnPlateau reducing learning rate to 4.064126551384106e-05.LR_[30]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 21/30educeLROnPlateau reducing learning rate to 4.064126551384106e-05.LR_[30]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 23/30educeLROnPlateau reducing learning rate to 4.064126551384106e-05.LR_[30]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 4.064126551384106e-05.LR_[30]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
Epoch 29/30educeLROnPlateau reducing learning rate to 4.064126551384106e-05.LR_[30]HN_16BS_1P_val_lossM_30epochs/model_7.h5mae: 0.0385 - val_mse: 0.0020 - lr: 0.0416e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.0149 - mae: 0.0478 - mse: 0.0040 - val_loss: 0.0030 - val_mae: 0.0370 - val_mse: 0.0019 - lr: 0.0416e-05
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.020808327943086624.e: 0.0478 - mse: 0.0040 - val_loss: 0.0030 - val_mae: 0.0370 - val_mse: 0.0019 - lr: 0.0416e-05
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.010404163971543312.e: 0.0478 - mse: 0.0040 - val_loss: 0.0030 - val_mae: 0.0370 - val_mse: 0.0019 - lr: 0.0416e-05
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.002601040992885828.e: 0.0478 - mse: 0.0040 - val_loss: 0.0030 - val_mae: 0.0370 - val_mse: 0.0019 - lr: 0.0416e-05
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.000650260248221457.: 0.0478 - mse: 0.0040 - val_loss: 0.0030 - val_mae: 0.0370 - val_mse: 0.0019 - lr: 0.0416e-05
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00016256506205536425.0.0478 - mse: 0.0040 - val_loss: 0.0030 - val_mae: 0.0370 - val_mse: 0.0019 - lr: 0.0416e-05
Epoch 16: ReduceLROnPlateau reducing learning rate to 2.032063275692053e-05..0.0478 - mse: 0.0040 - val_loss: 0.0030 - val_mae: 0.0370 - val_mse: 0.0019 - lr: 0.0416e-05
Epoch 20/30educeLROnPlateau reducing learning rate to 2.032063275692053e-05..0.0478 - mse: 0.0040 - val_loss: 0.0030 - val_mae: 0.0370 - val_mse: 0.0019 - lr: 0.0416e-05
Epoch 25/30educeLROnPlateau reducing learning rate to 2.032063275692053e-05..0.0478 - mse: 0.0040 - val_loss: 0.0030 - val_mae: 0.0370 - val_mse: 0.0019 - lr: 0.0416e-05
Epoch 29/30educeLROnPlateau reducing learning rate to 2.032063275692053e-05..0.0478 - mse: 0.0040 - val_loss: 0.0030 - val_mae: 0.0370 - val_mse: 0.0019 - lr: 0.0416e-05
Epoch 29/30educeLROnPlateau reducing learning rate to 2.032063275692053e-05..0.0478 - mse: 0.0040 - val_loss: 0.0030 - val_mae: 0.0370 - val_mse: 0.0019 - lr: 0.0416e-05