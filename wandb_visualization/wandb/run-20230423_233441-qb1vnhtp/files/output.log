Epoch 1/30
234/243 [===========================>..] - ETA: 0s - loss: 0.8578 - mae: 0.9252 - mse: 0.8578
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0024s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0024s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
243/243 [==============================] - 2s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0171
Epoch 2/30
222/243 [==========================>...] - ETA: 0s - loss: 0.8582 - mae: 0.9254 - mse: 0.8582
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.008551298640668392.
243/243 [==============================] - 0s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0171
Epoch 3/30
234/243 [===========================>..] - ETA: 0s - loss: 0.8581 - mae: 0.9253 - mse: 0.8581
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.004275649320334196.
243/243 [==============================] - 1s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0086
Epoch 4/30
219/243 [==========================>...] - ETA: 0s - loss: 0.8574 - mae: 0.9249 - mse: 0.8574
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.002137824660167098.
243/243 [==============================] - 0s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0043
Epoch 5/30
216/243 [=========================>....] - ETA: 0s - loss: 0.8584 - mae: 0.9255 - mse: 0.8584
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.001068912330083549.
243/243 [==============================] - 1s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0021
Epoch 6/30
235/243 [============================>.] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005344561650417745.
243/243 [==============================] - 1s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0011
Epoch 7/30
231/243 [===========================>..] - ETA: 0s - loss: 0.8583 - mae: 0.9254 - mse: 0.8583
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00026722808252088726.
243/243 [==============================] - 1s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 5.3446e-04
Epoch 8/30
242/243 [============================>.] - ETA: 0s - loss: 0.8578 - mae: 0.9251 - mse: 0.8578
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00013361404126044363.
243/243 [==============================] - 1s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 2.6723e-04
Epoch 9/30
218/243 [=========================>....] - ETA: 0s - loss: 0.8577 - mae: 0.9251 - mse: 0.8577
Epoch 9: ReduceLROnPlateau reducing learning rate to 6.680702063022181e-05.
243/243 [==============================] - 1s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.3361e-04
Epoch 10/30
229/243 [===========================>..] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579
Epoch 10: ReduceLROnPlateau reducing learning rate to 3.340351031511091e-05.
243/243 [==============================] - 0s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.6807e-05
Epoch 11/30
227/243 [===========================>..] - ETA: 0s - loss: 0.8583 - mae: 0.9254 - mse: 0.8583
Epoch 11: ReduceLROnPlateau reducing learning rate to 1.6701755157555453e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 3.3404e-05
Epoch 12/30
231/243 [===========================>..] - ETA: 0s - loss: 0.8580 - mae: 0.9252 - mse: 0.8580
Epoch 12: ReduceLROnPlateau reducing learning rate to 1e-05.
243/243 [==============================] - 0s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.6702e-05
Epoch 13/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 14/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 15/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 16/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 17/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 18/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 19/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 20/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 21/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 22/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 23/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 24/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 25/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 26/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 27/30
243/243 [==============================] - 0s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 28/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 29/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 30/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.017102596379974477LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
181/323 [===============>..............] - ETA: 0s - loss: 0.6432 - mae: 0.7999 - mse: 0.6432
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.

261/323 [=======================>......] - ETA: 0s - loss: 0.6444 - mae: 0.8006 - mse: 0.6444
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
323/323 [==============================] - 1s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0171
Epoch 2/30
278/323 [========================>.....] - ETA: 0s - loss: 0.6429 - mae: 0.7997 - mse: 0.6429
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.008551298640668392.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0171
Epoch 3/30
274/323 [========================>.....] - ETA: 0s - loss: 0.6446 - mae: 0.8007 - mse: 0.6446
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.004275649320334196.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0086
Epoch 4/30
286/323 [=========================>....] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.002137824660167098.
323/323 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0043
Epoch 5/30
273/323 [========================>.....] - ETA: 0s - loss: 0.6432 - mae: 0.7999 - mse: 0.6432
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.001068912330083549.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0021
Epoch 6/30
305/323 [===========================>..] - ETA: 0s - loss: 0.6435 - mae: 0.8001 - mse: 0.6435
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005344561650417745.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0011
Epoch 7/30
264/323 [=======================>......] - ETA: 0s - loss: 0.6424 - mae: 0.7994 - mse: 0.6424
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00026722808252088726.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 5.3446e-04
Epoch 8/30
291/323 [==========================>...] - ETA: 0s - loss: 0.6430 - mae: 0.7998 - mse: 0.6430
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00013361404126044363.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 2.6723e-04
Epoch 9/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 9: ReduceLROnPlateau reducing learning rate to 6.680702063022181e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.3361e-04
Epoch 10/30
287/323 [=========================>....] - ETA: 0s - loss: 0.6440 - mae: 0.8004 - mse: 0.6440
Epoch 10: ReduceLROnPlateau reducing learning rate to 3.340351031511091e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 6.6807e-05
Epoch 11/30
292/323 [==========================>...] - ETA: 0s - loss: 0.6430 - mae: 0.7997 - mse: 0.6430
Epoch 11: ReduceLROnPlateau reducing learning rate to 1.6701755157555453e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 3.3404e-05
Epoch 12/30
316/323 [============================>.] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431
Epoch 12: ReduceLROnPlateau reducing learning rate to 1e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.6702e-05
Epoch 13/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 14/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 15/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 16/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 17/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 18/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 19/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 20/30
  1/323 [..............................] - ETA: 0s - loss: 0.6233 - mae: 0.7869 - mse: 0.6233
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 24/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 25/30
219/323 [===================>..........] - ETA: 0s - loss: 0.6440 - mae: 0.8003 - mse: 0.6440
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
242/243 [============================>.] - ETA: 0s - loss: 0.4577 - mae: 0.6752 - mse: 0.4577  31 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
242/243 [============================>.] - ETA: 0s - loss: 0.4577 - mae: 0.6752 - mse: 0.4577  31 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
236/243 [============================>.] - ETA: 0s - loss: 0.4579 - mae: 0.6753 - mse: 0.45794578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0171e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 6.6807e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 6.6807e-05
243/243 [==============================] - 1s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
243/243 [==============================] - 1s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
243/243 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
243/243 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
243/243 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
243/243 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00013361404126044363. 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 13/30duceLROnPlateau reducing learning rate to 0.00013361404126044363. 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 13/30duceLROnPlateau reducing learning rate to 0.00013361404126044363. 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 22/30duceLROnPlateau reducing learning rate to 0.00013361404126044363. 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.017102596379974477LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_4.h56 - val_mse: 0.4570 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.017102596379974477LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_4.h56 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00013361404126044363.77LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_4.h56 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 13/30duceLROnPlateau reducing learning rate to 0.00013361404126044363.77LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_4.h56 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 22/30duceLROnPlateau reducing learning rate to 0.00013361404126044363.77LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_4.h56 - val_mse: 0.4570 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.017102596379974477LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_5.h56 - val_mse: 0.4570 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.017102596379974477LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_5.h56 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0027s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0027s). Check your callbacks.
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.017102596379974477LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_5.h56 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00013361404126044363.77LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_5.h56 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 13/30duceLROnPlateau reducing learning rate to 0.00013361404126044363.77LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_5.h56 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 22/30duceLROnPlateau reducing learning rate to 0.00013361404126044363.77LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_5.h56 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 22/30duceLROnPlateau reducing learning rate to 0.00013361404126044363.77LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_5.h56 - val_mse: 0.4570 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.017102596379974477LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.4570 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.017102596379974477LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00013361404126044363.77LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 13/30duceLROnPlateau reducing learning rate to 0.00013361404126044363.77LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 22/30duceLROnPlateau reducing learning rate to 0.00013361404126044363.77LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.4570 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.017102596379974477LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_7.h56 - val_mse: 0.4570 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.017102596379974477LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_7.h56 - val_mse: 0.4570 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.017102596379974477LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_7.h56 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00013361404126044363.77LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_7.h56 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 13/30duceLROnPlateau reducing learning rate to 0.00013361404126044363.77LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_7.h56 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 22/30duceLROnPlateau reducing learning rate to 0.00013361404126044363.77LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_7.h56 - val_mse: 0.4570 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.017102596379974477LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.4570 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.017102596379974477LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.4570 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.017102596379974477LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00013361404126044363.77LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 13/30duceLROnPlateau reducing learning rate to 0.00013361404126044363.77LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 22/30duceLROnPlateau reducing learning rate to 0.00013361404126044363.77LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 22/30duceLROnPlateau reducing learning rate to 0.00013361404126044363.77LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.4570 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.017102596379974477LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_9.h56 - val_mse: 0.4570 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.017102596379974477LR_[21]CHN_32CNNI_16BS_1P_val_lossM_30epochs/model_9.h56 - val_mse: 0.4570 - lr: 1.0000e-05