Epoch 1/50
110/122 [==========================>...] - ETA: 0s - loss: 0.1020 - mae: 0.0510 - mse: 0.0057
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0057s). Check your callbacks.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182216-rlq2w3cm\files\model-best)... Done. 0.0s
122/122 [==============================] - 3s 20ms/step - loss: 0.0929 - mae: 0.0502 - mse: 0.0054 - val_loss: 0.0035 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0215
Epoch 2/50
112/122 [==========================>...] - ETA: 0s - loss: 0.0039 - mae: 0.0419 - mse: 0.0026
122/122 [==============================] - 2s 13ms/step - loss: 0.0040 - mae: 0.0421 - mse: 0.0026 - val_loss: 0.0031 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0215
Epoch 3/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0408 - mse: 0.0024 - val_loss: 0.0040 - val_mae: 0.0433 - val_mse: 0.0027 - lr: 0.0215
Epoch 4/50
111/122 [==========================>...] - ETA: 0s - loss: 0.0029 - mae: 0.0388 - mse: 0.0021
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.010738572105765343.
122/122 [==============================] - 1s 11ms/step - loss: 0.0029 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0215
Epoch 5/50
105/122 [========================>.....] - ETA: 0s - loss: 0.0020 - mae: 0.0380 - mse: 0.0019
122/122 [==============================] - 2s 12ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0107
Epoch 6/50
100/122 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
122/122 [==============================] - 2s 15ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0107
Epoch 7/50
 99/122 [=======================>......] - ETA: 0s - loss: 0.0020 - mae: 0.0380 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.005369286052882671.
122/122 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0107
Epoch 8/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0054
Epoch 9/50
 96/122 [======================>.......] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182216-rlq2w3cm\files\model-best)... Done. 0.0s
122/122 [==============================] - 2s 15ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0054
Epoch 10/50
 99/122 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0026846430264413357.
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 11/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0027
Epoch 12/50
122/122 [==============================] - 2s 13ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0027
Epoch 13/50
 97/122 [======================>.......] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0013423215132206678.
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0027
Epoch 14/50
106/122 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
122/122 [==============================] - 2s 13ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0013
Epoch 15/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0013
Epoch 16/50
109/122 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0006711607566103339.
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0013
Epoch 17/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7116e-04
Epoch 18/50
104/122 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182216-rlq2w3cm\files\model-best)... Done. 0.0s
122/122 [==============================] - 2s 19ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7116e-04
Epoch 19/50
118/122 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00033558037830516696.
122/122 [==============================] - 2s 16ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7116e-04
Epoch 20/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.3558e-04
Epoch 21/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.3558e-04
Epoch 22/50
107/122 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00016779018915258348.
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.3558e-04
Epoch 23/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.6779e-04
Epoch 24/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6779e-04
Epoch 25/50
101/122 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 25: ReduceLROnPlateau reducing learning rate to 8.389509457629174e-05.
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.6779e-04
Epoch 26/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 8.3895e-05
Epoch 27/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 8.3895e-05
Epoch 28/50
104/122 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 28: ReduceLROnPlateau reducing learning rate to 4.194754728814587e-05.
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.3895e-05
Epoch 29/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.1948e-05
Epoch 30/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.1948e-05
Epoch 31/50
109/122 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 31: ReduceLROnPlateau reducing learning rate to 2.0973773644072935e-05.
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.1948e-05
Epoch 32/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.0974e-05
Epoch 33/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.0974e-05
Epoch 34/50
 93/122 [=====================>........] - ETA: 0s - loss: 0.0019 - mae: 0.0374 - mse: 0.0019
Epoch 34: ReduceLROnPlateau reducing learning rate to 1.0486886822036467e-05.
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.0974e-05
Epoch 35/50
122/122 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0487e-05
Epoch 36/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0487e-05
Epoch 37/50
114/122 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 37: ReduceLROnPlateau reducing learning rate to 1e-05.
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0487e-05
Epoch 38/50
122/122 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 39/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 40/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 41/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 42/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 43/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 44/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 45/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 46/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 47/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 48/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 49/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 50/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.02147714499639665_70_32_50epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/50
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0027s). Check your callbacks.
162/162 [==============================] - 1s 4ms/step - loss: 0.0747 - mae: 0.0569 - mse: 0.0050 - val_loss: 0.0054 - val_mae: 0.0557 - val_mse: 0.0044 - lr: 0.0215
Epoch 2/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0520 - mse: 0.0037 - val_loss: 0.0045 - val_mae: 0.0516 - val_mse: 0.0036 - lr: 0.0215
Epoch 3/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0042 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0215
Epoch 4/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0047 - val_mae: 0.0523 - val_mse: 0.0038 - lr: 0.0215
Epoch 5/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0044 - val_mae: 0.0515 - val_mse: 0.0036 - lr: 0.0215
Epoch 6/50
144/162 [=========================>....] - ETA: 0s - loss: 0.0041 - mae: 0.0504 - mse: 0.0034
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.010738572105765343.
162/162 [==============================] - 0s 2ms/step - loss: 0.0042 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0042 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0215
Epoch 7/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0107
Epoch 8/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0107
Epoch 9/50
135/162 [========================>.....] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.005369286052882671.
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0107
Epoch 10/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0054
Epoch 11/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0054
Epoch 12/50
140/162 [========================>.....] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0026846430264413357.
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0054
Epoch 13/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0027
Epoch 14/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0027
Epoch 15/50
135/162 [========================>.....] - ETA: 0s - loss: 0.0034 - mae: 0.0509 - mse: 0.0034
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0013423215132206678.
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0027
Epoch 16/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0013
Epoch 17/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0013
Epoch 18/50
144/162 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0509 - mse: 0.0034
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006711607566103339.
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0013
Epoch 19/50
162/162 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.7116e-04
Epoch 20/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.7116e-04
Epoch 21/50
142/162 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00033558037830516696.
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.7116e-04
Epoch 22/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.3558e-04
Epoch 23/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.3558e-04
Epoch 24/50
139/162 [========================>.....] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00016779018915258348.
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.3558e-04
Epoch 25/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6779e-04
Epoch 26/50
162/162 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6779e-04
Epoch 27/50
160/162 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 27: ReduceLROnPlateau reducing learning rate to 8.389509457629174e-05.
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6779e-04
Epoch 28/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.3895e-05
Epoch 29/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.3895e-05
Epoch 30/50
145/162 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 30: ReduceLROnPlateau reducing learning rate to 4.194754728814587e-05.
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.3895e-05
Epoch 31/50
149/162 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 4.1948e-05
Epoch 33/50
148/162 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034
Epoch 33: ReduceLROnPlateau reducing learning rate to 2.0973773644072935e-05.
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 4.1948e-05
Epoch 34/50
162/162 [==============================] - 0s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 2.0974e-05
Epoch 35/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 2.0974e-05
Epoch 36/50
150/162 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 36: ReduceLROnPlateau reducing learning rate to 1.0486886822036467e-05.
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 2.0974e-05
Epoch 37/50
 79/162 [=============>................] - ETA: 0s - loss: 0.0033 - mae: 0.0501 - mse: 0.0033
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0487e-05
Epoch 39/50
149/162 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0508 - mse: 0.0034
Epoch 39: ReduceLROnPlateau reducing learning rate to 1e-05.
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0487e-05
Epoch 40/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 41/50
144/162 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 46/50
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 47/50
 73/162 [============>.................] - ETA: 0s - loss: 0.0034 - mae: 0.0510 - mse: 0.0034
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
162/162 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
122/122 [==============================] - 0s 3ms/step - loss: 0.0028 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0215e-05
122/122 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0107e-05
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0027e-05
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7116e-04
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.6779e-04
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0487e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0027 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0215e-05
  1/122 [..............................] - ETA: 0s - loss: 0.0015 - mae: 0.0331 - mse: 0.00150019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0054e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.3558e-04
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 8.3895e-05
115/122 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.0974e-05
117/122 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
 83/122 [===================>..........] - ETA: 0s - loss: 0.0027 - mae: 0.0382 - mse: 0.00200019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
120/122 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00016779018915258348.
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.3558e-04
Epoch 23/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.6779e-04
Epoch 24/50
 46/122 [==========>...................] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
109/122 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.00190019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 28: ReduceLROnPlateau reducing learning rate to 4.194754728814587e-05.
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 8.3895e-05
Epoch 29/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.1948e-05
Epoch 30/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.1948e-05
Epoch 31/50
 25/122 [=====>........................] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.0019
119/122 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 34: ReduceLROnPlateau reducing learning rate to 1.0486886822036467e-05.
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.0974e-05
Epoch 35/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0487e-05
Epoch 36/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0487e-05
Epoch 37/50
 99/122 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 41/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 42/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 43/50
119/122 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 49/50
  1/122 [..............................] - ETA: 0s - loss: 0.0018 - mae: 0.0387 - mse: 0.0018
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
 69/122 [===============>..............] - ETA: 0s - loss: 0.0027 - mae: 0.0383 - mse: 0.00200019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
 95/122 [======================>.......] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006711607566103339.
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0013
Epoch 18/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.7116e-04
Epoch 19/50
  1/122 [..............................] - ETA: 0s - loss: 0.0019 - mae: 0.0385 - mse: 0.0019
 65/122 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00016779018915258348.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.3558e-04
Epoch 24/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.6779e-04
Epoch 25/50
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6779e-04
Epoch 26/50
103/122 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 26: ReduceLROnPlateau reducing learning rate to 8.389509457629174e-05.
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6779e-04
Epoch 27/50
100/122 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
118/122 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 29: ReduceLROnPlateau reducing learning rate to 4.194754728814587e-05.
122/122 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.3895e-05
Epoch 30/50
122/122 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.1948e-05
Epoch 31/50
122/122 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.1948e-05
Epoch 32/50
 95/122 [======================>.......] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
104/122 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 35: ReduceLROnPlateau reducing learning rate to 1.0486886822036467e-05.
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.0974e-05
Epoch 36/50
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0487e-05
Epoch 37/50
 76/122 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 42/50
 88/122 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.0019
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0107e-05
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0027e-05
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7116e-04
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6779e-04
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.1948e-05
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0487e-05
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
122/122 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.
122/122 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0032 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215e-05
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006711607566103339. 0.0381 - mse: 0.0019 - val_loss: 0.0032 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215e-05
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00016779018915258348.0.0381 - mse: 0.0019 - val_loss: 0.0032 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215e-05
Epoch 30: ReduceLROnPlateau reducing learning rate to 4.194754728814587e-05..0.0381 - mse: 0.0019 - val_loss: 0.0032 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215e-05
Epoch 36: ReduceLROnPlateau reducing learning rate to 1.0486886822036467e-05.0.0381 - mse: 0.0019 - val_loss: 0.0032 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215e-05
Epoch 43/50educeLROnPlateau reducing learning rate to 1.0486886822036467e-05.0.0381 - mse: 0.0019 - val_loss: 0.0032 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215e-05
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.02147714499639665_70_32_50epochs/model_8.h5 val_mse: 0.0020 - lr: 0.0215e-05
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.02147714499639665_70_32_50epochs/model_8.h5 val_mse: 0.0020 - lr: 0.0215e-05
Epoch 7/50trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.02147714499639665_70_32_50epochs/model_8.h5 val_mse: 0.0020 - lr: 0.0215e-05
Epoch 13/50rained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.02147714499639665_70_32_50epochs/model_8.h5 val_mse: 0.0020 - lr: 0.0215e-05
Epoch 19/50rained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.02147714499639665_70_32_50epochs/model_8.h5 val_mse: 0.0020 - lr: 0.0215e-05
Epoch 25/50rained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.02147714499639665_70_32_50epochs/model_8.h5 val_mse: 0.0020 - lr: 0.0215e-05
Epoch 31/50rained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.02147714499639665_70_32_50epochs/model_8.h5 val_mse: 0.0020 - lr: 0.0215e-05
Epoch 37/50rained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.02147714499639665_70_32_50epochs/model_8.h5 val_mse: 0.0020 - lr: 0.0215e-05
Epoch 44/50rained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.02147714499639665_70_32_50epochs/model_8.h5 val_mse: 0.0020 - lr: 0.0215e-05
Epoch 44/50rained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.02147714499639665_70_32_50epochs/model_8.h5 val_mse: 0.0020 - lr: 0.0215e-05
Epoch 44/50rained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.02147714499639665_70_32_50epochs/model_8.h5 val_mse: 0.0020 - lr: 0.0215e-05