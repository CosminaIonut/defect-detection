Epoch 1/50
152/162 [===========================>..] - ETA: 0s - loss: 0.0036 - mae: 0.0515 - mse: 0.0036 - root_mean_squared_error: 0.0602
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_055032-hozfb971\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
162/162 [==============================] - 2s 13ms/step - loss: 0.0036 - mae: 0.0515 - mse: 0.0036 - root_mean_squared_error: 0.0601 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0171
Epoch 2/50
158/162 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - root_mean_squared_error: 0.0587
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
162/162 [==============================] - 2s 15ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - root_mean_squared_error: 0.0587 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0171
Epoch 3/50
162/162 [==============================] - 2s 13ms/step - loss: 0.0035 - mae: 0.0510 - mse: 0.0035 - root_mean_squared_error: 0.0593 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0171
Epoch 4/50
162/162 [==============================] - 1s 7ms/step - loss: 0.0035 - mae: 0.0510 - mse: 0.0035 - root_mean_squared_error: 0.0592 - val_loss: 0.0035 - val_mae: 0.0509 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0590 - lr: 0.0171
Epoch 5/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0035 - mae: 0.0509 - mse: 0.0035 - root_mean_squared_error: 0.0589 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0171
Epoch 6/50
162/162 [==============================] - ETA: 0s - loss: 0.0035 - mae: 0.0507 - mse: 0.0035 - root_mean_squared_error: 0.0588
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.008560496382415295.
162/162 [==============================] - 1s 6ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0035 - root_mean_squared_error: 0.0588 - val_loss: 0.0034 - val_mae: 0.0507 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0586 - lr: 0.0171
Epoch 7/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0035 - val_mae: 0.0509 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0589 - lr: 0.0086
Epoch 8/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0034 - val_mae: 0.0508 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0586 - lr: 0.0086
Epoch 9/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0086
Epoch 10/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0086
Epoch 11/50
152/162 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0508 - mse: 0.0034 - root_mean_squared_error: 0.0587
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.004280248191207647.
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0086
Epoch 12/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0585 - lr: 0.0043
Epoch 13/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0585 - lr: 0.0043
Epoch 14/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0043
Epoch 15/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0035 - val_mae: 0.0509 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0588 - lr: 0.0043
Epoch 16/50
159/162 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0021401240956038237.
162/162 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0043
Epoch 17/50
162/162 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0021
Epoch 18/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0021
Epoch 19/50
162/162 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0021
Epoch 20/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0508 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0587 - lr: 0.0021
Epoch 21/50
153/162 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0010700620478019118.
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0021
Epoch 22/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0011
Epoch 23/50
 84/162 [==============>...............] - ETA: 0s - loss: 0.0035 - mae: 0.0513 - mse: 0.0035 - root_mean_squared_error: 0.0591
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.

161/162 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
162/162 [==============================] - 2s 12ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0011
Epoch 24/50
152/162 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0584
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
162/162 [==============================] - 2s 13ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0011
Epoch 25/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0011
Epoch 26/50
161/162 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005350310239009559.
162/162 [==============================] - 2s 12ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 0.0011
Epoch 27/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 5.3503e-04
Epoch 28/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 5.3503e-04
Epoch 29/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 5.3503e-04
Epoch 30/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 5.3503e-04
Epoch 31/50
153/162 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0582
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00026751551195047796.
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 5.3503e-04
Epoch 32/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.6752e-04
Epoch 33/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.6752e-04
Epoch 34/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.6752e-04
Epoch 35/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.6752e-04
Epoch 36/50
158/162 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0584
Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00013375775597523898.
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 2.6752e-04
Epoch 37/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.3376e-04
Epoch 38/50
155/162 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0584
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
162/162 [==============================] - 2s 12ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.3376e-04
Epoch 39/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0506 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.3376e-04
Epoch 40/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.3376e-04
Epoch 41/50
152/162 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - root_mean_squared_error: 0.0585
Epoch 41: ReduceLROnPlateau reducing learning rate to 6.687887798761949e-05.
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 1.3376e-04
Epoch 42/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 6.6879e-05
Epoch 43/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 6.6879e-05
Epoch 44/50
 22/162 [===>..........................] - ETA: 0s - loss: 0.0035 - mae: 0.0516 - mse: 0.0035 - root_mean_squared_error: 0.05910583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 6.6879e-05
Epoch 45/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 6.6879e-05
Epoch 46/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 3.3439e-05
Epoch 46: ReduceLROnPlateau reducing learning rate to 3.3439438993809745e-05.
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 6.6879e-05
Epoch 47/50
162/162 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 3.3439e-05
Epoch 48/50
162/162 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 3.3439e-05
Epoch 49/50
162/162 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 3.3439e-05
Epoch 50/50
109/162 [===================>..........] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0584
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 3.3439e-05
Epoch 1/50
 42/242 [====>.........................] - ETA: 1s - loss: 0.0092 - mae: 0.0798 - mse: 0.0092 - root_mean_squared_error: 0.0961
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 3.3439e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_train_batch_end` time: 0.0028s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_train_batch_end` time: 0.0028s). Check your callbacks.
239/242 [============================>.] - ETA: 0s - loss: 0.0077 - mae: 0.0757 - mse: 0.0077 - root_mean_squared_error: 0.0878r']) - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0583 - lr: 3.3439e-05
242/242 [==============================] - 1s 6ms/step - loss: 0.0077 - mae: 0.0757 - mse: 0.0077 - root_mean_squared_error: 0.0877 - val_loss: 0.0076 - val_mae: 0.0761 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0875 - lr: 0.0171e-05
242/242 [==============================] - 1s 6ms/step - loss: 0.0078 - mae: 0.0759 - mse: 0.0078 - root_mean_squared_error: 0.0882 - val_loss: 0.0076 - val_mae: 0.0761 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0875 - lr: 0.0171e-05
242/242 [==============================] - 1s 6ms/step - loss: 0.0078 - mae: 0.0759 - mse: 0.0078 - root_mean_squared_error: 0.0882 - val_loss: 0.0076 - val_mae: 0.0761 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0875 - lr: 0.0171e-05
242/242 [==============================] - 1s 6ms/step - loss: 0.0078 - mae: 0.0759 - mse: 0.0078 - root_mean_squared_error: 0.0881 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 0.0171e-05
156/242 [==================>...........] - ETA: 0s - loss: 0.0077 - mae: 0.0757 - mse: 0.0077 - root_mean_squared_error: 0.08770881 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 0.0171e-05
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0754 - mse: 0.0076 - root_mean_squared_error: 0.0874 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 0.0086e-05
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0754 - mse: 0.0076 - root_mean_squared_error: 0.0874 - val_loss: 0.0080 - val_mae: 0.0772 - val_mse: 0.0080 - val_root_mean_squared_error: 0.0894 - lr: 0.0086e-05
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0754 - mse: 0.0076 - root_mean_squared_error: 0.0874 - val_loss: 0.0080 - val_mae: 0.0772 - val_mse: 0.0080 - val_root_mean_squared_error: 0.0894 - lr: 0.0086e-05
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 0.0043e-05
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 0.0043e-05
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0874 - val_loss: 0.0076 - val_mae: 0.0761 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 0.0043e-05
190/242 [======================>.......] - ETA: 0s - loss: 0.0076 - mae: 0.0754 - mse: 0.0076 - root_mean_squared_error: 0.08710874 - val_loss: 0.0076 - val_mae: 0.0761 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 0.0043e-05
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0754 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 0.0021e-05
242/242 [==============================] - 2s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0021e-05
242/242 [==============================] - 2s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0021e-05
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 0.0011e-05
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 0.0011e-05
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0011e-05
154/242 [==================>...........] - ETA: 0s - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.08700871 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0875 - lr: 0.0011e-05
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0761 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 5.3503e-04
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 5.3503e-04
  1/242 [..............................] - ETA: 1s - loss: 0.0064 - mae: 0.0685 - mse: 0.0064 - root_mean_squared_error: 0.07990872 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 5.3503e-04
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 2.6752e-04
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 2.6752e-04
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 2.6752e-04
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 1.3376e-04
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 1.3376e-04
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 1.3376e-04
 68/242 [=======>......................] - ETA: 0s - loss: 0.0075 - mae: 0.0749 - mse: 0.0075 - root_mean_squared_error: 0.08670871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 1.3376e-04
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
242/242 [==============================] - 1s 6ms/step - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0871 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_055032-hozfb971\files\model-best)... Done. 0.0s
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 4/50['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 4/50['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 6/50['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 6/50['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 6/50['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_055032-hozfb971\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_055032-hozfb971\files\model-best)... Done. 0.0s
Epoch 10/50'loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 10/50'loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.008560496382415295.l_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.008560496382415295.l_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_055032-hozfb971\files\model-best)... Done. 0.0s
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.008560496382415295.l_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_055032-hozfb971\files\model-best)... Done. 0.0s
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.008560496382415295.l_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 16/50educeLROnPlateau reducing learning rate to 0.008560496382415295.l_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 18/50educeLROnPlateau reducing learning rate to 0.008560496382415295.l_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 18/50educeLROnPlateau reducing learning rate to 0.008560496382415295.l_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_055032-hozfb971\files\model-best)... Done. 0.0s
Epoch 18/50educeLROnPlateau reducing learning rate to 0.008560496382415295.l_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_055032-hozfb971\files\model-best)... Done. 0.0s
Epoch 18/50educeLROnPlateau reducing learning rate to 0.008560496382415295.l_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 22/50educeLROnPlateau reducing learning rate to 0.008560496382415295.l_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 22/50educeLROnPlateau reducing learning rate to 0.008560496382415295.l_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_055032-hozfb971\files\model-best)... Done. 0.0s
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0021401240956038237._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0021401240956038237._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_055032-hozfb971\files\model-best)... Done. 0.0s
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0021401240956038237._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 29/50educeLROnPlateau reducing learning rate to 0.0021401240956038237._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 29/50educeLROnPlateau reducing learning rate to 0.0021401240956038237._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_055032-hozfb971\files\model-best)... Done. 0.0s
Epoch 29/50educeLROnPlateau reducing learning rate to 0.0021401240956038237._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 31/50educeLROnPlateau reducing learning rate to 0.0021401240956038237._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 31/50educeLROnPlateau reducing learning rate to 0.0021401240956038237._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 33/50educeLROnPlateau reducing learning rate to 0.0021401240956038237._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 33/50educeLROnPlateau reducing learning rate to 0.0021401240956038237._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_055032-hozfb971\files\model-best)... Done. 0.0s
Epoch 36/50educeLROnPlateau reducing learning rate to 0.0021401240956038237._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 36/50educeLROnPlateau reducing learning rate to 0.0021401240956038237._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 36/50educeLROnPlateau reducing learning rate to 0.0021401240956038237._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00026751551195047796.mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00026751551195047796.mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 42/50educeLROnPlateau reducing learning rate to 0.00026751551195047796.mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00013375775597523898.mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00013375775597523898.mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_055032-hozfb971\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230510_055032-hozfb971\files\model-best)... Done. 0.0s
Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00013375775597523898.mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 48/50educeLROnPlateau reducing learning rate to 0.00013375775597523898.mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 1/50ReduceLROnPlateau reducing learning rate to 6.687887798761949e-05..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 1/50ReduceLROnPlateau reducing learning rate to 6.687887798761949e-05..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 4/50ReduceLROnPlateau reducing learning rate to 6.687887798761949e-05..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 4/50ReduceLROnPlateau reducing learning rate to 6.687887798761949e-05..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 4/50ReduceLROnPlateau reducing learning rate to 6.687887798761949e-05..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 8/50ReduceLROnPlateau reducing learning rate to 6.687887798761949e-05..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 8/50ReduceLROnPlateau reducing learning rate to 6.687887798761949e-05..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 11/50educeLROnPlateau reducing learning rate to 6.687887798761949e-05..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 11/50educeLROnPlateau reducing learning rate to 6.687887798761949e-05..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 14/50educeLROnPlateau reducing learning rate to 6.687887798761949e-05..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 14/50educeLROnPlateau reducing learning rate to 6.687887798761949e-05..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 14/50educeLROnPlateau reducing learning rate to 6.687887798761949e-05..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 18/50educeLROnPlateau reducing learning rate to 6.687887798761949e-05..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 18/50educeLROnPlateau reducing learning rate to 6.687887798761949e-05..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 24/50educeLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 24/50educeLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.004280248191207647...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.004280248191207647...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 30/50educeLROnPlateau reducing learning rate to 0.004280248191207647...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 30/50educeLROnPlateau reducing learning rate to 0.004280248191207647...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 30/50educeLROnPlateau reducing learning rate to 0.004280248191207647...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 39/50educeLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 39/50educeLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 43/50educeLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 44/50educeLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 44/50educeLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 47/50educeLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 47/50educeLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 49/50educeLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 1/500educeLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 1/500educeLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0005s vs `on_train_batch_end` time: 0.0049s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0005s vs `on_train_batch_end` time: 0.0049s). Check your callbacks.
Epoch 1/500educeLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 5/500educeLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 5/500educeLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 8/500educeLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 8/500educeLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 8/500educeLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 12/50educeLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 12/50educeLROnPlateau reducing learning rate to 0.0021401240956038237..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 18/50educeLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 18/50educeLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 21/50educeLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 21/50educeLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 24/50educeLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 25/50educeLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 25/50educeLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 28/50educeLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 28/50educeLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 31/50educeLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 31/50educeLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 33/50educeLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 33/50educeLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 38/50educeLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 40/50educeLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 40/50educeLROnPlateau reducing learning rate to 0.008560496382415295...mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0005350310239009559..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0005350310239009559..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0005350310239009559..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 47/50educeLROnPlateau reducing learning rate to 0.0005350310239009559..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 48/50educeLROnPlateau reducing learning rate to 0.0005350310239009559..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 48/50educeLROnPlateau reducing learning rate to 0.0005350310239009559..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 1/500educeLROnPlateau reducing learning rate to 0.0005350310239009559..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 1/500educeLROnPlateau reducing learning rate to 0.0005350310239009559..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 1/500educeLROnPlateau reducing learning rate to 0.0005350310239009559..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 5/500educeLROnPlateau reducing learning rate to 0.0005350310239009559..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 5/500educeLROnPlateau reducing learning rate to 0.0005350310239009559..mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
128/242 [==============>...............] - ETA: 0s - loss: 0.0015 - mae: 0.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
128/242 [==============>...............] - ETA: 0s - loss: 0.0015 - mae: 0.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 11/50============>...............] - ETA: 0s - loss: 0.0015 - mae: 0.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 11/50============>...............] - ETA: 0s - loss: 0.0015 - mae: 0.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 11/50============>...............] - ETA: 0s - loss: 0.0015 - mae: 0.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 15/50============>...............] - ETA: 0s - loss: 0.0015 - mae: 0.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 15/50============>...............] - ETA: 0s - loss: 0.0015 - mae: 0.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 18/50============>...............] - ETA: 0s - loss: 0.0015 - mae: 0.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 18/50============>...............] - ETA: 0s - loss: 0.0015 - mae: 0.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 21/50============>...............] - ETA: 0s - loss: 0.0015 - mae: 0.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 21/50============>...............] - ETA: 0s - loss: 0.0015 - mae: 0.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 24/50============>...............] - ETA: 0s - loss: 0.0015 - mae: 0.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 24/50============>...............] - ETA: 0s - loss: 0.0015 - mae: 0.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.008560496382415295.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.008560496382415295.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 30/50educeLROnPlateau reducing learning rate to 0.008560496382415295.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 30/50educeLROnPlateau reducing learning rate to 0.008560496382415295.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 32: ReduceLROnPlateau reducing learning rate to 0.004280248191207647.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 32: ReduceLROnPlateau reducing learning rate to 0.004280248191207647.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 36/50educeLROnPlateau reducing learning rate to 0.004280248191207647.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 36/50educeLROnPlateau reducing learning rate to 0.004280248191207647.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 38/50educeLROnPlateau reducing learning rate to 0.004280248191207647.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 38/50educeLROnPlateau reducing learning rate to 0.004280248191207647.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 42/50educeLROnPlateau reducing learning rate to 0.004280248191207647.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 42/50educeLROnPlateau reducing learning rate to 0.004280248191207647.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 45/50educeLROnPlateau reducing learning rate to 0.004280248191207647.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 46/50educeLROnPlateau reducing learning rate to 0.004280248191207647.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 46/50educeLROnPlateau reducing learning rate to 0.004280248191207647.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 49/50educeLROnPlateau reducing learning rate to 0.004280248191207647.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 49/50educeLROnPlateau reducing learning rate to 0.004280248191207647.0288 - mse: 0.0015 - root_mean_squared_error: 0.0390r']) - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 5/50trained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 5/50trained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 8/50trained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 8/50trained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 11/50rained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 11/50rained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 14/50rained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 14/50rained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 17/50rained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 17/50rained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 20/50rained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 20/50rained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 23/50rained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 24/50rained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 26/50rained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 26/50rained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 29/50rained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 30/50rained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 32/50rained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 32/50rained_models/CNN/models_segments_overlap-cnn-more_adam_0.017120992331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0021401240956038237.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0021401240956038237.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0021401240956038237.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 39/50educeLROnPlateau reducing learning rate to 0.0021401240956038237.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 40/50educeLROnPlateau reducing learning rate to 0.0021401240956038237.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 42/50educeLROnPlateau reducing learning rate to 0.0021401240956038237.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 42/50educeLROnPlateau reducing learning rate to 0.0021401240956038237.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 48/50educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 48/50educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 50/50educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 50/50educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 50/50educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0043s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0043s). Check your callbacks.
Epoch 4/500educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 4/500educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 7/500educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 7/500educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 10/50educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 10/50educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 13/50educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 13/50educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 16/50educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 16/50educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 20/50educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 20/50educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 23/50educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 23/50educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 23/50educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 26/50educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 26/50educeLROnPlateau reducing learning rate to 0.0005350310239009559.92331690465LR_[30]CHN_100CNNI_32BS_1000DU_5P_val_lossM_50epochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
153/242 [=================>............] - ETA: 0s - loss: 1.0655e-04 - mae: 0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 31/50===============>............] - ETA: 0s - loss: 1.0655e-04 - mae: 0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 31/50===============>............] - ETA: 0s - loss: 1.0655e-04 - mae: 0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 35/50===============>............] - ETA: 0s - loss: 1.0655e-04 - mae: 0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 36/50===============>............] - ETA: 0s - loss: 1.0655e-04 - mae: 0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 38/50===============>............] - ETA: 0s - loss: 1.0655e-04 - mae: 0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 38/50===============>............] - ETA: 0s - loss: 1.0655e-04 - mae: 0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 38/50===============>............] - ETA: 0s - loss: 1.0655e-04 - mae: 0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 41/50===============>............] - ETA: 0s - loss: 1.0655e-04 - mae: 0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 41/50===============>............] - ETA: 0s - loss: 1.0655e-04 - mae: 0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 45/50===============>............] - ETA: 0s - loss: 1.0655e-04 - mae: 0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 46/50===============>............] - ETA: 0s - loss: 1.0655e-04 - mae: 0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 48/50===============>............] - ETA: 0s - loss: 1.0655e-04 - mae: 0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 48/50===============>............] - ETA: 0s - loss: 1.0655e-04 - mae: 0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.0054s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.0054s). Check your callbacks.
Epoch 4/50ReduceLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 4/50ReduceLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 4/50ReduceLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 8/50ReduceLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 10/50educeLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 10/50educeLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 13/50educeLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 13/50educeLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 16/50educeLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 16/50educeLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 23/50educeLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 23/50educeLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 26/50educeLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 26/50educeLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 28/50educeLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 28/50educeLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 32/50educeLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 32/50educeLROnPlateau reducing learning rate to 0.00013375775597523898.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 34: ReduceLROnPlateau reducing learning rate to 0.004280248191207647.8.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 34: ReduceLROnPlateau reducing learning rate to 0.004280248191207647.8.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 38/50educeLROnPlateau reducing learning rate to 0.004280248191207647.8.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 38/50educeLROnPlateau reducing learning rate to 0.004280248191207647.8.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 40/50educeLROnPlateau reducing learning rate to 0.004280248191207647.8.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 42/50educeLROnPlateau reducing learning rate to 0.004280248191207647.8.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 42/50educeLROnPlateau reducing learning rate to 0.004280248191207647.8.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0010700620478019118..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0010700620478019118..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 48/50educeLROnPlateau reducing learning rate to 0.0010700620478019118..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 48/50educeLROnPlateau reducing learning rate to 0.0010700620478019118..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 50/50educeLROnPlateau reducing learning rate to 0.0010700620478019118..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 2/500educeLROnPlateau reducing learning rate to 0.0010700620478019118..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 4/500educeLROnPlateau reducing learning rate to 0.0010700620478019118..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 6/500educeLROnPlateau reducing learning rate to 0.0010700620478019118..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 8/500educeLROnPlateau reducing learning rate to 0.0010700620478019118..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 10/50educeLROnPlateau reducing learning rate to 0.0010700620478019118..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 12/50educeLROnPlateau reducing learning rate to 0.0010700620478019118..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 14/50educeLROnPlateau reducing learning rate to 0.0010700620478019118..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 16/50educeLROnPlateau reducing learning rate to 0.0010700620478019118..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 18/50educeLROnPlateau reducing learning rate to 0.0010700620478019118..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 20/50educeLROnPlateau reducing learning rate to 0.0010700620478019118..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 22/50educeLROnPlateau reducing learning rate to 0.0010700620478019118..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 24/50educeLROnPlateau reducing learning rate to 0.0010700620478019118..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 0.0010700620478019118..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 29/50educeLROnPlateau reducing learning rate to 0.0010700620478019118..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 30/50educeLROnPlateau reducing learning rate to 0.0010700620478019118..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 33/50educeLROnPlateau reducing learning rate to 0.0010700620478019118..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0021401240956038237..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 0.0021401240956038237..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 37/50educeLROnPlateau reducing learning rate to 0.0021401240956038237..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 40/50educeLROnPlateau reducing learning rate to 0.0021401240956038237..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 43/50educeLROnPlateau reducing learning rate to 0.0021401240956038237..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0005350310239009559..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 47/50educeLROnPlateau reducing learning rate to 0.0005350310239009559..0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00026751551195047796.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00026751551195047796.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05
Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00026751551195047796.0.0075 - mse: 1.0655e-04 - root_mean_squared_error: 0.0103ochs/model_6.h5 - val_mae: 0.0760 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0874 - lr: 6.6879e-05