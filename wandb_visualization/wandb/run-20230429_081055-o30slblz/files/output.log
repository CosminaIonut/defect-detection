Epoch 1/30
98/98 [==============================] - ETA: 0s - loss: 0.0172 - mae: 0.0588 - mse: 0.0172 - root_mean_squared_error: 0.1313
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
98/98 [==============================] - 3s 22ms/step - loss: 0.0172 - mae: 0.0588 - mse: 0.0172 - root_mean_squared_error: 0.1313 - val_loss: 0.0028 - val_mae: 0.0439 - val_mse: 0.0028 - val_root_mean_squared_error: 0.0530 - lr: 0.0627
Epoch 2/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0029 - mae: 0.0439 - mse: 0.0029 - root_mean_squared_error: 0.0536 - val_loss: 0.0045 - val_mae: 0.0549 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0673 - lr: 0.0627
Epoch 3/30
98/98 [==============================] - 1s 9ms/step - loss: 0.0029 - mae: 0.0446 - mse: 0.0029 - root_mean_squared_error: 0.0539 - val_loss: 0.0070 - val_mae: 0.0712 - val_mse: 0.0070 - val_root_mean_squared_error: 0.0836 - lr: 0.0627
Epoch 4/30
91/98 [==========================>...] - ETA: 0s - loss: 0.0030 - mae: 0.0449 - mse: 0.0030 - root_mean_squared_error: 0.0545
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.03136058524250984.
98/98 [==============================] - 1s 8ms/step - loss: 0.0030 - mae: 0.0453 - mse: 0.0030 - root_mean_squared_error: 0.0550 - val_loss: 0.0065 - val_mae: 0.0679 - val_mse: 0.0065 - val_root_mean_squared_error: 0.0806 - lr: 0.0627
Epoch 5/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0022 - mae: 0.0394 - mse: 0.0022 - root_mean_squared_error: 0.0465 - val_loss: 0.0044 - val_mae: 0.0541 - val_mse: 0.0044 - val_root_mean_squared_error: 0.0663 - lr: 0.0314
Epoch 6/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0022 - mae: 0.0398 - mse: 0.0022 - root_mean_squared_error: 0.0469 - val_loss: 0.0070 - val_mae: 0.0716 - val_mse: 0.0070 - val_root_mean_squared_error: 0.0840 - lr: 0.0314
Epoch 7/30
91/98 [==========================>...] - ETA: 0s - loss: 0.0022 - mae: 0.0398 - mse: 0.0022 - root_mean_squared_error: 0.0471
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
98/98 [==============================] - 2s 18ms/step - loss: 0.0022 - mae: 0.0399 - mse: 0.0022 - root_mean_squared_error: 0.0472 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0443 - lr: 0.0314
Epoch 8/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0022 - mae: 0.0397 - mse: 0.0022 - root_mean_squared_error: 0.0465 - val_loss: 0.0027 - val_mae: 0.0428 - val_mse: 0.0027 - val_root_mean_squared_error: 0.0516 - lr: 0.0314
Epoch 9/30
98/98 [==============================] - 1s 9ms/step - loss: 0.0022 - mae: 0.0396 - mse: 0.0022 - root_mean_squared_error: 0.0469 - val_loss: 0.0023 - val_mae: 0.0407 - val_mse: 0.0023 - val_root_mean_squared_error: 0.0481 - lr: 0.0314
Epoch 10/30
90/98 [==========================>...] - ETA: 0s - loss: 0.0022 - mae: 0.0400 - mse: 0.0022 - root_mean_squared_error: 0.0472
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.01568029262125492.
98/98 [==============================] - 1s 8ms/step - loss: 0.0022 - mae: 0.0398 - mse: 0.0022 - root_mean_squared_error: 0.0470 - val_loss: 0.0050 - val_mae: 0.0586 - val_mse: 0.0050 - val_root_mean_squared_error: 0.0710 - lr: 0.0314
Epoch 11/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0384 - mse: 0.0020 - root_mean_squared_error: 0.0449 - val_loss: 0.0022 - val_mae: 0.0398 - val_mse: 0.0022 - val_root_mean_squared_error: 0.0466 - lr: 0.0157
Epoch 12/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0384 - mse: 0.0020 - root_mean_squared_error: 0.0447 - val_loss: 0.0021 - val_mae: 0.0391 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0454 - lr: 0.0157
Epoch 13/30
93/98 [===========================>..] - ETA: 0s - loss: 0.0020 - mae: 0.0384 - mse: 0.0020 - root_mean_squared_error: 0.0446
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00784014631062746.
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0385 - mse: 0.0020 - root_mean_squared_error: 0.0446 - val_loss: 0.0027 - val_mae: 0.0435 - val_mse: 0.0027 - val_root_mean_squared_error: 0.0524 - lr: 0.0157
Epoch 14/30
39/98 [==========>...................] - ETA: 0s - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - root_mean_squared_error: 0.0444
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - root_mean_squared_error: 0.0442 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0449 - lr: 0.0078
Epoch 15/30
93/98 [===========================>..] - ETA: 0s - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - root_mean_squared_error: 0.0442
98/98 [==============================] - 2s 18ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - root_mean_squared_error: 0.0443 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0078
Epoch 16/30
91/98 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0382 - mse: 0.0019 - root_mean_squared_error: 0.0441
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00392007315531373.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - root_mean_squared_error: 0.0440 - val_loss: 0.0022 - val_mae: 0.0399 - val_mse: 0.0022 - val_root_mean_squared_error: 0.0468 - lr: 0.0078
Epoch 17/30
98/98 [==============================] - 1s 9ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0440 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0039
Epoch 18/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0440 - val_loss: 0.0020 - val_mae: 0.0388 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0452 - lr: 0.0039
Epoch 19/30
91/98 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - root_mean_squared_error: 0.0438
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.001960036577656865.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0439 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0039
Epoch 20/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0445 - lr: 0.0020
Epoch 21/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0439 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0020
Epoch 22/30
90/98 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0009800182888284326.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0439 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0020
Epoch 23/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 9.8002e-04
Epoch 24/30
95/98 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230429_081055-o30slblz\files\model-best)... Done. 0.0s
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
98/98 [==============================] - 2s 18ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 9.8002e-04
Epoch 25/30
91/98 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019 - root_mean_squared_error: 0.0436
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0004900091444142163.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0444 - lr: 9.8002e-04
Epoch 26/30
98/98 [==============================] - 1s 9ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 4.9001e-04
Epoch 27/30
98/98 [==============================] - 2s 20ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - lr: 4.9001e-04
Epoch 28/30
89/98 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00024500457220710814.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 4.9001e-04
Epoch 29/30
98/98 [==============================] - 1s 9ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 2.4500e-04
Epoch 30/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 2.4500e-04
>Saved ../trained_models/CNN/models_segments_overlap-cnn_rmsprop_0.06272117293767086LR_[39]CHN_16CNNI_40BS_40DU_3P_val_lossM_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
Epoch 1/30
130/130 [==============================] - 2s 10ms/step - loss: 1.0821 - mae: 0.1566 - mse: 1.0821 - root_mean_squared_error: 1.0403 - val_loss: 0.0040 - val_mae: 0.0530 - val_mse: 0.0040 - val_root_mean_squared_error: 0.0629 - lr: 0.0627
Epoch 2/30
130/130 [==============================] - 1s 8ms/step - loss: 0.0043 - mae: 0.0551 - mse: 0.0043 - root_mean_squared_error: 0.0658 - val_loss: 0.0126 - val_mae: 0.0961 - val_mse: 0.0126 - val_root_mean_squared_error: 0.1124 - lr: 0.0627
Epoch 3/30
130/130 [==============================] - 1s 8ms/step - loss: 0.0044 - mae: 0.0553 - mse: 0.0044 - root_mean_squared_error: 0.0662 - val_loss: 0.0081 - val_mae: 0.0741 - val_mse: 0.0081 - val_root_mean_squared_error: 0.0903 - lr: 0.0627
Epoch 4/30
123/130 [===========================>..] - ETA: 0s - loss: 0.0045 - mae: 0.0560 - mse: 0.0045 - root_mean_squared_error: 0.0671
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.03136058524250984.
130/130 [==============================] - 1s 8ms/step - loss: 0.0045 - mae: 0.0558 - mse: 0.0045 - root_mean_squared_error: 0.0667 - val_loss: 0.0111 - val_mae: 0.0887 - val_mse: 0.0111 - val_root_mean_squared_error: 0.1053 - lr: 0.0627
Epoch 5/30
130/130 [==============================] - 1s 8ms/step - loss: 0.0037 - mae: 0.0521 - mse: 0.0037 - root_mean_squared_error: 0.0610 - val_loss: 0.0122 - val_mae: 0.0943 - val_mse: 0.0122 - val_root_mean_squared_error: 0.1106 - lr: 0.0314
Epoch 6/30
130/130 [==============================] - 1s 8ms/step - loss: 0.0037 - mae: 0.0522 - mse: 0.0037 - root_mean_squared_error: 0.0610 - val_loss: 0.0054 - val_mae: 0.0606 - val_mse: 0.0054 - val_root_mean_squared_error: 0.0738 - lr: 0.0314
Epoch 7/30
122/130 [===========================>..] - ETA: 0s - loss: 0.0037 - mae: 0.0519 - mse: 0.0037 - root_mean_squared_error: 0.0605
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.01568029262125492.
130/130 [==============================] - 1s 8ms/step - loss: 0.0037 - mae: 0.0522 - mse: 0.0037 - root_mean_squared_error: 0.0609 - val_loss: 0.0097 - val_mae: 0.0815 - val_mse: 0.0097 - val_root_mean_squared_error: 0.0984 - lr: 0.0314
Epoch 8/30
130/130 [==============================] - 1s 8ms/step - loss: 0.0035 - mae: 0.0512 - mse: 0.0035 - root_mean_squared_error: 0.0595 - val_loss: 0.0042 - val_mae: 0.0544 - val_mse: 0.0042 - val_root_mean_squared_error: 0.0650 - lr: 0.0157
Epoch 9/30
130/130 [==============================] - 1s 8ms/step - loss: 0.0035 - mae: 0.0512 - mse: 0.0035 - root_mean_squared_error: 0.0594 - val_loss: 0.0055 - val_mae: 0.0608 - val_mse: 0.0055 - val_root_mean_squared_error: 0.0739 - lr: 0.0157
Epoch 10/30
130/130 [==============================] - 1s 8ms/step - loss: 0.0035 - mae: 0.0511 - mse: 0.0035 - root_mean_squared_error: 0.0593 - val_loss: 0.0054 - val_mae: 0.0607 - val_mse: 0.0054 - val_root_mean_squared_error: 0.0737 - lr: 0.0157
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00784014631062746.
130/130 [==============================] - 1s 8ms/step - loss: 0.0035 - mae: 0.0511 - mse: 0.0035 - root_mean_squared_error: 0.0593 - val_loss: 0.0054 - val_mae: 0.0607 - val_mse: 0.0054 - val_root_mean_squared_error: 0.0737 - lr: 0.0157
Epoch 11/30
130/130 [==============================] - 1s 8ms/step - loss: 0.0035 - mae: 0.0509 - mse: 0.0035 - root_mean_squared_error: 0.0589 - val_loss: 0.0036 - val_mae: 0.0514 - val_mse: 0.0036 - val_root_mean_squared_error: 0.0599 - lr: 0.0078
Epoch 12/30
130/130 [==============================] - 1s 8ms/step - loss: 0.0034 - mae: 0.0509 - mse: 0.0034 - root_mean_squared_error: 0.0587 - val_loss: 0.0045 - val_mae: 0.0559 - val_mse: 0.0045 - val_root_mean_squared_error: 0.0668 - lr: 0.0078
Epoch 13/30
130/130 [==============================] - 1s 8ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - root_mean_squared_error: 0.0587 - val_loss: 0.0038 - val_mae: 0.0525 - val_mse: 0.0038 - val_root_mean_squared_error: 0.0615 - lr: 0.0078
Epoch 14/30
 85/130 [==================>...........] - ETA: 0s - loss: 0.0035 - mae: 0.0509 - mse: 0.0035 - root_mean_squared_error: 0.0588
130/130 [==============================] - 1s 8ms/step - loss: 0.0034 - mae: 0.0508 - mse: 0.0034 - root_mean_squared_error: 0.0587 - val_loss: 0.0039 - val_mae: 0.0531 - val_mse: 0.0039 - val_root_mean_squared_error: 0.0625 - lr: 0.0078
Epoch 15/30
130/130 [==============================] - 1s 8ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0585 - lr: 0.0039
Epoch 16/30
  1/130 [..............................] - ETA: 0s - loss: 0.0030 - mae: 0.0463 - mse: 0.0030 - root_mean_squared_error: 0.0548
125/130 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0509 - mse: 0.0034 - root_mean_squared_error: 0.05860587 - val_loss: 0.0039 - val_mae: 0.0531 - val_mse: 0.0039 - val_root_mean_squared_error: 0.0625 - lr: 0.0078
122/130 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - root_mean_squared_error: 0.05830585 - val_loss: 0.0035 - val_mae: 0.0505 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0588 - lr: 0.0039
130/130 [==============================] - 1s 8ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0020
130/130 [==============================] - 1s 8ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0020
130/130 [==============================] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.05840584 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 0.0020
130/130 [==============================] - 1s 8ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0585 - lr: 4.9001e-04
130/130 [==============================] - 1s 8ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 2.4500e-04
130/130 [==============================] - 1s 8ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - root_mean_squared_error: 0.0583 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0584 - lr: 2.4500e-04
98/98 [==============================] - 1s 8ms/step - loss: 0.0037 - mae: 0.0491 - mse: 0.0037 - root_mean_squared_error: 0.0607 - val_loss: 0.0021 - val_mae: 0.0390 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0453 - lr: 0.062700e-04
98/98 [==============================] - 1s 8ms/step - loss: 0.0029 - mae: 0.0450 - mse: 0.0029 - root_mean_squared_error: 0.0542 - val_loss: 0.0107 - val_mae: 0.0936 - val_mse: 0.0107 - val_root_mean_squared_error: 0.1035 - lr: 0.062700e-04
94/98 [===========================>..] - ETA: 0s - loss: 0.0022 - mae: 0.0397 - mse: 0.0022 - root_mean_squared_error: 0.04670542 - val_loss: 0.0107 - val_mae: 0.0936 - val_mse: 0.0107 - val_root_mean_squared_error: 0.1035 - lr: 0.062700e-04
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0384 - mse: 0.0020 - root_mean_squared_error: 0.0447 - val_loss: 0.0021 - val_mae: 0.0389 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0454 - lr: 0.015700e-04
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - root_mean_squared_error: 0.0441 - val_loss: 0.0023 - val_mae: 0.0402 - val_mse: 0.0023 - val_root_mean_squared_error: 0.0476 - lr: 0.007800e-04
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - root_mean_squared_error: 0.0442 - val_loss: 0.0024 - val_mae: 0.0410 - val_mse: 0.0024 - val_root_mean_squared_error: 0.0488 - lr: 0.007800e-04
94/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.04390442 - val_loss: 0.0024 - val_mae: 0.0410 - val_mse: 0.0024 - val_root_mean_squared_error: 0.0488 - lr: 0.007800e-04
48/98 [=============>................] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.04380438 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0446 - lr: 0.002000e-04
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 9.8002e-0404
Epoch 23/30
 1/98 [..............................] - ETA: 0s - loss: 0.0017 - mae: 0.0363 - mse: 0.0017 - root_mean_squared_error: 0.0416
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 9.8002e-0404
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230429_081055-o30slblz\files\model-best)... Done. 0.0s
29/98 [=======>......................] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - root_mean_squared_error: 0.04390438 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - lr: 2.4500e-0404
Epoch 28/30
94/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019 - root_mean_squared_error: 0.0436
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00012250228610355407.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 2.4500e-04
Epoch 29/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 1.2250e-0404
Epoch 30/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 1.2250e-04
>Saved ../trained_models/CNN/models_segments_overlap-cnn_rmsprop_0.06272117293767086LR_[39]CHN_16CNNI_40BS_40DU_3P_val_lossM_30epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
98/98 [==============================] - 1s 9ms/step - loss: 1.9606 - mae: 0.2305 - mse: 1.9606 - root_mean_squared_error: 1.4002 - val_loss: 0.0102 - val_mae: 0.0908 - val_mse: 0.0102 - val_root_mean_squared_error: 0.1010 - lr: 0.0627e-0404
Epoch 2/30
55/98 [===============>..............] - ETA: 0s - loss: 0.0061 - mae: 0.0646 - mse: 0.0061 - root_mean_squared_error: 0.0784
98/98 [==============================] - 1s 8ms/step - loss: 0.0029 - mae: 0.0439 - mse: 0.0029 - root_mean_squared_error: 0.0534 - val_loss: 0.0021 - val_mae: 0.0396 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0463 - lr: 0.0627e-0404
Epoch 5/30
 9/98 [=>............................] - ETA: 0s - loss: 0.0034 - mae: 0.0481 - mse: 0.0034 - root_mean_squared_error: 0.0579
74/98 [=====================>........] - ETA: 0s - loss: 0.0029 - mae: 0.0441 - mse: 0.0029 - root_mean_squared_error: 0.05350534 - val_loss: 0.0021 - val_mae: 0.0396 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0463 - lr: 0.0627e-0404
98/98 [==============================] - 1s 8ms/step - loss: 0.0022 - mae: 0.0395 - mse: 0.0022 - root_mean_squared_error: 0.0467 - val_loss: 0.0034 - val_mae: 0.0479 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0586 - lr: 0.0314e-0404
Epoch 10/30
29/98 [=======>......................] - ETA: 0s - loss: 0.0022 - mae: 0.0396 - mse: 0.0022 - root_mean_squared_error: 0.0471
98/98 [==============================] - 1s 8ms/step - loss: 0.0022 - mae: 0.0397 - mse: 0.0022 - root_mean_squared_error: 0.0470 - val_loss: 0.0065 - val_mae: 0.0676 - val_mse: 0.0065 - val_root_mean_squared_error: 0.0803 - lr: 0.0314e-0404
Epoch 12/30
94/98 [===========================>..] - ETA: 0s - loss: 0.0020 - mae: 0.0387 - mse: 0.0020 - root_mean_squared_error: 0.0452
95/98 [============================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0384 - mse: 0.0020 - root_mean_squared_error: 0.04470470 - val_loss: 0.0065 - val_mae: 0.0676 - val_mse: 0.0065 - val_root_mean_squared_error: 0.0803 - lr: 0.0314e-0404
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00784014631062746.
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0385 - mse: 0.0020 - root_mean_squared_error: 0.0447 - val_loss: 0.0026 - val_mae: 0.0426 - val_mse: 0.0026 - val_root_mean_squared_error: 0.0510 - lr: 0.0157
Epoch 15/30
47/98 [=============>................] - ETA: 0s - loss: 0.0020 - mae: 0.0388 - mse: 0.0020 - root_mean_squared_error: 0.0448
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - root_mean_squared_error: 0.0441 - val_loss: 0.0023 - val_mae: 0.0405 - val_mse: 0.0023 - val_root_mean_squared_error: 0.0480 - lr: 0.0078e-0404
Epoch 17/30
94/98 [===========================>..] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - root_mean_squared_error: 0.0442
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00392007315531373.
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - root_mean_squared_error: 0.0442 - val_loss: 0.0020 - val_mae: 0.0389 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0451 - lr: 0.0078
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0440 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0039e-0404
Epoch 19/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0439 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0443 - lr: 0.0039
Epoch 20/30
66/98 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.0019 - root_mean_squared_error: 0.0435
 9/98 [=>............................] - ETA: 0s - loss: 0.0019 - mae: 0.0384 - mse: 0.0019 - root_mean_squared_error: 0.04410439 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0446 - lr: 0.0039e-0404
Epoch 21/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0439 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0020
Epoch 22/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0388 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0449 - lr: 0.0020
Epoch 23/30
75/98 [=====================>........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - root_mean_squared_error: 0.04370439 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0446 - lr: 0.0039e-0404
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0009800182888284326.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0439 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0444 - lr: 0.0020
Epoch 24/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - lr: 9.8002e-04
Epoch 25/30
75/98 [=====================>........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - root_mean_squared_error: 0.04370439 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0446 - lr: 0.0039e-0404
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 9.8002e-0404
Epoch 26/30
98/98 [==============================] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004900091444142163.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 9.8002e-0404
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 4.9001e-0404
Epoch 28/30
98/98 [==============================] - 1s 9ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 4.9001e-04
Epoch 29/30
93/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - root_mean_squared_error: 0.0438
Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00024500457220710814.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 4.9001e-0404
Epoch 30/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 2.4500e-04
>Saved ../trained_models/CNN/models_segments_overlap-cnn_rmsprop_0.06272117293767086LR_[39]CHN_16CNNI_40BS_40DU_3P_val_lossM_30epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
Epoch 1/30
98/98 [==============================] - 1s 9ms/step - loss: 0.0385 - mae: 0.0978 - mse: 0.0385 - root_mean_squared_error: 0.1963 - val_loss: 0.0065 - val_mae: 0.0682 - val_mse: 0.0065 - val_root_mean_squared_error: 0.0808 - lr: 0.0627
Epoch 2/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0034 - mae: 0.0477 - mse: 0.0034 - root_mean_squared_error: 0.0582 - val_loss: 0.0094 - val_mae: 0.0860 - val_mse: 0.0094 - val_root_mean_squared_error: 0.0972 - lr: 0.0627
Epoch 3/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0029 - mae: 0.0440 - mse: 0.0029 - root_mean_squared_error: 0.0534 - val_loss: 0.0081 - val_mae: 0.0781 - val_mse: 0.0081 - val_root_mean_squared_error: 0.0898 - lr: 0.0627
Epoch 4/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0029 - mae: 0.0442 - mse: 0.0029 - root_mean_squared_error: 0.0536 - val_loss: 0.0036 - val_mae: 0.0492 - val_mse: 0.0036 - val_root_mean_squared_error: 0.0602 - lr: 0.0627
Epoch 5/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0029 - mae: 0.0439 - mse: 0.0029 - root_mean_squared_error: 0.0537 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0444 - lr: 0.0627
Epoch 6/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0029 - mae: 0.0441 - mse: 0.0029 - root_mean_squared_error: 0.0537 - val_loss: 0.0031 - val_mae: 0.0458 - val_mse: 0.0031 - val_root_mean_squared_error: 0.0556 - lr: 0.0627
Epoch 7/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0029 - mae: 0.0444 - mse: 0.0029 - root_mean_squared_error: 0.0537 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0444 - lr: 0.0627
Epoch 8/30
94/98 [===========================>..] - ETA: 0s - loss: 0.0029 - mae: 0.0448 - mse: 0.0029 - root_mean_squared_error: 0.0541
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.03136058524250984.
98/98 [==============================] - 1s 8ms/step - loss: 0.0029 - mae: 0.0448 - mse: 0.0029 - root_mean_squared_error: 0.0541 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0443 - lr: 0.0627
Epoch 9/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0022 - mae: 0.0395 - mse: 0.0022 - root_mean_squared_error: 0.0466 - val_loss: 0.0035 - val_mae: 0.0484 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0592 - lr: 0.0314
Epoch 10/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0022 - mae: 0.0395 - mse: 0.0022 - root_mean_squared_error: 0.0467 - val_loss: 0.0066 - val_mae: 0.0688 - val_mse: 0.0066 - val_root_mean_squared_error: 0.0814 - lr: 0.0314
Epoch 11/30
94/98 [===========================>..] - ETA: 0s - loss: 0.0022 - mae: 0.0395 - mse: 0.0022 - root_mean_squared_error: 0.0467
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.01568029262125492.
98/98 [==============================] - 1s 8ms/step - loss: 0.0022 - mae: 0.0395 - mse: 0.0022 - root_mean_squared_error: 0.0466 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0314
Epoch 12/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0387 - mse: 0.0020 - root_mean_squared_error: 0.0448 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0157
Epoch 13/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - root_mean_squared_error: 0.0446 - val_loss: 0.0021 - val_mae: 0.0390 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0455 - lr: 0.0157
Epoch 14/30
92/98 [===========================>..] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0020 - root_mean_squared_error: 0.0446
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00784014631062746.
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0383 - mse: 0.0020 - root_mean_squared_error: 0.0447 - val_loss: 0.0021 - val_mae: 0.0394 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0463 - lr: 0.0157
Epoch 15/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - root_mean_squared_error: 0.0442 - val_loss: 0.0025 - val_mae: 0.0419 - val_mse: 0.0025 - val_root_mean_squared_error: 0.0502 - lr: 0.0078
Epoch 16/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - root_mean_squared_error: 0.0442 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0078
Epoch 17/30
92/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - root_mean_squared_error: 0.0441
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00392007315531373.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - root_mean_squared_error: 0.0441 - val_loss: 0.0023 - val_mae: 0.0402 - val_mse: 0.0023 - val_root_mean_squared_error: 0.0476 - lr: 0.0078
Epoch 18/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - root_mean_squared_error: 0.0440 - val_loss: 0.0020 - val_mae: 0.0387 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0450 - lr: 0.0039
Epoch 19/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0440 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0443 - lr: 0.0039
Epoch 20/30
92/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - root_mean_squared_error: 0.0440
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.001960036577656865.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0440 - val_loss: 0.0020 - val_mae: 0.0387 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0451 - lr: 0.0039
Epoch 21/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0443 - lr: 0.0020
Epoch 22/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0439 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0020
Epoch 23/30
92/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0009800182888284326.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0020
Epoch 24/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 9.8002e-04
Epoch 25/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 9.8002e-04
Epoch 26/30
93/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - root_mean_squared_error: 0.0439
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0004900091444142163.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - lr: 9.8002e-04
Epoch 27/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 4.9001e-04
Epoch 28/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 4.9001e-04
Epoch 29/30
94/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0437
Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00024500457220710814.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 4.9001e-04
Epoch 30/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 2.4500e-04
>Saved ../trained_models/CNN/models_segments_overlap-cnn_rmsprop_0.06272117293767086LR_[39]CHN_16CNNI_40BS_40DU_3P_val_lossM_30epochs/model_5.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
Epoch 1/30
98/98 [==============================] - 1s 10ms/step - loss: 0.3142 - mae: 0.1695 - mse: 0.3142 - root_mean_squared_error: 0.5605 - val_loss: 0.0029 - val_mae: 0.0442 - val_mse: 0.0029 - val_root_mean_squared_error: 0.0535 - lr: 0.0627
Epoch 2/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0056 - mae: 0.0604 - mse: 0.0056 - root_mean_squared_error: 0.0745 - val_loss: 0.0037 - val_mae: 0.0484 - val_mse: 0.0037 - val_root_mean_squared_error: 0.0605 - lr: 0.0627
Epoch 3/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0029 - mae: 0.0446 - mse: 0.0029 - root_mean_squared_error: 0.0540 - val_loss: 0.0076 - val_mae: 0.0749 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0627
Epoch 4/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0030 - mae: 0.0452 - mse: 0.0030 - root_mean_squared_error: 0.0548 - val_loss: 0.0021 - val_mae: 0.0392 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0456 - lr: 0.0627
Epoch 5/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0028 - mae: 0.0435 - mse: 0.0028 - root_mean_squared_error: 0.0525 - val_loss: 0.0024 - val_mae: 0.0413 - val_mse: 0.0024 - val_root_mean_squared_error: 0.0491 - lr: 0.0627
Epoch 6/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0029 - mae: 0.0443 - mse: 0.0029 - root_mean_squared_error: 0.0540 - val_loss: 0.0040 - val_mae: 0.0520 - val_mse: 0.0040 - val_root_mean_squared_error: 0.0636 - lr: 0.0627
Epoch 7/30
93/98 [===========================>..] - ETA: 0s - loss: 0.0028 - mae: 0.0437 - mse: 0.0028 - root_mean_squared_error: 0.0531
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.03136058524250984.
98/98 [==============================] - 1s 8ms/step - loss: 0.0028 - mae: 0.0436 - mse: 0.0028 - root_mean_squared_error: 0.0531 - val_loss: 0.0043 - val_mae: 0.0535 - val_mse: 0.0043 - val_root_mean_squared_error: 0.0655 - lr: 0.0627
Epoch 8/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0022 - mae: 0.0394 - mse: 0.0022 - root_mean_squared_error: 0.0464 - val_loss: 0.0062 - val_mae: 0.0658 - val_mse: 0.0062 - val_root_mean_squared_error: 0.0785 - lr: 0.0314
Epoch 9/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0022 - mae: 0.0396 - mse: 0.0022 - root_mean_squared_error: 0.0468 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0314
Epoch 10/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0022 - mae: 0.0397 - mse: 0.0022 - root_mean_squared_error: 0.0469 - val_loss: 0.0055 - val_mae: 0.0610 - val_mse: 0.0055 - val_root_mean_squared_error: 0.0739 - lr: 0.0314
Epoch 11/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0022 - mae: 0.0400 - mse: 0.0022 - root_mean_squared_error: 0.0468 - val_loss: 0.0034 - val_mae: 0.0474 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0579 - lr: 0.0314
Epoch 12/30
94/98 [===========================>..] - ETA: 0s - loss: 0.0022 - mae: 0.0401 - mse: 0.0022 - root_mean_squared_error: 0.0470
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.01568029262125492.
98/98 [==============================] - 1s 8ms/step - loss: 0.0022 - mae: 0.0399 - mse: 0.0022 - root_mean_squared_error: 0.0468 - val_loss: 0.0041 - val_mae: 0.0526 - val_mse: 0.0041 - val_root_mean_squared_error: 0.0643 - lr: 0.0314
Epoch 13/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0386 - mse: 0.0020 - root_mean_squared_error: 0.0450 - val_loss: 0.0041 - val_mae: 0.0521 - val_mse: 0.0041 - val_root_mean_squared_error: 0.0637 - lr: 0.0157
Epoch 14/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0386 - mse: 0.0020 - root_mean_squared_error: 0.0449 - val_loss: 0.0024 - val_mae: 0.0411 - val_mse: 0.0024 - val_root_mean_squared_error: 0.0488 - lr: 0.0157
Epoch 15/30
95/98 [============================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0385 - mse: 0.0020 - root_mean_squared_error: 0.0447
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00784014631062746.
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0385 - mse: 0.0020 - root_mean_squared_error: 0.0447 - val_loss: 0.0031 - val_mae: 0.0457 - val_mse: 0.0031 - val_root_mean_squared_error: 0.0556 - lr: 0.0157
Epoch 16/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - root_mean_squared_error: 0.0442 - val_loss: 0.0023 - val_mae: 0.0406 - val_mse: 0.0023 - val_root_mean_squared_error: 0.0482 - lr: 0.0078
Epoch 17/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - root_mean_squared_error: 0.0442 - val_loss: 0.0020 - val_mae: 0.0387 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0450 - lr: 0.0078
Epoch 18/30
93/98 [===========================>..] - ETA: 0s - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - root_mean_squared_error: 0.0442
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00392007315531373.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - root_mean_squared_error: 0.0442 - val_loss: 0.0022 - val_mae: 0.0397 - val_mse: 0.0022 - val_root_mean_squared_error: 0.0467 - lr: 0.0078
Epoch 19/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0440 - val_loss: 0.0020 - val_mae: 0.0387 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0448 - lr: 0.0039
Epoch 20/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0439 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0445 - lr: 0.0039
Epoch 21/30
94/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0439
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.001960036577656865.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0439 - val_loss: 0.0022 - val_mae: 0.0399 - val_mse: 0.0022 - val_root_mean_squared_error: 0.0472 - lr: 0.0039
Epoch 22/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - root_mean_squared_error: 0.0440 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0445 - lr: 0.0020
Epoch 23/30
74/98 [=====================>........] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019 - root_mean_squared_error: 0.0436
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.

98/98 [==============================] - 2s 19ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - lr: 0.0020
Epoch 24/30
93/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0009800182888284326.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0020
Epoch 25/30
98/98 [==============================] - 1s 9ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0443 - lr: 9.8002e-04
Epoch 26/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 9.8002e-04
Epoch 27/30
92/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438
Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0004900091444142163.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 9.8002e-04
Epoch 28/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 4.9001e-04
Epoch 29/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - lr: 4.9001e-04
Epoch 30/30
92/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438
Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00024500457220710814.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 4.9001e-04
>Saved ../trained_models/CNN/models_segments_overlap-cnn_rmsprop_0.06272117293767086LR_[39]CHN_16CNNI_40BS_40DU_3P_val_lossM_30epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
Epoch 1/30
98/98 [==============================] - 1s 9ms/step - loss: 0.7543 - mae: 0.2116 - mse: 0.7543 - root_mean_squared_error: 0.8685 - val_loss: 0.0187 - val_mae: 0.1293 - val_mse: 0.0187 - val_root_mean_squared_error: 0.1368 - lr: 0.0627
Epoch 2/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0070 - mae: 0.0699 - mse: 0.0070 - root_mean_squared_error: 0.0837 - val_loss: 0.0132 - val_mae: 0.1058 - val_mse: 0.0132 - val_root_mean_squared_error: 0.1147 - lr: 0.0627
Epoch 3/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0045 - mae: 0.0545 - mse: 0.0045 - root_mean_squared_error: 0.0671 - val_loss: 0.0110 - val_mae: 0.0953 - val_mse: 0.0110 - val_root_mean_squared_error: 0.1051 - lr: 0.0627
Epoch 4/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0031 - mae: 0.0454 - mse: 0.0031 - root_mean_squared_error: 0.0555 - val_loss: 0.0025 - val_mae: 0.0417 - val_mse: 0.0025 - val_root_mean_squared_error: 0.0499 - lr: 0.0627
Epoch 5/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0029 - mae: 0.0442 - mse: 0.0029 - root_mean_squared_error: 0.0537 - val_loss: 0.0065 - val_mae: 0.0677 - val_mse: 0.0065 - val_root_mean_squared_error: 0.0804 - lr: 0.0627
Epoch 6/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0029 - mae: 0.0446 - mse: 0.0029 - root_mean_squared_error: 0.0543 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0627
Epoch 7/30
98/98 [==============================] - 1s 9ms/step - loss: 0.0028 - mae: 0.0438 - mse: 0.0028 - root_mean_squared_error: 0.0529 - val_loss: 0.0052 - val_mae: 0.0596 - val_mse: 0.0052 - val_root_mean_squared_error: 0.0724 - lr: 0.0627
Epoch 8/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0029 - mae: 0.0444 - mse: 0.0029 - root_mean_squared_error: 0.0541 - val_loss: 0.0080 - val_mae: 0.0781 - val_mse: 0.0080 - val_root_mean_squared_error: 0.0897 - lr: 0.0627
Epoch 9/30
90/98 [==========================>...] - ETA: 0s - loss: 0.0030 - mae: 0.0451 - mse: 0.0030 - root_mean_squared_error: 0.0548
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.03136058524250984.
98/98 [==============================] - 1s 8ms/step - loss: 0.0029 - mae: 0.0446 - mse: 0.0029 - root_mean_squared_error: 0.0542 - val_loss: 0.0103 - val_mae: 0.0915 - val_mse: 0.0103 - val_root_mean_squared_error: 0.1016 - lr: 0.0627
Epoch 10/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0022 - mae: 0.0397 - mse: 0.0022 - root_mean_squared_error: 0.0470 - val_loss: 0.0033 - val_mae: 0.0470 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0573 - lr: 0.0314
Epoch 11/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0022 - mae: 0.0401 - mse: 0.0022 - root_mean_squared_error: 0.0474 - val_loss: 0.0036 - val_mae: 0.0491 - val_mse: 0.0036 - val_root_mean_squared_error: 0.0600 - lr: 0.0314
Epoch 12/30
95/98 [============================>.] - ETA: 0s - loss: 0.0022 - mae: 0.0398 - mse: 0.0022 - root_mean_squared_error: 0.0468
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.01568029262125492.
98/98 [==============================] - 1s 8ms/step - loss: 0.0022 - mae: 0.0397 - mse: 0.0022 - root_mean_squared_error: 0.0467 - val_loss: 0.0024 - val_mae: 0.0413 - val_mse: 0.0024 - val_root_mean_squared_error: 0.0490 - lr: 0.0314
Epoch 13/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0384 - mse: 0.0020 - root_mean_squared_error: 0.0449 - val_loss: 0.0026 - val_mae: 0.0424 - val_mse: 0.0026 - val_root_mean_squared_error: 0.0507 - lr: 0.0157
Epoch 14/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0386 - mse: 0.0020 - root_mean_squared_error: 0.0449 - val_loss: 0.0022 - val_mae: 0.0397 - val_mse: 0.0022 - val_root_mean_squared_error: 0.0467 - lr: 0.0157
Epoch 15/30
93/98 [===========================>..] - ETA: 0s - loss: 0.0020 - mae: 0.0384 - mse: 0.0020 - root_mean_squared_error: 0.0446
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00784014631062746.
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0384 - mse: 0.0020 - root_mean_squared_error: 0.0446 - val_loss: 0.0025 - val_mae: 0.0419 - val_mse: 0.0025 - val_root_mean_squared_error: 0.0500 - lr: 0.0157
Epoch 16/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0383 - mse: 0.0020 - root_mean_squared_error: 0.0444 - val_loss: 0.0023 - val_mae: 0.0405 - val_mse: 0.0023 - val_root_mean_squared_error: 0.0481 - lr: 0.0078
Epoch 17/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - root_mean_squared_error: 0.0442 - val_loss: 0.0020 - val_mae: 0.0389 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0452 - lr: 0.0078
Epoch 18/30
93/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0440
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00392007315531373.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0440 - val_loss: 0.0023 - val_mae: 0.0405 - val_mse: 0.0023 - val_root_mean_squared_error: 0.0481 - lr: 0.0078
Epoch 19/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0439 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0445 - lr: 0.0039
Epoch 20/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0439 - val_loss: 0.0020 - val_mae: 0.0387 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0447 - lr: 0.0039
Epoch 21/30
95/98 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0439
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.001960036577656865.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0440 - val_loss: 0.0020 - val_mae: 0.0387 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0447 - lr: 0.0039
Epoch 22/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0439 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0443 - lr: 0.0020
Epoch 23/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0439 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0020
Epoch 24/30
94/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0009800182888284326.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0020
Epoch 25/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0443 - lr: 9.8002e-04
Epoch 26/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 9.8002e-04
Epoch 27/30
93/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438
Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0004900091444142163.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - lr: 9.8002e-04
Epoch 28/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 4.9001e-04
Epoch 29/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 4.9001e-04
Epoch 30/30
92/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438
Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00024500457220710814.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - lr: 4.9001e-04
>Saved ../trained_models/CNN/models_segments_overlap-cnn_rmsprop_0.06272117293767086LR_[39]CHN_16CNNI_40BS_40DU_3P_val_lossM_30epochs/model_7.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0049s vs `on_train_batch_end` time: 0.0053s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0049s vs `on_train_batch_end` time: 0.0053s). Check your callbacks.
Epoch 1/30
98/98 [==============================] - 1s 9ms/step - loss: 8.2367 - mae: 0.3865 - mse: 8.2367 - root_mean_squared_error: 2.8700 - val_loss: 0.0437 - val_mae: 0.2043 - val_mse: 0.0437 - val_root_mean_squared_error: 0.2090 - lr: 0.0627
Epoch 2/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0117 - mae: 0.0845 - mse: 0.0117 - root_mean_squared_error: 0.1079 - val_loss: 0.0023 - val_mae: 0.0402 - val_mse: 0.0023 - val_root_mean_squared_error: 0.0476 - lr: 0.0627
Epoch 3/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0078 - mae: 0.0749 - mse: 0.0078 - root_mean_squared_error: 0.0883 - val_loss: 0.0166 - val_mae: 0.1212 - val_mse: 0.0166 - val_root_mean_squared_error: 0.1290 - lr: 0.0627
Epoch 4/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0067 - mae: 0.0676 - mse: 0.0067 - root_mean_squared_error: 0.0820 - val_loss: 0.0021 - val_mae: 0.0392 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0459 - lr: 0.0627
Epoch 5/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0054 - mae: 0.0610 - mse: 0.0054 - root_mean_squared_error: 0.0738 - val_loss: 0.0021 - val_mae: 0.0395 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0461 - lr: 0.0627
Epoch 6/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0039 - mae: 0.0509 - mse: 0.0039 - root_mean_squared_error: 0.0623 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0447 - lr: 0.0627
Epoch 7/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0029 - mae: 0.0442 - mse: 0.0029 - root_mean_squared_error: 0.0536 - val_loss: 0.0032 - val_mae: 0.0464 - val_mse: 0.0032 - val_root_mean_squared_error: 0.0565 - lr: 0.0627
Epoch 8/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0029 - mae: 0.0439 - mse: 0.0029 - root_mean_squared_error: 0.0535 - val_loss: 0.0047 - val_mae: 0.0562 - val_mse: 0.0047 - val_root_mean_squared_error: 0.0686 - lr: 0.0627
Epoch 9/30
93/98 [===========================>..] - ETA: 0s - loss: 0.0028 - mae: 0.0437 - mse: 0.0028 - root_mean_squared_error: 0.0533
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.03136058524250984.
98/98 [==============================] - 1s 8ms/step - loss: 0.0028 - mae: 0.0436 - mse: 0.0028 - root_mean_squared_error: 0.0532 - val_loss: 0.0059 - val_mae: 0.0640 - val_mse: 0.0059 - val_root_mean_squared_error: 0.0768 - lr: 0.0627
Epoch 10/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0022 - mae: 0.0397 - mse: 0.0022 - root_mean_squared_error: 0.0466 - val_loss: 0.0022 - val_mae: 0.0401 - val_mse: 0.0022 - val_root_mean_squared_error: 0.0471 - lr: 0.0314
Epoch 11/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0022 - mae: 0.0393 - mse: 0.0022 - root_mean_squared_error: 0.0464 - val_loss: 0.0036 - val_mae: 0.0490 - val_mse: 0.0036 - val_root_mean_squared_error: 0.0600 - lr: 0.0314
Epoch 12/30
95/98 [============================>.] - ETA: 0s - loss: 0.0022 - mae: 0.0400 - mse: 0.0022 - root_mean_squared_error: 0.0472
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.01568029262125492.
98/98 [==============================] - 1s 8ms/step - loss: 0.0022 - mae: 0.0400 - mse: 0.0022 - root_mean_squared_error: 0.0472 - val_loss: 0.0055 - val_mae: 0.0616 - val_mse: 0.0055 - val_root_mean_squared_error: 0.0745 - lr: 0.0314
Epoch 13/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0388 - mse: 0.0020 - root_mean_squared_error: 0.0452 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0444 - lr: 0.0157
Epoch 14/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0386 - mse: 0.0020 - root_mean_squared_error: 0.0448 - val_loss: 0.0035 - val_mae: 0.0485 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0593 - lr: 0.0157
Epoch 15/30
90/98 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0385 - mse: 0.0020 - root_mean_squared_error: 0.0447
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00784014631062746.
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0385 - mse: 0.0020 - root_mean_squared_error: 0.0448 - val_loss: 0.0036 - val_mae: 0.0487 - val_mse: 0.0036 - val_root_mean_squared_error: 0.0596 - lr: 0.0157
Epoch 16/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - root_mean_squared_error: 0.0442 - val_loss: 0.0020 - val_mae: 0.0389 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0451 - lr: 0.0078
Epoch 17/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - root_mean_squared_error: 0.0442 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0078
Epoch 18/30
92/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0382 - mse: 0.0019 - root_mean_squared_error: 0.0441
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00392007315531373.
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - root_mean_squared_error: 0.0442 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0078
Epoch 19/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0439 - val_loss: 0.0021 - val_mae: 0.0390 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0455 - lr: 0.0039
Epoch 20/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0440 - val_loss: 0.0022 - val_mae: 0.0396 - val_mse: 0.0022 - val_root_mean_squared_error: 0.0467 - lr: 0.0039
Epoch 21/30
92/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019 - root_mean_squared_error: 0.0437
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.001960036577656865.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0439 - val_loss: 0.0022 - val_mae: 0.0398 - val_mse: 0.0022 - val_root_mean_squared_error: 0.0466 - lr: 0.0039
Epoch 22/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0439 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0444 - lr: 0.0020
Epoch 23/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0020
Epoch 24/30
91/98 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0439
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0009800182888284326.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0439 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0020
Epoch 25/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - lr: 9.8002e-04
Epoch 26/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0443 - lr: 9.8002e-04
Epoch 27/30
93/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0437
Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0004900091444142163.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 9.8002e-04
Epoch 28/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 4.9001e-04
Epoch 29/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0443 - lr: 4.9001e-04
Epoch 30/30
93/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019 - root_mean_squared_error: 0.0436
Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00024500457220710814.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 4.9001e-04
>Saved ../trained_models/CNN/models_segments_overlap-cnn_rmsprop_0.06272117293767086LR_[39]CHN_16CNNI_40BS_40DU_3P_val_lossM_30epochs/model_8.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
Epoch 1/30
98/98 [==============================] - 1s 9ms/step - loss: 0.8070 - mae: 0.2331 - mse: 0.8070 - root_mean_squared_error: 0.8983 - val_loss: 0.0074 - val_mae: 0.0740 - val_mse: 0.0074 - val_root_mean_squared_error: 0.0859 - lr: 0.0627
Epoch 2/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0101 - mae: 0.0844 - mse: 0.0101 - root_mean_squared_error: 0.1005 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0445 - lr: 0.0627
Epoch 3/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0067 - mae: 0.0659 - mse: 0.0067 - root_mean_squared_error: 0.0820 - val_loss: 0.0023 - val_mae: 0.0406 - val_mse: 0.0023 - val_root_mean_squared_error: 0.0479 - lr: 0.0627
Epoch 4/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0034 - mae: 0.0475 - mse: 0.0034 - root_mean_squared_error: 0.0580 - val_loss: 0.0073 - val_mae: 0.0733 - val_mse: 0.0073 - val_root_mean_squared_error: 0.0857 - lr: 0.0627
Epoch 5/30
93/98 [===========================>..] - ETA: 0s - loss: 0.0030 - mae: 0.0455 - mse: 0.0030 - root_mean_squared_error: 0.0550
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.03136058524250984.
98/98 [==============================] - 1s 8ms/step - loss: 0.0030 - mae: 0.0453 - mse: 0.0030 - root_mean_squared_error: 0.0547 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0447 - lr: 0.0627
Epoch 6/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0021 - mae: 0.0395 - mse: 0.0021 - root_mean_squared_error: 0.0464 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - lr: 0.0314
Epoch 7/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0022 - mae: 0.0400 - mse: 0.0022 - root_mean_squared_error: 0.0471 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0314
Epoch 8/30
95/98 [============================>.] - ETA: 0s - loss: 0.0021 - mae: 0.0394 - mse: 0.0021 - root_mean_squared_error: 0.0463
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.01568029262125492.
98/98 [==============================] - 1s 8ms/step - loss: 0.0021 - mae: 0.0394 - mse: 0.0021 - root_mean_squared_error: 0.0463 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - lr: 0.0314
Epoch 9/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0385 - mse: 0.0020 - root_mean_squared_error: 0.0447 - val_loss: 0.0028 - val_mae: 0.0438 - val_mse: 0.0028 - val_root_mean_squared_error: 0.0530 - lr: 0.0157
Epoch 10/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0385 - mse: 0.0020 - root_mean_squared_error: 0.0448 - val_loss: 0.0032 - val_mae: 0.0464 - val_mse: 0.0032 - val_root_mean_squared_error: 0.0565 - lr: 0.0157
Epoch 11/30
93/98 [===========================>..] - ETA: 0s - loss: 0.0020 - mae: 0.0386 - mse: 0.0020 - root_mean_squared_error: 0.0450
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00784014631062746.
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0386 - mse: 0.0020 - root_mean_squared_error: 0.0449 - val_loss: 0.0020 - val_mae: 0.0387 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0449 - lr: 0.0157
Epoch 12/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - root_mean_squared_error: 0.0441 - val_loss: 0.0023 - val_mae: 0.0408 - val_mse: 0.0023 - val_root_mean_squared_error: 0.0483 - lr: 0.0078
Epoch 13/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - root_mean_squared_error: 0.0442 - val_loss: 0.0022 - val_mae: 0.0400 - val_mse: 0.0022 - val_root_mean_squared_error: 0.0469 - lr: 0.0078
Epoch 14/30
96/98 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0441
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00392007315531373.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - root_mean_squared_error: 0.0442 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0445 - lr: 0.0078
Epoch 15/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0439 - val_loss: 0.0021 - val_mae: 0.0392 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0459 - lr: 0.0039
Epoch 16/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0440 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0039
Epoch 17/30
95/98 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - root_mean_squared_error: 0.0441
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.001960036577656865.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0440 - val_loss: 0.0021 - val_mae: 0.0390 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0455 - lr: 0.0039
Epoch 18/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0439 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0020
Epoch 19/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0444 - lr: 0.0020
Epoch 20/30
94/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0438
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0009800182888284326.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0020
Epoch 21/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 9.8002e-04
Epoch 22/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0445 - lr: 9.8002e-04
Epoch 23/30
93/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0439
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0004900091444142163.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 9.8002e-04
Epoch 24/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 4.9001e-04
Epoch 25/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 4.9001e-04
Epoch 26/30
95/98 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - root_mean_squared_error: 0.0438
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00024500457220710814.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - val_root_mean_squared_error: 0.0442 - lr: 4.9001e-04
Epoch 27/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 2.4500e-04
Epoch 28/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 2.4500e-04
Epoch 29/30
95/98 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - root_mean_squared_error: 0.0438
Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00012250228610355407.
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - root_mean_squared_error: 0.0437 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0443 - lr: 2.4500e-04
Epoch 30/30
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - root_mean_squared_error: 0.0438 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 1.2250e-04
>Saved ../trained_models/CNN/models_segments_overlap-cnn_rmsprop_0.06272117293767086LR_[39]CHN_16CNNI_40BS_40DU_3P_val_lossM_30epochs/model_9.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])