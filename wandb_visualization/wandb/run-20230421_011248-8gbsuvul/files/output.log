Epoch 1/150
240/243 [============================>.] - ETA: 0s - loss: 0.0204 - mae: 0.0440 - mse: 0.0039
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0013s). Check your callbacks.
243/243 [==============================] - 1s 4ms/step - loss: 0.0202 - mae: 0.0439 - mse: 0.0038 - val_loss: 0.0023 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 0.0488
Epoch 2/150
243/243 [==============================] - 0s 930us/step - loss: 0.0027 - mae: 0.0383 - mse: 0.0021 - val_loss: 0.0028 - val_mae: 0.0380 - val_mse: 0.0021 - lr: 0.0488
Epoch 3/150
243/243 [==============================] - ETA: 0s - loss: 0.0021 - mae: 0.0342 - mse: 0.0017
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011248-8gbsuvul\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0342 - mse: 0.0017 - val_loss: 0.0017 - val_mae: 0.0296 - val_mse: 0.0013 - lr: 0.0488
Epoch 4/150
243/243 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0287 - mse: 0.0013 - val_loss: 0.0016 - val_mae: 0.0297 - val_mse: 0.0013 - lr: 0.0488
Epoch 5/150
242/243 [============================>.] - ETA: 0s - loss: 0.0015 - mae: 0.0277 - mse: 0.0012
243/243 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0277 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0266 - val_mse: 0.0011 - lr: 0.0488
Epoch 6/150
243/243 [==============================] - 0s 945us/step - loss: 0.0014 - mae: 0.0273 - mse: 0.0012 - val_loss: 0.0014 - val_mae: 0.0265 - val_mse: 0.0011 - lr: 0.0488
Epoch 7/150
162/243 [===================>..........] - ETA: 0s - loss: 0.0012 - mae: 0.0248 - mse: 0.0010
243/243 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0248 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0238 - val_mse: 9.3078e-04 - lr: 0.0488
Epoch 8/150
243/243 [==============================] - 0s 927us/step - loss: 0.0013 - mae: 0.0254 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0237 - val_mse: 9.1161e-04 - lr: 0.0488
Epoch 9/150
243/243 [==============================] - 0s 893us/step - loss: 0.0012 - mae: 0.0243 - mse: 9.6233e-04 - val_loss: 0.0011 - val_mae: 0.0241 - val_mse: 9.2860e-04 - lr: 0.0488
Epoch 10/150
238/243 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0248 - mse: 9.9459e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0247 - mse: 9.9213e-04 - val_loss: 0.0011 - val_mae: 0.0229 - val_mse: 8.4193e-04 - lr: 0.0488
Epoch 11/150
243/243 [==============================] - 0s 995us/step - loss: 0.0011 - mae: 0.0242 - mse: 9.3766e-04 - val_loss: 0.0011 - val_mae: 0.0239 - val_mse: 9.2595e-04 - lr: 0.0488
Epoch 12/150
166/243 [===================>..........] - ETA: 0s - loss: 0.0011 - mae: 0.0239 - mse: 9.2461e-04
243/243 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0238 - mse: 9.2007e-04 - val_loss: 9.5569e-04 - val_mae: 0.0226 - val_mse: 8.3826e-04 - lr: 0.0488
Epoch 13/150
243/243 [==============================] - 0s 923us/step - loss: 0.0011 - mae: 0.0236 - mse: 9.0448e-04 - val_loss: 9.6352e-04 - val_mae: 0.0230 - val_mse: 8.4659e-04 - lr: 0.0488
Epoch 14/150
243/243 [==============================] - 0s 915us/step - loss: 0.0010 - mae: 0.0232 - mse: 8.7670e-04 - val_loss: 0.0013 - val_mae: 0.0269 - val_mse: 0.0011 - lr: 0.0488
Epoch 15/150
163/243 [===================>..........] - ETA: 0s - loss: 0.0010 - mae: 0.0231 - mse: 8.6407e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0228 - mse: 8.4844e-04 - val_loss: 9.4226e-04 - val_mae: 0.0217 - val_mse: 7.6031e-04 - lr: 0.0488
Epoch 16/150
243/243 [==============================] - 0s 921us/step - loss: 0.0010 - mae: 0.0230 - mse: 8.6327e-04 - val_loss: 0.0013 - val_mae: 0.0268 - val_mse: 0.0011 - lr: 0.0488
Epoch 17/150
243/243 [==============================] - 0s 919us/step - loss: 0.0010 - mae: 0.0228 - mse: 8.5597e-04 - val_loss: 0.0015 - val_mae: 0.0287 - val_mse: 0.0013 - lr: 0.0488
Epoch 18/150
161/243 [==================>...........] - ETA: 0s - loss: 9.7196e-04 - mae: 0.0223 - mse: 8.0613e-04
243/243 [==============================] - 1s 4ms/step - loss: 9.9195e-04 - mae: 0.0225 - mse: 8.2785e-04 - val_loss: 8.6009e-04 - val_mae: 0.0222 - val_mse: 7.8707e-04 - lr: 0.0488
Epoch 19/150
243/243 [==============================] - 0s 920us/step - loss: 0.0010 - mae: 0.0230 - mse: 8.7259e-04 - val_loss: 0.0011 - val_mae: 0.0228 - val_mse: 8.0432e-04 - lr: 0.0488
Epoch 20/150
243/243 [==============================] - 0s 938us/step - loss: 9.6553e-04 - mae: 0.0220 - mse: 7.8474e-04 - val_loss: 0.0010 - val_mae: 0.0225 - val_mse: 7.8967e-04 - lr: 0.0488
Epoch 21/150
243/243 [==============================] - 0s 909us/step - loss: 9.7362e-04 - mae: 0.0221 - mse: 8.1084e-04 - val_loss: 0.0010 - val_mae: 0.0245 - val_mse: 9.5701e-04 - lr: 0.0488
Epoch 22/150
219/243 [==========================>...] - ETA: 0s - loss: 9.6165e-04 - mae: 0.0221 - mse: 8.0414e-04
243/243 [==============================] - 1s 4ms/step - loss: 9.6217e-04 - mae: 0.0222 - mse: 8.0766e-04 - val_loss: 8.2384e-04 - val_mae: 0.0209 - val_mse: 6.9678e-04 - lr: 0.0488
Epoch 23/150
243/243 [==============================] - 0s 975us/step - loss: 9.3042e-04 - mae: 0.0220 - mse: 7.8897e-04 - val_loss: 9.4933e-04 - val_mae: 0.0224 - val_mse: 8.1598e-04 - lr: 0.0488
Epoch 24/150
161/243 [==================>...........] - ETA: 0s - loss: 0.0011 - mae: 0.0239 - mse: 9.4209e-04
243/243 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0232 - mse: 8.8204e-04 - val_loss: 8.0045e-04 - val_mae: 0.0207 - val_mse: 7.0036e-04 - lr: 0.0488
Epoch 25/150
241/243 [============================>.] - ETA: 0s - loss: 9.2004e-04 - mae: 0.0220 - mse: 7.8972e-04
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.02441217750310898.
243/243 [==============================] - 0s 934us/step - loss: 9.1863e-04 - mae: 0.0220 - mse: 7.8825e-04 - val_loss: 0.0010 - val_mae: 0.0246 - val_mse: 9.2830e-04 - lr: 0.0488
Epoch 26/150
163/243 [===================>..........] - ETA: 0s - loss: 7.9560e-04 - mae: 0.0207 - mse: 6.9860e-04
243/243 [==============================] - 1s 4ms/step - loss: 8.2130e-04 - mae: 0.0210 - mse: 7.2458e-04 - val_loss: 7.7564e-04 - val_mae: 0.0205 - val_mse: 6.9378e-04 - lr: 0.0244
Epoch 27/150
243/243 [==============================] - 0s 932us/step - loss: 8.4841e-04 - mae: 0.0213 - mse: 7.4763e-04 - val_loss: 8.6202e-04 - val_mae: 0.0217 - val_mse: 7.8363e-04 - lr: 0.0244
Epoch 28/150
243/243 [==============================] - ETA: 0s - loss: 8.2612e-04 - mae: 0.0212 - mse: 7.3498e-04
243/243 [==============================] - 1s 4ms/step - loss: 8.2612e-04 - mae: 0.0212 - mse: 7.3498e-04 - val_loss: 7.6404e-04 - val_mae: 0.0208 - val_mse: 6.8555e-04 - lr: 0.0244
Epoch 29/150
243/243 [==============================] - 0s 927us/step - loss: 8.1594e-04 - mae: 0.0210 - mse: 7.1166e-04 - val_loss: 7.6469e-04 - val_mae: 0.0205 - val_mse: 6.9521e-04 - lr: 0.0244
Epoch 30/150
163/243 [===================>..........] - ETA: 0s - loss: 8.7695e-04 - mae: 0.0216 - mse: 7.6405e-04
243/243 [==============================] - 1s 3ms/step - loss: 8.5994e-04 - mae: 0.0214 - mse: 7.4804e-04 - val_loss: 7.4044e-04 - val_mae: 0.0203 - val_mse: 6.6219e-04 - lr: 0.0244
Epoch 31/150
243/243 [==============================] - 0s 937us/step - loss: 8.0912e-04 - mae: 0.0209 - mse: 7.1997e-04 - val_loss: 0.0010 - val_mae: 0.0237 - val_mse: 9.0390e-04 - lr: 0.0244
Epoch 32/150
243/243 [==============================] - 0s 916us/step - loss: 8.6936e-04 - mae: 0.0216 - mse: 7.5263e-04 - val_loss: 8.9054e-04 - val_mae: 0.0227 - val_mse: 7.8647e-04 - lr: 0.0244
Epoch 33/150
243/243 [==============================] - 0s 906us/step - loss: 8.3394e-04 - mae: 0.0207 - mse: 7.1175e-04 - val_loss: 7.9125e-04 - val_mae: 0.0214 - val_mse: 7.1066e-04 - lr: 0.0244
Epoch 34/150
242/243 [============================>.] - ETA: 0s - loss: 7.9508e-04 - mae: 0.0203 - mse: 6.8858e-04
243/243 [==============================] - 1s 4ms/step - loss: 7.9475e-04 - mae: 0.0203 - mse: 6.8822e-04 - val_loss: 7.3697e-04 - val_mae: 0.0199 - val_mse: 6.3171e-04 - lr: 0.0244
Epoch 35/150
243/243 [==============================] - 0s 994us/step - loss: 7.8301e-04 - mae: 0.0202 - mse: 6.7293e-04 - val_loss: 7.7502e-04 - val_mae: 0.0207 - val_mse: 6.7320e-04 - lr: 0.0244
Epoch 36/150
243/243 [==============================] - 0s 914us/step - loss: 7.7565e-04 - mae: 0.0201 - mse: 6.6778e-04 - val_loss: 7.7266e-04 - val_mae: 0.0185 - val_mse: 6.1879e-04 - lr: 0.0244
Epoch 37/150
243/243 [==============================] - ETA: 0s - loss: 7.6620e-04 - mae: 0.0196 - mse: 6.4510e-04
243/243 [==============================] - 1s 3ms/step - loss: 7.6620e-04 - mae: 0.0196 - mse: 6.4510e-04 - val_loss: 7.0484e-04 - val_mae: 0.0178 - val_mse: 5.6249e-04 - lr: 0.0244
Epoch 38/150
243/243 [==============================] - 0s 910us/step - loss: 8.4403e-04 - mae: 0.0200 - mse: 6.7642e-04 - val_loss: 7.2784e-04 - val_mae: 0.0196 - val_mse: 6.1385e-04 - lr: 0.0244
Epoch 39/150
243/243 [==============================] - 0s 925us/step - loss: 7.7944e-04 - mae: 0.0198 - mse: 6.6235e-04 - val_loss: 8.1603e-04 - val_mae: 0.0214 - val_mse: 7.1839e-04 - lr: 0.0244
Epoch 40/150
164/243 [===================>..........] - ETA: 0s - loss: 7.3803e-04 - mae: 0.0193 - mse: 6.2868e-04
243/243 [==============================] - 1s 4ms/step - loss: 7.5682e-04 - mae: 0.0194 - mse: 6.3256e-04 - val_loss: 6.8063e-04 - val_mae: 0.0174 - val_mse: 5.3897e-04 - lr: 0.0244
Epoch 41/150
239/243 [============================>.] - ETA: 0s - loss: 8.3737e-04 - mae: 0.0199 - mse: 6.6591e-04
243/243 [==============================] - 1s 3ms/step - loss: 8.3360e-04 - mae: 0.0199 - mse: 6.6274e-04 - val_loss: 6.7523e-04 - val_mae: 0.0175 - val_mse: 5.5247e-04 - lr: 0.0244
Epoch 42/150
243/243 [==============================] - 0s 945us/step - loss: 8.0045e-04 - mae: 0.0198 - mse: 6.5499e-04 - val_loss: 7.5539e-04 - val_mae: 0.0190 - val_mse: 6.1385e-04 - lr: 0.0244
Epoch 43/150
243/243 [==============================] - 0s 902us/step - loss: 7.6719e-04 - mae: 0.0194 - mse: 6.3627e-04 - val_loss: 6.9604e-04 - val_mae: 0.0187 - val_mse: 5.6087e-04 - lr: 0.0244
Epoch 44/150
239/243 [============================>.] - ETA: 0s - loss: 7.1705e-04 - mae: 0.0191 - mse: 6.1814e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011248-8gbsuvul\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 4ms/step - loss: 7.1841e-04 - mae: 0.0191 - mse: 6.1950e-04 - val_loss: 6.3362e-04 - val_mae: 0.0175 - val_mse: 5.3035e-04 - lr: 0.0244
Epoch 45/150
243/243 [==============================] - 0s 919us/step - loss: 8.3460e-04 - mae: 0.0200 - mse: 6.6129e-04 - val_loss: 0.0012 - val_mae: 0.0231 - val_mse: 8.3479e-04 - lr: 0.0244
Epoch 46/150
243/243 [==============================] - 0s 937us/step - loss: 8.2614e-04 - mae: 0.0202 - mse: 6.8090e-04 - val_loss: 0.0010 - val_mae: 0.0243 - val_mse: 9.3546e-04 - lr: 0.0244
Epoch 47/150
243/243 [==============================] - 1s 4ms/step - loss: 7.2339e-04 - mae: 0.0190 - mse: 6.1583e-04 - val_loss: 6.2746e-04 - val_mae: 0.0173 - val_mse: 5.4463e-04 - lr: 0.0244
Epoch 48/150
243/243 [==============================] - 0s 934us/step - loss: 7.2766e-04 - mae: 0.0191 - mse: 6.1217e-04 - val_loss: 6.4948e-04 - val_mae: 0.0171 - val_mse: 5.4833e-04 - lr: 0.0244
Epoch 49/150
243/243 [==============================] - 0s 1ms/step - loss: 7.5386e-04 - mae: 0.0194 - mse: 6.4069e-04 - val_loss: 0.0015 - val_mae: 0.0229 - val_mse: 8.3973e-04 - lr: 0.0244
Epoch 50/150
243/243 [==============================] - 0s 906us/step - loss: 8.2394e-04 - mae: 0.0198 - mse: 6.5711e-04 - val_loss: 6.4703e-04 - val_mae: 0.0178 - val_mse: 5.3456e-04 - lr: 0.0244
Epoch 51/150
243/243 [==============================] - ETA: 0s - loss: 6.8836e-04 - mae: 0.0185 - mse: 5.8422e-04
243/243 [==============================] - 0s 922us/step - loss: 7.6730e-04 - mae: 0.0194 - mse: 6.2966e-04 - val_loss: 6.6560e-04 - val_mae: 0.0191 - val_mse: 5.8367e-04 - lr: 0.0244
Epoch 52/150
243/243 [==============================] - 0s 926us/step - loss: 7.3831e-04 - mae: 0.0193 - mse: 6.2571e-04 - val_loss: 0.0014 - val_mae: 0.0297 - val_mse: 0.0013 - lr: 0.0244
Epoch 53/150
243/243 [==============================] - 0s 922us/step - loss: 7.6730e-04 - mae: 0.0194 - mse: 6.2966e-04 - val_loss: 6.6560e-04 - val_mae: 0.0191 - val_mse: 5.8367e-04 - lr: 0.0244
Epoch 54/150
238/243 [============================>.] - ETA: 0s - loss: 7.6518e-04 - mae: 0.0198 - mse: 6.4723e-04
Epoch 54: ReduceLROnPlateau reducing learning rate to 0.01220608875155449.
243/243 [==============================] - 0s 940us/step - loss: 7.6267e-04 - mae: 0.0198 - mse: 6.4535e-04 - val_loss: 6.8042e-04 - val_mae: 0.0194 - val_mse: 5.9688e-04 - lr: 0.0244
Epoch 55/150
243/243 [==============================] - 0s 963us/step - loss: 6.7810e-04 - mae: 0.0185 - mse: 5.8679e-04 - val_loss: 6.9231e-04 - val_mae: 0.0182 - val_mse: 5.7605e-04 - lr: 0.0122
Epoch 56/150
243/243 [==============================] - 0s 940us/step - loss: 6.8653e-04 - mae: 0.0185 - mse: 5.8305e-04 - val_loss: 6.8190e-04 - val_mae: 0.0188 - val_mse: 5.9083e-04 - lr: 0.0122
Epoch 57/150
241/243 [============================>.] - ETA: 0s - loss: 6.5593e-04 - mae: 0.0183 - mse: 5.6901e-04
243/243 [==============================] - 1s 4ms/step - loss: 6.5453e-04 - mae: 0.0182 - mse: 5.6763e-04 - val_loss: 6.1724e-04 - val_mae: 0.0173 - val_mse: 5.2665e-04 - lr: 0.0122
Epoch 58/150
240/243 [============================>.] - ETA: 0s - loss: 6.4732e-04 - mae: 0.0180 - mse: 5.5716e-04
243/243 [==============================] - 1s 4ms/step - loss: 6.5453e-04 - mae: 0.0182 - mse: 5.6763e-04 - val_loss: 6.1724e-04 - val_mae: 0.0173 - val_mse: 5.2665e-04 - lr: 0.0122
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011248-8gbsuvul\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 4ms/step - loss: 6.5453e-04 - mae: 0.0182 - mse: 5.6763e-04 - val_loss: 6.1724e-04 - val_mae: 0.0173 - val_mse: 5.2665e-04 - lr: 0.0122
243/243 [==============================] - ETA: 0s - loss: 6.7555e-04 - mae: 0.0182 - mse: 5.7078e-04e-04 - val_loss: 6.1724e-04 - val_mae: 0.0173 - val_mse: 5.2665e-04 - lr: 0.0122
243/243 [==============================] - ETA: 0s - loss: 6.7555e-04 - mae: 0.0182 - mse: 5.7078e-04e-04 - val_loss: 6.1724e-04 - val_mae: 0.0173 - val_mse: 5.2665e-04 - lr: 0.0122
243/243 [==============================] - 0s 916us/step - loss: 5.8385e-04 - mae: 0.0169 - mse: 5.0124e-04 - val_loss: 5.8022e-04 - val_mae: 0.0162 - val_mse: 4.8135e-04 - lr: 0.0061
243/243 [==============================] - 0s 916us/step - loss: 5.8385e-04 - mae: 0.0169 - mse: 5.0124e-04 - val_loss: 5.8022e-04 - val_mae: 0.0162 - val_mse: 4.8135e-04 - lr: 0.0061
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011248-8gbsuvul\files\model-best)... Done. 0.0s
243/243 [==============================] - 0s 916us/step - loss: 5.8385e-04 - mae: 0.0169 - mse: 5.0124e-04 - val_loss: 5.8022e-04 - val_mae: 0.0162 - val_mse: 4.8135e-04 - lr: 0.0061
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011248-8gbsuvul\files\model-best)... Done. 0.0s
243/243 [==============================] - 0s 916us/step - loss: 5.8385e-04 - mae: 0.0169 - mse: 5.0124e-04 - val_loss: 5.8022e-04 - val_mae: 0.0162 - val_mse: 4.8135e-04 - lr: 0.0061
243/243 [==============================] - 0s 985us/step - loss: 5.5251e-04 - mae: 0.0163 - mse: 4.7530e-04 - val_loss: 5.6620e-04 - val_mae: 0.0169 - val_mse: 4.8993e-04 - lr: 0.0031
243/243 [==============================] - 0s 985us/step - loss: 5.5251e-04 - mae: 0.0163 - mse: 4.7530e-04 - val_loss: 5.6620e-04 - val_mae: 0.0169 - val_mse: 4.8993e-04 - lr: 0.0031
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011248-8gbsuvul\files\model-best)... Done. 0.0s
243/243 [==============================] - 0s 985us/step - loss: 5.5251e-04 - mae: 0.0163 - mse: 4.7530e-04 - val_loss: 5.6620e-04 - val_mae: 0.0169 - val_mse: 4.8993e-04 - lr: 0.0031
166/243 [===================>..........] - ETA: 0s - loss: 5.3191e-04 - mae: 0.0158 - mse: 4.5651e-0430e-04 - val_loss: 5.6620e-04 - val_mae: 0.0169 - val_mse: 4.8993e-04 - lr: 0.0031
166/243 [===================>..........] - ETA: 0s - loss: 5.3191e-04 - mae: 0.0158 - mse: 4.5651e-0430e-04 - val_loss: 5.6620e-04 - val_mae: 0.0169 - val_mse: 4.8993e-04 - lr: 0.0031
243/243 [==============================] - 1s 3ms/step - loss: 5.3936e-04 - mae: 0.0160 - mse: 4.6515e-04 - val_loss: 5.2814e-04 - val_mae: 0.0160 - val_mse: 4.5753e-04 - lr: 0.003131
243/243 [==============================] - 1s 3ms/step - loss: 5.3936e-04 - mae: 0.0160 - mse: 4.6515e-04 - val_loss: 5.2814e-04 - val_mae: 0.0160 - val_mse: 4.5753e-04 - lr: 0.003131
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011248-8gbsuvul\files\model-best)... Done. 0.0s
243/243 [==============================] - 0s 915us/step - loss: 5.2940e-04 - mae: 0.0158 - mse: 4.5739e-04 - val_loss: 5.2613e-04 - val_mae: 0.0158 - val_mse: 4.5103e-04 - lr: 0.0015
243/243 [==============================] - 0s 915us/step - loss: 5.2940e-04 - mae: 0.0158 - mse: 4.5739e-04 - val_loss: 5.2613e-04 - val_mae: 0.0158 - val_mse: 4.5103e-04 - lr: 0.0015
243/243 [==============================] - 0s 901us/step - loss: 5.1911e-04 - mae: 0.0155 - mse: 4.4484e-04 - val_loss: 5.2381e-04 - val_mae: 0.0157 - val_mse: 4.5005e-04 - lr: 7.6288e-04
243/243 [==============================] - 0s 911us/step - loss: 5.1673e-04 - mae: 0.0155 - mse: 4.4541e-04 - val_loss: 5.2011e-04 - val_mae: 0.0161 - val_mse: 4.5004e-04 - lr: 7.6288e-04
243/243 [==============================] - 0s 911us/step - loss: 5.1673e-04 - mae: 0.0155 - mse: 4.4541e-04 - val_loss: 5.2011e-04 - val_mae: 0.0161 - val_mse: 4.5004e-04 - lr: 7.6288e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011248-8gbsuvul\files\model-best)... Done. 0.0s
243/243 [==============================] - 0s 911us/step - loss: 5.1673e-04 - mae: 0.0155 - mse: 4.4541e-04 - val_loss: 5.2011e-04 - val_mae: 0.0161 - val_mse: 4.5004e-04 - lr: 7.6288e-04
243/243 [==============================] - 0s 924us/step - loss: 5.1279e-04 - mae: 0.0155 - mse: 4.4424e-04 - val_loss: 5.2485e-04 - val_mae: 0.0160 - val_mse: 4.5387e-04 - lr: 3.8144e-04
243/243 [==============================] - 0s 924us/step - loss: 5.1279e-04 - mae: 0.0155 - mse: 4.4424e-04 - val_loss: 5.2485e-04 - val_mae: 0.0160 - val_mse: 4.5387e-04 - lr: 3.8144e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011248-8gbsuvul\files\model-best)... Done. 0.0s
243/243 [==============================] - 0s 924us/step - loss: 5.1279e-04 - mae: 0.0155 - mse: 4.4424e-04 - val_loss: 5.2485e-04 - val_mae: 0.0160 - val_mse: 4.5387e-04 - lr: 3.8144e-04
Epoch 114/150==========================] - 0s 924us/step - loss: 5.1279e-04 - mae: 0.0155 - mse: 4.4424e-04 - val_loss: 5.2485e-04 - val_mae: 0.0160 - val_mse: 4.5387e-04 - lr: 3.8144e-04
Epoch 114/150==========================] - 0s 924us/step - loss: 5.1279e-04 - mae: 0.0155 - mse: 4.4424e-04 - val_loss: 5.2485e-04 - val_mae: 0.0160 - val_mse: 4.5387e-04 - lr: 3.8144e-04
Epoch 115/150==========================] - 0s 924us/step - loss: 5.1279e-04 - mae: 0.0155 - mse: 4.4424e-04 - val_loss: 5.2485e-04 - val_mae: 0.0160 - val_mse: 4.5387e-04 - lr: 3.8144e-04
Epoch 115/150==========================] - 0s 924us/step - loss: 5.1279e-04 - mae: 0.0155 - mse: 4.4424e-04 - val_loss: 5.2485e-04 - val_mae: 0.0160 - val_mse: 4.5387e-04 - lr: 3.8144e-04
Epoch 116/150==========================] - 0s 924us/step - loss: 5.1279e-04 - mae: 0.0155 - mse: 4.4424e-04 - val_loss: 5.2485e-04 - val_mae: 0.0160 - val_mse: 4.5387e-04 - lr: 3.8144e-04
Epoch 116/150==========================] - 0s 924us/step - loss: 5.1279e-04 - mae: 0.0155 - mse: 4.4424e-04 - val_loss: 5.2485e-04 - val_mae: 0.0160 - val_mse: 4.5387e-04 - lr: 3.8144e-04
Epoch 118/150==========================] - 0s 924us/step - loss: 5.1279e-04 - mae: 0.0155 - mse: 4.4424e-04 - val_loss: 5.2485e-04 - val_mae: 0.0160 - val_mse: 4.5387e-04 - lr: 3.8144e-04
Epoch 118/150==========================] - 0s 924us/step - loss: 5.1279e-04 - mae: 0.0155 - mse: 4.4424e-04 - val_loss: 5.2485e-04 - val_mae: 0.0160 - val_mse: 4.5387e-04 - lr: 3.8144e-04
Epoch 126/150==========================] - 0s 924us/step - loss: 5.1279e-04 - mae: 0.0155 - mse: 4.4424e-04 - val_loss: 5.2485e-04 - val_mae: 0.0160 - val_mse: 4.5387e-04 - lr: 3.8144e-04
Epoch 126/150==========================] - 0s 924us/step - loss: 5.1279e-04 - mae: 0.0155 - mse: 4.4424e-04 - val_loss: 5.2485e-04 - val_mae: 0.0160 - val_mse: 4.5387e-04 - lr: 3.8144e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230421_011248-8gbsuvul\files\model-best)... Done. 0.0s
Epoch 126/150==========================] - 0s 924us/step - loss: 5.1279e-04 - mae: 0.0155 - mse: 4.4424e-04 - val_loss: 5.2485e-04 - val_mae: 0.0160 - val_mse: 4.5387e-04 - lr: 3.8144e-04
Epoch 129/150==========================] - 0s 924us/step - loss: 5.1279e-04 - mae: 0.0155 - mse: 4.4424e-04 - val_loss: 5.2485e-04 - val_mae: 0.0160 - val_mse: 4.5387e-04 - lr: 3.8144e-04
Epoch 129/150==========================] - 0s 924us/step - loss: 5.1279e-04 - mae: 0.0155 - mse: 4.4424e-04 - val_loss: 5.2485e-04 - val_mae: 0.0160 - val_mse: 4.5387e-04 - lr: 3.8144e-04
Epoch 35/1500==========================] - 0s 924us/step - loss: 5.1279e-04 - mae: 0.0155 - mse: 4.4424e-04 - val_loss: 5.2485e-04 - val_mae: 0.0160 - val_mse: 4.5387e-04 - lr: 3.8144e-04
323/323 [==============================] - 0s 877us/step - loss: 0.0013 - mae: 0.0256 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0240 - val_mse: 0.0011 - lr: 0.0244
Epoch 30/150
323/323 [==============================] - 0s 881us/step - loss: 0.0014 - mae: 0.0258 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0249 - val_mse: 0.0011 - lr: 0.0244
Epoch 31/150
245/323 [=====================>........] - ETA: 0s - loss: 0.0013 - mae: 0.0256 - mse: 0.0011
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.01220608875155449.
323/323 [==============================] - 0s 898us/step - loss: 0.0013 - mae: 0.0256 - mse: 0.0011 - val_loss: 0.0016 - val_mae: 0.0309 - val_mse: 0.0014 - lr: 0.0244
Epoch 32/150
323/323 [==============================] - 0s 893us/step - loss: 0.0012 - mae: 0.0244 - mse: 0.0011 - val_loss: 0.0014 - val_mae: 0.0282 - val_mse: 0.0013 - lr: 0.0122
Epoch 33/150
323/323 [==============================] - 0s 883us/step - loss: 0.0012 - mae: 0.0243 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0229 - val_mse: 9.8937e-04 - lr: 0.0122
Epoch 34/150
323/323 [==============================] - 0s 920us/step - loss: 0.0012 - mae: 0.0247 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0231 - val_mse: 9.7274e-04 - lr: 0.0122
Epoch 35/1500==========================] - 0s 924us/step - loss: 5.1279e-04 - mae: 0.0155 - mse: 4.4424e-04 - val_loss: 5.2485e-04 - val_mae: 0.0160 - val_mse: 4.5387e-04 - lr: 3.8144e-04
323/323 [==============================] - 0s 936us/step - loss: 0.0012 - mae: 0.0247 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0234 - val_mse: 0.0010 - lr: 0.0122
Epoch 36/150
323/323 [==============================] - 0s 886us/step - loss: 0.0012 - mae: 0.0243 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0255 - val_mse: 0.0011 - lr: 0.0122
Epoch 37/150
323/323 [==============================] - 0s 885us/step - loss: 0.0012 - mae: 0.0246 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0230 - val_mse: 9.6905e-04 - lr: 0.0122
Epoch 38/150
323/323 [==============================] - 0s 874us/step - loss: 0.0012 - mae: 0.0246 - mse: 0.0011 - val_loss: 0.0014 - val_mae: 0.0281 - val_mse: 0.0012 - lr: 0.0122
Epoch 39/150
323/323 [==============================] - 0s 876us/step - loss: 0.0012 - mae: 0.0242 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0242 - val_mse: 0.0010 - lr: 0.0122
Epoch 40/150
323/323 [==============================] - 0s 876us/step - loss: 0.0012 - mae: 0.0242 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0242 - val_mse: 0.0011 - lr: 0.0122
Epoch 41/150
323/323 [==============================] - 0s 889us/step - loss: 0.0012 - mae: 0.0241 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0224 - val_mse: 9.5592e-04 - lr: 0.0122
Epoch 42/150
323/323 [==============================] - 0s 879us/step - loss: 0.0012 - mae: 0.0242 - mse: 0.0010 - val_loss: 0.0016 - val_mae: 0.0311 - val_mse: 0.0014 - lr: 0.0122
Epoch 43/150
323/323 [==============================] - 0s 871us/step - loss: 0.0012 - mae: 0.0243 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0230 - val_mse: 9.6186e-04 - lr: 0.0122
Epoch 44/150
323/323 [==============================] - 0s 880us/step - loss: 0.0011 - mae: 0.0238 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0226 - val_mse: 9.6948e-04 - lr: 0.0122
Epoch 45/150
323/323 [==============================] - 0s 887us/step - loss: 0.0011 - mae: 0.0239 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0224 - val_mse: 9.3258e-04 - lr: 0.0122
Epoch 46/150
323/323 [==============================] - 0s 878us/step - loss: 0.0012 - mae: 0.0247 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0223 - val_mse: 9.3326e-04 - lr: 0.0122
Epoch 47/150
323/323 [==============================] - 0s 879us/step - loss: 0.0012 - mae: 0.0243 - mse: 0.0010 - val_loss: 0.0013 - val_mae: 0.0271 - val_mse: 0.0012 - lr: 0.0122
Epoch 48/150
323/323 [==============================] - 0s 934us/step - loss: 0.0012 - mae: 0.0245 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0248 - val_mse: 0.0010 - lr: 0.0122
Epoch 49/150
323/323 [==============================] - 0s 891us/step - loss: 0.0012 - mae: 0.0248 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0224 - val_mse: 9.3481e-04 - lr: 0.0122
Epoch 50/150
323/323 [==============================] - 0s 886us/step - loss: 0.0011 - mae: 0.0240 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0227 - val_mse: 9.6547e-04 - lr: 0.0122
Epoch 51/150
246/323 [=====================>........] - ETA: 0s - loss: 0.0011 - mae: 0.0240 - mse: 0.0010
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.006103044375777245.
323/323 [==============================] - 0s 883us/step - loss: 0.0011 - mae: 0.0239 - mse: 0.0010 - val_loss: 0.0010 - val_mae: 0.0222 - val_mse: 9.2000e-04 - lr: 0.0122
Epoch 52/150
323/323 [==============================] - 0s 899us/step - loss: 0.0011 - mae: 0.0231 - mse: 9.6718e-04 - val_loss: 0.0011 - val_mae: 0.0233 - val_mse: 9.6539e-04 - lr: 0.0061
Epoch 53/150
323/323 [==============================] - 0s 887us/step - loss: 0.0011 - mae: 0.0232 - mse: 9.6953e-04 - val_loss: 0.0010 - val_mae: 0.0220 - val_mse: 9.1318e-04 - lr: 0.0061
Epoch 54/150
323/323 [==============================] - 0s 887us/step - loss: 0.0011 - mae: 0.0234 - mse: 9.7774e-04 - val_loss: 0.0010 - val_mae: 0.0220 - val_mse: 9.1662e-04 - lr: 0.0061
Epoch 55/150
323/323 [==============================] - 0s 884us/step - loss: 0.0011 - mae: 0.0231 - mse: 9.6143e-04 - val_loss: 0.0011 - val_mae: 0.0225 - val_mse: 9.5344e-04 - lr: 0.0061
Epoch 56/150
323/323 [==============================] - 0s 932us/step - loss: 0.0011 - mae: 0.0233 - mse: 9.7866e-04 - val_loss: 0.0010 - val_mae: 0.0224 - val_mse: 9.2761e-04 - lr: 0.0061
Epoch 57/150
323/323 [==============================] - 0s 896us/step - loss: 0.0011 - mae: 0.0234 - mse: 9.7551e-04 - val_loss: 0.0010 - val_mae: 0.0220 - val_mse: 9.0960e-04 - lr: 0.0061
Epoch 58/150
323/323 [==============================] - 0s 876us/step - loss: 0.0011 - mae: 0.0235 - mse: 9.8672e-04 - val_loss: 0.0010 - val_mae: 0.0220 - val_mse: 9.1332e-04 - lr: 0.0061
Epoch 59/150
323/323 [==============================] - 0s 882us/step - loss: 0.0011 - mae: 0.0234 - mse: 9.8420e-04 - val_loss: 0.0011 - val_mae: 0.0225 - val_mse: 9.4231e-04 - lr: 0.0061
Epoch 60/150
323/323 [==============================] - 0s 885us/step - loss: 0.0011 - mae: 0.0230 - mse: 9.5043e-04 - val_loss: 0.0012 - val_mae: 0.0248 - val_mse: 0.0011 - lr: 0.0061
Epoch 61/150
243/323 [=====================>........] - ETA: 0s - loss: 0.0010 - mae: 0.0229 - mse: 9.4204e-04
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0030515221878886223.
323/323 [==============================] - 0s 896us/step - loss: 0.0011 - mae: 0.0229 - mse: 9.4705e-04 - val_loss: 0.0010 - val_mae: 0.0227 - val_mse: 9.2708e-04 - lr: 0.0061
Epoch 62/150
323/323 [==============================] - 0s 875us/step - loss: 0.0010 - mae: 0.0227 - mse: 9.3632e-04 - val_loss: 0.0011 - val_mae: 0.0224 - val_mse: 9.5417e-04 - lr: 0.0031
Epoch 63/150
323/323 [==============================] - 0s 934us/step - loss: 0.0010 - mae: 0.0226 - mse: 9.3051e-04 - val_loss: 0.0010 - val_mae: 0.0219 - val_mse: 9.0876e-04 - lr: 0.0031
Epoch 64/150
323/323 [==============================] - 0s 898us/step - loss: 0.0010 - mae: 0.0227 - mse: 9.2847e-04 - val_loss: 0.0010 - val_mae: 0.0220 - val_mse: 9.1677e-04 - lr: 0.0031
Epoch 65/150
323/323 [==============================] - 0s 885us/step - loss: 0.0010 - mae: 0.0225 - mse: 9.2715e-04 - val_loss: 0.0011 - val_mae: 0.0228 - val_mse: 9.5720e-04 - lr: 0.0031
Epoch 66/150
323/323 [==============================] - 0s 882us/step - loss: 0.0010 - mae: 0.0224 - mse: 9.2027e-04 - val_loss: 0.0010 - val_mae: 0.0226 - val_mse: 9.2779e-04 - lr: 0.0031
Epoch 67/150
323/323 [==============================] - 0s 892us/step - loss: 0.0010 - mae: 0.0225 - mse: 9.1956e-04 - val_loss: 9.9672e-04 - val_mae: 0.0219 - val_mse: 8.9884e-04 - lr: 0.0031
Epoch 68/150
323/323 [==============================] - 0s 890us/step - loss: 0.0011 - mae: 0.0231 - mse: 9.6123e-04 - val_loss: 0.0011 - val_mae: 0.0234 - val_mse: 9.9367e-04 - lr: 0.0031
Epoch 69/150
323/323 [==============================] - 0s 890us/step - loss: 0.0010 - mae: 0.0226 - mse: 9.2328e-04 - val_loss: 9.9939e-04 - val_mae: 0.0219 - val_mse: 8.9167e-04 - lr: 0.0031
Epoch 70/150
323/323 [==============================] - 0s 893us/step - loss: 0.0010 - mae: 0.0225 - mse: 9.2583e-04 - val_loss: 0.0011 - val_mae: 0.0245 - val_mse: 0.0010 - lr: 0.0031
Epoch 71/150
312/323 [===========================>..] - ETA: 0s - loss: 0.0010 - mae: 0.0227 - mse: 9.2682e-04
Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0015257610939443111.
323/323 [==============================] - 0s 914us/step - loss: 0.0010 - mae: 0.0227 - mse: 9.2789e-04 - val_loss: 0.0010 - val_mae: 0.0222 - val_mse: 9.0221e-04 - lr: 0.0031
Epoch 72/150
323/323 [==============================] - 0s 901us/step - loss: 9.9862e-04 - mae: 0.0221 - mse: 9.0422e-04 - val_loss: 0.0010 - val_mae: 0.0227 - val_mse: 9.3029e-04 - lr: 0.0015
Epoch 73/150
323/323 [==============================] - 0s 876us/step - loss: 0.0010 - mae: 0.0223 - mse: 9.1251e-04 - val_loss: 0.0010 - val_mae: 0.0230 - val_mse: 9.3818e-04 - lr: 0.0015
Epoch 74/150
323/323 [==============================] - 0s 902us/step - loss: 0.0010 - mae: 0.0223 - mse: 9.0608e-04 - val_loss: 0.0010 - val_mae: 0.0225 - val_mse: 9.2512e-04 - lr: 0.0015
Epoch 75/150
323/323 [==============================] - 0s 896us/step - loss: 0.0010 - mae: 0.0222 - mse: 9.0733e-04 - val_loss: 9.9182e-04 - val_mae: 0.0221 - val_mse: 9.0211e-04 - lr: 0.0015
Epoch 76/150
323/323 [==============================] - 0s 878us/step - loss: 9.9953e-04 - mae: 0.0222 - mse: 9.0448e-04 - val_loss: 9.9600e-04 - val_mae: 0.0222 - val_mse: 8.9924e-04 - lr: 0.0015
Epoch 77/150
323/323 [==============================] - 0s 880us/step - loss: 0.0010 - mae: 0.0222 - mse: 9.0566e-04 - val_loss: 9.9245e-04 - val_mae: 0.0220 - val_mse: 9.0564e-04 - lr: 0.0015
Epoch 78/150
323/323 [==============================] - 0s 938us/step - loss: 0.0010 - mae: 0.0222 - mse: 9.0987e-04 - val_loss: 9.8568e-04 - val_mae: 0.0218 - val_mse: 8.8756e-04 - lr: 0.0015
Epoch 79/150
323/323 [==============================] - 0s 997us/step - loss: 9.9349e-04 - mae: 0.0222 - mse: 8.9890e-04 - val_loss: 0.0010 - val_mae: 0.0224 - val_mse: 9.3566e-04 - lr: 0.0015
Epoch 80/150
323/323 [==============================] - 0s 899us/step - loss: 9.9917e-04 - mae: 0.0222 - mse: 9.0409e-04 - val_loss: 9.8758e-04 - val_mae: 0.0218 - val_mse: 8.8775e-04 - lr: 0.0015
Epoch 81/150
247/323 [=====================>........] - ETA: 0s - loss: 0.0010 - mae: 0.0223 - mse: 9.0591e-04
Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0007628805469721556.
323/323 [==============================] - 0s 881us/step - loss: 9.9541e-04 - mae: 0.0222 - mse: 9.0142e-04 - val_loss: 9.9674e-04 - val_mae: 0.0222 - val_mse: 9.0537e-04 - lr: 0.0015
Epoch 82/150
323/323 [==============================] - 0s 881us/step - loss: 9.8501e-04 - mae: 0.0220 - mse: 8.9191e-04 - val_loss: 9.8292e-04 - val_mae: 0.0218 - val_mse: 8.9090e-04 - lr: 7.6288e-04
Epoch 83/150
323/323 [==============================] - 0s 878us/step - loss: 9.8635e-04 - mae: 0.0220 - mse: 8.9345e-04 - val_loss: 0.0010 - val_mae: 0.0224 - val_mse: 9.1581e-04 - lr: 7.6288e-04
Epoch 84/150
323/323 [==============================] - 0s 891us/step - loss: 9.8360e-04 - mae: 0.0220 - mse: 8.9382e-04 - val_loss: 9.8567e-04 - val_mae: 0.0220 - val_mse: 8.9346e-04 - lr: 7.6288e-04
Epoch 85/150
323/323 [==============================] - 0s 892us/step - loss: 9.9057e-04 - mae: 0.0221 - mse: 8.9892e-04 - val_loss: 9.8328e-04 - val_mae: 0.0219 - val_mse: 8.9489e-04 - lr: 7.6288e-04
Epoch 86/150
323/323 [==============================] - 0s 928us/step - loss: 9.8281e-04 - mae: 0.0220 - mse: 8.9151e-04 - val_loss: 9.7912e-04 - val_mae: 0.0218 - val_mse: 8.8857e-04 - lr: 7.6288e-04
Epoch 87/150
323/323 [==============================] - 0s 890us/step - loss: 9.8168e-04 - mae: 0.0220 - mse: 8.9050e-04 - val_loss: 9.8101e-04 - val_mae: 0.0218 - val_mse: 8.9088e-04 - lr: 7.6288e-04
Epoch 88/150
323/323 [==============================] - 0s 883us/step - loss: 9.8223e-04 - mae: 0.0220 - mse: 8.9186e-04 - val_loss: 0.0010 - val_mae: 0.0229 - val_mse: 9.3574e-04 - lr: 7.6288e-04
Epoch 89/150
323/323 [==============================] - 0s 898us/step - loss: 9.8226e-04 - mae: 0.0220 - mse: 8.9222e-04 - val_loss: 9.7796e-04 - val_mae: 0.0218 - val_mse: 8.8912e-04 - lr: 7.6288e-04
Epoch 90/150
323/323 [==============================] - 0s 879us/step - loss: 9.8580e-04 - mae: 0.0221 - mse: 8.9589e-04 - val_loss: 9.8883e-04 - val_mae: 0.0221 - val_mse: 9.0106e-04 - lr: 7.6288e-04
Epoch 91/150
241/323 [=====================>........] - ETA: 0s - loss: 9.7106e-04 - mae: 0.0219 - mse: 8.8005e-04
Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0003814402734860778.
323/323 [==============================] - 0s 893us/step - loss: 9.8554e-04 - mae: 0.0220 - mse: 8.9552e-04 - val_loss: 9.8525e-04 - val_mae: 0.0219 - val_mse: 8.9506e-04 - lr: 7.6288e-04
Epoch 92/150
323/323 [==============================] - 0s 887us/step - loss: 9.7846e-04 - mae: 0.0219 - mse: 8.8957e-04 - val_loss: 9.7762e-04 - val_mae: 0.0218 - val_mse: 8.8791e-04 - lr: 3.8144e-04
Epoch 93/150
323/323 [==============================] - 0s 886us/step - loss: 9.7717e-04 - mae: 0.0219 - mse: 8.8847e-04 - val_loss: 9.7902e-04 - val_mae: 0.0219 - val_mse: 8.9019e-04 - lr: 3.8144e-04
Epoch 94/150
323/323 [==============================] - 0s 922us/step - loss: 9.7413e-04 - mae: 0.0219 - mse: 8.8527e-04 - val_loss: 9.9256e-04 - val_mae: 0.0222 - val_mse: 9.0525e-04 - lr: 3.8144e-04
Epoch 95/150
323/323 [==============================] - 0s 896us/step - loss: 9.7504e-04 - mae: 0.0219 - mse: 8.8636e-04 - val_loss: 9.7867e-04 - val_mae: 0.0217 - val_mse: 8.8761e-04 - lr: 3.8144e-04
Epoch 96/150
323/323 [==============================] - 0s 880us/step - loss: 9.7737e-04 - mae: 0.0219 - mse: 8.8875e-04 - val_loss: 9.7741e-04 - val_mae: 0.0218 - val_mse: 8.8804e-04 - lr: 3.8144e-04
Epoch 97/150
323/323 [==============================] - 0s 874us/step - loss: 9.7426e-04 - mae: 0.0219 - mse: 8.8583e-04 - val_loss: 9.8009e-04 - val_mae: 0.0219 - val_mse: 8.9072e-04 - lr: 3.8144e-04
Epoch 98/150
323/323 [==============================] - 0s 877us/step - loss: 9.7459e-04 - mae: 0.0219 - mse: 8.8472e-04 - val_loss: 0.0010 - val_mae: 0.0228 - val_mse: 9.3464e-04 - lr: 3.8144e-04
Epoch 99/150
323/323 [==============================] - 0s 883us/step - loss: 9.7608e-04 - mae: 0.0219 - mse: 8.8860e-04 - val_loss: 9.7792e-04 - val_mae: 0.0217 - val_mse: 8.8903e-04 - lr: 3.8144e-04
Epoch 100/150
323/323 [==============================] - 0s 887us/step - loss: 9.7336e-04 - mae: 0.0218 - mse: 8.8355e-04 - val_loss: 9.8948e-04 - val_mae: 0.0222 - val_mse: 9.0415e-04 - lr: 3.8144e-04
Epoch 101/150
249/323 [======================>.......] - ETA: 0s - loss: 9.7200e-04 - mae: 0.0218 - mse: 8.8436e-04
Epoch 101: ReduceLROnPlateau reducing learning rate to 0.0001907201367430389.
323/323 [==============================] - 0s 880us/step - loss: 9.7440e-04 - mae: 0.0219 - mse: 8.8661e-04 - val_loss: 9.7573e-04 - val_mae: 0.0218 - val_mse: 8.8785e-04 - lr: 3.8144e-04
Epoch 102/150
323/323 [==============================] - 0s 941us/step - loss: 9.7083e-04 - mae: 0.0218 - mse: 8.8279e-04 - val_loss: 9.7923e-04 - val_mae: 0.0218 - val_mse: 8.9003e-04 - lr: 1.9072e-04
Epoch 103/150
323/323 [==============================] - 0s 890us/step - loss: 9.7353e-04 - mae: 0.0218 - mse: 8.8608e-04 - val_loss: 9.8480e-04 - val_mae: 0.0221 - val_mse: 8.9807e-04 - lr: 1.9072e-04
Epoch 104/150
323/323 [==============================] - 0s 878us/step - loss: 9.7081e-04 - mae: 0.0219 - mse: 8.8233e-04 - val_loss: 9.7520e-04 - val_mae: 0.0218 - val_mse: 8.8808e-04 - lr: 1.9072e-04
Epoch 105/150
246/323 [=====================>........] - ETA: 0s - loss: 0.0010 - mae: 0.0223 - mse: 9.1800e-04
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0023s). Check your callbacks.
Epoch 33/150===========================] - 0s 891us/step - loss: 9.6993e-04 - mae: 0.0218 - mse: 8.8272e-04 - val_loss: 9.7575e-04 - val_mae: 0.0218 - val_mse: 8.8876e-04 - lr: 1.9072e-04
Epoch 106/150
323/323 [==============================] - 0s 878us/step - loss: 9.7408e-04 - mae: 0.0219 - mse: 8.8743e-04 - val_loss: 9.7659e-04 - val_mae: 0.0218 - val_mse: 8.8871e-04 - lr: 1.9072e-04
Epoch 107/150
323/323 [==============================] - 0s 880us/step - loss: 9.7268e-04 - mae: 0.0218 - mse: 8.8512e-04 - val_loss: 9.7659e-04 - val_mae: 0.0218 - val_mse: 8.8904e-04 - lr: 1.9072e-04
Epoch 108/150
323/323 [==============================] - 0s 885us/step - loss: 9.6803e-04 - mae: 0.0218 - mse: 8.8012e-04 - val_loss: 9.8191e-04 - val_mae: 0.0220 - val_mse: 8.9458e-04 - lr: 1.9072e-04
Epoch 109/150
323/323 [==============================] - 0s 929us/step - loss: 9.6944e-04 - mae: 0.0218 - mse: 8.8215e-04 - val_loss: 9.7596e-04 - val_mae: 0.0217 - val_mse: 8.8661e-04 - lr: 1.9072e-04
Epoch 110/150
323/323 [==============================] - 0s 882us/step - loss: 9.7258e-04 - mae: 0.0218 - mse: 8.8447e-04 - val_loss: 9.7752e-04 - val_mae: 0.0219 - val_mse: 8.9060e-04 - lr: 1.9072e-04
Epoch 111/150
245/323 [=====================>........] - ETA: 0s - loss: 9.6897e-04 - mae: 0.0219 - mse: 8.8193e-04
Epoch 111: ReduceLROnPlateau reducing learning rate to 9.536006837151945e-05.
323/323 [==============================] - 0s 896us/step - loss: 9.7037e-04 - mae: 0.0218 - mse: 8.8336e-04 - val_loss: 9.7537e-04 - val_mae: 0.0218 - val_mse: 8.8827e-04 - lr: 1.9072e-04
Epoch 112/150
323/323 [==============================] - 0s 882us/step - loss: 9.6848e-04 - mae: 0.0218 - mse: 8.8122e-04 - val_loss: 9.7491e-04 - val_mae: 0.0218 - val_mse: 8.8755e-04 - lr: 9.5360e-05
Epoch 113/150
323/323 [==============================] - 0s 871us/step - loss: 9.6821e-04 - mae: 0.0218 - mse: 8.8076e-04 - val_loss: 9.7877e-04 - val_mae: 0.0219 - val_mse: 8.9238e-04 - lr: 9.5360e-05
Epoch 114/150
323/323 [==============================] - 0s 881us/step - loss: 9.6877e-04 - mae: 0.0218 - mse: 8.8214e-04 - val_loss: 9.7431e-04 - val_mae: 0.0217 - val_mse: 8.8617e-04 - lr: 9.5360e-05
Epoch 115/150
323/323 [==============================] - 0s 879us/step - loss: 9.6895e-04 - mae: 0.0218 - mse: 8.8186e-04 - val_loss: 9.7454e-04 - val_mae: 0.0217 - val_mse: 8.8641e-04 - lr: 9.5360e-05
Epoch 116/150
323/323 [==============================] - 0s 886us/step - loss: 9.6865e-04 - mae: 0.0218 - mse: 8.8118e-04 - val_loss: 9.7512e-04 - val_mae: 0.0217 - val_mse: 8.8685e-04 - lr: 9.5360e-05
Epoch 117/150
323/323 [==============================] - 0s 931us/step - loss: 9.6808e-04 - mae: 0.0218 - mse: 8.8098e-04 - val_loss: 9.8035e-04 - val_mae: 0.0220 - val_mse: 8.9435e-04 - lr: 9.5360e-05
Epoch 118/150
323/323 [==============================] - 0s 1ms/step - loss: 9.6784e-04 - mae: 0.0218 - mse: 8.8080e-04 - val_loss: 9.7622e-04 - val_mae: 0.0219 - val_mse: 8.8988e-04 - lr: 9.5360e-05
Epoch 119/150
323/323 [==============================] - 0s 900us/step - loss: 9.6715e-04 - mae: 0.0218 - mse: 8.8055e-04 - val_loss: 9.7821e-04 - val_mae: 0.0219 - val_mse: 8.9201e-04 - lr: 9.5360e-05
Epoch 120/150
323/323 [==============================] - 0s 872us/step - loss: 9.6784e-04 - mae: 0.0218 - mse: 8.8081e-04 - val_loss: 9.7904e-04 - val_mae: 0.0220 - val_mse: 8.9306e-04 - lr: 9.5360e-05
Epoch 121/150
249/323 [======================>.......] - ETA: 0s - loss: 9.8110e-04 - mae: 0.0220 - mse: 8.9401e-04
Epoch 121: ReduceLROnPlateau reducing learning rate to 4.768003418575972e-05.
323/323 [==============================] - 0s 891us/step - loss: 9.6812e-04 - mae: 0.0218 - mse: 8.8100e-04 - val_loss: 9.7716e-04 - val_mae: 0.0219 - val_mse: 8.9101e-04 - lr: 9.5360e-05
Epoch 122/150
323/323 [==============================] - 0s 929us/step - loss: 9.6757e-04 - mae: 0.0218 - mse: 8.8082e-04 - val_loss: 9.7533e-04 - val_mae: 0.0218 - val_mse: 8.8889e-04 - lr: 4.7680e-05
Epoch 123/150
323/323 [==============================] - 0s 884us/step - loss: 9.6749e-04 - mae: 0.0218 - mse: 8.8090e-04 - val_loss: 9.7428e-04 - val_mae: 0.0218 - val_mse: 8.8740e-04 - lr: 4.7680e-05
Epoch 124/150
323/323 [==============================] - 0s 892us/step - loss: 9.6716e-04 - mae: 0.0218 - mse: 8.8063e-04 - val_loss: 9.7383e-04 - val_mae: 0.0218 - val_mse: 8.8674e-04 - lr: 4.7680e-05
Epoch 125/150
323/323 [==============================] - 0s 926us/step - loss: 9.6795e-04 - mae: 0.0217 - mse: 8.8113e-04 - val_loss: 9.7401e-04 - val_mae: 0.0218 - val_mse: 8.8704e-04 - lr: 4.7680e-05
Epoch 126/150
323/323 [==============================] - 0s 884us/step - loss: 9.6714e-04 - mae: 0.0218 - mse: 8.8016e-04 - val_loss: 9.7431e-04 - val_mae: 0.0218 - val_mse: 8.8753e-04 - lr: 4.7680e-05
Epoch 127/150
323/323 [==============================] - 0s 883us/step - loss: 9.6698e-04 - mae: 0.0217 - mse: 8.8038e-04 - val_loss: 9.7505e-04 - val_mae: 0.0218 - val_mse: 8.8845e-04 - lr: 4.7680e-05
Epoch 128/150
323/323 [==============================] - 0s 871us/step - loss: 9.6710e-04 - mae: 0.0218 - mse: 8.8006e-04 - val_loss: 9.7433e-04 - val_mae: 0.0218 - val_mse: 8.8754e-04 - lr: 4.7680e-05
Epoch 129/150
323/323 [==============================] - 0s 879us/step - loss: 9.6704e-04 - mae: 0.0218 - mse: 8.8062e-04 - val_loss: 9.7625e-04 - val_mae: 0.0219 - val_mse: 8.8995e-04 - lr: 4.7680e-05
Epoch 130/150
323/323 [==============================] - 0s 882us/step - loss: 9.6755e-04 - mae: 0.0218 - mse: 8.8084e-04 - val_loss: 9.7665e-04 - val_mae: 0.0219 - val_mse: 8.9038e-04 - lr: 4.7680e-05
Epoch 131/150
296/323 [==========================>...] - ETA: 0s - loss: 9.6713e-04 - mae: 0.0218 - mse: 8.8032e-04
Epoch 131: ReduceLROnPlateau reducing learning rate to 2.384001709287986e-05.
323/323 [==============================] - 0s 957us/step - loss: 9.6739e-04 - mae: 0.0218 - mse: 8.8061e-04 - val_loss: 9.7462e-04 - val_mae: 0.0218 - val_mse: 8.8794e-04 - lr: 4.7680e-05
Epoch 132/150
323/323 [==============================] - 0s 888us/step - loss: 9.6650e-04 - mae: 0.0218 - mse: 8.7969e-04 - val_loss: 9.7505e-04 - val_mae: 0.0218 - val_mse: 8.8854e-04 - lr: 2.3840e-05
Epoch 133/150
323/323 [==============================] - 0s 883us/step - loss: 9.6666e-04 - mae: 0.0218 - mse: 8.7992e-04 - val_loss: 9.7443e-04 - val_mae: 0.0218 - val_mse: 8.8775e-04 - lr: 2.3840e-05
Epoch 134/150
323/323 [==============================] - 0s 865us/step - loss: 9.6659e-04 - mae: 0.0218 - mse: 8.7986e-04 - val_loss: 9.7395e-04 - val_mae: 0.0218 - val_mse: 8.8712e-04 - lr: 2.3840e-05
Epoch 135/150
323/323 [==============================] - 0s 930us/step - loss: 9.6640e-04 - mae: 0.0218 - mse: 8.7947e-04 - val_loss: 9.7555e-04 - val_mae: 0.0219 - val_mse: 8.8915e-04 - lr: 2.3840e-05
Epoch 136/150
323/323 [==============================] - 0s 881us/step - loss: 9.6705e-04 - mae: 0.0218 - mse: 8.8039e-04 - val_loss: 9.7441e-04 - val_mae: 0.0218 - val_mse: 8.8772e-04 - lr: 2.3840e-05
Epoch 137/150
323/323 [==============================] - 0s 880us/step - loss: 9.6658e-04 - mae: 0.0218 - mse: 8.7991e-04 - val_loss: 9.7425e-04 - val_mae: 0.0218 - val_mse: 8.8754e-04 - lr: 2.3840e-05
Epoch 138/150
323/323 [==============================] - 0s 868us/step - loss: 9.6652e-04 - mae: 0.0218 - mse: 8.7979e-04 - val_loss: 9.7343e-04 - val_mae: 0.0218 - val_mse: 8.8634e-04 - lr: 2.3840e-05
Epoch 139/150
323/323 [==============================] - 0s 887us/step - loss: 9.6649e-04 - mae: 0.0217 - mse: 8.7968e-04 - val_loss: 9.7521e-04 - val_mae: 0.0218 - val_mse: 8.8887e-04 - lr: 2.3840e-05
Epoch 140/150
323/323 [==============================] - 0s 870us/step - loss: 9.6655e-04 - mae: 0.0218 - mse: 8.7994e-04 - val_loss: 9.7429e-04 - val_mae: 0.0218 - val_mse: 8.8768e-04 - lr: 2.3840e-05
Epoch 141/150
248/323 [======================>.......] - ETA: 0s - loss: 9.3840e-04 - mae: 0.0214 - mse: 8.5186e-04
Epoch 141: ReduceLROnPlateau reducing learning rate to 1.192000854643993e-05.
323/323 [==============================] - 0s 878us/step - loss: 9.6652e-04 - mae: 0.0218 - mse: 8.7989e-04 - val_loss: 9.7407e-04 - val_mae: 0.0218 - val_mse: 8.8736e-04 - lr: 2.3840e-05
Epoch 142/150
323/323 [==============================] - 0s 885us/step - loss: 9.6622e-04 - mae: 0.0217 - mse: 8.7938e-04 - val_loss: 9.7434e-04 - val_mae: 0.0218 - val_mse: 8.8772e-04 - lr: 1.1920e-05
Epoch 143/150
323/323 [==============================] - 0s 912us/step - loss: 9.6626e-04 - mae: 0.0218 - mse: 8.7957e-04 - val_loss: 9.7396e-04 - val_mae: 0.0218 - val_mse: 8.8720e-04 - lr: 1.1920e-05
Epoch 144/150
323/323 [==============================] - 0s 906us/step - loss: 9.6623e-04 - mae: 0.0218 - mse: 8.7966e-04 - val_loss: 9.7394e-04 - val_mae: 0.0218 - val_mse: 8.8721e-04 - lr: 1.1920e-05
Epoch 145/150
323/323 [==============================] - 0s 877us/step - loss: 9.6628e-04 - mae: 0.0217 - mse: 8.7958e-04 - val_loss: 9.7402e-04 - val_mae: 0.0218 - val_mse: 8.8732e-04 - lr: 1.1920e-05
Epoch 146/150
323/323 [==============================] - 0s 889us/step - loss: 9.6629e-04 - mae: 0.0218 - mse: 8.7949e-04 - val_loss: 9.7406e-04 - val_mae: 0.0218 - val_mse: 8.8735e-04 - lr: 1.1920e-05
Epoch 147/150
323/323 [==============================] - 0s 884us/step - loss: 9.6620e-04 - mae: 0.0218 - mse: 8.7944e-04 - val_loss: 9.7442e-04 - val_mae: 0.0218 - val_mse: 8.8781e-04 - lr: 1.1920e-05
Epoch 148/150
323/323 [==============================] - 0s 882us/step - loss: 9.6622e-04 - mae: 0.0218 - mse: 8.7968e-04 - val_loss: 9.7362e-04 - val_mae: 0.0218 - val_mse: 8.8678e-04 - lr: 1.1920e-05
Epoch 149/150
323/323 [==============================] - 0s 877us/step - loss: 9.6632e-04 - mae: 0.0217 - mse: 8.7956e-04 - val_loss: 9.7425e-04 - val_mae: 0.0218 - val_mse: 8.8760e-04 - lr: 1.1920e-05
Epoch 150/150
323/323 [==============================] - 0s 926us/step - loss: 9.6613e-04 - mae: 0.0217 - mse: 8.7945e-04 - val_loss: 9.7445e-04 - val_mae: 0.0218 - val_mse: 8.8786e-04 - lr: 1.1920e-05
>Saved ../trained_models/models_segments_overlap_adam_0.04882435498550114LR_[28]HN_16BS_10P_val_mseM_150epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
243/243 [==============================] - 1s 1ms/step - loss: 0.0155 - mae: 0.0399 - mse: 0.0023 - val_loss: 0.0021 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0488
Epoch 2/150
243/243 [==============================] - 0s 894us/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0488
Epoch 3/150
243/243 [==============================] - 0s 911us/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0488
Epoch 4/150
243/243 [==============================] - 0s 922us/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0488
Epoch 5/150
243/243 [==============================] - 0s 905us/step - loss: 0.0021 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0488
Epoch 6/150
243/243 [==============================] - 0s 910us/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0488
Epoch 7/150
243/243 [==============================] - 0s 957us/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0488
Epoch 8/150
243/243 [==============================] - 0s 917us/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0375 - val_mse: 0.0019 - lr: 0.0488
Epoch 9/150
243/243 [==============================] - 0s 916us/step - loss: 0.0022 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0382 - val_mse: 0.0019 - lr: 0.0488
Epoch 10/150
243/243 [==============================] - 0s 922us/step - loss: 0.0018 - mae: 0.0324 - mse: 0.0015 - val_loss: 0.0014 - val_mae: 0.0268 - val_mse: 0.0011 - lr: 0.0488
Epoch 11/150
243/243 [==============================] - 0s 921us/step - loss: 0.0014 - mae: 0.0274 - mse: 0.0012 - val_loss: 0.0016 - val_mae: 0.0295 - val_mse: 0.0014 - lr: 0.0488
Epoch 12/150
243/243 [==============================] - 0s 913us/step - loss: 0.0014 - mae: 0.0271 - mse: 0.0011 - val_loss: 0.0021 - val_mae: 0.0342 - val_mse: 0.0018 - lr: 0.0488
Epoch 13/150
243/243 [==============================] - 0s 905us/step - loss: 0.0014 - mae: 0.0265 - mse: 0.0011 - val_loss: 0.0014 - val_mae: 0.0264 - val_mse: 0.0012 - lr: 0.0488
Epoch 14/150
243/243 [==============================] - 0s 911us/step - loss: 0.0013 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0020 - val_mae: 0.0341 - val_mse: 0.0017 - lr: 0.0488
Epoch 15/150
243/243 [==============================] - 0s 966us/step - loss: 0.0012 - mae: 0.0254 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0266 - val_mse: 0.0010 - lr: 0.0488
Epoch 16/150
243/243 [==============================] - 0s 958us/step - loss: 0.0012 - mae: 0.0256 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0248 - val_mse: 9.2585e-04 - lr: 0.0488
Epoch 17/150
243/243 [==============================] - 0s 929us/step - loss: 0.0012 - mae: 0.0255 - mse: 0.0010 - val_loss: 0.0013 - val_mae: 0.0276 - val_mse: 0.0011 - lr: 0.0488
Epoch 18/150
243/243 [==============================] - 0s 972us/step - loss: 0.0013 - mae: 0.0259 - mse: 0.0010 - val_loss: 0.0013 - val_mae: 0.0265 - val_mse: 0.0011 - lr: 0.0488
Epoch 19/150
243/243 [==============================] - 0s 907us/step - loss: 0.0012 - mae: 0.0251 - mse: 9.9571e-04 - val_loss: 0.0011 - val_mae: 0.0243 - val_mse: 9.6788e-04 - lr: 0.0488
Epoch 20/150
243/243 [==============================] - 0s 913us/step - loss: 0.0011 - mae: 0.0248 - mse: 9.6321e-04 - val_loss: 0.0011 - val_mae: 0.0241 - val_mse: 9.1612e-04 - lr: 0.0488
Epoch 21/150
243/243 [==============================] - 0s 920us/step - loss: 0.0012 - mae: 0.0252 - mse: 9.9408e-04 - val_loss: 0.0012 - val_mae: 0.0240 - val_mse: 9.1539e-04 - lr: 0.0488
Epoch 22/150
243/243 [==============================] - 0s 911us/step - loss: 0.0012 - mae: 0.0253 - mse: 9.9923e-04 - val_loss: 0.0012 - val_mae: 0.0249 - val_mse: 9.4413e-04 - lr: 0.0488
Epoch 23/150
243/243 [==============================] - 0s 918us/step - loss: 0.0012 - mae: 0.0251 - mse: 9.9037e-04 - val_loss: 0.0012 - val_mae: 0.0244 - val_mse: 9.6238e-04 - lr: 0.0488
Epoch 24/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0253 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0243 - val_mse: 9.0560e-04 - lr: 0.0488
Epoch 25/150
243/243 [==============================] - 0s 963us/step - loss: 0.0011 - mae: 0.0244 - mse: 9.4483e-04 - val_loss: 0.0012 - val_mae: 0.0261 - val_mse: 0.0011 - lr: 0.0488
Epoch 26/150
236/243 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0256 - mse: 0.0010
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.02441217750310898.
243/243 [==============================] - 0s 943us/step - loss: 0.0012 - mae: 0.0256 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0263 - val_mse: 0.0010 - lr: 0.0488
Epoch 27/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0240 - mse: 9.1001e-04 - val_loss: 0.0011 - val_mae: 0.0252 - val_mse: 9.4684e-04 - lr: 0.0244
Epoch 28/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0242 - mse: 9.2914e-04 - val_loss: 0.0014 - val_mae: 0.0305 - val_mse: 0.0013 - lr: 0.0244
Epoch 29/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0242 - mse: 9.3186e-04 - val_loss: 0.0010 - val_mae: 0.0237 - val_mse: 9.0095e-04 - lr: 0.0244
Epoch 30/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0239 - mse: 9.0564e-04 - val_loss: 0.0011 - val_mae: 0.0241 - val_mse: 9.5596e-04 - lr: 0.0244
Epoch 31/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0243 - mse: 9.2362e-04 - val_loss: 9.6217e-04 - val_mae: 0.0238 - val_mse: 8.9117e-04 - lr: 0.0244
Epoch 32/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0244 - mse: 9.3518e-04 - val_loss: 9.9443e-04 - val_mae: 0.0243 - val_mse: 9.0624e-04 - lr: 0.0244
Epoch 33/150===========================] - 0s 891us/step - loss: 9.6993e-04 - mae: 0.0218 - mse: 8.8272e-04 - val_loss: 9.7575e-04 - val_mae: 0.0218 - val_mse: 8.8876e-04 - lr: 1.9072e-04
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
Epoch 34/150
243/243 [==============================] - 0s 1ms/step - loss: 9.7751e-04 - mae: 0.0238 - mse: 8.9082e-04 - val_loss: 0.0011 - val_mae: 0.0247 - val_mse: 0.0010 - lr: 0.0244
Epoch 35/150
243/243 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0238 - mse: 8.9390e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4658e-04 - lr: 0.0244
Epoch 36/150
207/243 [========================>.....] - ETA: 0s - loss: 0.0010 - mae: 0.0240 - mse: 9.0303e-04
Epoch 36: ReduceLROnPlateau reducing learning rate to 0.01220608875155449.
243/243 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0239 - mse: 8.9599e-04 - val_loss: 9.6397e-04 - val_mae: 0.0236 - val_mse: 8.9958e-04 - lr: 0.0244
Epoch 37/150
243/243 [==============================] - 0s 1ms/step - loss: 9.2068e-04 - mae: 0.0233 - mse: 8.5620e-04 - val_loss: 0.0016 - val_mae: 0.0301 - val_mse: 0.0015 - lr: 0.0122
Epoch 38/150
243/243 [==============================] - 0s 1ms/step - loss: 9.4756e-04 - mae: 0.0236 - mse: 8.7864e-04 - val_loss: 9.5537e-04 - val_mae: 0.0242 - val_mse: 8.8563e-04 - lr: 0.0122
Epoch 39/150
243/243 [==============================] - 0s 1ms/step - loss: 9.2507e-04 - mae: 0.0233 - mse: 8.5412e-04 - val_loss: 0.0011 - val_mae: 0.0251 - val_mse: 0.0010 - lr: 0.0122
Epoch 40/150
243/243 [==============================] - 0s 1ms/step - loss: 9.4687e-04 - mae: 0.0235 - mse: 8.8144e-04 - val_loss: 0.0010 - val_mae: 0.0235 - val_mse: 8.7488e-04 - lr: 0.0122
Epoch 41/150
 72/243 [=======>......................] - ETA: 0s - loss: 9.1441e-04 - mae: 0.0230 - mse: 8.3660e-04
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0014s). Check your callbacks.
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0021s). Check your callbacks.
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0014s). Check your callbacks.
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0016s). Check your callbacks.
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3893e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.4021e-04 - lr: 0.0244