Epoch 1/150
162/162 [==============================] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
162/162 [==============================] - 3s 15ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0154
Epoch 2/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0154
Epoch 3/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0154
Epoch 4/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0154
Epoch 5/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0154
Epoch 6/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0154
Epoch 7/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0154
Epoch 8/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0154
Epoch 9/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0154
Epoch 10/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0154
Epoch 11/150
158/162 [============================>.] - ETA: 0s - loss: 0.8580 - mae: 0.9253 - mse: 0.8580 - root_mean_squared_error: 0.9263
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.007713573519140482.
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0154
Epoch 12/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0077
Epoch 13/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0077
Epoch 14/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0077
Epoch 15/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0077
Epoch 16/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0077
Epoch 17/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0077
Epoch 18/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0077
Epoch 19/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0077
Epoch 20/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0077
Epoch 21/150
158/162 [============================>.] - ETA: 0s - loss: 0.8578 - mae: 0.9252 - mse: 0.8578 - root_mean_squared_error: 0.9262
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.003856786759570241.
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0077
Epoch 22/150
162/162 [==============================] - 1s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0039
Epoch 23/150
162/162 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0039
Epoch 24/150
162/162 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0039
Epoch 25/150
162/162 [==============================] - 1s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0039
Epoch 26/150
162/162 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0039
Epoch 27/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0039
Epoch 28/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0039
Epoch 29/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0039
Epoch 30/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0039
Epoch 31/150
155/162 [===========================>..] - ETA: 0s - loss: 0.8584 - mae: 0.9255 - mse: 0.8584 - root_mean_squared_error: 0.9265
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0019283933797851205.
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0039
Epoch 32/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0019
Epoch 33/150
162/162 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0019
Epoch 34/150
162/162 [==============================] - 1s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0019
Epoch 35/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0019
Epoch 36/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0019
Epoch 37/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0019
Epoch 38/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0019
Epoch 39/150
162/162 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0019
Epoch 40/150
162/162 [==============================] - 1s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0019
Epoch 41/150
159/162 [============================>.] - ETA: 0s - loss: 0.8578 - mae: 0.9251 - mse: 0.8578 - root_mean_squared_error: 0.9262
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0009641966898925602.
162/162 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0019
Epoch 42/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 9.6420e-04
Epoch 43/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 9.6420e-04
Epoch 44/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 9.6420e-04
Epoch 45/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 9.6420e-04
Epoch 46/150
162/162 [==============================] - 1s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 9.6420e-04
Epoch 47/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 9.6420e-04
Epoch 48/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 9.6420e-04
Epoch 49/150
120/162 [=====================>........] - ETA: 0s - loss: 0.8589 - mae: 0.9257 - mse: 0.8589 - root_mean_squared_error: 0.92689262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 9.6420e-04
Epoch 50/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 9.6420e-04
Epoch 51/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 4.8210e-04
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0004820983449462801.
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 9.6420e-04
Epoch 52/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 4.8210e-04
Epoch 53/150
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 4.8210e-04
Epoch 54/150
162/162 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 4.8210e-04
Epoch 55/150
117/162 [====================>.........] - ETA: 0s - loss: 0.8587 - mae: 0.9257 - mse: 0.8587 - root_mean_squared_error: 0.9267
162/162 [==============================] - 1s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 4.8210e-04
Epoch 57/150
 51/162 [========>.....................] - ETA: 0s - loss: 0.8591 - mae: 0.9259 - mse: 0.8591 - root_mean_squared_error: 0.9269
104/162 [==================>...........] - ETA: 0s - loss: 0.8571 - mae: 0.9247 - mse: 0.8571 - root_mean_squared_error: 0.92589262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 4.8210e-04
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 4.8210e-04
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 4.8210e-04
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 2.4105e-04
105/162 [==================>...........] - ETA: 0s - loss: 0.8562 - mae: 0.9243 - mse: 0.8562 - root_mean_squared_error: 0.92539262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 2.4105e-04
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 2.4105e-04
162/162 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 2.4105e-04
162/162 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.2052e-04
 52/162 [========>.....................] - ETA: 0s - loss: 0.8606 - mae: 0.9266 - mse: 0.8606 - root_mean_squared_error: 0.92779262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.2052e-04
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.2052e-04
154/162 [===========================>..] - ETA: 0s - loss: 0.8578 - mae: 0.9252 - mse: 0.8578 - root_mean_squared_error: 0.92629262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.2052e-04
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.2052e-04
159/162 [============================>.] - ETA: 0s - loss: 0.8578 - mae: 0.9252 - mse: 0.8578 - root_mean_squared_error: 0.92629262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.2052e-04
162/162 [==============================] - 1s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 6.0262e-05
 69/162 [===========>..................] - ETA: 0s - loss: 0.8599 - mae: 0.9263 - mse: 0.8599 - root_mean_squared_error: 0.92739262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 6.0262e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 6.0262e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 6.0262e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 6.0262e-05
102/162 [=================>............] - ETA: 0s - loss: 0.8597 - mae: 0.9262 - mse: 0.8597 - root_mean_squared_error: 0.92729262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 6.0262e-05
162/162 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.0131e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.0131e-05
141/162 [=========================>....] - ETA: 0s - loss: 0.8573 - mae: 0.9249 - mse: 0.8573 - root_mean_squared_error: 0.92599262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.0131e-05
 90/162 [===============>..............] - ETA: 0s - loss: 0.8586 - mae: 0.9256 - mse: 0.8586 - root_mean_squared_error: 0.92669262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.0131e-05
162/162 [==============================] - 1s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.5066e-05
162/162 [==============================] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.92629262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.5066e-05
 13/162 [=>............................] - ETA: 0s - loss: 0.8585 - mae: 0.9255 - mse: 0.8585 - root_mean_squared_error: 0.92659262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.5066e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.5066e-05
162/162 [==============================] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.92629262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.5066e-05
162/162 [==============================] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.92629262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.5066e-05
162/162 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
128/162 [======================>.......] - ETA: 0s - loss: 0.8571 - mae: 0.9247 - mse: 0.8571 - root_mean_squared_error: 0.92589262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
162/162 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
102/162 [=================>............] - ETA: 0s - loss: 0.8593 - mae: 0.9260 - mse: 0.8593 - root_mean_squared_error: 0.92709262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
162/162 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
157/162 [============================>.] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.92629262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
 24/162 [===>..........................] - ETA: 0s - loss: 0.8557 - mae: 0.9240 - mse: 0.8557 - root_mean_squared_error: 0.92509262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
161/162 [============================>.] - ETA: 0s - loss: 0.8578 - mae: 0.9251 - mse: 0.8578 - root_mean_squared_error: 0.92629262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
162/162 [==============================] - 1s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
162/162 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
 32/216 [===>..........................] - ETA: 0s - loss: 0.6453 - mae: 0.8011 - mse: 0.6453 - root_mean_squared_error: 0.8033  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
 32/216 [===>..........................] - ETA: 0s - loss: 0.6453 - mae: 0.8011 - mse: 0.6453 - root_mean_squared_error: 0.8033  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
216/216 [==============================] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 3/150============================] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 3/150============================] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 3/150============================] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 8/150============================] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 8/150============================] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 11/150===========================] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 12/150===========================] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 12/150===========================] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 16/150===========================] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 16/150===========================] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 16/150===========================] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 20/150===========================] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.003856786759570241.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.003856786759570241.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 25/150duceLROnPlateau reducing learning rate to 0.003856786759570241.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 27/150duceLROnPlateau reducing learning rate to 0.003856786759570241.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 29/150duceLROnPlateau reducing learning rate to 0.003856786759570241.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 29/150duceLROnPlateau reducing learning rate to 0.003856786759570241.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0019283933797851205.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0019283933797851205.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 35/150duceLROnPlateau reducing learning rate to 0.0019283933797851205.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 35/150duceLROnPlateau reducing learning rate to 0.0019283933797851205.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 35/150duceLROnPlateau reducing learning rate to 0.0019283933797851205.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 39/150duceLROnPlateau reducing learning rate to 0.0019283933797851205.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 39/150duceLROnPlateau reducing learning rate to 0.0019283933797851205.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0009641966898925602.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 44/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 44/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 47/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 47/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 50/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 50/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 52/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 52/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 52/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 57/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 57/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 60/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 60/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 62/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 62/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 66/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 66/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 69/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 69/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.998 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 71: ReduceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 73/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 73/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 73/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 73/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 78/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 78/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 81/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 82/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 84/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 84/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 84/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 88/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 88/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 88/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 88/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 92/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 94/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 94/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 94/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 94/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 99/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 99/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 99/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 102/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 102/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 106/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 106/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 109/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 109/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 109/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 112/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 112/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 112/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 112/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 118/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 118/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 118/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 118/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 122/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 122/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 122/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 126/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 126/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 129/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 129/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 132/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 132/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 132/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 132/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 132/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 138/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 138/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 138/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 138/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 143/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 145/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 145/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 145/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 149/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 149/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 149/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 149/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 149/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 3/15050uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 5/15050uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 5/15050uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 9/15050uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 9/15050uceLROnPlateau reducing learning rate to 0.00012052458623657003.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.007713573519140482.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.007713573519140482.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.007713573519140482.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 16/150duceLROnPlateau reducing learning rate to 0.007713573519140482.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 18/150duceLROnPlateau reducing learning rate to 0.007713573519140482.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 18/150duceLROnPlateau reducing learning rate to 0.007713573519140482.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 18/150duceLROnPlateau reducing learning rate to 0.007713573519140482.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 26/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 28/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 28/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 31/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 32/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 35/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 37/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 39/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 41/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 43/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 46/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 48/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 50/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 52/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 55/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 55/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 58/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 58/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 58/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00024104917247314006.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00024104917247314006.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 65/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 65/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 68/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 68/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 71/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 78/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 78/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 78/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 81: ReduceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 84/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 84/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 87/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 87/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 87/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 91/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 92/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 94/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 94/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 97/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 99/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 99/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 99/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 102/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 105/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 105/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 105/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 105/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 112/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 115/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 115/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 115/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 119/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 121/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 121/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 124/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 124/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 124/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 128/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 130/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 130/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 130/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 134/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 136/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 136/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 139/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 139/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 142/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 142/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 145/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 145/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 148/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 148/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 148/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 1/15050uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 1/15050uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 1/15050uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 3/15050uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 6/15050uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 8/15050uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 8/15050uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 11/1500uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 12/1500uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 14/1500uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 14/1500uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 17/1500uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 17/1500uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 20/1500uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 20/1500uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 22/1500uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 22/1500uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 26/1500uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 26/1500uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 29/1500uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 29/1500uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.98 - mse: 0.6431 - root_mean_squared_error: 0.8019  62 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
162/162 [==============================] - 1s 9ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
162/162 [==============================] - 1s 9ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 35/150===========================] - 1s 9ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 37/150===========================] - 1s 9ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 37/150===========================] - 1s 9ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 37/150===========================] - 1s 9ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 41/150===========================] - 1s 9ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 42/150===========================] - 1s 9ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 42/150===========================] - 1s 9ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 42/150===========================] - 1s 9ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 47/150===========================] - 1s 9ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 49/150===========================] - 1s 9ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 49/150===========================] - 1s 9ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0004820983449462801. 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0004820983449462801. 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 55/150duceLROnPlateau reducing learning rate to 0.0004820983449462801. 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 55/150duceLROnPlateau reducing learning rate to 0.0004820983449462801. 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 55/150duceLROnPlateau reducing learning rate to 0.0004820983449462801. 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 59/150duceLROnPlateau reducing learning rate to 0.0004820983449462801. 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 59/150duceLROnPlateau reducing learning rate to 0.0004820983449462801. 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 64/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 64/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 67/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 67/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 70/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 70/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 76/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 76/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 79/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 79/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 81: ReduceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 81: ReduceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 85/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 85/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 88/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 88/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 91/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 92/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 94/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 94/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 97/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 97/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 100/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 100/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 102/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 102/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 106/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 106/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 109/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 109/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 111: ReduceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 111: ReduceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 115/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 115/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 118/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 118/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 121/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 121/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 124/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 126/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 126/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 126/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 130/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 130/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 133/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 135/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 135/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 138/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 138/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 141/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 141/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 141/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 145/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 147/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 147/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 150/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 1/15050duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 1/15050duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 1/15050duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 3/15050duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 6/15050duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 9/15050duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 9/15050duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 9/15050duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 12/1500duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 12/1500duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 16/1500duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 16/1500duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 19/1500duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 19/1500duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.003856786759570241.5.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.003856786759570241.5.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 25/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 25/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 25/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 29/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 29/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0019283933797851205..0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0019283933797851205..0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 35/150duceLROnPlateau reducing learning rate to 0.0019283933797851205..0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 35/150duceLROnPlateau reducing learning rate to 0.0019283933797851205..0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 38/150duceLROnPlateau reducing learning rate to 0.0019283933797851205..0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 38/150duceLROnPlateau reducing learning rate to 0.0019283933797851205..0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 41/150duceLROnPlateau reducing learning rate to 0.0019283933797851205..0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 42/150duceLROnPlateau reducing learning rate to 0.0019283933797851205..0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 44/150duceLROnPlateau reducing learning rate to 0.0019283933797851205..0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 44/150duceLROnPlateau reducing learning rate to 0.0019283933797851205..0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 47/150duceLROnPlateau reducing learning rate to 0.0019283933797851205..0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 47/150duceLROnPlateau reducing learning rate to 0.0019283933797851205..0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 50/150duceLROnPlateau reducing learning rate to 0.0019283933797851205..0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0004820983449462801..0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0004820983449462801..0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 55/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 55/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 58/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 58/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 58/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 64/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 64/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 67/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 67/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 70/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 70/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 76/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 76/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 79/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 79/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 81: ReduceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 81: ReduceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 85/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 87/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 87/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 90/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 90/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 92/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 92/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 96/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 96/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 96/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 100/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 101: ReduceLROnPlateau reducing learning rate to 1.5065573279571254e-05..5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 101: ReduceLROnPlateau reducing learning rate to 1.5065573279571254e-05..5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 105/150duceLROnPlateau reducing learning rate to 1.5065573279571254e-05..5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 105/150duceLROnPlateau reducing learning rate to 1.5065573279571254e-05..5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 108/150duceLROnPlateau reducing learning rate to 1.5065573279571254e-05..5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 108/150duceLROnPlateau reducing learning rate to 1.5065573279571254e-05..5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 111/150duceLROnPlateau reducing learning rate to 1.5065573279571254e-05..5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 112/150duceLROnPlateau reducing learning rate to 1.5065573279571254e-05..5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 114/150duceLROnPlateau reducing learning rate to 1.5065573279571254e-05..5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 114/150duceLROnPlateau reducing learning rate to 1.5065573279571254e-05..5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
 19/162 [==>...........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
 19/162 [==>...........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 120/150..........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 120/150..........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 123/150..........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 125/150..........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 125/150..........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 128/150..........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 128/150..........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 131/150..........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 131/150..........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 131/150..........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 135/150..........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 137/150..........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 137/150..........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 140/150..........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 140/150..........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 143/150..........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 143/150..........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 146/150..........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 146/150..........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 149/150..........................] - ETA: 0s - loss: 0.2306 - mae: 0.4783 - mse: 0.2306 - root_mean_squared_error: 0.48025768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn_adam_0.015427147349193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn_adam_0.015427147349193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn_adam_0.015427147349193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn_adam_0.015427147349193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 3/150rained_models/CNN/models_segments_overlap-cnn_adam_0.015427147349193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 6/150rained_models/CNN/models_segments_overlap-cnn_adam_0.015427147349193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 6/150rained_models/CNN/models_segments_overlap-cnn_adam_0.015427147349193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 9/150rained_models/CNN/models_segments_overlap-cnn_adam_0.015427147349193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 9/150rained_models/CNN/models_segments_overlap-cnn_adam_0.015427147349193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.007713573519140482.9193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.007713573519140482.9193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 15/150duceLROnPlateau reducing learning rate to 0.007713573519140482.9193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 15/150duceLROnPlateau reducing learning rate to 0.007713573519140482.9193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 15/150duceLROnPlateau reducing learning rate to 0.007713573519140482.9193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 19/150duceLROnPlateau reducing learning rate to 0.007713573519140482.9193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 19/150duceLROnPlateau reducing learning rate to 0.007713573519140482.9193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.003856786759570241.9193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 24/150duceLROnPlateau reducing learning rate to 0.003856786759570241.9193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 24/150duceLROnPlateau reducing learning rate to 0.003856786759570241.9193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 27/150duceLROnPlateau reducing learning rate to 0.003856786759570241.9193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 27/150duceLROnPlateau reducing learning rate to 0.003856786759570241.9193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 30/150duceLROnPlateau reducing learning rate to 0.003856786759570241.9193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 30/150duceLROnPlateau reducing learning rate to 0.003856786759570241.9193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 32/150duceLROnPlateau reducing learning rate to 0.003856786759570241.9193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 32/150duceLROnPlateau reducing learning rate to 0.003856786759570241.9193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 32/150duceLROnPlateau reducing learning rate to 0.003856786759570241.9193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 37/150duceLROnPlateau reducing learning rate to 0.003856786759570241.9193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 37/150duceLROnPlateau reducing learning rate to 0.003856786759570241.9193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 40/150duceLROnPlateau reducing learning rate to 0.003856786759570241.9193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0009641966898925602.193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0009641966898925602.193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 45/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 45/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 48/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 48/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 51/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 52/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 52/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 55/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 57/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 57/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 60/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 60/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 62/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 62/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 66/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 66/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 69/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 69/150duceLROnPlateau reducing learning rate to 0.0009641966898925602.193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 71: ReduceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 71: ReduceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 75/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 75/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 78/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 78/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 81/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 82/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 84/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 84/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 87/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 87/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 90/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 90/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 92/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 92/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 96/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 98/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 98/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 101/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 102/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 104/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 104/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 104/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 108/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 108/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 111/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 112/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 114/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 114/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 117/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 117/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 120/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 120/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 123/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 126/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 128/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 131/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 133/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 135/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 137/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 139/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 141/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 141/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 144/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 146/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 146/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 149/150uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 1/15050uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 1/15050uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230429_225124-rmwg565a\files\model-best)... Done. 0.0s
Epoch 6/15050uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 9/15050uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 9/15050uceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.007713573519140482.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 14/150duceLROnPlateau reducing learning rate to 0.007713573519140482.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 17/150duceLROnPlateau reducing learning rate to 0.007713573519140482.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 20/150duceLROnPlateau reducing learning rate to 0.007713573519140482.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 24/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 26/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 29/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 29/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 29/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 32/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 32/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 35/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 37/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 37/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 40/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 42/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 44/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 46/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 46/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 49/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 49/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 49/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 52/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 52/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 56/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 58/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 60/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 60/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 62/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 65/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 65/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 68/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 68/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 71/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 75/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 75/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 78/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 80/150duceLROnPlateau reducing learning rate to 0.003856786759570241.3.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 81: ReduceLROnPlateau reducing learning rate to 6.0262293118285015e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 84/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 84/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 87/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 89/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 89/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 91: ReduceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 94/150duceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 94/150duceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 97/150duceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 99/150duceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 101/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 102/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 102/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 106/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 108/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 112/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 115/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 117/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 117/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 120/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 122/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 124/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 124/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 127/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 129/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 131/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 133/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 133/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 136/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 138/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 140/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 140/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 143/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 145/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 147/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 147/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 150/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 1/15050uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 1/15050uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230429_225124-rmwg565a\files\model-best)... Done. 0.0s
Epoch 3/15050uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 6/15050uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 6/15050uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 10/1500uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.007713573519140482.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.007713573519140482.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 15/150duceLROnPlateau reducing learning rate to 0.007713573519140482.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 17/150duceLROnPlateau reducing learning rate to 0.007713573519140482.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 19/150duceLROnPlateau reducing learning rate to 0.007713573519140482.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 19/150duceLROnPlateau reducing learning rate to 0.007713573519140482.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.003856786759570241.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 24/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 26/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 26/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 29/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 31/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 32/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 34/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 34/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 37/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 39/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 41/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 42/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 42/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 46/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 48/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 50/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0004820983449462801..93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0004820983449462801..93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 55/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 55/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 58/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 60/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00024104917247314006.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00024104917247314006.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 65/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 67/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 69/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 69/150duceLROnPlateau reducing learning rate to 0.00024104917247314006.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 71: ReduceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 74/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 74/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 77/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 77/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 80/150duceLROnPlateau reducing learning rate to 0.00012052458623657003.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 81: ReduceLROnPlateau reducing learning rate to 6.0262293118285015e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 84/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 84/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.93229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
103/162 [==================>...........] - ETA: 0s - loss: 0.0325 - mae: 0.1749 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 89/150===============>...........] - ETA: 0s - loss: 0.0325 - mae: 0.1749 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 89/150===============>...........] - ETA: 0s - loss: 0.0325 - mae: 0.1749 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 91: ReduceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 94/150duceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 96/150duceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 98/150duceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 100/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 100/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 102/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 102/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 106/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 108/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 112/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 115/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 117/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 119/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 119/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 122/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 122/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 125/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 127/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 127/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 130/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 132/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 134/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 136/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 136/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 139/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 141/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 143/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 143/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 146/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 148/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 150/150uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 1/15050uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 1/15050uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 1/15050uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 3/15050uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 6/15050uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 8/15050uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 10/1500uceLROnPlateau reducing learning rate to 3.0131146559142508e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.007713573519140482.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 14/150duceLROnPlateau reducing learning rate to 0.007713573519140482.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 14/150duceLROnPlateau reducing learning rate to 0.007713573519140482.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 14/150duceLROnPlateau reducing learning rate to 0.007713573519140482.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 18/150duceLROnPlateau reducing learning rate to 0.007713573519140482.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 20/150duceLROnPlateau reducing learning rate to 0.007713573519140482.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.003856786759570241.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 24/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 24/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 27/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 29/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 31/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 32/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 32/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 36/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 36/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 39/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 41/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 42/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 45/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 47/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 49/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 49/150duceLROnPlateau reducing learning rate to 0.003856786759570241.5.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0004820983449462801..49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0004820983449462801..49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 55/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 57/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 59/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 61/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 62/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 62/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 66/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 68/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 70/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 70/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 72/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 75/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 75/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 78/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 80/150duceLROnPlateau reducing learning rate to 0.0004820983449462801..49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 81: ReduceLROnPlateau reducing learning rate to 6.0262293118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 84/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 84/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 87/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 89/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 91/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 92/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 94/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 96/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 98/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 98/150duceLROnPlateau reducing learning rate to 6.0262293118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 101/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 102/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 105/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 107/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 107/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 6.0262293118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 111: ReduceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 111: ReduceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 115/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 115/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 118/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 118/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 121/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 123/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 125/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 127/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 127/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 130/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 132/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 134/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 136/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 136/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 139/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 139/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 142/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 144/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 146/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 148/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
Epoch 148/150duceLROnPlateau reducing learning rate to 1e-05.93118285015e-05.49 - mse: 0.0325 - root_mean_squared_error: 0.1803pochs/model_5.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn_adam_0.015427147349193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_9.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn_adam_0.015427147349193229LR_[31]CHN_64CNNI_24BS_1DU_10P_val_lossM_150epochs/model_9.h5 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0039e-05