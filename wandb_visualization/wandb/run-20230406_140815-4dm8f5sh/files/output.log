Y [[0.396]
 [0.314]
 [0.326]
 ...
 [0.32 ]
 [0.374]
 [0.386]]
X [[0.01118243 0.01738499 0.01228667 ... 0.00130245 0.01862108 0.01527098]
 [0.02270906 0.0097482  0.02967412 ... 0.03415757 0.01340192 0.0044837 ]
 [0.01650482 0.00882636 0.0223758  ... 0.02595569 0.00470275 0.00906345]
 ...
 [0.00079213 0.00058654 0.0009241  ... 0.00101096 0.00056759 0.00053519]
 [0.00334416 0.00371257 0.0040112  ... 0.00257067 0.00239752 0.00563637]
 [0.00320211 0.00400127 0.00362818 ... 0.00174091 0.00353137 0.00485635]]
Epoch 1/10
86/86 [==============================] - ETA: 0s - loss: 14.6272 - mae: 0.1873 - mse: 0.0428
86/86 [==============================] - 2s 19ms/step - loss: 14.6272 - mae: 0.1873 - mse: 0.0428 - val_loss: 13.8812 - val_mae: 0.0619 - val_mse: 0.0049 - lr: 1.0000e-04
Epoch 2/10
73/86 [========================>.....] - ETA: 0s - loss: 13.3510 - mae: 0.0304 - mse: 0.0015
86/86 [==============================] - 1s 17ms/step - loss: 13.2659 - mae: 0.0287 - mse: 0.0014 - val_loss: 12.6563 - val_mae: 0.0203 - val_mse: 6.2876e-04 - lr: 1.0000e-04
Epoch 3/10
84/86 [============================>.] - ETA: 0s - loss: 12.1335 - mae: 0.0177 - mse: 4.9383e-04
86/86 [==============================] - 1s 16ms/step - loss: 12.1265 - mae: 0.0177 - mse: 4.9250e-04 - val_loss: 11.6007 - val_mae: 0.0184 - val_mse: 5.1113e-04 - lr: 1.0000e-04
Epoch 4/10
86/86 [==============================] - ETA: 0s - loss: 11.1453 - mae: 0.0168 - mse: 4.5458e-04
86/86 [==============================] - 2s 19ms/step - loss: 11.1453 - mae: 0.0168 - mse: 4.5458e-04 - val_loss: 10.6946 - val_mae: 0.0189 - val_mse: 5.4254e-04 - lr: 1.0000e-04
Epoch 5/10
61/86 [====================>.........] - ETA: 0s - loss: 10.4135 - mae: 0.0169 - mse: 4.5442e-04
86/86 [==============================] - 1s 15ms/step - loss: 10.3062 - mae: 0.0169 - mse: 4.5993e-04 - val_loss: 9.9227 - val_mae: 0.0177 - val_mse: 4.9881e-04 - lr: 1.0000e-04
Epoch 6/10
71/86 [=======================>......] - ETA: 0s - loss: 9.6468 - mae: 0.0176 - mse: 4.8438e-04
Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\wandb\run-20230406_140815-4dm8f5sh\files\model-best)... Done. 0.0s
86/86 [==============================] - 1s 16ms/step - loss: 9.5940 - mae: 0.0175 - mse: 4.8044e-04 - val_loss: 9.2702 - val_mae: 0.0195 - val_mse: 5.6751e-04 - lr: 1.0000e-04
Epoch 7/10
79/86 [==========================>...] - ETA: 0s - loss: 9.1372 - mae: 0.0174 - mse: 4.8016e-04
86/86 [==============================] - 2s 20ms/step - loss: 9.1270 - mae: 0.0173 - mse: 4.7770e-04 - val_loss: 8.9819 - val_mae: 0.0186 - val_mse: 5.3027e-04 - lr: 5.0000e-05
Epoch 8/10
77/86 [=========================>....] - ETA: 0s - loss: 8.8632 - mae: 0.0174 - mse: 4.7963e-04
86/86 [==============================] - 1s 17ms/step - loss: 8.8508 - mae: 0.0176 - mse: 4.8634e-04 - val_loss: 8.7182 - val_mae: 0.0185 - val_mse: 5.2567e-04 - lr: 5.0000e-05
Epoch 9/10
83/86 [===========================>..] - ETA: 0s - loss: 8.6015 - mae: 0.0178 - mse: 4.9610e-04
Epoch 9: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\wandb\run-20230406_140815-4dm8f5sh\files\model-best)... Done. 0.0s
86/86 [==============================] - 1s 17ms/step - loss: 8.5985 - mae: 0.0178 - mse: 4.9504e-04 - val_loss: 8.4775 - val_mae: 0.0221 - val_mse: 7.2274e-04 - lr: 5.0000e-05
Epoch 10/10
79/86 [==========================>...] - ETA: 0s - loss: 8.4257 - mae: 0.0178 - mse: 4.9732e-04
86/86 [==============================] - 1s 17ms/step - loss: 8.4217 - mae: 0.0177 - mse: 4.9589e-04 - val_loss: 8.3645 - val_mae: 0.0186 - val_mse: 5.3461e-04 - lr: 2.5000e-05
>Saved models_no_overlap_30.0_10epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])