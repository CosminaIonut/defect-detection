(5161, 8)
(2212, 8)
Epoch 1/20
  1/130 [..............................] - ETA: 2:43 - loss: 0.2065 - mae: 0.3641 - mse: 0.2065 - root_mean_squared_error: 0.4545
WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.


129/130 [============================>.] - ETA: 0s - loss: 0.0084 - mae: 0.0635 - mse: 0.0084 - root_mean_squared_error: 0.0914
130/130 [==============================] - 7s 47ms/step - loss: 0.0084 - mae: 0.0635 - mse: 0.0084 - root_mean_squared_error: 0.0914 - val_loss: 0.0035 - val_mae: 0.0510 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0590 - lr: 0.0554
Epoch 2/20
130/130 [==============================] - ETA: 0s - loss: 0.0035 - mae: 0.0509 - mse: 0.0035 - root_mean_squared_error: 0.0590
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.027698896825313568.
130/130 [==============================] - 3s 26ms/step - loss: 0.0035 - mae: 0.0509 - mse: 0.0035 - root_mean_squared_error: 0.0590 - val_loss: 0.0036 - val_mae: 0.0512 - val_mse: 0.0036 - val_root_mean_squared_error: 0.0599 - lr: 0.0554
Epoch 3/20

128/130 [============================>.] - ETA: 0s - loss: 0.0035 - mae: 0.0509 - mse: 0.0035 - root_mean_squared_error: 0.0590
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.013849448412656784.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230506_221813-tgot3mn0\files\model-best)... Done. 0.0s
130/130 [==============================] - 5s 41ms/step - loss: 0.0035 - mae: 0.0509 - mse: 0.0035 - root_mean_squared_error: 0.0589 - val_loss: 0.0035 - val_mae: 0.0511 - val_mse: 0.0035 - val_root_mean_squared_error: 0.0589 - lr: 0.0277
Epoch 4/20
129/130 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - root_mean_squared_error: 0.0585
130/130 [==============================] - 6s 43ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0580 - lr: 0.0138
Epoch 5/20
128/130 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0581
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.006924724206328392.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230506_221813-tgot3mn0\files\model-best)... Done. 0.0s
130/130 [==============================] - 6s 44ms/step - loss: 0.0034 - mae: 0.0504 - mse: 0.0034 - root_mean_squared_error: 0.0580 - val_loss: 0.0033 - val_mae: 0.0502 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0575 - lr: 0.0138
Epoch 6/20
129/130 [============================>.] - ETA: 0s - loss: 0.0033 - mae: 0.0502 - mse: 0.0033 - root_mean_squared_error: 0.0577
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.003462362103164196.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230506_221813-tgot3mn0\files\model-best)... Done. 0.0s
130/130 [==============================] - 6s 43ms/step - loss: 0.0033 - mae: 0.0502 - mse: 0.0033 - root_mean_squared_error: 0.0577 - val_loss: 0.0033 - val_mae: 0.0501 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0574 - lr: 0.0069
Epoch 7/20
128/130 [============================>.] - ETA: 0s - loss: 0.0033 - mae: 0.0502 - mse: 0.0033 - root_mean_squared_error: 0.0576
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.001731181051582098.
130/130 [==============================] - 3s 26ms/step - loss: 0.0033 - mae: 0.0502 - mse: 0.0033 - root_mean_squared_error: 0.0576 - val_loss: 0.0033 - val_mae: 0.0501 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0576 - lr: 0.0035
Epoch 8/20
130/130 [==============================] - ETA: 0s - loss: 0.0033 - mae: 0.0502 - mse: 0.0033 - root_mean_squared_error: 0.0576
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.000865590525791049.
130/130 [==============================] - 3s 25ms/step - loss: 0.0033 - mae: 0.0502 - mse: 0.0033 - root_mean_squared_error: 0.0576 - val_loss: 0.0033 - val_mae: 0.0500 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0575 - lr: 0.0017
Epoch 9/20

128/130 [============================>.] - ETA: 0s - loss: 0.0033 - mae: 0.0502 - mse: 0.0033 - root_mean_squared_error: 0.0575
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0004327952628955245.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230506_221813-tgot3mn0\files\model-best)... Done. 0.0s
130/130 [==============================] - 6s 43ms/step - loss: 0.0033 - mae: 0.0502 - mse: 0.0033 - root_mean_squared_error: 0.0575 - val_loss: 0.0033 - val_mae: 0.0501 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0573 - lr: 8.6559e-04
Epoch 10/20
128/130 [============================>.] - ETA: 0s - loss: 0.0033 - mae: 0.0502 - mse: 0.0033 - root_mean_squared_error: 0.0575
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00021639763144776225.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230506_221813-tgot3mn0\files\model-best)... Done. 0.0s
130/130 [==============================] - 6s 43ms/step - loss: 0.0033 - mae: 0.0502 - mse: 0.0033 - root_mean_squared_error: 0.0575 - val_loss: 0.0033 - val_mae: 0.0500 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0573 - lr: 4.3280e-04
Epoch 11/20
130/130 [==============================] - ETA: 0s - loss: 0.0033 - mae: 0.0501 - mse: 0.0033 - root_mean_squared_error: 0.0575
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00010819881572388113.
130/130 [==============================] - 4s 28ms/step - loss: 0.0033 - mae: 0.0501 - mse: 0.0033 - root_mean_squared_error: 0.0575 - val_loss: 0.0033 - val_mae: 0.0501 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0573 - lr: 2.1640e-04
Epoch 12/20

130/130 [==============================] - ETA: 0s - loss: 0.0033 - mae: 0.0502 - mse: 0.0033 - root_mean_squared_error: 0.0575
Epoch 12: ReduceLROnPlateau reducing learning rate to 5.409940786194056e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230506_221813-tgot3mn0\files\model-best)... Done. 0.0s
130/130 [==============================] - 6s 49ms/step - loss: 0.0033 - mae: 0.0502 - mse: 0.0033 - root_mean_squared_error: 0.0575 - val_loss: 0.0033 - val_mae: 0.0501 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0573 - lr: 1.0820e-04
Epoch 13/20
129/130 [============================>.] - ETA: 0s - loss: 0.0033 - mae: 0.0502 - mse: 0.0033 - root_mean_squared_error: 0.0575
Epoch 13: ReduceLROnPlateau reducing learning rate to 2.704970393097028e-05.
130/130 [==============================] - 3s 26ms/step - loss: 0.0033 - mae: 0.0501 - mse: 0.0033 - root_mean_squared_error: 0.0575 - val_loss: 0.0033 - val_mae: 0.0500 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0573 - lr: 5.4099e-05
Epoch 14/20
128/130 [============================>.] - ETA: 0s - loss: 0.0033 - mae: 0.0501 - mse: 0.0033 - root_mean_squared_error: 0.0575
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.352485196548514e-05.
130/130 [==============================] - 3s 25ms/step - loss: 0.0033 - mae: 0.0501 - mse: 0.0033 - root_mean_squared_error: 0.0575 - val_loss: 0.0033 - val_mae: 0.0500 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0573 - lr: 2.7050e-05
Epoch 15/20

128/130 [============================>.] - ETA: 0s - loss: 0.0033 - mae: 0.0502 - mse: 0.0033 - root_mean_squared_error: 0.0575
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230506_221813-tgot3mn0\files\model-best)... Done. 0.0s
130/130 [==============================] - 5s 42ms/step - loss: 0.0033 - mae: 0.0501 - mse: 0.0033 - root_mean_squared_error: 0.0575 - val_loss: 0.0033 - val_mae: 0.0500 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0573 - lr: 1.3525e-05
Epoch 16/20
130/130 [==============================] - 3s 26ms/step - loss: 0.0033 - mae: 0.0501 - mse: 0.0033 - root_mean_squared_error: 0.0575 - val_loss: 0.0033 - val_mae: 0.0500 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0573 - lr: 1.0000e-05
Epoch 17/20

128/130 [============================>.] - ETA: 0s - loss: 0.0033 - mae: 0.0501 - mse: 0.0033 - root_mean_squared_error: 0.0574
130/130 [==============================] - 5s 41ms/step - loss: 0.0033 - mae: 0.0501 - mse: 0.0033 - root_mean_squared_error: 0.0575 - val_loss: 0.0033 - val_mae: 0.0501 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0573 - lr: 1.0000e-05
Epoch 18/20
129/130 [============================>.] - ETA: 0s - loss: 0.0033 - mae: 0.0502 - mse: 0.0033 - root_mean_squared_error: 0.0575
130/130 [==============================] - 6s 47ms/step - loss: 0.0033 - mae: 0.0502 - mse: 0.0033 - root_mean_squared_error: 0.0575 - val_loss: 0.0033 - val_mae: 0.0501 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0573 - lr: 1.0000e-05
Epoch 19/20
128/130 [============================>.] - ETA: 0s - loss: 0.0033 - mae: 0.0501 - mse: 0.0033 - root_mean_squared_error: 0.0574
130/130 [==============================] - 6s 43ms/step - loss: 0.0033 - mae: 0.0502 - mse: 0.0033 - root_mean_squared_error: 0.0575 - val_loss: 0.0033 - val_mae: 0.0501 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0573 - lr: 1.0000e-05
Epoch 20/20
130/130 [==============================] - 3s 26ms/step - loss: 0.0033 - mae: 0.0501 - mse: 0.0033 - root_mean_squared_error: 0.0575 - val_loss: 0.0033 - val_mae: 0.0501 - val_mse: 0.0033 - val_root_mean_squared_error: 0.0573 - lr: 1.0000e-05
>Saved ../trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
(7716, 8)
(3307, 8)
Epoch 1/20
 31/193 [===>..........................] - ETA: 3s - loss: 0.0117 - mae: 0.0884 - mse: 0.0117 - root_mean_squared_error: 0.1080
WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.


193/193 [==============================] - 6s 26ms/step - loss: 0.0084 - mae: 0.0779 - mse: 0.0084 - root_mean_squared_error: 0.0918 - val_loss: 0.0079 - val_mae: 0.0769 - val_mse: 0.0079 - val_root_mean_squared_error: 0.0890 - lr: 0.0554
Epoch 2/20

193/193 [==============================] - ETA: 0s - loss: 0.0079 - mae: 0.0763 - mse: 0.0079 - root_mean_squared_error: 0.0888
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.027698896825313568.
193/193 [==============================] - 5s 25ms/step - loss: 0.0079 - mae: 0.0763 - mse: 0.0079 - root_mean_squared_error: 0.0888 - val_loss: 0.0079 - val_mae: 0.0770 - val_mse: 0.0079 - val_root_mean_squared_error: 0.0890 - lr: 0.0554
Epoch 3/20

192/193 [============================>.] - ETA: 0s - loss: 0.0078 - mae: 0.0759 - mse: 0.0078 - root_mean_squared_error: 0.0882
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.013849448412656784.
193/193 [==============================] - 5s 25ms/step - loss: 0.0078 - mae: 0.0758 - mse: 0.0078 - root_mean_squared_error: 0.0881 - val_loss: 0.0083 - val_mae: 0.0781 - val_mse: 0.0083 - val_root_mean_squared_error: 0.0911 - lr: 0.0277
Epoch 4/20


193/193 [==============================] - 5s 25ms/step - loss: 0.0076 - mae: 0.0754 - mse: 0.0076 - root_mean_squared_error: 0.0874 - val_loss: 0.0077 - val_mae: 0.0760 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0876 - lr: 0.0138
Epoch 5/20

191/193 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0754 - mse: 0.0076 - root_mean_squared_error: 0.0874
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.006924724206328392.
193/193 [==============================] - 5s 25ms/step - loss: 0.0076 - mae: 0.0754 - mse: 0.0076 - root_mean_squared_error: 0.0874 - val_loss: 0.0077 - val_mae: 0.0762 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0880 - lr: 0.0138
Epoch 6/20


192/193 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0872
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.003462362103164196.
193/193 [==============================] - 5s 25ms/step - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0069
Epoch 7/20

192/193 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.001731181051582098.
193/193 [==============================] - 5s 24ms/step - loss: 0.0076 - mae: 0.0751 - mse: 0.0076 - root_mean_squared_error: 0.0870 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0035
Epoch 8/20

191/193 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0750 - mse: 0.0075 - root_mean_squared_error: 0.0868
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.000865590525791049.
193/193 [==============================] - 5s 24ms/step - loss: 0.0075 - mae: 0.0751 - mse: 0.0075 - root_mean_squared_error: 0.0869 - val_loss: 0.0076 - val_mae: 0.0757 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0017
Epoch 9/20
129/193 [===================>..........] - ETA: 1s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0874
191/193 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0751 - mse: 0.0075 - root_mean_squared_error: 0.0869
 76/193 [==========>...................] - ETA: 2s - loss: 0.0075 - mae: 0.0750 - mse: 0.0075 - root_mean_squared_error: 0.0868.0868 - val_loss: 0.0076 - val_mae: 0.0757 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 8.6559e-04
171/193 [=========================>....] - ETA: 0s - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0871.0868 - val_loss: 0.0076 - val_mae: 0.0757 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 8.6559e-04
 49/193 [======>.......................] - ETA: 3s - loss: 0.0075 - mae: 0.0743 - mse: 0.0075 - root_mean_squared_error: 0.0863.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 4.3280e-04
144/193 [=====================>........] - ETA: 1s - loss: 0.0075 - mae: 0.0749 - mse: 0.0075 - root_mean_squared_error: 0.0866.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 4.3280e-04
 21/193 [==>...........................] - ETA: 3s - loss: 0.0078 - mae: 0.0772 - mse: 0.0078 - root_mean_squared_error: 0.0885.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 2.1640e-04
116/193 [=================>............] - ETA: 1s - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0870.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 2.1640e-04
192/193 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0750 - mse: 0.0075 - root_mean_squared_error: 0.0868.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 2.1640e-04
 91/193 [=============>................] - ETA: 2s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0870.0868 - val_loss: 0.0076 - val_mae: 0.0757 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0820e-04
186/193 [===========================>..] - ETA: 0s - loss: 0.0075 - mae: 0.0750 - mse: 0.0075 - root_mean_squared_error: 0.0868.0868 - val_loss: 0.0076 - val_mae: 0.0757 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0820e-04
 39/193 [=====>........................] - ETA: 3s - loss: 0.0076 - mae: 0.0754 - mse: 0.0076 - root_mean_squared_error: 0.0870.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 5.4099e-05
128/193 [==================>...........] - ETA: 1s - loss: 0.0076 - mae: 0.0751 - mse: 0.0076 - root_mean_squared_error: 0.0870.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 5.4099e-05
  7/193 [>.............................] - ETA: 4s - loss: 0.0076 - mae: 0.0752 - mse: 0.0076 - root_mean_squared_error: 0.0873.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 2.7050e-05
105/193 [===============>..............] - ETA: 1s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0871.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 2.7050e-05
191/193 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0750 - mse: 0.0075 - root_mean_squared_error: 0.0868.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 2.7050e-05
 78/193 [===========>..................] - ETA: 2s - loss: 0.0074 - mae: 0.0744 - mse: 0.0074 - root_mean_squared_error: 0.0862.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.3525e-05
175/193 [==========================>...] - ETA: 0s - loss: 0.0075 - mae: 0.0749 - mse: 0.0075 - root_mean_squared_error: 0.0866.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.3525e-05
 43/193 [=====>........................] - ETA: 3s - loss: 0.0075 - mae: 0.0749 - mse: 0.0075 - root_mean_squared_error: 0.0868.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
129/193 [===================>..........] - ETA: 1s - loss: 0.0075 - mae: 0.0749 - mse: 0.0075 - root_mean_squared_error: 0.0866.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
178/193 [==========================>...] - ETA: 0s - loss: 0.0075 - mae: 0.0749 - mse: 0.0075 - root_mean_squared_error: 0.0867.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
 36/193 [====>.........................] - ETA: 4s - loss: 0.0076 - mae: 0.0759 - mse: 0.0076 - root_mean_squared_error: 0.0874.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
117/193 [=================>............] - ETA: 1s - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0869.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
192/193 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0750 - mse: 0.0075 - root_mean_squared_error: 0.0868.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
 51/193 [======>.......................] - ETA: 4s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0872.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
122/193 [=================>............] - ETA: 2s - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0870.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
192/193 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0750 - mse: 0.0075 - root_mean_squared_error: 0.0868.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
 55/193 [=======>......................] - ETA: 3s - loss: 0.0076 - mae: 0.0754 - mse: 0.0076 - root_mean_squared_error: 0.0871.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
148/193 [======================>.......] - ETA: 1s - loss: 0.0075 - mae: 0.0751 - mse: 0.0075 - root_mean_squared_error: 0.0868.0868 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])8 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])8 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
(3307, 8)(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])8 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
 67/193 [=========>....................] - ETA: 2s - loss: 0.0229 - mae: 0.1057 - mse: 0.0229 - root_mean_squared_error: 0.1512  ])8 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
160/193 [=======================>......] - ETA: 0s - loss: 0.0140 - mae: 0.0882 - mse: 0.0140 - root_mean_squared_error: 0.1185  ])8 - val_loss: 0.0076 - val_mae: 0.0758 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
 15/193 [=>............................] - ETA: 4s - loss: 0.0086 - mae: 0.0802 - mse: 0.0086 - root_mean_squared_error: 0.0929.1139 - val_loss: 0.0081 - val_mae: 0.0769 - val_mse: 0.0081 - val_root_mean_squared_error: 0.0897 - lr: 0.0554e-05
108/193 [===============>..............] - ETA: 1s - loss: 0.0079 - mae: 0.0766 - mse: 0.0079 - root_mean_squared_error: 0.0886.1139 - val_loss: 0.0081 - val_mae: 0.0769 - val_mse: 0.0081 - val_root_mean_squared_error: 0.0897 - lr: 0.0554e-05
192/193 [============================>.] - ETA: 0s - loss: 0.0078 - mae: 0.0765 - mse: 0.0078 - root_mean_squared_error: 0.0886.1139 - val_loss: 0.0081 - val_mae: 0.0769 - val_mse: 0.0081 - val_root_mean_squared_error: 0.0897 - lr: 0.0554e-05
 76/193 [==========>...................] - ETA: 2s - loss: 0.0081 - mae: 0.0780 - mse: 0.0081 - root_mean_squared_error: 0.0900.0886 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0554e-05
169/193 [=========================>....] - ETA: 0s - loss: 0.0079 - mae: 0.0768 - mse: 0.0079 - root_mean_squared_error: 0.0888.0886 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0554e-05
 43/193 [=====>........................] - ETA: 3s - loss: 0.0074 - mae: 0.0745 - mse: 0.0074 - root_mean_squared_error: 0.0862.0885 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 0.0554e-05
136/193 [====================>.........] - ETA: 1s - loss: 0.0078 - mae: 0.0765 - mse: 0.0078 - root_mean_squared_error: 0.0884.0885 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 0.0554e-05
 13/193 [=>............................] - ETA: 4s - loss: 0.0074 - mae: 0.0739 - mse: 0.0074 - root_mean_squared_error: 0.0862.0887 - val_loss: 0.0079 - val_mae: 0.0764 - val_mse: 0.0079 - val_root_mean_squared_error: 0.0887 - lr: 0.0277e-05
103/193 [===============>..............] - ETA: 2s - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0869.0887 - val_loss: 0.0079 - val_mae: 0.0764 - val_mse: 0.0079 - val_root_mean_squared_error: 0.0887 - lr: 0.0277e-05
171/193 [=========================>....] - ETA: 0s - loss: 0.0076 - mae: 0.0759 - mse: 0.0076 - root_mean_squared_error: 0.0874.0887 - val_loss: 0.0079 - val_mae: 0.0764 - val_mse: 0.0079 - val_root_mean_squared_error: 0.0887 - lr: 0.0277e-05
 43/193 [=====>........................] - ETA: 3s - loss: 0.0075 - mae: 0.0756 - mse: 0.0075 - root_mean_squared_error: 0.0867.0874 - val_loss: 0.0078 - val_mae: 0.0761 - val_mse: 0.0078 - val_root_mean_squared_error: 0.0882 - lr: 0.0138e-05
134/193 [===================>..........] - ETA: 1s - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0870.0874 - val_loss: 0.0078 - val_mae: 0.0761 - val_mse: 0.0078 - val_root_mean_squared_error: 0.0882 - lr: 0.0138e-05
  3/193 [..............................] - ETA: 4s - loss: 0.0067 - mae: 0.0703 - mse: 0.0067 - root_mean_squared_error: 0.0817.0872 - val_loss: 0.0076 - val_mae: 0.0755 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0069e-05
 89/193 [============>.................] - ETA: 2s - loss: 0.0077 - mae: 0.0762 - mse: 0.0077 - root_mean_squared_error: 0.0875.0872 - val_loss: 0.0076 - val_mae: 0.0755 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0069e-05
179/193 [==========================>...] - ETA: 0s - loss: 0.0076 - mae: 0.0758 - mse: 0.0076 - root_mean_squared_error: 0.0871.0872 - val_loss: 0.0076 - val_mae: 0.0755 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0069e-05
 50/193 [======>.......................] - ETA: 3s - loss: 0.0075 - mae: 0.0754 - mse: 0.0075 - root_mean_squared_error: 0.0867.0871 - val_loss: 0.0076 - val_mae: 0.0755 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0035e-05
137/193 [====================>.........] - ETA: 1s - loss: 0.0076 - mae: 0.0759 - mse: 0.0076 - root_mean_squared_error: 0.0870.0871 - val_loss: 0.0076 - val_mae: 0.0755 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0035e-05
 10/193 [>.............................] - ETA: 4s - loss: 0.0080 - mae: 0.0783 - mse: 0.0080 - root_mean_squared_error: 0.0892.0870 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 0.0017e-05
100/193 [==============>...............] - ETA: 2s - loss: 0.0077 - mae: 0.0768 - mse: 0.0077 - root_mean_squared_error: 0.0879.0870 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 0.0017e-05
187/193 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0757 - mse: 0.0075 - root_mean_squared_error: 0.0869.0870 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 0.0017e-05
 58/193 [========>.....................] - ETA: 3s - loss: 0.0076 - mae: 0.0764 - mse: 0.0076 - root_mean_squared_error: 0.0872.0869 - val_loss: 0.0075 - val_mae: 0.0754 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0868 - lr: 8.6559e-04
146/193 [=====================>........] - ETA: 1s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0869.0869 - val_loss: 0.0075 - val_mae: 0.0754 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0868 - lr: 8.6559e-04
 19/193 [=>............................] - ETA: 3s - loss: 0.0079 - mae: 0.0776 - mse: 0.0079 - root_mean_squared_error: 0.0888.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 4.3280e-04
 86/193 [============>.................] - ETA: 2s - loss: 0.0076 - mae: 0.0763 - mse: 0.0076 - root_mean_squared_error: 0.0874.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 4.3280e-04
176/193 [==========================>...] - ETA: 0s - loss: 0.0076 - mae: 0.0758 - mse: 0.0076 - root_mean_squared_error: 0.0869.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 4.3280e-04
 49/193 [======>.......................] - ETA: 3s - loss: 0.0075 - mae: 0.0756 - mse: 0.0075 - root_mean_squared_error: 0.0867.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 2.1640e-04
135/193 [===================>..........] - ETA: 1s - loss: 0.0075 - mae: 0.0757 - mse: 0.0075 - root_mean_squared_error: 0.0869.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 2.1640e-04
  9/193 [>.............................] - ETA: 4s - loss: 0.0076 - mae: 0.0763 - mse: 0.0076 - root_mean_squared_error: 0.0872.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.0820e-04
 95/193 [=============>................] - ETA: 2s - loss: 0.0076 - mae: 0.0758 - mse: 0.0076 - root_mean_squared_error: 0.0869.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.0820e-04
171/193 [=========================>....] - ETA: 0s - loss: 0.0075 - mae: 0.0753 - mse: 0.0075 - root_mean_squared_error: 0.0865.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.0820e-04
 19/193 [=>............................] - ETA: 5s - loss: 0.0078 - mae: 0.0770 - mse: 0.0078 - root_mean_squared_error: 0.0882.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 5.4099e-05
 76/193 [==========>...................] - ETA: 4s - loss: 0.0077 - mae: 0.0769 - mse: 0.0077 - root_mean_squared_error: 0.0880.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 5.4099e-05
153/193 [======================>.......] - ETA: 1s - loss: 0.0076 - mae: 0.0761 - mse: 0.0076 - root_mean_squared_error: 0.0873.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 5.4099e-05
 26/193 [===>..........................] - ETA: 4s - loss: 0.0075 - mae: 0.0761 - mse: 0.0075 - root_mean_squared_error: 0.0868.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 2.7050e-05
 92/193 [=============>................] - ETA: 2s - loss: 0.0074 - mae: 0.0746 - mse: 0.0074 - root_mean_squared_error: 0.0858.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 2.7050e-05
181/193 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0758 - mse: 0.0076 - root_mean_squared_error: 0.0870.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 2.7050e-05
 55/193 [=======>......................] - ETA: 3s - loss: 0.0075 - mae: 0.0756 - mse: 0.0075 - root_mean_squared_error: 0.0868.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.3525e-05
131/193 [===================>..........] - ETA: 1s - loss: 0.0076 - mae: 0.0759 - mse: 0.0076 - root_mean_squared_error: 0.0870.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.3525e-05
188/193 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0758 - mse: 0.0076 - root_mean_squared_error: 0.0870.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.3525e-05
 52/193 [=======>......................] - ETA: 3s - loss: 0.0076 - mae: 0.0761 - mse: 0.0076 - root_mean_squared_error: 0.0871.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.0000e-05
140/193 [====================>.........] - ETA: 1s - loss: 0.0076 - mae: 0.0758 - mse: 0.0076 - root_mean_squared_error: 0.0871.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.0000e-05
 12/193 [>.............................] - ETA: 4s - loss: 0.0078 - mae: 0.0770 - mse: 0.0078 - root_mean_squared_error: 0.0882.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.0000e-05
 99/193 [==============>...............] - ETA: 2s - loss: 0.0076 - mae: 0.0762 - mse: 0.0076 - root_mean_squared_error: 0.0872.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.0000e-05
173/193 [=========================>....] - ETA: 0s - loss: 0.0076 - mae: 0.0760 - mse: 0.0076 - root_mean_squared_error: 0.0872.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.0000e-05
 19/193 [=>............................] - ETA: 6s - loss: 0.0077 - mae: 0.0760 - mse: 0.0077 - root_mean_squared_error: 0.0878.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.0000e-05
 97/193 [==============>...............] - ETA: 2s - loss: 0.0075 - mae: 0.0752 - mse: 0.0075 - root_mean_squared_error: 0.0865.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.0000e-05
163/193 [========================>.....] - ETA: 0s - loss: 0.0076 - mae: 0.0758 - mse: 0.0076 - root_mean_squared_error: 0.0870.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.0000e-05
 33/193 [====>.........................] - ETA: 3s - loss: 0.0077 - mae: 0.0769 - mse: 0.0077 - root_mean_squared_error: 0.0878.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.0000e-05
122/193 [=================>............] - ETA: 1s - loss: 0.0076 - mae: 0.0760 - mse: 0.0076 - root_mean_squared_error: 0.0872.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.0000e-05
192/193 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0869.0869 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])9 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])9 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.0000e-05
WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
  5/193 [..............................] - ETA: 4s - loss: 0.0663 - mae: 0.1994 - mse: 0.0663 - root_mean_squared_error: 0.2574  ])9 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.0000e-05
 92/193 [=============>................] - ETA: 2s - loss: 0.0131 - mae: 0.0900 - mse: 0.0131 - root_mean_squared_error: 0.1146  ])9 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.0000e-05
177/193 [==========================>...] - ETA: 0s - loss: 0.0105 - mae: 0.0830 - mse: 0.0105 - root_mean_squared_error: 0.1025  ])9 - val_loss: 0.0075 - val_mae: 0.0753 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0866 - lr: 1.0000e-05
 37/193 [====>.........................] - ETA: 3s - loss: 0.0077 - mae: 0.0756 - mse: 0.0077 - root_mean_squared_error: 0.0879.1014 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0554e-05
127/193 [==================>...........] - ETA: 1s - loss: 0.0077 - mae: 0.0760 - mse: 0.0077 - root_mean_squared_error: 0.0880.1014 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0554e-05
191/193 [============================>.] - ETA: 0s - loss: 0.0078 - mae: 0.0763 - mse: 0.0078 - root_mean_squared_error: 0.0883.1014 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0554e-05
 87/193 [============>.................] - ETA: 2s - loss: 0.0077 - mae: 0.0760 - mse: 0.0077 - root_mean_squared_error: 0.0878.0883 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0554e-05
173/193 [=========================>....] - ETA: 0s - loss: 0.0077 - mae: 0.0759 - mse: 0.0077 - root_mean_squared_error: 0.0878.0883 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0554e-05
 44/193 [=====>........................] - ETA: 3s - loss: 0.0079 - mae: 0.0764 - mse: 0.0079 - root_mean_squared_error: 0.0886.0880 - val_loss: 0.0085 - val_mae: 0.0784 - val_mse: 0.0085 - val_root_mean_squared_error: 0.0919 - lr: 0.0277e-05
133/193 [===================>..........] - ETA: 1s - loss: 0.0077 - mae: 0.0759 - mse: 0.0077 - root_mean_squared_error: 0.0877.0880 - val_loss: 0.0085 - val_mae: 0.0784 - val_mse: 0.0085 - val_root_mean_squared_error: 0.0919 - lr: 0.0277e-05
  6/193 [..............................] - ETA: 4s - loss: 0.0078 - mae: 0.0763 - mse: 0.0078 - root_mean_squared_error: 0.0885.0875 - val_loss: 0.0077 - val_mae: 0.0760 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0879 - lr: 0.0138e-05
 89/193 [============>.................] - ETA: 2s - loss: 0.0075 - mae: 0.0750 - mse: 0.0075 - root_mean_squared_error: 0.0867.0875 - val_loss: 0.0077 - val_mae: 0.0760 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0879 - lr: 0.0138e-05
133/193 [===================>..........] - ETA: 1s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0873.0875 - val_loss: 0.0077 - val_mae: 0.0760 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0879 - lr: 0.0138e-05
193/193 [==============================] - ETA: 0s - loss: 0.0076 - mae: 0.0758 - mse: 0.0076 - root_mean_squared_error: 0.0874.0875 - val_loss: 0.0077 - val_mae: 0.0760 - val_mse: 0.0077 - val_root_mean_squared_error: 0.0879 - lr: 0.0138e-05
 46/193 [======>.......................] - ETA: 4s - loss: 0.0075 - mae: 0.0751 - mse: 0.0075 - root_mean_squared_error: 0.0866.0874 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0069e-05
137/193 [====================>.........] - ETA: 1s - loss: 0.0076 - mae: 0.0759 - mse: 0.0076 - root_mean_squared_error: 0.0874.0874 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 0.0069e-05
 10/193 [>.............................] - ETA: 4s - loss: 0.0071 - mae: 0.0729 - mse: 0.0071 - root_mean_squared_error: 0.0844.0873 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 0.0035e-05
 96/193 [=============>................] - ETA: 2s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0871.0873 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 0.0035e-05
183/193 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0758 - mse: 0.0076 - root_mean_squared_error: 0.0872.0873 - val_loss: 0.0076 - val_mae: 0.0753 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0869 - lr: 0.0035e-05
 39/193 [=====>........................] - ETA: 4s - loss: 0.0075 - mae: 0.0747 - mse: 0.0075 - root_mean_squared_error: 0.0864.0872 - val_loss: 0.0076 - val_mae: 0.0755 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0017e-05
 97/193 [==============>...............] - ETA: 3s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871.0872 - val_loss: 0.0076 - val_mae: 0.0755 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0017e-05
168/193 [=========================>....] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0870.0872 - val_loss: 0.0076 - val_mae: 0.0755 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0871 - lr: 0.0017e-05
 42/193 [=====>........................] - ETA: 3s - loss: 0.0074 - mae: 0.0751 - mse: 0.0074 - root_mean_squared_error: 0.0862.0872 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 8.6559e-04
131/193 [===================>..........] - ETA: 1s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871.0872 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 8.6559e-04
  3/193 [..............................] - ETA: 4s - loss: 0.0078 - mae: 0.0773 - mse: 0.0078 - root_mean_squared_error: 0.0882.0872 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 4.3280e-04
 59/193 [========>.....................] - ETA: 3s - loss: 0.0077 - mae: 0.0765 - mse: 0.0077 - root_mean_squared_error: 0.0878.0872 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 4.3280e-04
122/193 [=================>............] - ETA: 2s - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0870.0872 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 4.3280e-04
167/193 [========================>.....] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0871.0872 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 4.3280e-04
  3/193 [..............................] - ETA: 8s - loss: 0.0086 - mae: 0.0801 - mse: 0.0086 - root_mean_squared_error: 0.0925.0872 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 2.1640e-04
 78/193 [===========>..................] - ETA: 3s - loss: 0.0078 - mae: 0.0767 - mse: 0.0078 - root_mean_squared_error: 0.0882.0872 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 2.1640e-04
165/193 [========================>.....] - ETA: 0s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0870.0872 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 2.1640e-04
 39/193 [=====>........................] - ETA: 3s - loss: 0.0077 - mae: 0.0765 - mse: 0.0077 - root_mean_squared_error: 0.0879.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0820e-04
114/193 [================>.............] - ETA: 2s - loss: 0.0077 - mae: 0.0763 - mse: 0.0077 - root_mean_squared_error: 0.0877.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0820e-04
174/193 [==========================>...] - ETA: 0s - loss: 0.0077 - mae: 0.0761 - mse: 0.0077 - root_mean_squared_error: 0.0875.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0820e-04
 31/193 [===>..........................] - ETA: 3s - loss: 0.0080 - mae: 0.0784 - mse: 0.0080 - root_mean_squared_error: 0.0895.0872 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 5.4099e-05
119/193 [=================>............] - ETA: 1s - loss: 0.0077 - mae: 0.0763 - mse: 0.0077 - root_mean_squared_error: 0.0877.0872 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 5.4099e-05
191/193 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0871.0872 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 5.4099e-05
 83/193 [===========>..................] - ETA: 2s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0869.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 2.7050e-05
170/193 [=========================>....] - ETA: 0s - loss: 0.0076 - mae: 0.0759 - mse: 0.0076 - root_mean_squared_error: 0.0873.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 2.7050e-05
 29/193 [===>..........................] - ETA: 5s - loss: 0.0076 - mae: 0.0759 - mse: 0.0076 - root_mean_squared_error: 0.0874.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.3525e-05
 75/193 [==========>...................] - ETA: 3s - loss: 0.0076 - mae: 0.0755 - mse: 0.0076 - root_mean_squared_error: 0.0869.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.3525e-05
134/193 [===================>..........] - ETA: 2s - loss: 0.0076 - mae: 0.0756 - mse: 0.0076 - root_mean_squared_error: 0.0870.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.3525e-05
  3/193 [..............................] - ETA: 4s - loss: 0.0083 - mae: 0.0810 - mse: 0.0083 - root_mean_squared_error: 0.0912.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
 91/193 [=============>................] - ETA: 2s - loss: 0.0075 - mae: 0.0754 - mse: 0.0075 - root_mean_squared_error: 0.0868.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
176/193 [==========================>...] - ETA: 0s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0873.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
 49/193 [======>.......................] - ETA: 3s - loss: 0.0076 - mae: 0.0753 - mse: 0.0076 - root_mean_squared_error: 0.0871.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
134/193 [===================>..........] - ETA: 1s - loss: 0.0077 - mae: 0.0761 - mse: 0.0077 - root_mean_squared_error: 0.0875.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
192/193 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0871.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
 42/193 [=====>........................] - ETA: 5s - loss: 0.0077 - mae: 0.0765 - mse: 0.0077 - root_mean_squared_error: 0.0876.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
119/193 [=================>............] - ETA: 2s - loss: 0.0077 - mae: 0.0763 - mse: 0.0077 - root_mean_squared_error: 0.0877.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
191/193 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0757 - mse: 0.0076 - root_mean_squared_error: 0.0872.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
 77/193 [==========>...................] - ETA: 2s - loss: 0.0075 - mae: 0.0753 - mse: 0.0075 - root_mean_squared_error: 0.0867.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
138/193 [====================>.........] - ETA: 1s - loss: 0.0075 - mae: 0.0751 - mse: 0.0075 - root_mean_squared_error: 0.0866.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
138/193 [====================>.........] - ETA: 1s - loss: 0.0075 - mae: 0.0751 - mse: 0.0075 - root_mean_squared_error: 0.0866.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 20/20==================>.........] - ETA: 1s - loss: 0.0075 - mae: 0.0751 - mse: 0.0075 - root_mean_squared_error: 0.0866.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 20/20==================>.........] - ETA: 1s - loss: 0.0075 - mae: 0.0751 - mse: 0.0075 - root_mean_squared_error: 0.0866.0871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
>Saved ../trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 4/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 4/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 4/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.027698896825313568.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.027698896825313568.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.027698896825313568.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.027698896825313568.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.027698896825313568.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.027698896825313568.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.013849448412656784.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.013849448412656784.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.006924724206328392.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.006924724206328392.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.006924724206328392.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.006924724206328392.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.003462362103164196.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.003462362103164196.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.001731181051582098.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.001731181051582098.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.001731181051582098.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.000865590525791049.014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.000865590525791049.014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.000865590525791049.014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.000865590525791049.014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.000865590525791049.014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.000865590525791049.014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 0.0004327952628955245.14795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 0.0004327952628955245.14795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 0.0004327952628955245.14795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 0.00021639763144776225.4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 0.00021639763144776225.4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 0.00010819881572388113.4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 0.00010819881572388113.4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 0.00010819881572388113.4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 5.409940786194056e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 5.409940786194056e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 5.409940786194056e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 2.704970393097028e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 2.704970393097028e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 2.704970393097028e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1.352485196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1.352485196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1.352485196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_4.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
>Saved ../trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_5.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_5.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_5.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_5.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_5.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
 85/193 [============>.................] - ETA: 2s - loss: 0.0078 - mae: 0.0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
 85/193 [============>.................] - ETA: 2s - loss: 0.0078 - mae: 0.0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 3/20===========>.................] - ETA: 2s - loss: 0.0078 - mae: 0.0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 3/20===========>.................] - ETA: 2s - loss: 0.0078 - mae: 0.0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.027698896825313568..0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.027698896825313568..0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.027698896825313568..0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.013849448412656784..0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.013849448412656784..0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.013849448412656784..0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.013849448412656784..0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.013849448412656784..0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.013849448412656784..0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.006924724206328392..0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.006924724206328392..0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.006924724206328392..0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.003462362103164196..0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.003462362103164196..0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.003462362103164196..0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.001731181051582098..0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.001731181051582098..0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.000865590525791049..0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.000865590525791049..0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.000865590525791049..0767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.0004327952628955245.767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.0004327952628955245.767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.0004327952628955245.767 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00021639763144776225.67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00021639763144776225.67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00021639763144776225.67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 0.00010819881572388113.67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 0.00010819881572388113.67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 0.00010819881572388113.67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 5.409940786194056e-05..67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 5.409940786194056e-05..67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 5.409940786194056e-05..67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.704970393097028e-05..67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 2.704970393097028e-05..67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.352485196548514e-05..67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.352485196548514e-05..67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.352485196548514e-05..67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1.352485196548514e-05..67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..67 - mse: 0.0078 - root_mean_squared_error: 0.0886h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
>Saved ../trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.027698896825313568.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.027698896825313568.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.013849448412656784.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.013849448412656784.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.013849448412656784.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006924724206328392.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006924724206328392.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006924724206328392.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006924724206328392.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003462362103164196.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003462362103164196.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.001731181051582098.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.001731181051582098.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.001731181051582098.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.000865590525791049.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.000865590525791049.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.000865590525791049.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0004327952628955245.014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0004327952628955245.014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0004327952628955245.014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00021639763144776225.14795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00021639763144776225.14795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00021639763144776225.14795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00010819881572388113.4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00010819881572388113.4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 5.409940786194056e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 5.409940786194056e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 5.409940786194056e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 5.409940786194056e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 2.704970393097028e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 2.704970393097028e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 1.352485196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 1.352485196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 1.352485196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_6.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
>Saved ../trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.027698896825313568.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.027698896825313568.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.027698896825313568.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.027698896825313568.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.027698896825313568.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.013849448412656784.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.013849448412656784.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.013849448412656784.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006924724206328392.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006924724206328392.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006924724206328392.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006924724206328392.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003462362103164196.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003462362103164196.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.001731181051582098.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.001731181051582098.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.001731181051582098.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.000865590525791049.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.000865590525791049.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.000865590525791049.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0004327952628955245.014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0004327952628955245.014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0004327952628955245.014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00021639763144776225.4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00021639763144776225.4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00021639763144776225.4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00010819881572388113.4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00010819881572388113.4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00010819881572388113.4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 5.409940786194056e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 5.409940786194056e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 2.704970393097028e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 2.704970393097028e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 2.704970393097028e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1.352485196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1.352485196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1.352485196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_7.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
>Saved ../trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.027698896825313568.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.027698896825313568.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 3/20educeLROnPlateau reducing learning rate to 0.027698896825313568.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.013849448412656784.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.013849448412656784.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.013849448412656784.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006924724206328392.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006924724206328392.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.006924724206328392.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003462362103164196.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.003462362103164196.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.001731181051582098.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.001731181051582098.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.001731181051582098.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.001731181051582098.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.000865590525791049.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.000865590525791049.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0004327952628955245.014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0004327952628955245.014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.0004327952628955245.014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00021639763144776225.14795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00021639763144776225.14795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00021639763144776225.14795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.00021639763144776225.14795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00010819881572388113.4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00010819881572388113.4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00010819881572388113.4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 5.409940786194056e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 5.409940786194056e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 2.704970393097028e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 2.704970393097028e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 2.704970393097028e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 1.352485196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 1.352485196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 1.352485196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_8.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
Epoch 1/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 2/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 3/20trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 4/20educeLROnPlateau reducing learning rate to 0.027698896825313568.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.013849448412656784.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 5/20educeLROnPlateau reducing learning rate to 0.013849448412656784.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006924724206328392.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 6/20educeLROnPlateau reducing learning rate to 0.006924724206328392.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003462362103164196.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 7/20educeLROnPlateau reducing learning rate to 0.003462362103164196.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.001731181051582098.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 8/20educeLROnPlateau reducing learning rate to 0.001731181051582098.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 9/20educeLROnPlateau reducing learning rate to 0.000865590525791049.9014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0004327952628955245.014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 10/20duceLROnPlateau reducing learning rate to 0.0004327952628955245.014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00021639763144776225.4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 11/20educeLROnPlateau reducing learning rate to 0.00021639763144776225.4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00010819881572388113.4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 12/20educeLROnPlateau reducing learning rate to 0.00010819881572388113.4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 5.409940786194056e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 13/20educeLROnPlateau reducing learning rate to 5.409940786194056e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 14/20educeLROnPlateau reducing learning rate to 2.704970393097028e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1.352485196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 15/20educeLROnPlateau reducing learning rate to 1.352485196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 16/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 17/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 18/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 19/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
Epoch 20/20educeLROnPlateau reducing learning rate to 1e-05.85196548514e-05..4795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_9.h5871 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
>Saved ../trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_10.h571 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05
>Saved ../trained_models/RNN/models_segments_overlap-rnn_adam_0.05539779309014795LR_[8]HL5DU_40BS_1P_val_mseM_20epochs/model_10.h571 - val_loss: 0.0076 - val_mae: 0.0754 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0870 - lr: 1.0000e-05