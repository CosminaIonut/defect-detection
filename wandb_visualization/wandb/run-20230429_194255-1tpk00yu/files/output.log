Epoch 1/50
122/122 [==============================] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0039s vs `on_train_batch_end` time: 0.0042s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0039s vs `on_train_batch_end` time: 0.0042s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
122/122 [==============================] - 3s 23ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0185
Epoch 2/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0185
Epoch 3/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0185
Epoch 4/50
122/122 [==============================] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.009232823736965656.
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0185
Epoch 5/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0092
Epoch 6/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0092
Epoch 7/50
119/122 [============================>.] - ETA: 0s - loss: 0.8577 - mae: 0.9251 - mse: 0.8577 - root_mean_squared_error: 0.9261
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.004616411868482828.
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0092
Epoch 8/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0046
Epoch 9/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0046
Epoch 10/50
121/122 [============================>.] - ETA: 0s - loss: 0.8580 - mae: 0.9253 - mse: 0.8580 - root_mean_squared_error: 0.9263
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.002308205934241414.
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0046
Epoch 11/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0023
Epoch 12/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0023
Epoch 13/50
121/122 [============================>.] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.001154102967120707.
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0023
Epoch 14/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0012
Epoch 15/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0012
Epoch 16/50
119/122 [============================>.] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005770514835603535.
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0012
Epoch 17/50
122/122 [==============================] - 1s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 5.7705e-04
Epoch 18/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 5.7705e-04
Epoch 19/50
118/122 [============================>.] - ETA: 0s - loss: 0.8580 - mae: 0.9252 - mse: 0.8580 - root_mean_squared_error: 0.9263
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00028852574178017676.
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 5.7705e-04
Epoch 20/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 2.8853e-04
Epoch 21/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 2.8853e-04
Epoch 22/50
120/122 [============================>.] - ETA: 0s - loss: 0.8577 - mae: 0.9251 - mse: 0.8577 - root_mean_squared_error: 0.9261
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00014426287089008838.
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 2.8853e-04
Epoch 23/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.4426e-04
Epoch 24/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.4426e-04
Epoch 25/50
119/122 [============================>.] - ETA: 0s - loss: 0.8580 - mae: 0.9252 - mse: 0.8580 - root_mean_squared_error: 0.9263
Epoch 25: ReduceLROnPlateau reducing learning rate to 7.213143544504419e-05.
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.4426e-04
Epoch 26/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 7.2131e-05
Epoch 27/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 7.2131e-05
Epoch 28/50
113/122 [==========================>...] - ETA: 0s - loss: 0.8578 - mae: 0.9251 - mse: 0.8578 - root_mean_squared_error: 0.9262
Epoch 28: ReduceLROnPlateau reducing learning rate to 3.6065717722522095e-05.
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 7.2131e-05
Epoch 29/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.6066e-05
Epoch 30/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.6066e-05
Epoch 31/50
122/122 [==============================] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262
Epoch 31: ReduceLROnPlateau reducing learning rate to 1.8032858861261047e-05.
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.6066e-05
Epoch 32/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.8033e-05
Epoch 33/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.8033e-05
Epoch 34/50
117/122 [===========================>..] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9263
Epoch 34: ReduceLROnPlateau reducing learning rate to 1e-05.
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.8033e-05
Epoch 35/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 36/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 37/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 38/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 39/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 40/50
122/122 [==============================] - 1s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 41/50
122/122 [==============================] - 1s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 42/50
122/122 [==============================] - 1s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 43/50
122/122 [==============================] - 1s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 44/50
 19/122 [===>..........................] - ETA: 0s - loss: 0.8614 - mae: 0.9271 - mse: 0.8614 - root_mean_squared_error: 0.9281
122/122 [==============================] - 1s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 46/50
 37/122 [========>.....................] - ETA: 0s - loss: 0.8577 - mae: 0.9250 - mse: 0.8577 - root_mean_squared_error: 0.9261
 36/122 [=======>......................] - ETA: 0s - loss: 0.8570 - mae: 0.9248 - mse: 0.8570 - root_mean_squared_error: 0.92589262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
122/122 [==============================] - 1s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
 77/162 [=============>................] - ETA: 0s - loss: 0.6420 - mae: 0.7991 - mse: 0.6420 - root_mean_squared_error: 0.80138019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0185e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0092e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0092e-05
138/162 [========================>.....] - ETA: 0s - loss: 0.6430 - mae: 0.7998 - mse: 0.6430 - root_mean_squared_error: 0.80198019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0092e-05
151/162 [==========================>...] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.80198019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0092e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0012e-05
162/162 [==============================] - 1s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0012e-05
162/162 [==============================] - 1s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0012e-05
 53/162 [========>.....................] - ETA: 0s - loss: 0.6407 - mae: 0.7983 - mse: 0.6407 - root_mean_squared_error: 0.80048019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0012e-05
 98/162 [=================>............] - ETA: 0s - loss: 0.6431 - mae: 0.7999 - mse: 0.6431 - root_mean_squared_error: 0.80208019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 2.8853e-04
162/162 [==============================] - 1s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.4426e-04
162/162 [==============================] - 1s 9ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.4426e-04
159/162 [============================>.] - ETA: 0s - loss: 0.6435 - mae: 0.8001 - mse: 0.6435 - root_mean_squared_error: 0.80228019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.4426e-04
157/162 [============================>.] - ETA: 0s - loss: 0.6432 - mae: 0.7999 - mse: 0.6432 - root_mean_squared_error: 0.80208019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.4426e-04
103/162 [==================>...........] - ETA: 0s - loss: 0.6442 - mae: 0.8005 - mse: 0.6442 - root_mean_squared_error: 0.80268019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 3.6066e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.8033e-05
162/162 [==============================] - 1s 7ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.8033e-05
126/162 [======================>.......] - ETA: 0s - loss: 0.6428 - mae: 0.7996 - mse: 0.6428 - root_mean_squared_error: 0.80188019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.8033e-05
162/162 [==============================] - 1s 7ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
115/162 [====================>.........] - ETA: 0s - loss: 0.6433 - mae: 0.8000 - mse: 0.6433 - root_mean_squared_error: 0.80218019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
162/162 [==============================] - 1s 7ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
162/162 [==============================] - 1s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
162/162 [==============================] - 1s 6ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
121/122 [============================>.] - ETA: 0s - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766  19 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
121/122 [============================>.] - ETA: 0s - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766  19 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
122/122 [==============================] - 3s 21ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 0.0185-05
 52/122 [===========>..................] - ETA: 0s - loss: 0.4593 - mae: 0.6763 - mse: 0.4593 - root_mean_squared_error: 0.67776766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 0.00925-05
122/122 [==============================] - 1s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 0.00465-05
 55/122 [============>.................] - ETA: 0s - loss: 0.4580 - mae: 0.6753 - mse: 0.4580 - root_mean_squared_error: 0.67686766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 0.00465-05
115/122 [===========================>..] - ETA: 0s - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.67666766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 0.00465-05
122/122 [==============================] - 1s 7ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 5.7705e-04
122/122 [==============================] - 1s 9ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 5.7705e-04
122/122 [==============================] - 1s 9ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 5.7705e-04
122/122 [==============================] - ETA: 0s - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.67666766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 5.7705e-04
122/122 [==============================] - 1s 8ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.4426e-04
122/122 [==============================] - 1s 6ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 7.2131e-05
122/122 [==============================] - 1s 7ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 7.2131e-05
115/122 [===========================>..] - ETA: 0s - loss: 0.4576 - mae: 0.6750 - mse: 0.4576 - root_mean_squared_error: 0.67656766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 7.2131e-05
122/122 [==============================] - 1s 7ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.8033e-05
122/122 [==============================] - 1s 8ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
 44/122 [=========>....................] - ETA: 0s - loss: 0.4586 - mae: 0.6758 - mse: 0.4586 - root_mean_squared_error: 0.67726766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
122/122 [==============================] - 1s 10ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
122/122 [==============================] - 1s 6ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-055
122/122 [==============================] - 1s 7ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-055
115/122 [===========================>..] - ETA: 0s - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.67666766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-055
122/122 [==============================] - 1s 6ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-055
122/122 [==============================] - 1s 7ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-055
122/122 [==============================] - 1s 7ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-055
122/122 [==============================] - 1s 7ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-055
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
122/122 [==============================] - 1s 6ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0185e-055
 90/122 [=====================>........] - ETA: 0s - loss: 0.3326 - mae: 0.5751 - mse: 0.3326 - root_mean_squared_error: 0.57675768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0185e-055
122/122 [==============================] - 1s 6ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0023e-055
122/122 [==============================] - 1s 6ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0023e-055
122/122 [==============================] - ETA: 0s - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.57685768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 0.0023e-055
122/122 [==============================] - 1s 8ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 5.7705e-045
122/122 [==============================] - 1s 8ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 2.8853e-045
122/122 [==============================] - 1s 9ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 2.8853e-045
 74/122 [=================>............] - ETA: 0s - loss: 0.3335 - mae: 0.5758 - mse: 0.3335 - root_mean_squared_error: 0.57755768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 2.8853e-045
122/122 [==============================] - 1s 6ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 7.2131e-055
122/122 [==============================] - 1s 6ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 3.6066e-055
122/122 [==============================] - 1s 8ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 3.6066e-055
119/122 [============================>.] - ETA: 0s - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.57695768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 3.6066e-055
122/122 [==============================] - 1s 8ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 1.0000e-055
 69/122 [===============>..............] - ETA: 0s - loss: 0.3331 - mae: 0.5755 - mse: 0.3331 - root_mean_squared_error: 0.57725768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 1.0000e-055
122/122 [==============================] - 1s 9ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 1.0000e-055
122/122 [==============================] - 1s 7ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 1.0000e-055
  1/122 [..............................] - ETA: 1s - loss: 0.3504 - mae: 0.5902 - mse: 0.3504 - root_mean_squared_error: 0.59205768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 1.0000e-055
122/122 [==============================] - 1s 10ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 1.0000e-05
122/122 [==============================] - ETA: 0s - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 1.0000e-05
122/122 [==============================] - 1s 8ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5768 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 1.0000e-055
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 1.0000e-055
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 1.0000e-055
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - val_root_mean_squared_error: 0.5763 - lr: 1.0000e-055
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0065s vs `on_train_batch_end` time: 0.0083s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0065s vs `on_train_batch_end` time: 0.0083s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
122/122 [==============================] - 1s 6ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - root_mean_squared_error: 0.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0092e-055
122/122 [==============================] - 1s 8ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - root_mean_squared_error: 0.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0092e-055
122/122 [==============================] - 1s 8ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - root_mean_squared_error: 0.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0092e-055
120/122 [============================>.] - ETA: 0s - loss: 0.2278 - mae: 0.4752 - mse: 0.2278 - root_mean_squared_error: 0.47724772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0092e-055
 52/122 [===========>..................] - ETA: 0s - loss: 0.2275 - mae: 0.4749 - mse: 0.2275 - root_mean_squared_error: 0.47694772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0092e-055
122/122 [==============================] - 1s 11ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - root_mean_squared_error: 0.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0023-055
122/122 [==============================] - 1s 11ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - root_mean_squared_error: 0.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
122/122 [==============================] - 1s 11ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - root_mean_squared_error: 0.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
122/122 [==============================] - 2s 18ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - root_mean_squared_error: 0.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
122/122 [==============================] - 2s 18ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - root_mean_squared_error: 0.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
 53/122 [============>.................] - ETA: 0s - loss: 0.2278 - mae: 0.4753 - mse: 0.2278 - root_mean_squared_error: 0.4773.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 20/50==========>.................] - ETA: 0s - loss: 0.2278 - mae: 0.4753 - mse: 0.2278 - root_mean_squared_error: 0.4773.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 20/50==========>.................] - ETA: 0s - loss: 0.2278 - mae: 0.4753 - mse: 0.2278 - root_mean_squared_error: 0.4773.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00014426287089008838.53 - mse: 0.2278 - root_mean_squared_error: 0.4773.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 25/50educeLROnPlateau reducing learning rate to 0.00014426287089008838.53 - mse: 0.2278 - root_mean_squared_error: 0.4773.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 26/50educeLROnPlateau reducing learning rate to 0.00014426287089008838.53 - mse: 0.2278 - root_mean_squared_error: 0.4773.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 26/50educeLROnPlateau reducing learning rate to 0.00014426287089008838.53 - mse: 0.2278 - root_mean_squared_error: 0.4773.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 28: ReduceLROnPlateau reducing learning rate to 3.6065717722522095e-05.53 - mse: 0.2278 - root_mean_squared_error: 0.4773.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 28: ReduceLROnPlateau reducing learning rate to 3.6065717722522095e-05.53 - mse: 0.2278 - root_mean_squared_error: 0.4773.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 31: ReduceLROnPlateau reducing learning rate to 1.8032858861261047e-05.53 - mse: 0.2278 - root_mean_squared_error: 0.4773.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 31: ReduceLROnPlateau reducing learning rate to 1.8032858861261047e-05.53 - mse: 0.2278 - root_mean_squared_error: 0.4773.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 34: ReduceLROnPlateau reducing learning rate to 1e-05.858861261047e-05.53 - mse: 0.2278 - root_mean_squared_error: 0.4773.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 34: ReduceLROnPlateau reducing learning rate to 1e-05.858861261047e-05.53 - mse: 0.2278 - root_mean_squared_error: 0.4773.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 34: ReduceLROnPlateau reducing learning rate to 1e-05.858861261047e-05.53 - mse: 0.2278 - root_mean_squared_error: 0.4773.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 39/50educeLROnPlateau reducing learning rate to 1e-05.858861261047e-05.53 - mse: 0.2278 - root_mean_squared_error: 0.4773.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 39/50educeLROnPlateau reducing learning rate to 1e-05.858861261047e-05.53 - mse: 0.2278 - root_mean_squared_error: 0.4773.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 42/50educeLROnPlateau reducing learning rate to 1e-05.858861261047e-05.53 - mse: 0.2278 - root_mean_squared_error: 0.4773.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 42/50educeLROnPlateau reducing learning rate to 1e-05.858861261047e-05.53 - mse: 0.2278 - root_mean_squared_error: 0.4773.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 45/50educeLROnPlateau reducing learning rate to 1e-05.858861261047e-05.53 - mse: 0.2278 - root_mean_squared_error: 0.4773.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 47/50educeLROnPlateau reducing learning rate to 1e-05.858861261047e-05.53 - mse: 0.2278 - root_mean_squared_error: 0.4773.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 49/50educeLROnPlateau reducing learning rate to 1e-05.858861261047e-05.53 - mse: 0.2278 - root_mean_squared_error: 0.4773.4772 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
>Saved ../trained_models/CNN/models_segments_overlap-cnn_sgd_0.018465647723283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
>Saved ../trained_models/CNN/models_segments_overlap-cnn_sgd_0.018465647723283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
>Saved ../trained_models/CNN/models_segments_overlap-cnn_sgd_0.018465647723283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 5/50trained_models/CNN/models_segments_overlap-cnn_sgd_0.018465647723283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 5/50trained_models/CNN/models_segments_overlap-cnn_sgd_0.018465647723283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.004616411868482828.3283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 10/50duceLROnPlateau reducing learning rate to 0.004616411868482828.3283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 11/50duceLROnPlateau reducing learning rate to 0.004616411868482828.3283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 11/50duceLROnPlateau reducing learning rate to 0.004616411868482828.3283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.001154102967120707.283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.001154102967120707.283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.001154102967120707.283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 17/50educeLROnPlateau reducing learning rate to 0.001154102967120707.283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 17/50educeLROnPlateau reducing learning rate to 0.001154102967120707.283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 17/50educeLROnPlateau reducing learning rate to 0.001154102967120707.283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 20/50educeLROnPlateau reducing learning rate to 0.001154102967120707.283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 22/50educeLROnPlateau reducing learning rate to 0.001154102967120707.283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 23/50educeLROnPlateau reducing learning rate to 0.001154102967120707.283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 25/50educeLROnPlateau reducing learning rate to 0.001154102967120707.283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 26/50educeLROnPlateau reducing learning rate to 0.001154102967120707.283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 26/50educeLROnPlateau reducing learning rate to 0.001154102967120707.283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 26/50educeLROnPlateau reducing learning rate to 0.001154102967120707.283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 29/50educeLROnPlateau reducing learning rate to 0.001154102967120707.283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 31: ReduceLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 34/50educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 35/50educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 38/50educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 40/50educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 42/50educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 44/50educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 46/50educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 48/50educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 50/50educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 1/500educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 1/500educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 1/500educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0035s vs `on_train_batch_end` time: 0.0043s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0035s vs `on_train_batch_end` time: 0.0043s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 5/500educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.004616411868482828.05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.004616411868482828.05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 10/50duceLROnPlateau reducing learning rate to 0.004616411868482828.05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 12/50duceLROnPlateau reducing learning rate to 0.004616411868482828.05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 14/50duceLROnPlateau reducing learning rate to 0.004616411868482828.05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 14/50duceLROnPlateau reducing learning rate to 0.004616411868482828.05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005770514835603535..3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005770514835603535..3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00028852574178017676.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00028852574178017676.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00028852574178017676.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 23/50educeLROnPlateau reducing learning rate to 0.00028852574178017676.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 25: ReduceLROnPlateau reducing learning rate to 7.213143544504419e-05..3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 28/50educeLROnPlateau reducing learning rate to 7.213143544504419e-05..3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 29/50educeLROnPlateau reducing learning rate to 7.213143544504419e-05..3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 31: ReduceLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 31: ReduceLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 31: ReduceLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 35/50educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 38/50educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 38/50educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 41/50educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 43/50educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 45/50educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 47/50educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 49/50educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 1/500educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 1/500educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 1/500educeLROnPlateau reducing learning rate to 1.8032858861261047e-05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.004616411868482828.05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 12/50duceLROnPlateau reducing learning rate to 0.004616411868482828.05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 14/50duceLROnPlateau reducing learning rate to 0.004616411868482828.05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 14/50duceLROnPlateau reducing learning rate to 0.004616411868482828.05.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005770514835603535..3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 19/50educeLROnPlateau reducing learning rate to 0.0005770514835603535..3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 19/50educeLROnPlateau reducing learning rate to 0.0005770514835603535..3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 21/50educeLROnPlateau reducing learning rate to 0.0005770514835603535..3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 23/50educeLROnPlateau reducing learning rate to 0.0005770514835603535..3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 28/50educeLROnPlateau reducing learning rate to 7.213143544504419e-05..3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 32/50educeLROnPlateau reducing learning rate to 7.213143544504419e-05..3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 34: ReduceLROnPlateau reducing learning rate to 1e-05.43544504419e-05..3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 37/50educeLROnPlateau reducing learning rate to 1e-05.43544504419e-05..3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 37/50educeLROnPlateau reducing learning rate to 1e-05.43544504419e-05..3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 40/50educeLROnPlateau reducing learning rate to 1e-05.43544504419e-05..3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 43/50educeLROnPlateau reducing learning rate to 1e-05.43544504419e-05..3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 43/50educeLROnPlateau reducing learning rate to 1e-05.43544504419e-05..3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 46/50educeLROnPlateau reducing learning rate to 1e-05.43544504419e-05..3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 46/50educeLROnPlateau reducing learning rate to 1e-05.43544504419e-05..3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 49/50educeLROnPlateau reducing learning rate to 1e-05.43544504419e-05..3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_5.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
>Saved ../trained_models/CNN/models_segments_overlap-cnn_sgd_0.018465647723283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
>Saved ../trained_models/CNN/models_segments_overlap-cnn_sgd_0.018465647723283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
>Saved ../trained_models/CNN/models_segments_overlap-cnn_sgd_0.018465647723283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230429_194255-1tpk00yu\files\model-best)... Done. 0.0s
Epoch 5/50trained_models/CNN/models_segments_overlap-cnn_sgd_0.018465647723283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 5/50trained_models/CNN/models_segments_overlap-cnn_sgd_0.018465647723283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.004616411868482828.3283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.004616411868482828.3283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.004616411868482828.3283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 11/50duceLROnPlateau reducing learning rate to 0.004616411868482828.3283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 11/50duceLROnPlateau reducing learning rate to 0.004616411868482828.3283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 14/50duceLROnPlateau reducing learning rate to 0.004616411868482828.3283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 14/50duceLROnPlateau reducing learning rate to 0.004616411868482828.3283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 14/50duceLROnPlateau reducing learning rate to 0.004616411868482828.3283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 17/50duceLROnPlateau reducing learning rate to 0.004616411868482828.3283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 17/50duceLROnPlateau reducing learning rate to 0.004616411868482828.3283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 20/50duceLROnPlateau reducing learning rate to 0.004616411868482828.3283917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00014426287089008838.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 25/50educeLROnPlateau reducing learning rate to 0.00014426287089008838.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 26/50educeLROnPlateau reducing learning rate to 0.00014426287089008838.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 28/50educeLROnPlateau reducing learning rate to 0.00014426287089008838.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 29/50educeLROnPlateau reducing learning rate to 0.00014426287089008838.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 29/50educeLROnPlateau reducing learning rate to 0.00014426287089008838.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 32/50educeLROnPlateau reducing learning rate to 0.00014426287089008838.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 37/50educeLROnPlateau reducing learning rate to 1e-05.4426287089008838.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 37/50educeLROnPlateau reducing learning rate to 1e-05.4426287089008838.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 37/50educeLROnPlateau reducing learning rate to 1e-05.4426287089008838.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 41/50educeLROnPlateau reducing learning rate to 1e-05.4426287089008838.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 43/50educeLROnPlateau reducing learning rate to 1e-05.4426287089008838.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 43/50educeLROnPlateau reducing learning rate to 1e-05.4426287089008838.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 46/50educeLROnPlateau reducing learning rate to 1e-05.4426287089008838.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 46/50educeLROnPlateau reducing learning rate to 1e-05.4426287089008838.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 46/50educeLROnPlateau reducing learning rate to 1e-05.4426287089008838.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 50/50educeLROnPlateau reducing learning rate to 1e-05.4426287089008838.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055
Epoch 50/50educeLROnPlateau reducing learning rate to 1e-05.4426287089008838.3917LR_[23]CHN_64CNNI_32BS_1DU_3P_val_mseM_50epochs/model_8.h5loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - val_root_mean_squared_error: 0.4766 - lr: 0.0012-055