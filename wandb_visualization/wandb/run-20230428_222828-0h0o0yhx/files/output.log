Epoch 1/150
35/35 [==============================] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
35/35 [==============================] - 2s 47ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0902
Epoch 2/150
30/35 [========================>.....] - ETA: 0s - loss: 0.8573 - mae: 0.9249 - mse: 0.8573 - root_mean_squared_error: 0.9259
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.045075226575136185.
35/35 [==============================] - 0s 11ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0902
Epoch 3/150
33/35 [===========================>..] - ETA: 0s - loss: 0.8581 - mae: 0.9253 - mse: 0.8581 - root_mean_squared_error: 0.9263
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.022537613287568092.
35/35 [==============================] - 0s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0451
Epoch 4/150
28/35 [=======================>......] - ETA: 0s - loss: 0.8582 - mae: 0.9254 - mse: 0.8582 - root_mean_squared_error: 0.9264
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.011268806643784046.
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0225
Epoch 5/150
29/35 [=======================>......] - ETA: 0s - loss: 0.8584 - mae: 0.9255 - mse: 0.8584 - root_mean_squared_error: 0.9265
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.005634403321892023.
35/35 [==============================] - 0s 10ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0113
Epoch 6/150
29/35 [=======================>......] - ETA: 0s - loss: 0.8586 - mae: 0.9256 - mse: 0.8586 - root_mean_squared_error: 0.9266
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0028172016609460115.
35/35 [==============================] - 0s 11ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0056
Epoch 7/150
34/35 [============================>.] - ETA: 0s - loss: 0.8580 - mae: 0.9252 - mse: 0.8580 - root_mean_squared_error: 0.9263
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0014086008304730058.
35/35 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0028
Epoch 8/150
31/35 [=========================>....] - ETA: 0s - loss: 0.8582 - mae: 0.9253 - mse: 0.8582 - root_mean_squared_error: 0.9264
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0007043004152365029.
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0014
Epoch 9/150
28/35 [=======================>......] - ETA: 0s - loss: 0.8574 - mae: 0.9249 - mse: 0.8574 - root_mean_squared_error: 0.9259
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00035215020761825144.
35/35 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 7.0430e-04
Epoch 10/150
28/35 [=======================>......] - ETA: 0s - loss: 0.8577 - mae: 0.9251 - mse: 0.8577 - root_mean_squared_error: 0.9261
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00017607510380912572.
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.5215e-04
Epoch 11/150
28/35 [=======================>......] - ETA: 0s - loss: 0.8568 - mae: 0.9246 - mse: 0.8568 - root_mean_squared_error: 0.9256
Epoch 11: ReduceLROnPlateau reducing learning rate to 8.803755190456286e-05.
35/35 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.7608e-04
Epoch 12/150
28/35 [=======================>......] - ETA: 0s - loss: 0.8574 - mae: 0.9249 - mse: 0.8574 - root_mean_squared_error: 0.9260
Epoch 12: ReduceLROnPlateau reducing learning rate to 4.401877595228143e-05.
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 8.8038e-05
Epoch 13/150
28/35 [=======================>......] - ETA: 0s - loss: 0.8582 - mae: 0.9254 - mse: 0.8582 - root_mean_squared_error: 0.9264
Epoch 13: ReduceLROnPlateau reducing learning rate to 2.2009387976140715e-05.
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 4.4019e-05
Epoch 14/150
30/35 [========================>.....] - ETA: 0s - loss: 0.8585 - mae: 0.9255 - mse: 0.8585 - root_mean_squared_error: 0.9265
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.1004693988070358e-05.
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 2.2009e-05
Epoch 15/150
29/35 [=======================>......] - ETA: 0s - loss: 0.8586 - mae: 0.9256 - mse: 0.8586 - root_mean_squared_error: 0.9266
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.1005e-05
Epoch 16/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 17/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 18/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 19/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 20/150
35/35 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 21/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 22/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 23/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 24/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 25/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 26/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 27/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 28/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 29/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 30/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 31/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 32/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 33/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 34/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 35/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 36/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 37/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 38/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 39/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 40/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 41/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 42/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 43/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 44/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 45/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 46/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 47/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 48/150
29/35 [=======================>......] - ETA: 0s - loss: 0.8583 - mae: 0.9254 - mse: 0.8583 - root_mean_squared_error: 0.92659262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 49/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 50/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 51/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 52/150
35/35 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 53/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 54/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 55/150
20/35 [================>.............] - ETA: 0s - loss: 0.8570 - mae: 0.9247 - mse: 0.8570 - root_mean_squared_error: 0.92579262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 56/150
35/35 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 57/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 58/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 59/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 60/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 61/150
35/35 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 62/150
30/35 [========================>.....] - ETA: 0s - loss: 0.8576 - mae: 0.9250 - mse: 0.8576 - root_mean_squared_error: 0.92619262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 63/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 64/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 65/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 66/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 67/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 68/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 69/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 70/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 71/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 72/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 73/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 74/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 75/150
 1/35 [..............................] - ETA: 0s - loss: 0.8572 - mae: 0.9249 - mse: 0.8572 - root_mean_squared_error: 0.9258
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 77/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 78/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 79/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 80/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 81/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 82/150
20/35 [================>.............] - ETA: 0s - loss: 0.8585 - mae: 0.9255 - mse: 0.8585 - root_mean_squared_error: 0.9265
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 84/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 85/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 86/150
35/35 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 87/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 88/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 89/150
10/35 [=======>......................] - ETA: 0s - loss: 0.8585 - mae: 0.9255 - mse: 0.8585 - root_mean_squared_error: 0.9265
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 91/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 92/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 93/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 94/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 95/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 96/150
21/35 [=================>............] - ETA: 0s - loss: 0.8562 - mae: 0.9243 - mse: 0.8562 - root_mean_squared_error: 0.9253
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 98/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 99/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 100/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 101/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 102/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 103/150
21/35 [=================>............] - ETA: 0s - loss: 0.8577 - mae: 0.9251 - mse: 0.8577 - root_mean_squared_error: 0.9261
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 105/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 106/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 107/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 108/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 109/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 110/150
28/35 [=======================>......] - ETA: 0s - loss: 0.8588 - mae: 0.9257 - mse: 0.8588 - root_mean_squared_error: 0.9267
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 112/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 113/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 114/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 115/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 116/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 117/150
28/35 [=======================>......] - ETA: 0s - loss: 0.8589 - mae: 0.9257 - mse: 0.8589 - root_mean_squared_error: 0.9268
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 119/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 120/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 121/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 122/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 123/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 124/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 126/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 127/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 128/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 129/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 130/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 131/150
29/35 [=======================>......] - ETA: 0s - loss: 0.8581 - mae: 0.9253 - mse: 0.8581 - root_mean_squared_error: 0.9263
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 133/150
35/35 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 134/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 135/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 136/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 137/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 138/150
30/35 [========================>.....] - ETA: 0s - loss: 0.8568 - mae: 0.9246 - mse: 0.8568 - root_mean_squared_error: 0.9256
 1/35 [..............................] - ETA: 0s - loss: 0.8707 - mae: 0.9319 - mse: 0.8707 - root_mean_squared_error: 0.93319262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 140/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 141/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 142/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 143/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 144/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 145/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 146/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 147/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 148/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 149/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 150/150
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn_sgd_0.09015045206808658LR_[34]CHN_8CNNI_112BS_1DU_1P_val_mseM_150epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
35/35 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
41/47 [=========================>....] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.80198019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0113e-05
Epoch 6/150
46/47 [============================>.] - ETA: 0s - loss: 0.6430 - mae: 0.7998 - mse: 0.6430 - root_mean_squared_error: 0.8019
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0028172016609460115.
47/47 [==============================] - 0s 9ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0056
Epoch 7/150
40/47 [========================>.....] - ETA: 0s - loss: 0.6429 - mae: 0.7997 - mse: 0.6429 - root_mean_squared_error: 0.8018
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0014086008304730058.
47/47 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0028
Epoch 8/150
42/47 [=========================>....] - ETA: 0s - loss: 0.6422 - mae: 0.7993 - mse: 0.6422 - root_mean_squared_error: 0.8014
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0007043004152365029.
47/47 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0014
Epoch 9/150
41/47 [=========================>....] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.80198019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0113e-05
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00035215020761825144.
47/47 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 7.0430e-04
Epoch 10/150
47/47 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 2.2009e-05
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00017607510380912572.
47/47 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 3.5215e-04
Epoch 11/150
38/47 [=======================>......] - ETA: 0s - loss: 0.6432 - mae: 0.7998 - mse: 0.6432 - root_mean_squared_error: 0.8020
Epoch 11: ReduceLROnPlateau reducing learning rate to 8.803755190456286e-05.
47/47 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.7608e-04
Epoch 12/150
41/47 [=========================>....] - ETA: 0s - loss: 0.6426 - mae: 0.7995 - mse: 0.6426 - root_mean_squared_error: 0.8016
Epoch 12: ReduceLROnPlateau reducing learning rate to 4.401877595228143e-05.
47/47 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 8.8038e-05
Epoch 13/150
39/47 [=======================>......] - ETA: 0s - loss: 0.6435 - mae: 0.8001 - mse: 0.6435 - root_mean_squared_error: 0.8022
Epoch 13: ReduceLROnPlateau reducing learning rate to 2.2009387976140715e-05.
47/47 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 4.4019e-05
Epoch 14/150
40/47 [========================>.....] - ETA: 0s - loss: 0.6440 - mae: 0.8004 - mse: 0.6440 - root_mean_squared_error: 0.8025
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.1004693988070358e-05.
47/47 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 2.2009e-05
Epoch 15/150
47/47 [==============================] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.
47/47 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.1005e-05
Epoch 16/150
47/47 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 17/150
47/47 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 18/150
47/47 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 19/150
47/47 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 20/150
47/47 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 21/150
47/47 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 22/150
 1/47 [..............................] - ETA: 0s - loss: 0.6481 - mae: 0.8029 - mse: 0.6481 - root_mean_squared_error: 0.8051
47/47 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
47/47 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
47/47 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
47/47 [==============================] - 0s 10ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
47/47 [==============================] - 0s 10ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
47/47 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
47/47 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 62/150=========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 68/150=========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 73/150=========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 79/150=========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 83/150=========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 88/150=========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 94/150=========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 99/150=========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 105/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 110/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 115/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 121/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 127/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 132/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 138/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 143/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 149/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 149/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 149/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0007043004152365029.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 25/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 25/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 37/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 44/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 50/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 57/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 64/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 71/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 78/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 85/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 90/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 97/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 104/150uceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 111/150uceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 118/150uceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 125/150uceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 132/150uceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 139/150uceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 146/150uceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 146/150uceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 146/150uceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 25/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 25/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 37/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 37/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 47/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 55/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 62/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 69/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 76/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 84/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 91/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 96/150duceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 102/150uceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 110/150uceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 119/150uceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
Epoch 126/150uceLROnPlateau reducing learning rate to 1.1004693988070358e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-055
