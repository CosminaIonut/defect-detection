Epoch 1/20
95/98 [============================>.] - ETA: 0s - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3778
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 0.0038s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 0.0038s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.
98/98 [==============================] - 2s 18ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3777 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - val_root_mean_squared_error: 0.3772 - lr: 0.1176
Epoch 2/20
88/98 [=========================>....] - ETA: 0s - loss: 0.1426 - mae: 0.3751 - mse: 0.1426 - root_mean_squared_error: 0.3777
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.058800000697374344.
98/98 [==============================] - 1s 6ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3777 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - val_root_mean_squared_error: 0.3772 - lr: 0.1176
Epoch 3/20
97/98 [============================>.] - ETA: 0s - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3777
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.029400000348687172.
98/98 [==============================] - 1s 6ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3777 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - val_root_mean_squared_error: 0.3772 - lr: 0.0588
Epoch 4/20
89/98 [==========================>...] - ETA: 0s - loss: 0.1426 - mae: 0.3750 - mse: 0.1426 - root_mean_squared_error: 0.3776
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.014700000174343586.
98/98 [==============================] - 0s 5ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3777 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - val_root_mean_squared_error: 0.3772 - lr: 0.0294
Epoch 5/20
87/98 [=========================>....] - ETA: 0s - loss: 0.1426 - mae: 0.3751 - mse: 0.1426 - root_mean_squared_error: 0.3776
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.007350000087171793.
98/98 [==============================] - 0s 5ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3777 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - val_root_mean_squared_error: 0.3772 - lr: 0.0147
Epoch 6/20
82/98 [========================>.....] - ETA: 0s - loss: 0.1432 - mae: 0.3759 - mse: 0.1432 - root_mean_squared_error: 0.3784
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0036750000435858965.
98/98 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3777 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - val_root_mean_squared_error: 0.3772 - lr: 0.0074
Epoch 7/20
97/98 [============================>.] - ETA: 0s - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3778
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0018375000217929482.
98/98 [==============================] - 0s 5ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3777 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - val_root_mean_squared_error: 0.3772 - lr: 0.0037
Epoch 8/20
89/98 [==========================>...] - ETA: 0s - loss: 0.1429 - mae: 0.3755 - mse: 0.1429 - root_mean_squared_error: 0.3780
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0009187500108964741.
98/98 [==============================] - 1s 6ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3777 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - val_root_mean_squared_error: 0.3772 - lr: 0.0018
Epoch 9/20
86/98 [=========================>....] - ETA: 0s - loss: 0.1428 - mae: 0.3754 - mse: 0.1428 - root_mean_squared_error: 0.3780
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00045937500544823706.
98/98 [==============================] - 0s 5ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3777 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - val_root_mean_squared_error: 0.3772 - lr: 9.1875e-04
Epoch 10/20
97/98 [============================>.] - ETA: 0s - loss: 0.1426 - mae: 0.3751 - mse: 0.1426 - root_mean_squared_error: 0.3777
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00022968750272411853.
98/98 [==============================] - 1s 5ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3777 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - val_root_mean_squared_error: 0.3772 - lr: 4.5938e-04
Epoch 11/20
90/98 [==========================>...] - ETA: 0s - loss: 0.1425 - mae: 0.3749 - mse: 0.1425 - root_mean_squared_error: 0.3775
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00011484375136205927.
98/98 [==============================] - 1s 6ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3777 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - val_root_mean_squared_error: 0.3772 - lr: 2.2969e-04
Epoch 12/20
96/98 [============================>.] - ETA: 0s - loss: 0.1426 - mae: 0.3751 - mse: 0.1426 - root_mean_squared_error: 0.3776
Epoch 12: ReduceLROnPlateau reducing learning rate to 5.742187568102963e-05.
98/98 [==============================] - 1s 5ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3777 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - val_root_mean_squared_error: 0.3772 - lr: 1.1484e-04
Epoch 13/20
92/98 [===========================>..] - ETA: 0s - loss: 0.1429 - mae: 0.3754 - mse: 0.1429 - root_mean_squared_error: 0.3780
Epoch 13: ReduceLROnPlateau reducing learning rate to 2.8710937840514816e-05.
98/98 [==============================] - 1s 5ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3777 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - val_root_mean_squared_error: 0.3772 - lr: 5.7422e-05
Epoch 14/20
93/98 [===========================>..] - ETA: 0s - loss: 0.1426 - mae: 0.3751 - mse: 0.1426 - root_mean_squared_error: 0.3776
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.4355468920257408e-05.
98/98 [==============================] - 1s 6ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3777 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - val_root_mean_squared_error: 0.3772 - lr: 2.8711e-05
Epoch 15/20
89/98 [==========================>...] - ETA: 0s - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3778
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.
98/98 [==============================] - 1s 6ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3777 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - val_root_mean_squared_error: 0.3772 - lr: 1.4355e-05
Epoch 16/20
98/98 [==============================] - 1s 5ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3777 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - val_root_mean_squared_error: 0.3772 - lr: 1.0000e-05
Epoch 17/20
98/98 [==============================] - 1s 6ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3777 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - val_root_mean_squared_error: 0.3772 - lr: 1.0000e-05
Epoch 18/20
98/98 [==============================] - 1s 7ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3777 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - val_root_mean_squared_error: 0.3772 - lr: 1.0000e-05
Epoch 19/20
98/98 [==============================] - 1s 6ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3777 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - val_root_mean_squared_error: 0.3772 - lr: 1.0000e-05
Epoch 20/20
98/98 [==============================] - 1s 6ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - root_mean_squared_error: 0.3777 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - val_root_mean_squared_error: 0.3772 - lr: 1.0000e-05
>Saved ../../trained_models/CNN/models_segments_overlap_sgd_0.1176LR_[124, 516]HN_[124, 516]HN_40BS_1P_val_lossM_20epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])