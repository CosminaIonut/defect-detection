Epoch 1/50
26/26 [==============================] - ETA: 0s - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.
26/26 [==============================] - 3s 67ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 0.0492
Epoch 2/50
26/26 [==============================] - ETA: 0s - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.024595044553279877.
26/26 [==============================] - 0s 10ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 0.0492
Epoch 3/50
18/26 [===================>..........] - ETA: 0s - loss: 0.0074 - mae: 0.0740 - mse: 0.0074 - root_mean_squared_error: 0.0860
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.012297522276639938.
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 0.0246
Epoch 4/50
25/26 [===========================>..] - ETA: 0s - loss: 0.0074 - mae: 0.0740 - mse: 0.0074 - root_mean_squared_error: 0.0859
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.006148761138319969.
26/26 [==============================] - 0s 11ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 0.0123
Epoch 5/50
22/26 [========================>.....] - ETA: 0s - loss: 0.0074 - mae: 0.0740 - mse: 0.0074 - root_mean_squared_error: 0.0860
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0030743805691599846.
26/26 [==============================] - 0s 10ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 0.0061
Epoch 6/50
22/26 [========================>.....] - ETA: 0s - loss: 0.0073 - mae: 0.0732 - mse: 0.0073 - root_mean_squared_error: 0.0852
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0015371902845799923.
26/26 [==============================] - 0s 10ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 0.0031
Epoch 7/50
24/26 [==========================>...] - ETA: 0s - loss: 0.0073 - mae: 0.0737 - mse: 0.0073 - root_mean_squared_error: 0.0857
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0007685951422899961.
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 0.0015
Epoch 8/50
25/26 [===========================>..] - ETA: 0s - loss: 0.0074 - mae: 0.0740 - mse: 0.0074 - root_mean_squared_error: 0.0859
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003842975711449981.
26/26 [==============================] - 0s 12ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 7.6860e-04
Epoch 9/50
22/26 [========================>.....] - ETA: 0s - loss: 0.0073 - mae: 0.0736 - mse: 0.0073 - root_mean_squared_error: 0.0855
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00019214878557249904.
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 3.8430e-04
Epoch 10/50
25/26 [===========================>..] - ETA: 0s - loss: 0.0073 - mae: 0.0737 - mse: 0.0073 - root_mean_squared_error: 0.0857
Epoch 10: ReduceLROnPlateau reducing learning rate to 9.607439278624952e-05.
26/26 [==============================] - 0s 13ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.9215e-04
Epoch 11/50
22/26 [========================>.....] - ETA: 0s - loss: 0.0074 - mae: 0.0737 - mse: 0.0074 - root_mean_squared_error: 0.0857
Epoch 11: ReduceLROnPlateau reducing learning rate to 4.803719639312476e-05.
26/26 [==============================] - 0s 12ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 9.6074e-05
Epoch 12/50
25/26 [===========================>..] - ETA: 0s - loss: 0.0074 - mae: 0.0739 - mse: 0.0074 - root_mean_squared_error: 0.0858
Epoch 12: ReduceLROnPlateau reducing learning rate to 2.401859819656238e-05.
26/26 [==============================] - 0s 14ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 4.8037e-05
Epoch 13/50
22/26 [========================>.....] - ETA: 0s - loss: 0.0073 - mae: 0.0734 - mse: 0.0073 - root_mean_squared_error: 0.0854
Epoch 13: ReduceLROnPlateau reducing learning rate to 1.200929909828119e-05.
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 2.4019e-05
Epoch 14/50
20/26 [======================>.......] - ETA: 0s - loss: 0.0074 - mae: 0.0740 - mse: 0.0074 - root_mean_squared_error: 0.0860
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.
26/26 [==============================] - 0s 10ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.2009e-05
Epoch 15/50
26/26 [==============================] - 0s 10ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 16/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 17/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 18/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 19/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 20/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 21/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 22/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 23/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 24/50
26/26 [==============================] - 0s 8ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 25/50
26/26 [==============================] - 0s 10ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 26/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 27/50
26/26 [==============================] - 0s 10ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 28/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 29/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 30/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 31/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 32/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 33/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 34/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 35/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 36/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 37/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 38/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 39/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 40/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 41/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 42/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 43/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 44/50
26/26 [==============================] - 0s 10ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 45/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 46/50
26/26 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 47/50
26/26 [==============================] - 0s 10ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 48/50
26/26 [==============================] - 0s 8ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 49/50
26/26 [==============================] - 0s 8ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 50/50
26/26 [==============================] - 0s 8ms/step - loss: 0.0074 - mae: 0.0738 - mse: 0.0074 - root_mean_squared_error: 0.0858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn_rmsprop_0.04919008751713956LR_[124, 516]CHN_32CNNI_152BS_1000DU_1P_val_lossM_50epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
Epoch 1/50
34/34 [==============================] - ETA: 0s - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076
32/34 [===========================>..] - ETA: 0s - loss: 0.0432 - mae: 0.1994 - mse: 0.0432 - root_mean_squared_error: 0.20770858 - val_loss: 0.0075 - val_mae: 0.0745 - val_mse: 0.0075 - val_root_mean_squared_error: 0.0865 - lr: 1.0000e-05
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.006148761138319969.
34/34 [==============================] - 0s 10ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 0.0123
Epoch 5/50
33/34 [============================>.] - ETA: 0s - loss: 0.0432 - mae: 0.1994 - mse: 0.0432 - root_mean_squared_error: 0.2078
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0030743805691599846.
34/34 [==============================] - 0s 9ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 0.0061
Epoch 6/50
25/34 [=====================>........] - ETA: 0s - loss: 0.0435 - mae: 0.2002 - mse: 0.0435 - root_mean_squared_error: 0.2086
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0015371902845799923.
34/34 [==============================] - 0s 9ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 0.0031
Epoch 7/50
25/34 [=====================>........] - ETA: 0s - loss: 0.0434 - mae: 0.2000 - mse: 0.0434 - root_mean_squared_error: 0.2084
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0007685951422899961.
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 0.0015
Epoch 8/50
 1/34 [..............................] - ETA: 0s - loss: 0.0461 - mae: 0.2064 - mse: 0.0461 - root_mean_squared_error: 0.2148
25/34 [=====================>........] - ETA: 0s - loss: 0.0433 - mae: 0.1997 - mse: 0.0433 - root_mean_squared_error: 0.20802076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 7.6860e-04
Epoch 9/50
28/34 [=======================>......] - ETA: 0s - loss: 0.0427 - mae: 0.1982 - mse: 0.0427 - root_mean_squared_error: 0.2066
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00019214878557249904.
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 3.8430e-04
Epoch 10/50
28/34 [=======================>......] - ETA: 0s - loss: 0.0429 - mae: 0.1987 - mse: 0.0429 - root_mean_squared_error: 0.2071
Epoch 10: ReduceLROnPlateau reducing learning rate to 9.607439278624952e-05.
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.9215e-04
Epoch 11/50
29/34 [========================>.....] - ETA: 0s - loss: 0.0432 - mae: 0.1996 - mse: 0.0432 - root_mean_squared_error: 0.2080
Epoch 11: ReduceLROnPlateau reducing learning rate to 4.803719639312476e-05.
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 9.6074e-05
Epoch 12/50
30/34 [=========================>....] - ETA: 0s - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076
Epoch 12: ReduceLROnPlateau reducing learning rate to 2.401859819656238e-05.
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 4.8037e-05
Epoch 13/50
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 13: ReduceLROnPlateau reducing learning rate to 1.200929909828119e-05.
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 2.4019e-05
Epoch 14/50
29/34 [========================>.....] - ETA: 0s - loss: 0.0429 - mae: 0.1989 - mse: 0.0429 - root_mean_squared_error: 0.2072
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.
34/34 [==============================] - 0s 9ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.2009e-05
Epoch 15/50
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 16/50
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 17/50
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 18/50
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 19/50
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 20/50
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 21/50
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 22/50
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 23/50
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 24/50
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 25/50
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 26/50
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 27/50
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 28/50
21/34 [=================>............] - ETA: 0s - loss: 0.0431 - mae: 0.1995 - mse: 0.0431 - root_mean_squared_error: 0.2077
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 32/50
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 33/50
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 34/50
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 35/50
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 36/50
 1/34 [..............................] - ETA: 0s - loss: 0.0422 - mae: 0.1976 - mse: 0.0422 - root_mean_squared_error: 0.2055
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 42/50
34/34 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1992 - mse: 0.0431 - root_mean_squared_error: 0.2076 - val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 43/50
28/34 [=======================>......] - ETA: 0s - loss: 0.0432 - mae: 0.1996 - mse: 0.0432 - root_mean_squared_error: 0.2079
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
25/26 [===========================>..] - ETA: 0s - loss: 0.1068 - mae: 0.3239 - mse: 0.1068 - root_mean_squared_error: 0.3269'lr']) val_loss: 0.0428 - val_mae: 0.1985 - val_mse: 0.0428 - val_root_mean_squared_error: 0.2069 - lr: 1.0000e-05
Epoch 11: ReduceLROnPlateau reducing learning rate to 4.803719639312476e-05.
26/26 [==============================] - 0s 9ms/step - loss: 0.1068 - mae: 0.3238 - mse: 0.1068 - root_mean_squared_error: 0.3268 - val_loss: 0.1072 - val_mae: 0.3244 - val_mse: 0.1072 - val_root_mean_squared_error: 0.3274 - lr: 9.6074e-05
Epoch 12/50
19/26 [====================>.........] - ETA: 0s - loss: 0.1067 - mae: 0.3237 - mse: 0.1067 - root_mean_squared_error: 0.3267
Epoch 12: ReduceLROnPlateau reducing learning rate to 2.401859819656238e-05.
26/26 [==============================] - 0s 8ms/step - loss: 0.1068 - mae: 0.3238 - mse: 0.1068 - root_mean_squared_error: 0.3268 - val_loss: 0.1072 - val_mae: 0.3244 - val_mse: 0.1072 - val_root_mean_squared_error: 0.3274 - lr: 4.8037e-05
Epoch 13/50
26/26 [==============================] - ETA: 0s - loss: 0.1068 - mae: 0.3238 - mse: 0.1068 - root_mean_squared_error: 0.3268
26/26 [==============================] - 0s 8ms/step - loss: 0.1068 - mae: 0.3238 - mse: 0.1068 - root_mean_squared_error: 0.3268 - val_loss: 0.1072 - val_mae: 0.3244 - val_mse: 0.1072 - val_root_mean_squared_error: 0.3274 - lr: 1.0000e-05
Epoch 18/50
26/26 [==============================] - 0s 9ms/step - loss: 0.1068 - mae: 0.3238 - mse: 0.1068 - root_mean_squared_error: 0.3268 - val_loss: 0.1072 - val_mae: 0.3244 - val_mse: 0.1072 - val_root_mean_squared_error: 0.3274 - lr: 1.0000e-05
Epoch 19/50
26/26 [==============================] - 0s 9ms/step - loss: 0.1068 - mae: 0.3238 - mse: 0.1068 - root_mean_squared_error: 0.3268 - val_loss: 0.1072 - val_mae: 0.3244 - val_mse: 0.1072 - val_root_mean_squared_error: 0.3274 - lr: 1.0000e-05
Epoch 20/50
26/26 [==============================] - 0s 9ms/step - loss: 0.1068 - mae: 0.3238 - mse: 0.1068 - root_mean_squared_error: 0.3268 - val_loss: 0.1072 - val_mae: 0.3244 - val_mse: 0.1072 - val_root_mean_squared_error: 0.3274 - lr: 1.0000e-05
Epoch 21/50
26/26 [==============================] - 0s 9ms/step - loss: 0.1068 - mae: 0.3238 - mse: 0.1068 - root_mean_squared_error: 0.3268 - val_loss: 0.1072 - val_mae: 0.3244 - val_mse: 0.1072 - val_root_mean_squared_error: 0.3274 - lr: 1.0000e-05
Epoch 22/50
17/26 [==================>...........] - ETA: 0s - loss: 0.1066 - mae: 0.3236 - mse: 0.1066 - root_mean_squared_error: 0.3265
26/26 [==============================] - 0s 10ms/step - loss: 0.1068 - mae: 0.3238 - mse: 0.1068 - root_mean_squared_error: 0.3268 - val_loss: 0.1072 - val_mae: 0.3244 - val_mse: 0.1072 - val_root_mean_squared_error: 0.3274 - lr: 1.0000e-05
Epoch 28/50
26/26 [==============================] - 0s 8ms/step - loss: 0.1068 - mae: 0.3238 - mse: 0.1068 - root_mean_squared_error: 0.3268 - val_loss: 0.1072 - val_mae: 0.3244 - val_mse: 0.1072 - val_root_mean_squared_error: 0.3274 - lr: 1.0000e-05
Epoch 29/50
26/26 [==============================] - 0s 9ms/step - loss: 0.1068 - mae: 0.3238 - mse: 0.1068 - root_mean_squared_error: 0.3268 - val_loss: 0.1072 - val_mae: 0.3244 - val_mse: 0.1072 - val_root_mean_squared_error: 0.3274 - lr: 1.0000e-05
Epoch 30/50
26/26 [==============================] - 0s 9ms/step - loss: 0.1068 - mae: 0.3238 - mse: 0.1068 - root_mean_squared_error: 0.3268 - val_loss: 0.1072 - val_mae: 0.3244 - val_mse: 0.1072 - val_root_mean_squared_error: 0.3274 - lr: 1.0000e-05
Epoch 31/50
20/26 [======================>.......] - ETA: 0s - loss: 0.1065 - mae: 0.3234 - mse: 0.1065 - root_mean_squared_error: 0.3264
26/26 [==============================] - 0s 9ms/step - loss: 0.1068 - mae: 0.3238 - mse: 0.1068 - root_mean_squared_error: 0.3268 - val_loss: 0.1072 - val_mae: 0.3244 - val_mse: 0.1072 - val_root_mean_squared_error: 0.3274 - lr: 1.0000e-055
Epoch 38/50
26/26 [==============================] - 0s 8ms/step - loss: 0.1068 - mae: 0.3238 - mse: 0.1068 - root_mean_squared_error: 0.3268 - val_loss: 0.1072 - val_mae: 0.3244 - val_mse: 0.1072 - val_root_mean_squared_error: 0.3274 - lr: 1.0000e-05
Epoch 39/50
26/26 [==============================] - 0s 8ms/step - loss: 0.1068 - mae: 0.3238 - mse: 0.1068 - root_mean_squared_error: 0.3268 - val_loss: 0.1072 - val_mae: 0.3244 - val_mse: 0.1072 - val_root_mean_squared_error: 0.3274 - lr: 1.0000e-05
Epoch 40/50
20/26 [======================>.......] - ETA: 0s - loss: 0.1068 - mae: 0.3239 - mse: 0.1068 - root_mean_squared_error: 0.3268
26/26 [==============================] - 0s 9ms/step - loss: 0.1068 - mae: 0.3238 - mse: 0.1068 - root_mean_squared_error: 0.3268 - val_loss: 0.1072 - val_mae: 0.3244 - val_mse: 0.1072 - val_root_mean_squared_error: 0.3274 - lr: 1.0000e-055
Epoch 48/50
26/26 [==============================] - 0s 9ms/step - loss: 0.1068 - mae: 0.3238 - mse: 0.1068 - root_mean_squared_error: 0.3268 - val_loss: 0.1072 - val_mae: 0.3244 - val_mse: 0.1072 - val_root_mean_squared_error: 0.3274 - lr: 1.0000e-05
Epoch 49/50
26/26 [==============================] - 0s 9ms/step - loss: 0.1068 - mae: 0.3238 - mse: 0.1068 - root_mean_squared_error: 0.3268 - val_loss: 0.1072 - val_mae: 0.3244 - val_mse: 0.1072 - val_root_mean_squared_error: 0.3274 - lr: 1.0000e-05
Epoch 50/50
 1/26 [>.............................] - ETA: 0s - loss: 0.1025 - mae: 0.3173 - mse: 0.1025 - root_mean_squared_error: 0.3201
 1/26 [>.............................] - ETA: 0s - loss: 0.1796 - mae: 0.4215 - mse: 0.1796 - root_mean_squared_error: 0.42373268 - val_loss: 0.1072 - val_mae: 0.3244 - val_mse: 0.1072 - val_root_mean_squared_error: 0.3274 - lr: 1.0000e-055
18/26 [===================>..........] - ETA: 0s - loss: 0.1818 - mae: 0.4242 - mse: 0.1818 - root_mean_squared_error: 0.42643268 - val_loss: 0.1072 - val_mae: 0.3244 - val_mse: 0.1072 - val_root_mean_squared_error: 0.3274 - lr: 1.0000e-055
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00019214878557249904.
26/26 [==============================] - 0s 8ms/step - loss: 0.1815 - mae: 0.4238 - mse: 0.1815 - root_mean_squared_error: 0.4261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 3.8430e-04
Epoch 10/50
20/26 [======================>.......] - ETA: 0s - loss: 0.1811 - mae: 0.4233 - mse: 0.1811 - root_mean_squared_error: 0.4255
18/26 [===================>..........] - ETA: 0s - loss: 0.1816 - mae: 0.4239 - mse: 0.1816 - root_mean_squared_error: 0.42623268 - val_loss: 0.1072 - val_mae: 0.3244 - val_mse: 0.1072 - val_root_mean_squared_error: 0.3274 - lr: 1.0000e-055
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.
26/26 [==============================] - 0s 9ms/step - loss: 0.1815 - mae: 0.4238 - mse: 0.1815 - root_mean_squared_error: 0.4261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 1.2009e-05
Epoch 15/50
26/26 [==============================] - 0s 9ms/step - loss: 0.1815 - mae: 0.4238 - mse: 0.1815 - root_mean_squared_error: 0.4261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 1.0000e-05
Epoch 16/50
26/26 [==============================] - 0s 8ms/step - loss: 0.1815 - mae: 0.4238 - mse: 0.1815 - root_mean_squared_error: 0.4261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 1.0000e-05
Epoch 17/50
26/26 [==============================] - 0s 8ms/step - loss: 0.1815 - mae: 0.4238 - mse: 0.1815 - root_mean_squared_error: 0.4261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 1.0000e-05
Epoch 18/50
26/26 [==============================] - 0s 8ms/step - loss: 0.1815 - mae: 0.4238 - mse: 0.1815 - root_mean_squared_error: 0.4261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 1.0000e-05
Epoch 19/50
18/26 [===================>..........] - ETA: 0s - loss: 0.1813 - mae: 0.4236 - mse: 0.1813 - root_mean_squared_error: 0.4258
26/26 [==============================] - 0s 9ms/step - loss: 0.1815 - mae: 0.4238 - mse: 0.1815 - root_mean_squared_error: 0.4261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 1.0000e-055
Epoch 24/50
26/26 [==============================] - 0s 9ms/step - loss: 0.1815 - mae: 0.4238 - mse: 0.1815 - root_mean_squared_error: 0.4261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 1.0000e-05
Epoch 25/50
26/26 [==============================] - 0s 9ms/step - loss: 0.1815 - mae: 0.4238 - mse: 0.1815 - root_mean_squared_error: 0.4261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 1.0000e-05
Epoch 26/50
26/26 [==============================] - 0s 9ms/step - loss: 0.1815 - mae: 0.4238 - mse: 0.1815 - root_mean_squared_error: 0.4261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 1.0000e-05
Epoch 27/50
26/26 [==============================] - 0s 9ms/step - loss: 0.1815 - mae: 0.4238 - mse: 0.1815 - root_mean_squared_error: 0.4261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 1.0000e-05
Epoch 28/50
19/26 [====================>.........] - ETA: 0s - loss: 0.1818 - mae: 0.4242 - mse: 0.1818 - root_mean_squared_error: 0.4264
26/26 [==============================] - 0s 8ms/step - loss: 0.1815 - mae: 0.4238 - mse: 0.1815 - root_mean_squared_error: 0.4261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 1.0000e-055
Epoch 34/50
26/26 [==============================] - 0s 8ms/step - loss: 0.1815 - mae: 0.4238 - mse: 0.1815 - root_mean_squared_error: 0.4261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 1.0000e-05
Epoch 35/50
26/26 [==============================] - 0s 8ms/step - loss: 0.1815 - mae: 0.4238 - mse: 0.1815 - root_mean_squared_error: 0.4261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 1.0000e-05
Epoch 36/50
26/26 [==============================] - 0s 8ms/step - loss: 0.1815 - mae: 0.4238 - mse: 0.1815 - root_mean_squared_error: 0.4261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 1.0000e-05
Epoch 37/50
19/26 [====================>.........] - ETA: 0s - loss: 0.1812 - mae: 0.4234 - mse: 0.1812 - root_mean_squared_error: 0.4257
26/26 [==============================] - 0s 9ms/step - loss: 0.1815 - mae: 0.4238 - mse: 0.1815 - root_mean_squared_error: 0.4261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 1.0000e-055
Epoch 44/50
26/26 [==============================] - 0s 8ms/step - loss: 0.1815 - mae: 0.4238 - mse: 0.1815 - root_mean_squared_error: 0.4261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 1.0000e-05
Epoch 45/50
26/26 [==============================] - 0s 8ms/step - loss: 0.1815 - mae: 0.4238 - mse: 0.1815 - root_mean_squared_error: 0.4261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 1.0000e-05
Epoch 46/50
26/26 [==============================] - 0s 8ms/step - loss: 0.1815 - mae: 0.4238 - mse: 0.1815 - root_mean_squared_error: 0.4261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 1.0000e-05
Epoch 47/50
 1/26 [>.............................] - ETA: 0s - loss: 0.1773 - mae: 0.4183 - mse: 0.1773 - root_mean_squared_error: 0.4211
26/26 [==============================] - 0s 9ms/step - loss: 0.1815 - mae: 0.4238 - mse: 0.1815 - root_mean_squared_error: 0.4261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 1.0000e-055
24/26 [==========================>...] - ETA: 0s - loss: 0.2764 - mae: 0.5239 - mse: 0.2764 - root_mean_squared_error: 0.52574261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 1.0000e-055
23/26 [=========================>....] - ETA: 0s - loss: 0.2758 - mae: 0.5233 - mse: 0.2758 - root_mean_squared_error: 0.52514261 - val_loss: 0.1821 - val_mae: 0.4244 - val_mse: 0.1821 - val_root_mean_squared_error: 0.4267 - lr: 1.0000e-055
Epoch 12: ReduceLROnPlateau reducing learning rate to 2.401859819656238e-05.
26/26 [==============================] - 0s 11ms/step - loss: 0.2763 - mae: 0.5238 - mse: 0.2763 - root_mean_squared_error: 0.5256 - val_loss: 0.2770 - val_mae: 0.5244 - val_mse: 0.2770 - val_root_mean_squared_error: 0.5263 - lr: 4.8037e-05
Epoch 13/50
19/26 [====================>.........] - ETA: 0s - loss: 0.2769 - mae: 0.5244 - mse: 0.2769 - root_mean_squared_error: 0.5262
Epoch 13: ReduceLROnPlateau reducing learning rate to 1.200929909828119e-05.
26/26 [==============================] - 0s 10ms/step - loss: 0.2763 - mae: 0.5238 - mse: 0.2763 - root_mean_squared_error: 0.5256 - val_loss: 0.2770 - val_mae: 0.5244 - val_mse: 0.2770 - val_root_mean_squared_error: 0.5263 - lr: 2.4019e-05
Epoch 14/50
 7/26 [=======>......................] - ETA: 0s - loss: 0.2784 - mae: 0.5258 - mse: 0.2784 - root_mean_squared_error: 0.5276
26/26 [==============================] - 0s 9ms/step - loss: 0.2763 - mae: 0.5238 - mse: 0.2763 - root_mean_squared_error: 0.5256 - val_loss: 0.2770 - val_mae: 0.5244 - val_mse: 0.2770 - val_root_mean_squared_error: 0.5263 - lr: 1.0000e-055
Epoch 20/50
26/26 [==============================] - 0s 12ms/step - loss: 0.2763 - mae: 0.5238 - mse: 0.2763 - root_mean_squared_error: 0.5256 - val_loss: 0.2770 - val_mae: 0.5244 - val_mse: 0.2770 - val_root_mean_squared_error: 0.5263 - lr: 1.0000e-05
Epoch 21/50
23/26 [=========================>....] - ETA: 0s - loss: 0.2767 - mae: 0.5242 - mse: 0.2767 - root_mean_squared_error: 0.5260
26/26 [==============================] - 0s 9ms/step - loss: 0.2763 - mae: 0.5238 - mse: 0.2763 - root_mean_squared_error: 0.5256 - val_loss: 0.2770 - val_mae: 0.5244 - val_mse: 0.2770 - val_root_mean_squared_error: 0.5263 - lr: 1.0000e-055
26/26 [==============================] - 0s 13ms/step - loss: 0.2763 - mae: 0.5238 - mse: 0.2763 - root_mean_squared_error: 0.5256 - val_loss: 0.2770 - val_mae: 0.5244 - val_mse: 0.2770 - val_root_mean_squared_error: 0.5263 - lr: 1.0000e-05
26/26 [==============================] - 0s 10ms/step - loss: 0.2763 - mae: 0.5238 - mse: 0.2763 - root_mean_squared_error: 0.5256 - val_loss: 0.2770 - val_mae: 0.5244 - val_mse: 0.2770 - val_root_mean_squared_error: 0.5263 - lr: 1.0000e-05
26/26 [==============================] - 0s 8ms/step - loss: 0.2763 - mae: 0.5238 - mse: 0.2763 - root_mean_squared_error: 0.5256 - val_loss: 0.2770 - val_mae: 0.5244 - val_mse: 0.2770 - val_root_mean_squared_error: 0.5263 - lr: 1.0000e-055
26/26 [==============================] - 0s 8ms/step - loss: 0.2763 - mae: 0.5238 - mse: 0.2763 - root_mean_squared_error: 0.5256 - val_loss: 0.2770 - val_mae: 0.5244 - val_mse: 0.2770 - val_root_mean_squared_error: 0.5263 - lr: 1.0000e-055
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0051s vs `on_train_batch_end` time: 0.0056s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0051s vs `on_train_batch_end` time: 0.0056s). Check your callbacks.
18/26 [===================>..........] - ETA: 0s - loss: 0.3922 - mae: 0.6248 - mse: 0.3922 - root_mean_squared_error: 0.62635256 - val_loss: 0.2770 - val_mae: 0.5244 - val_mse: 0.2770 - val_root_mean_squared_error: 0.5263 - lr: 1.0000e-055
26/26 [==============================] - 0s 10ms/step - loss: 0.3911 - mae: 0.6238 - mse: 0.3911 - root_mean_squared_error: 0.6253 - val_loss: 0.3919 - val_mae: 0.6244 - val_mse: 0.3919 - val_root_mean_squared_error: 0.6260 - lr: 1.0000e-05
26/26 [==============================] - 0s 9ms/step - loss: 0.3911 - mae: 0.6238 - mse: 0.3911 - root_mean_squared_error: 0.6253 - val_loss: 0.3919 - val_mae: 0.6244 - val_mse: 0.3919 - val_root_mean_squared_error: 0.6260 - lr: 1.0000e-055
26/26 [==============================] - 0s 9ms/step - loss: 0.3911 - mae: 0.6238 - mse: 0.3911 - root_mean_squared_error: 0.6253 - val_loss: 0.3919 - val_mae: 0.6244 - val_mse: 0.3919 - val_root_mean_squared_error: 0.6260 - lr: 1.0000e-055
26/26 [==============================] - 0s 10ms/step - loss: 0.3911 - mae: 0.6238 - mse: 0.3911 - root_mean_squared_error: 0.6253 - val_loss: 0.3919 - val_mae: 0.6244 - val_mse: 0.3919 - val_root_mean_squared_error: 0.6260 - lr: 1.0000e-05
26/26 [==============================] - 0s 10ms/step - loss: 0.3911 - mae: 0.6238 - mse: 0.3911 - root_mean_squared_error: 0.6253 - val_loss: 0.3919 - val_mae: 0.6244 - val_mse: 0.3919 - val_root_mean_squared_error: 0.6260 - lr: 1.0000e-05
24/26 [==========================>...] - ETA: 0s - loss: 0.5257 - mae: 0.7237 - mse: 0.5257 - root_mean_squared_error: 0.7250.6253 - val_loss: 0.3919 - val_mae: 0.6244 - val_mse: 0.3919 - val_root_mean_squared_error: 0.6260 - lr: 1.0000e-05
17/26 [==================>...........] - ETA: 0s - loss: 0.5248 - mae: 0.7231 - mse: 0.5248 - root_mean_squared_error: 0.7244.6253 - val_loss: 0.3919 - val_mae: 0.6244 - val_mse: 0.3919 - val_root_mean_squared_error: 0.6260 - lr: 1.0000e-05
26/26 [==============================] - 0s 8ms/step - loss: 0.5258 - mae: 0.7238 - mse: 0.5258 - root_mean_squared_error: 0.7251 - val_loss: 0.5268 - val_mae: 0.7244 - val_mse: 0.5268 - val_root_mean_squared_error: 0.7258 - lr: 1.0000e-055
26/26 [==============================] - 0s 8ms/step - loss: 0.5258 - mae: 0.7238 - mse: 0.5258 - root_mean_squared_error: 0.7251 - val_loss: 0.5268 - val_mae: 0.7244 - val_mse: 0.5268 - val_root_mean_squared_error: 0.7258 - lr: 1.0000e-055
15/26 [================>.............] - ETA: 0s - loss: 0.5272 - mae: 0.7248 - mse: 0.5272 - root_mean_squared_error: 0.72617251 - val_loss: 0.5268 - val_mae: 0.7244 - val_mse: 0.5268 - val_root_mean_squared_error: 0.7258 - lr: 1.0000e-055
26/26 [==============================] - 0s 9ms/step - loss: 0.5258 - mae: 0.7238 - mse: 0.5258 - root_mean_squared_error: 0.7251 - val_loss: 0.5268 - val_mae: 0.7244 - val_mse: 0.5268 - val_root_mean_squared_error: 0.7258 - lr: 1.0000e-055
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.5268 - val_mae: 0.7244 - val_mse: 0.5268 - val_root_mean_squared_error: 0.7258 - lr: 1.0000e-055
18/26 [===================>..........] - ETA: 0s - loss: 0.6810 - mae: 0.8240 - mse: 0.6810 - root_mean_squared_error: 0.8252'lr']) val_loss: 0.5268 - val_mae: 0.7244 - val_mse: 0.5268 - val_root_mean_squared_error: 0.7258 - lr: 1.0000e-055
26/26 [==============================] - 0s 8ms/step - loss: 0.6806 - mae: 0.8238 - mse: 0.6806 - root_mean_squared_error: 0.8250 - val_loss: 0.6816 - val_mae: 0.8244 - val_mse: 0.6816 - val_root_mean_squared_error: 0.8256 - lr: 1.0000e-055
26/26 [==============================] - 0s 8ms/step - loss: 0.6806 - mae: 0.8238 - mse: 0.6806 - root_mean_squared_error: 0.8250 - val_loss: 0.6816 - val_mae: 0.8244 - val_mse: 0.6816 - val_root_mean_squared_error: 0.8256 - lr: 1.0000e-055
26/26 [==============================] - 0s 9ms/step - loss: 0.6806 - mae: 0.8238 - mse: 0.6806 - root_mean_squared_error: 0.8250 - val_loss: 0.6816 - val_mae: 0.8244 - val_mse: 0.6816 - val_root_mean_squared_error: 0.8256 - lr: 1.0000e-055
26/26 [==============================] - 0s 9ms/step - loss: 0.6806 - mae: 0.8238 - mse: 0.6806 - root_mean_squared_error: 0.8250 - val_loss: 0.6816 - val_mae: 0.8244 - val_mse: 0.6816 - val_root_mean_squared_error: 0.8256 - lr: 1.0000e-055
 1/26 [>.............................] - ETA: 0s - loss: 0.8592 - mae: 0.9260 - mse: 0.8592 - root_mean_squared_error: 0.92698250 - val_loss: 0.6816 - val_mae: 0.8244 - val_mse: 0.6816 - val_root_mean_squared_error: 0.8256 - lr: 1.0000e-055
20/26 [======================>.......] - ETA: 0s - loss: 0.8549 - mae: 0.9236 - mse: 0.8549 - root_mean_squared_error: 0.92468250 - val_loss: 0.6816 - val_mae: 0.8244 - val_mse: 0.6816 - val_root_mean_squared_error: 0.8256 - lr: 1.0000e-055
20/26 [======================>.......] - ETA: 0s - loss: 0.8552 - mae: 0.9237 - mse: 0.8552 - root_mean_squared_error: 0.92488250 - val_loss: 0.6816 - val_mae: 0.8244 - val_mse: 0.6816 - val_root_mean_squared_error: 0.8256 - lr: 1.0000e-055
26/26 [==============================] - 0s 8ms/step - loss: 0.8553 - mae: 0.9238 - mse: 0.8553 - root_mean_squared_error: 0.9249 - val_loss: 0.8565 - val_mae: 0.9244 - val_mse: 0.8565 - val_root_mean_squared_error: 0.9255 - lr: 1.0000e-055
26/26 [==============================] - 0s 9ms/step - loss: 0.8553 - mae: 0.9238 - mse: 0.8553 - root_mean_squared_error: 0.9249 - val_loss: 0.8565 - val_mae: 0.9244 - val_mse: 0.8565 - val_root_mean_squared_error: 0.9255 - lr: 1.0000e-055
26/26 [==============================] - 0s 8ms/step - loss: 0.8553 - mae: 0.9238 - mse: 0.8553 - root_mean_squared_error: 0.9249 - val_loss: 0.8565 - val_mae: 0.9244 - val_mse: 0.8565 - val_root_mean_squared_error: 0.9255 - lr: 1.0000e-055
26/26 [==============================] - 0s 8ms/step - loss: 0.8553 - mae: 0.9238 - mse: 0.8553 - root_mean_squared_error: 0.9249 - val_loss: 0.8565 - val_mae: 0.9244 - val_mse: 0.8565 - val_root_mean_squared_error: 0.9255 - lr: 1.0000e-055
26/26 [==============================] - 0s 8ms/step - loss: 0.8553 - mae: 0.9238 - mse: 0.8553 - root_mean_squared_error: 0.9249 - val_loss: 0.8565 - val_mae: 0.9244 - val_mse: 0.8565 - val_root_mean_squared_error: 0.9255 - lr: 1.0000e-055