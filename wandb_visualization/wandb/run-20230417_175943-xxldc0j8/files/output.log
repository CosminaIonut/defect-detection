Epoch 1/30
 75/122 [=================>............] - ETA: 0s - loss: 0.0210 - mae: 0.0555 - mse: 0.0062
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_175943-xxldc0j8\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 7ms/step - loss: 0.0149 - mae: 0.0506 - mse: 0.0049 - val_loss: 0.0084 - val_mae: 0.0553 - val_mse: 0.0046 - lr: 0.0594
Epoch 2/30
122/122 [==============================] - 1s 7ms/step - loss: 0.0039 - mae: 0.0391 - mse: 0.0021 - val_loss: 0.0035 - val_mae: 0.0380 - val_mse: 0.0020 - lr: 0.0594
Epoch 3/30
 71/122 [================>.............] - ETA: 0s - loss: 0.0035 - mae: 0.0375 - mse: 0.0019
122/122 [==============================] - 1s 6ms/step - loss: 0.0036 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.0034 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0594
Epoch 4/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0034 - val_mae: 0.0366 - val_mse: 0.0018 - lr: 0.0594
Epoch 5/30
122/122 [==============================] - 0s 994us/step - loss: 0.0036 - mae: 0.0366 - mse: 0.0019 - val_loss: 0.0042 - val_mae: 0.0389 - val_mse: 0.0020 - lr: 0.0594
Epoch 6/30
122/122 [==============================] - 0s 969us/step - loss: 0.0035 - mae: 0.0361 - mse: 0.0018 - val_loss: 0.0037 - val_mae: 0.0374 - val_mse: 0.0020 - lr: 0.0594
Epoch 7/30
 85/122 [===================>..........] - ETA: 0s - loss: 0.0034 - mae: 0.0341 - mse: 0.0017
122/122 [==============================] - 1s 6ms/step - loss: 0.0034 - mae: 0.0336 - mse: 0.0016 - val_loss: 0.0030 - val_mae: 0.0301 - val_mse: 0.0013 - lr: 0.0594
Epoch 8/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0332 - mse: 0.0016 - val_loss: 0.0035 - val_mae: 0.0348 - val_mse: 0.0018 - lr: 0.0594
Epoch 9/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0032 - mae: 0.0309 - mse: 0.0015 - val_loss: 0.0031 - val_mae: 0.0324 - val_mse: 0.0016 - lr: 0.0594
Epoch 10/30
 80/122 [==================>...........] - ETA: 0s - loss: 0.0032 - mae: 0.0303 - mse: 0.0014
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.029723942279815674.
122/122 [==============================] - 0s 1ms/step - loss: 0.0032 - mae: 0.0301 - mse: 0.0014 - val_loss: 0.0033 - val_mae: 0.0298 - val_mse: 0.0013 - lr: 0.0594
Epoch 11/30
 84/122 [===================>..........] - ETA: 0s - loss: 0.0016 - mae: 0.0273 - mse: 0.0012
122/122 [==============================] - 1s 6ms/step - loss: 0.0016 - mae: 0.0267 - mse: 0.0011 - val_loss: 0.0020 - val_mae: 0.0299 - val_mse: 0.0013 - lr: 0.0297
Epoch 12/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0255 - mse: 0.0011 - val_loss: 0.0025 - val_mae: 0.0350 - val_mse: 0.0018 - lr: 0.0297
Epoch 13/30
 85/122 [===================>..........] - ETA: 0s - loss: 0.0016 - mae: 0.0254 - mse: 0.0010
122/122 [==============================] - 1s 6ms/step - loss: 0.0016 - mae: 0.0252 - mse: 0.0010 - val_loss: 0.0015 - val_mae: 0.0252 - val_mse: 9.9978e-04 - lr: 0.0297
Epoch 14/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0252 - mse: 0.0010 - val_loss: 0.0020 - val_mae: 0.0316 - val_mse: 0.0015 - lr: 0.0297
Epoch 15/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0250 - mse: 0.0010 - val_loss: 0.0020 - val_mae: 0.0308 - val_mse: 0.0014 - lr: 0.0297
Epoch 16/30
 84/122 [===================>..........] - ETA: 0s - loss: 0.0015 - mae: 0.0247 - mse: 0.0010
122/122 [==============================] - 1s 6ms/step - loss: 0.0015 - mae: 0.0248 - mse: 0.0010 - val_loss: 0.0014 - val_mae: 0.0224 - val_mse: 8.1077e-04 - lr: 0.0297
Epoch 17/30
 70/122 [================>.............] - ETA: 0s - loss: 0.0015 - mae: 0.0242 - mse: 9.4713e-04
122/122 [==============================] - 1s 7ms/step - loss: 0.0015 - mae: 0.0247 - mse: 9.9180e-04 - val_loss: 0.0013 - val_mae: 0.0229 - val_mse: 8.4198e-04 - lr: 0.0297
Epoch 18/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0246 - mse: 9.8673e-04 - val_loss: 0.0023 - val_mae: 0.0324 - val_mse: 0.0015 - lr: 0.0297
Epoch 19/30
 79/122 [==================>...........] - ETA: 0s - loss: 0.0015 - mae: 0.0244 - mse: 9.6300e-04
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.014861971139907837.
122/122 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0245 - mse: 9.8787e-04 - val_loss: 0.0014 - val_mae: 0.0240 - val_mse: 9.2759e-04 - lr: 0.0297
Epoch 20/30
 76/122 [=================>............] - ETA: 0s - loss: 9.7617e-04 - mae: 0.0224 - mse: 8.3136e-04
122/122 [==============================] - 1s 6ms/step - loss: 9.9192e-04 - mae: 0.0227 - mse: 8.4462e-04 - val_loss: 9.5434e-04 - val_mae: 0.0226 - val_mse: 8.2434e-04 - lr: 0.0149
Epoch 21/30
122/122 [==============================] - 0s 1ms/step - loss: 9.9451e-04 - mae: 0.0227 - mse: 8.5520e-04 - val_loss: 0.0015 - val_mae: 0.0299 - val_mse: 0.0014 - lr: 0.0149
Epoch 22/30
 79/122 [==================>...........] - ETA: 0s - loss: 9.6313e-04 - mae: 0.0224 - mse: 8.3027e-04
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0074309855699539185.
122/122 [==============================] - 0s 1ms/step - loss: 9.6784e-04 - mae: 0.0225 - mse: 8.3487e-04 - val_loss: 0.0012 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0149
Epoch 23/30
122/122 [==============================] - 0s 1ms/step - loss: 9.0895e-04 - mae: 0.0221 - mse: 8.0248e-04 - val_loss: 0.0011 - val_mae: 0.0260 - val_mse: 0.0011 - lr: 0.0074
Epoch 24/30
122/122 [==============================] - 0s 1ms/step - loss: 9.0588e-04 - mae: 0.0221 - mse: 8.0072e-04 - val_loss: 9.6940e-04 - val_mae: 0.0235 - val_mse: 8.6488e-04 - lr: 0.0074
Epoch 25/30
 71/122 [================>.............] - ETA: 0s - loss: 9.3319e-04 - mae: 0.0224 - mse: 8.2866e-04
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0037154927849769592.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_175943-xxldc0j8\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 8ms/step - loss: 9.0034e-04 - mae: 0.0220 - mse: 7.9714e-04 - val_loss: 9.3522e-04 - val_mae: 0.0225 - val_mse: 8.2592e-04 - lr: 0.0074
Epoch 26/30
 68/122 [===============>..............] - ETA: 0s - loss: 8.7628e-04 - mae: 0.0217 - mse: 7.8686e-04
122/122 [==============================] - 1s 6ms/step - loss: 8.7494e-04 - mae: 0.0217 - mse: 7.8497e-04 - val_loss: 8.8914e-04 - val_mae: 0.0225 - val_mse: 8.0310e-04 - lr: 0.0037
Epoch 27/30
 68/122 [===============>..............] - ETA: 0s - loss: 8.8138e-04 - mae: 0.0218 - mse: 7.8664e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_175943-xxldc0j8\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 6ms/step - loss: 8.6698e-04 - mae: 0.0217 - mse: 7.7432e-04 - val_loss: 8.7798e-04 - val_mae: 0.0222 - val_mse: 7.9734e-04 - lr: 0.0037
Epoch 28/30
 75/122 [=================>............] - ETA: 0s - loss: 8.4401e-04 - mae: 0.0214 - mse: 7.5746e-04
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0018577463924884796.
122/122 [==============================] - 1s 6ms/step - loss: 8.6301e-04 - mae: 0.0216 - mse: 7.7418e-04 - val_loss: 8.7012e-04 - val_mae: 0.0221 - val_mse: 7.8285e-04 - lr: 0.0037
Epoch 29/30
122/122 [==============================] - 0s 1ms/step - loss: 8.5003e-04 - mae: 0.0214 - mse: 7.6355e-04 - val_loss: 8.7315e-04 - val_mae: 0.0224 - val_mse: 7.9399e-04 - lr: 0.0019
Epoch 30/30
122/122 [==============================] - 0s 1ms/step - loss: 8.5092e-04 - mae: 0.0215 - mse: 7.6753e-04 - val_loss: 8.7581e-04 - val_mae: 0.0221 - val_mse: 7.9124e-04 - lr: 0.0019
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.05944788340483801_20_32_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
162/162 [==============================] - 1s 2ms/step - loss: 0.0124 - mae: 0.0570 - mse: 0.0050 - val_loss: 0.0052 - val_mae: 0.0519 - val_mse: 0.0037 - lr: 0.0594
Epoch 2/30
162/162 [==============================] - 0s 1ms/step - loss: 0.0051 - mae: 0.0509 - mse: 0.0035 - val_loss: 0.0049 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0594
Epoch 3/30
162/162 [==============================] - 0s 1ms/step - loss: 0.0051 - mae: 0.0511 - mse: 0.0035 - val_loss: 0.0057 - val_mae: 0.0544 - val_mse: 0.0042 - lr: 0.0594
Epoch 4/30
162/162 [==============================] - 0s 951us/step - loss: 0.0051 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.0052 - val_mae: 0.0512 - val_mse: 0.0036 - lr: 0.0594
Epoch 5/30
 84/162 [==============>...............] - ETA: 0s - loss: 0.0051 - mae: 0.0507 - mse: 0.0035
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.029723942279815674.
162/162 [==============================] - 0s 932us/step - loss: 0.0051 - mae: 0.0512 - mse: 0.0035 - val_loss: 0.0109 - val_mae: 0.0717 - val_mse: 0.0076 - lr: 0.0594
Epoch 6/30
162/162 [==============================] - 0s 975us/step - loss: 0.0038 - mae: 0.0509 - mse: 0.0035 - val_loss: 0.0037 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0297
Epoch 7/30
162/162 [==============================] - 0s 928us/step - loss: 0.0038 - mae: 0.0509 - mse: 0.0034 - val_loss: 0.0043 - val_mae: 0.0524 - val_mse: 0.0038 - lr: 0.0297
Epoch 8/30
 86/162 [==============>...............] - ETA: 0s - loss: 0.0038 - mae: 0.0508 - mse: 0.0034
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.014861971139907837.
162/162 [==============================] - 0s 943us/step - loss: 0.0038 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0038 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0297
Epoch 9/30
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0149
Epoch 10/30
162/162 [==============================] - 0s 998us/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0149
Epoch 11/30
 87/162 [===============>..............] - ETA: 0s - loss: 0.0035 - mae: 0.0512 - mse: 0.0035
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0074309855699539185.
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0149
Epoch 12/30
162/162 [==============================] - 0s 924us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0074
Epoch 13/30
162/162 [==============================] - 0s 965us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0074
Epoch 14/30
 85/162 [==============>...............] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0037154927849769592.
162/162 [==============================] - 0s 921us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0074
Epoch 15/30
162/162 [==============================] - 0s 970us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0037
Epoch 16/30
162/162 [==============================] - 0s 929us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0037
Epoch 17/30
 86/162 [==============>...............] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0018577463924884796.
162/162 [==============================] - 0s 970us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0037
Epoch 18/30
162/162 [==============================] - 0s 947us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0019
Epoch 19/30
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0019
Epoch 20/30
 83/162 [==============>...............] - ETA: 0s - loss: 0.0035 - mae: 0.0510 - mse: 0.0035
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0009288731962442398.
162/162 [==============================] - 0s 955us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0019
Epoch 21/30
162/162 [==============================] - 0s 987us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 9.2887e-04
Epoch 22/30
162/162 [==============================] - 0s 992us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 9.2887e-04
Epoch 23/30
159/162 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0004644365981221199.
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 9.2887e-04
Epoch 24/30
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 4.6444e-04
Epoch 25/30
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 4.6444e-04
Epoch 26/30
152/162 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00023221829906105995.
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 4.6444e-04
Epoch 27/30
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 2.3222e-04
Epoch 28/30
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 2.3222e-04
Epoch 29/30
147/162 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00011610914953052998.
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 2.3222e-04
Epoch 30/30
162/162 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.1611e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.05944788340483801_20_32_30epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
122/122 [==============================] - 1s 2ms/step - loss: 0.0116 - mae: 0.0426 - mse: 0.0028 - val_loss: 0.0053 - val_mae: 0.0482 - val_mse: 0.0035 - lr: 0.0594
Epoch 2/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0391 - mse: 0.0021 - val_loss: 0.0050 - val_mae: 0.0465 - val_mse: 0.0032 - lr: 0.0594
Epoch 3/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0391 - mse: 0.0021 - val_loss: 0.0035 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0594
Epoch 4/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0393 - mse: 0.0021 - val_loss: 0.0036 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0594
Epoch 5/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0389 - mse: 0.0021 - val_loss: 0.0039 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0594
Epoch 6/30
 80/122 [==================>...........] - ETA: 0s - loss: 0.0036 - mae: 0.0387 - mse: 0.0020
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.029723942279815674.
122/122 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0388 - mse: 0.0020 - val_loss: 0.0038 - val_mae: 0.0402 - val_mse: 0.0023 - lr: 0.0594
Epoch 7/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0297
Epoch 8/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0402 - val_mse: 0.0023 - lr: 0.0297
Epoch 9/30
 80/122 [==================>...........] - ETA: 0s - loss: 0.0024 - mae: 0.0384 - mse: 0.0020
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.014861971139907837.
122/122 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0297
Epoch 10/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0394 - val_mse: 0.0021 - lr: 0.0149
Epoch 11/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0149
Epoch 12/30
 77/122 [=================>............] - ETA: 0s - loss: 0.0020 - mae: 0.0385 - mse: 0.0020
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0074309855699539185.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0149
Epoch 13/30
122/122 [==============================] - 0s 995us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0074
Epoch 14/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0074
Epoch 15/30
 84/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0382 - mse: 0.0019
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0037154927849769592.
122/122 [==============================] - 0s 995us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0074
Epoch 16/30
122/122 [==============================] - 0s 989us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0037
Epoch 17/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0037
Epoch 18/30
 80/122 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0382 - mse: 0.0019
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0018577463924884796.
122/122 [==============================] - 0s 992us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0037
Epoch 19/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0019
Epoch 20/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0019
Epoch 21/30
 84/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0009288731962442398.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0019
Epoch 22/30
122/122 [==============================] - 0s 993us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 9.2887e-04
Epoch 23/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.2887e-04
Epoch 24/30
 80/122 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0382 - mse: 0.0019
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0004644365981221199.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.2887e-04
Epoch 25/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.6444e-04
Epoch 26/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.6444e-04
Epoch 27/30
 83/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0382 - mse: 0.0019
Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00023221829906105995.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.6444e-04
Epoch 28/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.3222e-04
Epoch 29/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.3222e-04
Epoch 30/30
 79/122 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00011610914953052998.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.3222e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.05944788340483801_20_32_30epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
122/122 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0409 - mse: 0.0025 - val_loss: 0.0035 - val_mae: 0.0393 - val_mse: 0.0021 - lr: 0.0594
Epoch 2/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0390 - mse: 0.0021 - val_loss: 0.0039 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0594
Epoch 3/30
122/122 [==============================] - 0s 982us/step - loss: 0.0037 - mae: 0.0393 - mse: 0.0021 - val_loss: 0.0034 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0594
Epoch 4/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0389 - mse: 0.0021 - val_loss: 0.0045 - val_mae: 0.0416 - val_mse: 0.0025 - lr: 0.0594
Epoch 5/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0389 - mse: 0.0021 - val_loss: 0.0034 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0594
Epoch 6/30
 77/122 [=================>............] - ETA: 0s - loss: 0.0036 - mae: 0.0385 - mse: 0.0020
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.029723942279815674.
122/122 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0387 - mse: 0.0021 - val_loss: 0.0041 - val_mae: 0.0406 - val_mse: 0.0023 - lr: 0.0594
Epoch 7/30
122/122 [==============================] - 0s 988us/step - loss: 0.0023 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0297
Epoch 8/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0024 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0025 - val_mae: 0.0390 - val_mse: 0.0020 - lr: 0.0297
Epoch 9/30
 84/122 [===================>..........] - ETA: 0s - loss: 0.0024 - mae: 0.0385 - mse: 0.0020
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.014861971139907837.
122/122 [==============================] - 0s 966us/step - loss: 0.0024 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0024 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0297
Epoch 10/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0149
Epoch 11/30
122/122 [==============================] - 0s 977us/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0149
Epoch 12/30
 82/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0074309855699539185.
122/122 [==============================] - 0s 999us/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0149
Epoch 13/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0074
Epoch 14/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0074
Epoch 15/30
 84/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.0019
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0037154927849769592.
122/122 [==============================] - 0s 975us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0074
Epoch 16/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0037
Epoch 17/30
122/122 [==============================] - 0s 983us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0037
Epoch 18/30
 78/122 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0018577463924884796.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0037
Epoch 19/30
122/122 [==============================] - 0s 978us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0019
Epoch 20/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0019
Epoch 21/30
 82/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0009288731962442398.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0019
Epoch 22/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 9.2887e-04
Epoch 23/30
122/122 [==============================] - 0s 991us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 9.2887e-04
Epoch 24/30
 72/122 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0004644365981221199.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.2887e-04
Epoch 25/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.6444e-04
Epoch 26/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.6444e-04
Epoch 27/30
 83/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00023221829906105995.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.6444e-04
Epoch 28/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.3222e-04
Epoch 29/30
122/122 [==============================] - 0s 972us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.3222e-04
Epoch 30/30
 78/122 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0374 - mse: 0.0019
Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00011610914953052998.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.3222e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.05944788340483801_20_32_30epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
122/122 [==============================] - 1s 2ms/step - loss: 0.0122 - mae: 0.0406 - mse: 0.0026 - val_loss: 0.0066 - val_mae: 0.0518 - val_mse: 0.0040 - lr: 0.0594
Epoch 2/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0038 - mae: 0.0396 - mse: 0.0022 - val_loss: 0.0034 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0594
Epoch 3/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0390 - mse: 0.0021 - val_loss: 0.0038 - val_mae: 0.0406 - val_mse: 0.0023 - lr: 0.0594
Epoch 4/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0390 - mse: 0.0021 - val_loss: 0.0036 - val_mae: 0.0396 - val_mse: 0.0021 - lr: 0.0594
Epoch 5/30
 79/122 [==================>...........] - ETA: 0s - loss: 0.0037 - mae: 0.0389 - mse: 0.0021
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.029723942279815674.
122/122 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0387 - mse: 0.0021 - val_loss: 0.0036 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0594
Epoch 6/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0024 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0297
Epoch 7/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0297
Epoch 8/30
 75/122 [=================>............] - ETA: 0s - loss: 0.0024 - mae: 0.0384 - mse: 0.0020
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.014861971139907837.
122/122 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0297
Epoch 9/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0149
Epoch 10/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0149
Epoch 11/30
 78/122 [==================>...........] - ETA: 0s - loss: 0.0020 - mae: 0.0382 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0074309855699539185.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0149
Epoch 12/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0074
Epoch 13/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0074
Epoch 14/30
 71/122 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0037154927849769592.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0074
Epoch 15/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0037
Epoch 16/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0037
Epoch 17/30
 86/122 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0373 - mse: 0.0019
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0018577463924884796.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0037
Epoch 18/30
122/122 [==============================] - 0s 1000us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0019
Epoch 19/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0019
Epoch 20/30
 79/122 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0009288731962442398.
122/122 [==============================] - 0s 996us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0019
Epoch 21/30
122/122 [==============================] - 0s 978us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 9.2887e-04
Epoch 22/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 9.2887e-04
Epoch 23/30
 86/122 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0004644365981221199.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 9.2887e-04
Epoch 24/30
122/122 [==============================] - 0s 964us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.6444e-04
Epoch 25/30
122/122 [==============================] - 0s 966us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.6444e-04
Epoch 26/30
 78/122 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.0019
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00023221829906105995.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.6444e-04
Epoch 27/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.3222e-04
Epoch 28/30
122/122 [==============================] - 0s 990us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.3222e-04
Epoch 29/30
 86/122 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00011610914953052998.
122/122 [==============================] - 0s 990us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.3222e-04
Epoch 30/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.1611e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.05944788340483801_20_32_30epochs/model_5.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
122/122 [==============================] - 1s 2ms/step - loss: 0.0105 - mae: 0.0419 - mse: 0.0026 - val_loss: 0.0044 - val_mae: 0.0416 - val_mse: 0.0025 - lr: 0.0594
Epoch 2/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0388 - mse: 0.0021 - val_loss: 0.0043 - val_mae: 0.0430 - val_mse: 0.0027 - lr: 0.0594
Epoch 3/30
122/122 [==============================] - 0s 980us/step - loss: 0.0037 - mae: 0.0387 - mse: 0.0021 - val_loss: 0.0035 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0594
Epoch 4/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.0038 - val_mae: 0.0408 - val_mse: 0.0023 - lr: 0.0594
Epoch 5/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0392 - mse: 0.0021 - val_loss: 0.0049 - val_mae: 0.0463 - val_mse: 0.0032 - lr: 0.0594
Epoch 6/30
 80/122 [==================>...........] - ETA: 0s - loss: 0.0037 - mae: 0.0388 - mse: 0.0020
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.029723942279815674.
122/122 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0390 - mse: 0.0021 - val_loss: 0.0034 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0594
Epoch 7/30
122/122 [==============================] - 0s 999us/step - loss: 0.0023 - mae: 0.0380 - mse: 0.0020 - val_loss: 0.0024 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0297
Epoch 8/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0297
Epoch 9/30
 84/122 [===================>..........] - ETA: 0s - loss: 0.0023 - mae: 0.0378 - mse: 0.0019
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.014861971139907837.
122/122 [==============================] - 0s 993us/step - loss: 0.0023 - mae: 0.0380 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0297
Epoch 10/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0149
Epoch 11/30
122/122 [==============================] - 0s 978us/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0149
Epoch 12/30
 79/122 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0074309855699539185.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0149
Epoch 13/30
122/122 [==============================] - 0s 982us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0074
Epoch 14/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0074
Epoch 15/30
 85/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0037154927849769592.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0074
Epoch 16/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0037
Epoch 17/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0037
Epoch 18/30
 80/122 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0018577463924884796.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0037
Epoch 19/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0019
Epoch 20/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0019
Epoch 21/30
 82/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0383 - mse: 0.0019
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0023s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0023s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0007s vs `on_train_batch_end` time: 0.0015s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0015s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0009288731962442398.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0019
Epoch 22/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 9.2887e-04
Epoch 23/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 9.2887e-04
Epoch 24/30
 77/122 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0004644365981221199.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 9.2887e-04
Epoch 25/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.6444e-04
Epoch 26/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.6444e-04
Epoch 27/30
 83/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00023221829906105995.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.6444e-04
Epoch 28/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.3222e-04
Epoch 29/30
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.3222e-04
Epoch 30/30
 77/122 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0382 - mse: 0.0019
Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00011610914953052998.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.3222e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.05944788340483801_20_32_30epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
 73/122 [================>.............] - ETA: 0s - loss: 0.0179 - mae: 0.0470 - mse: 0.0036
 82/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0383 - mse: 0.0019
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
 82/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0383 - mse: 0.0019
 82/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0383 - mse: 0.0019
 82/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0383 - mse: 0.0019
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.
 82/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0383 - mse: 0.0019
 82/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0383 - mse: 0.0019
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0022s). Check your callbacks.
 82/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0383 - mse: 0.0019
 82/122 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0383 - mse: 0.0019