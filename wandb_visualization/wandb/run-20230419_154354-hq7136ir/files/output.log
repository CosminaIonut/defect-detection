Epoch 1/50
232/243 [===========================>..] - ETA: 0s - loss: 0.0107 - mae: 0.0457 - mse: 0.0037
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
243/243 [==============================] - 2s 6ms/step - loss: 0.0104 - mae: 0.0453 - mse: 0.0037 - val_loss: 0.0029 - val_mae: 0.0375 - val_mse: 0.0019 - lr: 0.0481
Epoch 2/50
217/243 [=========================>....] - ETA: 0s - loss: 0.0030 - mae: 0.0372 - mse: 0.0019
243/243 [==============================] - 2s 6ms/step - loss: 0.0030 - mae: 0.0371 - mse: 0.0019 - val_loss: 0.0026 - val_mae: 0.0358 - val_mse: 0.0017 - lr: 0.0481
Epoch 3/50
214/243 [=========================>....] - ETA: 0s - loss: 0.0030 - mae: 0.0358 - mse: 0.0018
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.024035340175032616.
243/243 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0357 - mse: 0.0018 - val_loss: 0.0027 - val_mae: 0.0361 - val_mse: 0.0017 - lr: 0.0481
Epoch 4/50
237/243 [============================>.] - ETA: 0s - loss: 0.0018 - mae: 0.0311 - mse: 0.0014
243/243 [==============================] - 2s 7ms/step - loss: 0.0018 - mae: 0.0310 - mse: 0.0014 - val_loss: 0.0016 - val_mae: 0.0282 - val_mse: 0.0012 - lr: 0.0240
Epoch 5/50
236/243 [============================>.] - ETA: 0s - loss: 0.0016 - mae: 0.0276 - mse: 0.0012
243/243 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0277 - mse: 0.0012 - val_loss: 0.0014 - val_mae: 0.0242 - val_mse: 9.4784e-04 - lr: 0.0240
Epoch 6/50
214/243 [=========================>....] - ETA: 0s - loss: 0.0015 - mae: 0.0262 - mse: 0.0011
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.012017670087516308.
243/243 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0023 - val_mae: 0.0352 - val_mse: 0.0018 - lr: 0.0240
Epoch 7/50
227/243 [===========================>..] - ETA: 0s - loss: 0.0011 - mae: 0.0241 - mse: 9.6119e-04
243/243 [==============================] - 1s 6ms/step - loss: 0.0011 - mae: 0.0241 - mse: 9.5995e-04 - val_loss: 0.0011 - val_mae: 0.0239 - val_mse: 9.2440e-04 - lr: 0.0120
Epoch 8/50
238/243 [============================>.] - ETA: 0s - loss: 0.0011 - mae: 0.0239 - mse: 9.3788e-04
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.006008835043758154.
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0238 - mse: 9.3477e-04 - val_loss: 0.0011 - val_mae: 0.0241 - val_mse: 9.3582e-04 - lr: 0.0120
Epoch 9/50
196/243 [=======================>......] - ETA: 0s - loss: 0.0010 - mae: 0.0230 - mse: 8.7043e-04
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.003004417521879077.
243/243 [==============================] - 1s 2ms/step - loss: 9.9844e-04 - mae: 0.0229 - mse: 8.6632e-04 - val_loss: 0.0012 - val_mae: 0.0248 - val_mse: 9.8094e-04 - lr: 0.0060
Epoch 10/50
210/243 [========================>.....] - ETA: 0s - loss: 9.6510e-04 - mae: 0.0225 - mse: 8.4256e-04
243/243 [==============================] - 1s 6ms/step - loss: 9.5671e-04 - mae: 0.0224 - mse: 8.3592e-04 - val_loss: 9.7469e-04 - val_mae: 0.0229 - val_mse: 8.5864e-04 - lr: 0.0030
Epoch 11/50
226/243 [==========================>...] - ETA: 0s - loss: 9.5071e-04 - mae: 0.0224 - mse: 8.3676e-04
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0015022087609395385.
243/243 [==============================] - 1s 3ms/step - loss: 9.4594e-04 - mae: 0.0223 - mse: 8.3242e-04 - val_loss: 9.7951e-04 - val_mae: 0.0229 - val_mse: 8.5695e-04 - lr: 0.0030
Epoch 12/50
217/243 [=========================>....] - ETA: 0s - loss: 9.3024e-04 - mae: 0.0222 - mse: 8.2018e-04
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0007511043804697692.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_154354-hq7136ir\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 7ms/step - loss: 9.2886e-04 - mae: 0.0221 - mse: 8.1943e-04 - val_loss: 9.6608e-04 - val_mae: 0.0229 - val_mse: 8.5852e-04 - lr: 0.0015
Epoch 13/50
229/243 [===========================>..] - ETA: 0s - loss: 9.1211e-04 - mae: 0.0219 - mse: 8.0758e-04
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0003755521902348846.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_154354-hq7136ir\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_154354-hq7136ir\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 6ms/step - loss: 9.1853e-04 - mae: 0.0220 - mse: 8.1405e-04 - val_loss: 9.4875e-04 - val_mae: 0.0227 - val_mse: 8.4312e-04 - lr: 7.5110e-04
Epoch 14/50
237/243 [============================>.] - ETA: 0s - loss: 9.1261e-04 - mae: 0.0219 - mse: 8.0912e-04
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0001877760951174423.
243/243 [==============================] - 2s 6ms/step - loss: 9.1513e-04 - mae: 0.0220 - mse: 8.1173e-04 - val_loss: 9.4467e-04 - val_mae: 0.0227 - val_mse: 8.4139e-04 - lr: 3.7555e-04
Epoch 15/50
229/243 [===========================>..] - ETA: 0s - loss: 9.0126e-04 - mae: 0.0218 - mse: 7.9895e-04
Epoch 15: ReduceLROnPlateau reducing learning rate to 9.388804755872115e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_154354-hq7136ir\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 6ms/step - loss: 9.1284e-04 - mae: 0.0220 - mse: 8.1066e-04 - val_loss: 9.4270e-04 - val_mae: 0.0227 - val_mse: 8.3817e-04 - lr: 1.8778e-04
Epoch 16/50
240/243 [============================>.] - ETA: 0s - loss: 9.1146e-04 - mae: 0.0219 - mse: 8.0728e-04
Epoch 16: ReduceLROnPlateau reducing learning rate to 4.694402377936058e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_154354-hq7136ir\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 6ms/step - loss: 9.1238e-04 - mae: 0.0219 - mse: 8.0823e-04 - val_loss: 9.4064e-04 - val_mae: 0.0227 - val_mse: 8.3880e-04 - lr: 9.3888e-05
Epoch 17/50
240/243 [============================>.] - ETA: 0s - loss: 9.1064e-04 - mae: 0.0219 - mse: 8.0861e-04
Epoch 17: ReduceLROnPlateau reducing learning rate to 2.347201188968029e-05.
243/243 [==============================] - 1s 3ms/step - loss: 9.1148e-04 - mae: 0.0220 - mse: 8.0943e-04 - val_loss: 9.4379e-04 - val_mae: 0.0227 - val_mse: 8.3975e-04 - lr: 4.6944e-05
Epoch 18/50
237/243 [============================>.] - ETA: 0s - loss: 9.1360e-04 - mae: 0.0220 - mse: 8.1002e-04
Epoch 18: ReduceLROnPlateau reducing learning rate to 1.1736005944840144e-05.
243/243 [==============================] - 1s 3ms/step - loss: 9.1160e-04 - mae: 0.0219 - mse: 8.0803e-04 - val_loss: 9.4200e-04 - val_mae: 0.0227 - val_mse: 8.3898e-04 - lr: 2.3472e-05
Epoch 19/50
242/243 [============================>.] - ETA: 0s - loss: 9.0983e-04 - mae: 0.0219 - mse: 8.0691e-04
Epoch 19: ReduceLROnPlateau reducing learning rate to 1e-05.
243/243 [==============================] - 1s 3ms/step - loss: 9.1129e-04 - mae: 0.0219 - mse: 8.0837e-04 - val_loss: 9.4175e-04 - val_mae: 0.0227 - val_mse: 8.3903e-04 - lr: 1.1736e-05
Epoch 20/50
243/243 [==============================] - 0s 2ms/step - loss: 9.1116e-04 - mae: 0.0219 - mse: 8.0868e-04 - val_loss: 9.4174e-04 - val_mae: 0.0227 - val_mse: 8.3906e-04 - lr: 1.0000e-05
Epoch 21/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1112e-04 - mae: 0.0219 - mse: 8.0824e-04 - val_loss: 9.4138e-04 - val_mae: 0.0227 - val_mse: 8.3900e-04 - lr: 1.0000e-05
Epoch 22/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1112e-04 - mae: 0.0219 - mse: 8.0875e-04 - val_loss: 9.4140e-04 - val_mae: 0.0227 - val_mse: 8.3903e-04 - lr: 1.0000e-05
Epoch 23/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1110e-04 - mae: 0.0219 - mse: 8.0872e-04 - val_loss: 9.4137e-04 - val_mae: 0.0227 - val_mse: 8.3897e-04 - lr: 1.0000e-05
Epoch 24/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1104e-04 - mae: 0.0219 - mse: 8.0888e-04 - val_loss: 9.4136e-04 - val_mae: 0.0227 - val_mse: 8.3896e-04 - lr: 1.0000e-05
Epoch 25/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1099e-04 - mae: 0.0219 - mse: 8.0877e-04 - val_loss: 9.4138e-04 - val_mae: 0.0227 - val_mse: 8.3903e-04 - lr: 1.0000e-05
Epoch 26/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1099e-04 - mae: 0.0219 - mse: 8.0876e-04 - val_loss: 9.4119e-04 - val_mae: 0.0227 - val_mse: 8.3896e-04 - lr: 1.0000e-05
Epoch 27/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1094e-04 - mae: 0.0219 - mse: 8.0843e-04 - val_loss: 9.4106e-04 - val_mae: 0.0227 - val_mse: 8.3891e-04 - lr: 1.0000e-05
Epoch 28/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1092e-04 - mae: 0.0219 - mse: 8.0856e-04 - val_loss: 9.4103e-04 - val_mae: 0.0227 - val_mse: 8.3892e-04 - lr: 1.0000e-05
Epoch 29/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1087e-04 - mae: 0.0219 - mse: 8.0865e-04 - val_loss: 9.4096e-04 - val_mae: 0.0227 - val_mse: 8.3893e-04 - lr: 1.0000e-05
Epoch 30/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1086e-04 - mae: 0.0219 - mse: 8.0863e-04 - val_loss: 9.4108e-04 - val_mae: 0.0227 - val_mse: 8.3894e-04 - lr: 1.0000e-05
Epoch 31/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1080e-04 - mae: 0.0219 - mse: 8.0869e-04 - val_loss: 9.4108e-04 - val_mae: 0.0227 - val_mse: 8.3894e-04 - lr: 1.0000e-05
Epoch 32/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1072e-04 - mae: 0.0219 - mse: 8.0849e-04 - val_loss: 9.4083e-04 - val_mae: 0.0227 - val_mse: 8.3891e-04 - lr: 1.0000e-05
Epoch 33/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1073e-04 - mae: 0.0219 - mse: 8.0878e-04 - val_loss: 9.4081e-04 - val_mae: 0.0227 - val_mse: 8.3889e-04 - lr: 1.0000e-05
Epoch 34/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1068e-04 - mae: 0.0219 - mse: 8.0867e-04 - val_loss: 9.4077e-04 - val_mae: 0.0227 - val_mse: 8.3884e-04 - lr: 1.0000e-05
Epoch 35/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1066e-04 - mae: 0.0219 - mse: 8.0861e-04 - val_loss: 9.4087e-04 - val_mae: 0.0227 - val_mse: 8.3882e-04 - lr: 1.0000e-05
Epoch 36/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1063e-04 - mae: 0.0219 - mse: 8.0844e-04 - val_loss: 9.4086e-04 - val_mae: 0.0227 - val_mse: 8.3890e-04 - lr: 1.0000e-05
Epoch 37/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1057e-04 - mae: 0.0219 - mse: 8.0850e-04 - val_loss: 9.4067e-04 - val_mae: 0.0227 - val_mse: 8.3876e-04 - lr: 1.0000e-05
Epoch 38/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1054e-04 - mae: 0.0219 - mse: 8.0875e-04 - val_loss: 9.4074e-04 - val_mae: 0.0227 - val_mse: 8.3877e-04 - lr: 1.0000e-05
Epoch 39/50
221/243 [==========================>...] - ETA: 0s - loss: 9.2153e-04 - mae: 0.0221 - mse: 8.1971e-04e-04 - val_loss: 9.4069e-04 - val_mae: 0.0227 - val_mse: 8.3877e-04 - lr: 1.0000e-05
Epoch 40/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1046e-04 - mae: 0.0219 - mse: 8.0856e-04 - val_loss: 9.4064e-04 - val_mae: 0.0227 - val_mse: 8.3882e-04 - lr: 1.0000e-05
Epoch 41/50
221/243 [==========================>...] - ETA: 0s - loss: 9.2153e-04 - mae: 0.0221 - mse: 8.1971e-04e-04 - val_loss: 9.4069e-04 - val_mae: 0.0227 - val_mse: 8.3877e-04 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 9.1037e-04 - mae: 0.0219 - mse: 8.0854e-04 - val_loss: 9.4053e-04 - val_mae: 0.0227 - val_mse: 8.3872e-04 - lr: 1.0000e-05
Epoch 42/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1043e-04 - mae: 0.0219 - mse: 8.0904e-04 - val_loss: 9.4054e-04 - val_mae: 0.0227 - val_mse: 8.3881e-04 - lr: 1.0000e-05
Epoch 43/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1037e-04 - mae: 0.0219 - mse: 8.0854e-04 - val_loss: 9.4053e-04 - val_mae: 0.0227 - val_mse: 8.3872e-04 - lr: 1.0000e-05
Epoch 44/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1034e-04 - mae: 0.0219 - mse: 8.0850e-04 - val_loss: 9.4067e-04 - val_mae: 0.0227 - val_mse: 8.3875e-04 - lr: 1.0000e-05
Epoch 45/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1030e-04 - mae: 0.0219 - mse: 8.0867e-04 - val_loss: 9.4073e-04 - val_mae: 0.0227 - val_mse: 8.3875e-04 - lr: 1.0000e-05
Epoch 46/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1027e-04 - mae: 0.0219 - mse: 8.0837e-04 - val_loss: 9.4066e-04 - val_mae: 0.0227 - val_mse: 8.3882e-04 - lr: 1.0000e-05
Epoch 47/50
243/243 [==============================] - 1s 3ms/step - loss: 9.1014e-04 - mae: 0.0219 - mse: 8.0844e-04 - val_loss: 9.4087e-04 - val_mae: 0.0227 - val_mse: 8.3882e-04 - lr: 1.0000e-05
Epoch 48/50
241/243 [============================>.] - ETA: 0s - loss: 9.1160e-04 - mae: 0.0220 - mse: 8.0961e-04
243/243 [==============================] - 1s 3ms/step - loss: 9.1027e-04 - mae: 0.0219 - mse: 8.0837e-04 - val_loss: 9.4066e-04 - val_mae: 0.0227 - val_mse: 8.3882e-04 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_154354-hq7136ir\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 3ms/step - loss: 9.1027e-04 - mae: 0.0219 - mse: 8.0837e-04 - val_loss: 9.4066e-04 - val_mae: 0.0227 - val_mse: 8.3882e-04 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_154354-hq7136ir\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 3ms/step - loss: 9.1027e-04 - mae: 0.0219 - mse: 8.0837e-04 - val_loss: 9.4066e-04 - val_mae: 0.0227 - val_mse: 8.3882e-04 - lr: 1.0000e-05
184/323 [================>.............] - ETA: 0s - loss: 0.0036 - mae: 0.0505 - mse: 0.0034: 8.0837e-04 - val_loss: 9.4066e-04 - val_mae: 0.0227 - val_mse: 8.3882e-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0240-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0036 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0240-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0060-04 - lr: 1.0000e-05
242/323 [=====================>........] - ETA: 0s - loss: 0.0034 - mae: 0.0509 - mse: 0.00340034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0060-04 - lr: 1.0000e-05
303/323 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.00340034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0060-04 - lr: 1.0000e-05
 90/323 [=======>......................] - ETA: 0s - loss: 0.0035 - mae: 0.0515 - mse: 0.00350034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.7555e-04- lr: 1.0000e-05
320/323 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.00340034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.7555e-04- lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.1736e-05- lr: 1.0000e-05
 27/323 [=>............................] - ETA: 0s - loss: 0.0037 - mae: 0.0531 - mse: 0.00370034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.1736e-05- lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
304/323 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.00340034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
259/323 [=======================>......] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.00340034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
 90/323 [=======>......................] - ETA: 0s - loss: 0.0033 - mae: 0.0501 - mse: 0.00330034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
Epoch 7/50=============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 10/50============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001877760951174423. 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 15/50educeLROnPlateau reducing learning rate to 0.0001877760951174423. 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 17: ReduceLROnPlateau reducing learning rate to 1e-05.877760951174423. 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 22/50educeLROnPlateau reducing learning rate to 1e-05.877760951174423. 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 1e-05.877760951174423. 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 1e-05.877760951174423. 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 1e-05.877760951174423. 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 1e-05.877760951174423. 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 1e-05.877760951174423. 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 1e-05.877760951174423. 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 1e-05.877760951174423. 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 1e-05.877760951174423. 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 1e-05.877760951174423. 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 1e-05.877760951174423. 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 1e-05.877760951174423. 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
Epoch 8/500educeLROnPlateau reducing learning rate to 1e-05.877760951174423. 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0003755521902348846. 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 13/50educeLROnPlateau reducing learning rate to 0.0003755521902348846. 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 15: ReduceLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 6/500educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 9/500educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 9/500educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 13: ReduceLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 16/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 20/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 20/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 20/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 20/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 20/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 20/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 20/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 20/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 20/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 20/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 20/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 20/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 20/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 7/500educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 10/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 10/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 14: ReduceLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 17/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 21/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 21/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 21/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 21/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 21/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 21/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 21/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 21/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 21/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 21/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 21/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 21/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 21/50educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 5/500educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 8/500educeLROnPlateau reducing learning rate to 4.694402377936058e-05..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0003755521902348846..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 13/50educeLROnPlateau reducing learning rate to 0.0003755521902348846..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 15: ReduceLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 5/500educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0003755521902348846..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 15: ReduceLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 24/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 24/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 29/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 34/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 34/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 39/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 44/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 44/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 44/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 44/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
Epoch 44/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 44/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 9/500educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 14/50educeLROnPlateau reducing learning rate to 0.0003755521902348846..0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 16: ReduceLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 20/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 25/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 30/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 35/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 35/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 40/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 45/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 45/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 45/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05
Epoch 45/50educeLROnPlateau reducing learning rate to 1.1736005944840144e-05.0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05- lr: 1.0000e-05