Epoch 1/150
 67/122 [===============>..............] - ETA: 0s - loss: 0.0496 - mae: 0.0524 - mse: 0.0066
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190136-bw20wynq\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 7ms/step - loss: 0.0287 - mae: 0.0469 - mse: 0.0047 - val_loss: 0.0024 - val_mae: 0.0358 - val_mse: 0.0018 - lr: 0.0992
Epoch 2/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0030 - mae: 0.0391 - mse: 0.0023 - val_loss: 0.0025 - val_mae: 0.0354 - val_mse: 0.0018 - lr: 0.0992
Epoch 3/150
122/122 [==============================] - 1s 10ms/step - loss: 0.0021 - mae: 0.0346 - mse: 0.0017 - val_loss: 0.0021 - val_mae: 0.0339 - val_mse: 0.0017 - lr: 0.0992
Epoch 4/150
102/122 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0329 - mse: 0.0016
122/122 [==============================] - 1s 8ms/step - loss: 0.0018 - mae: 0.0322 - mse: 0.0015 - val_loss: 0.0016 - val_mae: 0.0308 - val_mse: 0.0014 - lr: 0.0992
Epoch 5/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0294 - mse: 0.0013 - val_loss: 0.0017 - val_mae: 0.0285 - val_mse: 0.0012 - lr: 0.0992
Epoch 6/150
107/122 [=========================>....] - ETA: 0s - loss: 0.0014 - mae: 0.0270 - mse: 0.0012
122/122 [==============================] - 1s 8ms/step - loss: 0.0014 - mae: 0.0272 - mse: 0.0012 - val_loss: 0.0015 - val_mae: 0.0270 - val_mse: 0.0012 - lr: 0.0992
Epoch 7/150
 99/122 [=======================>......] - ETA: 0s - loss: 0.0015 - mae: 0.0273 - mse: 0.0012
122/122 [==============================] - 1s 9ms/step - loss: 0.0015 - mae: 0.0268 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0253 - val_mse: 0.0010 - lr: 0.0992
Epoch 8/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0265 - mse: 0.0011 - val_loss: 0.0019 - val_mae: 0.0339 - val_mse: 0.0018 - lr: 0.0992
Epoch 9/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0014 - val_mae: 0.0236 - val_mse: 8.7794e-04 - lr: 0.0992
Epoch 10/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0014 - val_mae: 0.0250 - val_mse: 9.8450e-04 - lr: 0.0992
Epoch 11/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0243 - mse: 9.5857e-04 - val_loss: 0.0012 - val_mae: 0.0229 - val_mse: 8.5603e-04 - lr: 0.0992
Epoch 12/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0247 - mse: 9.8483e-04 - val_loss: 0.0013 - val_mae: 0.0275 - val_mse: 0.0012 - lr: 0.0992
Epoch 13/150
 75/122 [=================>............] - ETA: 0s - loss: 0.0014 - mae: 0.0264 - mse: 0.0011
122/122 [==============================] - 1s 7ms/step - loss: 0.0013 - mae: 0.0253 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0231 - val_mse: 8.4209e-04 - lr: 0.0992
Epoch 14/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0235 - mse: 9.0444e-04 - val_loss: 0.0014 - val_mae: 0.0267 - val_mse: 0.0011 - lr: 0.0992
Epoch 15/150
 73/122 [================>.............] - ETA: 0s - loss: 0.0011 - mae: 0.0235 - mse: 9.0233e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190136-bw20wynq\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 7ms/step - loss: 0.0011 - mae: 0.0236 - mse: 9.0685e-04 - val_loss: 9.9103e-04 - val_mae: 0.0227 - val_mse: 8.3793e-04 - lr: 0.0992
Epoch 16/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0243 - mse: 9.7231e-04 - val_loss: 0.0013 - val_mae: 0.0245 - val_mse: 9.5728e-04 - lr: 0.0992
Epoch 17/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0246 - mse: 9.8832e-04 - val_loss: 0.0013 - val_mae: 0.0231 - val_mse: 8.7787e-04 - lr: 0.0992
Epoch 18/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0228 - mse: 8.5621e-04 - val_loss: 9.9740e-04 - val_mae: 0.0213 - val_mse: 7.2320e-04 - lr: 0.0992
Epoch 19/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0225 - mse: 8.3948e-04 - val_loss: 0.0014 - val_mae: 0.0293 - val_mse: 0.0014 - lr: 0.0992
Epoch 20/150
122/122 [==============================] - 1s 7ms/step - loss: 0.0011 - mae: 0.0228 - mse: 8.5386e-04 - val_loss: 9.8822e-04 - val_mae: 0.0236 - val_mse: 8.6141e-04 - lr: 0.0992
Epoch 21/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0230 - mse: 8.6897e-04 - val_loss: 9.9706e-04 - val_mae: 0.0224 - val_mse: 8.3649e-04 - lr: 0.0992
Epoch 22/150
122/122 [==============================] - 0s 1ms/step - loss: 9.8259e-04 - mae: 0.0221 - mse: 8.1218e-04 - val_loss: 0.0028 - val_mae: 0.0393 - val_mse: 0.0022 - lr: 0.0992
Epoch 23/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0223 - mse: 8.2104e-04 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0011 - lr: 0.0992
Epoch 24/150
 76/122 [=================>............] - ETA: 0s - loss: 0.0012 - mae: 0.0231 - mse: 8.8036e-04
122/122 [==============================] - 1s 7ms/step - loss: 0.0011 - mae: 0.0222 - mse: 8.2000e-04 - val_loss: 8.3866e-04 - val_mae: 0.0204 - val_mse: 6.8883e-04 - lr: 0.0992
Epoch 25/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0229 - mse: 8.6522e-04 - val_loss: 0.0010 - val_mae: 0.0234 - val_mse: 8.4951e-04 - lr: 0.0992
Epoch 26/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0219 - mse: 7.9576e-04 - val_loss: 0.0013 - val_mae: 0.0258 - val_mse: 0.0010 - lr: 0.0992
Epoch 27/150
 76/122 [=================>............] - ETA: 0s - loss: 9.0316e-04 - mae: 0.0213 - mse: 7.5615e-04
122/122 [==============================] - 1s 7ms/step - loss: 8.8071e-04 - mae: 0.0211 - mse: 7.4035e-04 - val_loss: 8.3755e-04 - val_mae: 0.0196 - val_mse: 6.3420e-04 - lr: 0.0992
Epoch 28/150
102/122 [========================>.....] - ETA: 0s - loss: 9.0584e-04 - mae: 0.0212 - mse: 7.4613e-04
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.049623262137174606.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190136-bw20wynq\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 8ms/step - loss: 9.0744e-04 - mae: 0.0213 - mse: 7.4779e-04 - val_loss: 7.9800e-04 - val_mae: 0.0201 - val_mse: 6.3039e-04 - lr: 0.0992
Epoch 29/150
103/122 [========================>.....] - ETA: 0s - loss: 8.0284e-04 - mae: 0.0202 - mse: 6.8614e-04
122/122 [==============================] - 1s 8ms/step - loss: 7.9352e-04 - mae: 0.0201 - mse: 6.7968e-04 - val_loss: 7.6089e-04 - val_mae: 0.0196 - val_mse: 6.5442e-04 - lr: 0.0496
Epoch 30/150
117/122 [===========================>..] - ETA: 0s - loss: 7.8937e-04 - mae: 0.0201 - mse: 6.8219e-04
122/122 [==============================] - 1s 11ms/step - loss: 7.8856e-04 - mae: 0.0201 - mse: 6.8106e-04 - val_loss: 7.3459e-04 - val_mae: 0.0199 - val_mse: 6.3241e-04 - lr: 0.0496
Epoch 31/150
122/122 [==============================] - 0s 2ms/step - loss: 8.0245e-04 - mae: 0.0203 - mse: 6.8970e-04 - val_loss: 7.6432e-04 - val_mae: 0.0209 - val_mse: 6.7257e-04 - lr: 0.0496
Epoch 32/150
122/122 [==============================] - 0s 1ms/step - loss: 7.7828e-04 - mae: 0.0199 - mse: 6.6697e-04 - val_loss: 0.0014 - val_mae: 0.0288 - val_mse: 0.0013 - lr: 0.0496
Epoch 33/150
 65/122 [==============>...............] - ETA: 0s - loss: 8.7053e-04 - mae: 0.0204 - mse: 7.0110e-04
122/122 [==============================] - 1s 8ms/step - loss: 8.1623e-04 - mae: 0.0199 - mse: 6.7581e-04 - val_loss: 7.1930e-04 - val_mae: 0.0197 - val_mse: 6.2468e-04 - lr: 0.0496
Epoch 34/150
 69/122 [===============>..............] - ETA: 0s - loss: 7.4579e-04 - mae: 0.0194 - mse: 6.4449e-04
122/122 [==============================] - 1s 7ms/step - loss: 7.4525e-04 - mae: 0.0195 - mse: 6.4354e-04 - val_loss: 7.0931e-04 - val_mae: 0.0191 - val_mse: 6.2046e-04 - lr: 0.0496
Epoch 35/150
122/122 [==============================] - 0s 1ms/step - loss: 7.9961e-04 - mae: 0.0202 - mse: 6.7912e-04 - val_loss: 7.8167e-04 - val_mae: 0.0185 - val_mse: 6.0545e-04 - lr: 0.0496
Epoch 36/150
122/122 [==============================] - 0s 1ms/step - loss: 7.8262e-04 - mae: 0.0197 - mse: 6.5610e-04 - val_loss: 7.5250e-04 - val_mae: 0.0201 - val_mse: 6.2225e-04 - lr: 0.0496
Epoch 37/150
122/122 [==============================] - 0s 1ms/step - loss: 7.8041e-04 - mae: 0.0197 - mse: 6.4947e-04 - val_loss: 8.1347e-04 - val_mae: 0.0211 - val_mse: 6.6797e-04 - lr: 0.0496
Epoch 38/150
122/122 [==============================] - 0s 1ms/step - loss: 7.6939e-04 - mae: 0.0192 - mse: 6.2366e-04 - val_loss: 7.5381e-04 - val_mae: 0.0177 - val_mse: 5.6794e-04 - lr: 0.0496
Epoch 39/150
122/122 [==============================] - 0s 1ms/step - loss: 7.2442e-04 - mae: 0.0186 - mse: 5.9762e-04 - val_loss: 7.5503e-04 - val_mae: 0.0190 - val_mse: 6.4201e-04 - lr: 0.0496
Epoch 40/150
122/122 [==============================] - 0s 1ms/step - loss: 7.5640e-04 - mae: 0.0194 - mse: 6.3796e-04 - val_loss: 0.0013 - val_mae: 0.0281 - val_mse: 0.0012 - lr: 0.0496
Epoch 41/150
 76/122 [=================>............] - ETA: 0s - loss: 8.1118e-04 - mae: 0.0200 - mse: 6.6985e-04
122/122 [==============================] - 1s 7ms/step - loss: 7.7731e-04 - mae: 0.0194 - mse: 6.3998e-04 - val_loss: 7.0931e-04 - val_mae: 0.0178 - val_mse: 5.8865e-04 - lr: 0.0496
Epoch 42/150
122/122 [==============================] - 0s 1ms/step - loss: 7.2132e-04 - mae: 0.0187 - mse: 5.9929e-04 - val_loss: 0.0010 - val_mae: 0.0227 - val_mse: 8.4678e-04 - lr: 0.0496
Epoch 43/150
 78/122 [==================>...........] - ETA: 0s - loss: 7.6026e-04 - mae: 0.0190 - mse: 6.2030e-04
122/122 [==============================] - 1s 6ms/step - loss: 7.3183e-04 - mae: 0.0187 - mse: 6.0334e-04 - val_loss: 7.0199e-04 - val_mae: 0.0186 - val_mse: 5.8613e-04 - lr: 0.0496
Epoch 44/150
 68/122 [===============>..............] - ETA: 0s - loss: 7.6834e-04 - mae: 0.0190 - mse: 6.1593e-04
Epoch 44: ReduceLROnPlateau reducing learning rate to 0.024811631068587303.
122/122 [==============================] - 0s 1ms/step - loss: 7.5272e-04 - mae: 0.0190 - mse: 6.1583e-04 - val_loss: 8.7484e-04 - val_mae: 0.0201 - val_mse: 7.3436e-04 - lr: 0.0496
Epoch 45/150
 80/122 [==================>...........] - ETA: 0s - loss: 6.7707e-04 - mae: 0.0180 - mse: 5.7819e-04
122/122 [==============================] - 1s 6ms/step - loss: 6.7069e-04 - mae: 0.0179 - mse: 5.7113e-04 - val_loss: 6.6303e-04 - val_mae: 0.0179 - val_mse: 5.7662e-04 - lr: 0.0248
Epoch 46/150
122/122 [==============================] - 0s 1ms/step - loss: 6.6610e-04 - mae: 0.0178 - mse: 5.5733e-04 - val_loss: 6.7035e-04 - val_mae: 0.0182 - val_mse: 5.5007e-04 - lr: 0.0248
Epoch 47/150
122/122 [==============================] - 0s 1ms/step - loss: 6.5675e-04 - mae: 0.0175 - mse: 5.4846e-04 - val_loss: 7.0284e-04 - val_mae: 0.0179 - val_mse: 5.9628e-04 - lr: 0.0248
Epoch 48/150
122/122 [==============================] - 0s 1ms/step - loss: 6.4982e-04 - mae: 0.0176 - mse: 5.4750e-04 - val_loss: 6.7707e-04 - val_mae: 0.0177 - val_mse: 5.7018e-04 - lr: 0.0248
Epoch 49/150
 77/122 [=================>............] - ETA: 0s - loss: 7.0332e-04 - mae: 0.0185 - mse: 5.8981e-04
118/122 [============================>.] - ETA: 0s - loss: 6.2677e-04 - mae: 0.0172 - mse: 5.2596e-04e-04 - val_loss: 5.9924e-04 - val_mae: 0.0169 - val_mse: 5.1561e-04 - lr: 0.0248
Epoch 50/150
118/122 [============================>.] - ETA: 0s - loss: 6.2677e-04 - mae: 0.0172 - mse: 5.2596e-04e-04 - val_loss: 5.9924e-04 - val_mae: 0.0169 - val_mse: 5.1561e-04 - lr: 0.0248
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190136-bw20wynq\files\model-best)... Done. 0.0s
122/122 [==============================] - 0s 1ms/step - loss: 6.3138e-04 - mae: 0.0172 - mse: 5.2735e-04 - val_loss: 6.6289e-04 - val_mae: 0.0175 - val_mse: 5.6396e-04 - lr: 0.0248
Epoch 51/150
122/122 [==============================] - 0s 1ms/step - loss: 6.3138e-04 - mae: 0.0172 - mse: 5.2735e-04 - val_loss: 6.6289e-04 - val_mae: 0.0175 - val_mse: 5.6396e-04 - lr: 0.0248
Epoch 52/150
122/122 [==============================] - 0s 2ms/step - loss: 6.0740e-04 - mae: 0.0168 - mse: 5.0869e-04 - val_loss: 6.9674e-04 - val_mae: 0.0165 - val_mse: 5.3655e-04 - lr: 0.0248
Epoch 53/150
122/122 [==============================] - 0s 1ms/step - loss: 6.0228e-04 - mae: 0.0166 - mse: 4.9719e-04 - val_loss: 5.8158e-04 - val_mae: 0.0160 - val_mse: 4.6474e-04 - lr: 0.0248
Epoch 54/150
122/122 [==============================] - 0s 2ms/step - loss: 6.3560e-04 - mae: 0.0174 - mse: 5.3282e-04 - val_loss: 6.7236e-04 - val_mae: 0.0182 - val_mse: 5.6656e-04 - lr: 0.0248
Epoch 55/150
122/122 [==============================] - 0s 1ms/step - loss: 6.3663e-04 - mae: 0.0170 - mse: 5.1273e-04 - val_loss: 5.8582e-04 - val_mae: 0.0161 - val_mse: 4.6250e-04 - lr: 0.0248
Epoch 56/150
122/122 [==============================] - 0s 1ms/step - loss: 6.0228e-04 - mae: 0.0166 - mse: 4.9719e-04 - val_loss: 5.8158e-04 - val_mae: 0.0160 - val_mse: 4.6474e-04 - lr: 0.0248
Epoch 57/150
122/122 [==============================] - 0s 1ms/step - loss: 5.8823e-04 - mae: 0.0163 - mse: 4.8561e-04 - val_loss: 6.0967e-04 - val_mae: 0.0157 - val_mse: 4.9412e-04 - lr: 0.0248
Epoch 58/150
116/122 [===========================>..] - ETA: 0s - loss: 6.5680e-04 - mae: 0.0177 - mse: 5.4484e-04
122/122 [==============================] - 1s 8ms/step - loss: 6.5130e-04 - mae: 0.0176 - mse: 5.3975e-04 - val_loss: 5.6502e-04 - val_mae: 0.0163 - val_mse: 4.8230e-04 - lr: 0.0248
Epoch 59/150
115/122 [===========================>..] - ETA: 0s - loss: 5.7318e-04 - mae: 0.0165 - mse: 4.9077e-04
Epoch 59: ReduceLROnPlateau reducing learning rate to 0.012405815534293652.
122/122 [==============================] - 0s 1ms/step - loss: 5.7093e-04 - mae: 0.0164 - mse: 4.8745e-04 - val_loss: 5.7547e-04 - val_mae: 0.0174 - val_mse: 5.0522e-04 - lr: 0.0248
Epoch 60/150
113/122 [==========================>...] - ETA: 0s - loss: 5.4224e-04 - mae: 0.0156 - mse: 4.5602e-04
122/122 [==============================] - 1s 8ms/step - loss: 6.5130e-04 - mae: 0.0176 - mse: 5.3975e-04 - val_loss: 5.6502e-04 - val_mae: 0.0163 - val_mse: 4.8230e-04 - lr: 0.0248
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190136-bw20wynq\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 8ms/step - loss: 6.5130e-04 - mae: 0.0176 - mse: 5.3975e-04 - val_loss: 5.6502e-04 - val_mae: 0.0163 - val_mse: 4.8230e-04 - lr: 0.0248
 67/122 [===============>..............] - ETA: 0s - loss: 5.2934e-04 - mae: 0.0151 - mse: 4.3937e-04e-04 - val_loss: 5.6502e-04 - val_mae: 0.0163 - val_mse: 4.8230e-04 - lr: 0.0248
 67/122 [===============>..............] - ETA: 0s - loss: 5.2934e-04 - mae: 0.0151 - mse: 4.3937e-04e-04 - val_loss: 5.6502e-04 - val_mae: 0.0163 - val_mse: 4.8230e-04 - lr: 0.0248
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190136-bw20wynq\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 7ms/step - loss: 5.2911e-04 - mae: 0.0152 - mse: 4.4038e-04 - val_loss: 5.4147e-04 - val_mae: 0.0159 - val_mse: 4.5979e-04 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 5.4107e-04 - mae: 0.0156 - mse: 4.5602e-04 - val_loss: 6.1096e-04 - val_mae: 0.0169 - val_mse: 5.2300e-04 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 5.4107e-04 - mae: 0.0156 - mse: 4.5602e-04 - val_loss: 6.1096e-04 - val_mae: 0.0169 - val_mse: 5.2300e-04 - lr: 0.0124
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190136-bw20wynq\files\model-best)... Done. 0.0s
122/122 [==============================] - 0s 1ms/step - loss: 5.4107e-04 - mae: 0.0156 - mse: 4.5602e-04 - val_loss: 6.1096e-04 - val_mae: 0.0169 - val_mse: 5.2300e-04 - lr: 0.0124
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190136-bw20wynq\files\model-best)... Done. 0.0s
122/122 [==============================] - 0s 1ms/step - loss: 5.4107e-04 - mae: 0.0156 - mse: 4.5602e-04 - val_loss: 6.1096e-04 - val_mae: 0.0169 - val_mse: 5.2300e-04 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 5.0207e-04 - mae: 0.0149 - mse: 4.2308e-04 - val_loss: 5.2192e-04 - val_mae: 0.0152 - val_mse: 4.3862e-04 - lr: 0.0062
122/122 [==============================] - 0s 1ms/step - loss: 5.0207e-04 - mae: 0.0149 - mse: 4.2308e-04 - val_loss: 5.2192e-04 - val_mae: 0.0152 - val_mse: 4.3862e-04 - lr: 0.0062
122/122 [==============================] - 0s 1ms/step - loss: 4.9564e-04 - mae: 0.0147 - mse: 4.1785e-04 - val_loss: 5.3758e-04 - val_mae: 0.0159 - val_mse: 4.5841e-04 - lr: 0.0062
122/122 [==============================] - 0s 1ms/step - loss: 4.9564e-04 - mae: 0.0147 - mse: 4.1785e-04 - val_loss: 5.3758e-04 - val_mae: 0.0159 - val_mse: 4.5841e-04 - lr: 0.0062
 72/122 [================>.............] - ETA: 0s - loss: 5.2723e-04 - mae: 0.0157 - mse: 4.4582e-04e-04 - val_loss: 5.3758e-04 - val_mae: 0.0159 - val_mse: 4.5841e-04 - lr: 0.0062
 72/122 [================>.............] - ETA: 0s - loss: 5.2723e-04 - mae: 0.0157 - mse: 4.4582e-04e-04 - val_loss: 5.3758e-04 - val_mae: 0.0159 - val_mse: 4.5841e-04 - lr: 0.0062
122/122 [==============================] - 1s 7ms/step - loss: 5.0406e-04 - mae: 0.0150 - mse: 4.2400e-04 - val_loss: 4.9145e-04 - val_mae: 0.0145 - val_mse: 4.0377e-04 - lr: 0.0062
122/122 [==============================] - 1s 7ms/step - loss: 5.0406e-04 - mae: 0.0150 - mse: 4.2400e-04 - val_loss: 4.9145e-04 - val_mae: 0.0145 - val_mse: 4.0377e-04 - lr: 0.0062
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190136-bw20wynq\files\model-best)... Done. 0.0s
122/122 [==============================] - 1s 7ms/step - loss: 5.0406e-04 - mae: 0.0150 - mse: 4.2400e-04 - val_loss: 4.9145e-04 - val_mae: 0.0145 - val_mse: 4.0377e-04 - lr: 0.0062
122/122 [==============================] - 0s 1ms/step - loss: 4.8207e-04 - mae: 0.0146 - mse: 4.0599e-04 - val_loss: 5.8819e-04 - val_mae: 0.0175 - val_mse: 5.0659e-04 - lr: 0.0062
122/122 [==============================] - 0s 1ms/step - loss: 4.8207e-04 - mae: 0.0146 - mse: 4.0599e-04 - val_loss: 5.8819e-04 - val_mae: 0.0175 - val_mse: 5.0659e-04 - lr: 0.0062
122/122 [==============================] - 0s 1ms/step - loss: 4.7168e-04 - mae: 0.0144 - mse: 3.9493e-04 - val_loss: 5.4229e-04 - val_mae: 0.0168 - val_mse: 4.6743e-04 - lr: 0.0031
122/122 [==============================] - 0s 1ms/step - loss: 4.7168e-04 - mae: 0.0144 - mse: 3.9493e-04 - val_loss: 5.4229e-04 - val_mae: 0.0168 - val_mse: 4.6743e-04 - lr: 0.0031
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190136-bw20wynq\files\model-best)... Done. 0.0s
122/122 [==============================] - 0s 1ms/step - loss: 4.7168e-04 - mae: 0.0144 - mse: 3.9493e-04 - val_loss: 5.4229e-04 - val_mae: 0.0168 - val_mse: 4.6743e-04 - lr: 0.0031
122/122 [==============================] - 0s 1ms/step - loss: 4.6594e-04 - mae: 0.0144 - mse: 3.9269e-04 - val_loss: 5.0100e-04 - val_mae: 0.0155 - val_mse: 4.2849e-04 - lr: 0.0031
122/122 [==============================] - 0s 1ms/step - loss: 4.6594e-04 - mae: 0.0144 - mse: 3.9269e-04 - val_loss: 5.0100e-04 - val_mae: 0.0155 - val_mse: 4.2849e-04 - lr: 0.0031
122/122 [==============================] - 0s 1ms/step - loss: 4.5156e-04 - mae: 0.0140 - mse: 3.7885e-04 - val_loss: 4.6561e-04 - val_mae: 0.0143 - val_mse: 3.9496e-04 - lr: 0.0016
122/122 [==============================] - 0s 1ms/step - loss: 4.5156e-04 - mae: 0.0140 - mse: 3.7885e-04 - val_loss: 4.6561e-04 - val_mae: 0.0143 - val_mse: 3.9496e-04 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190136-bw20wynq\files\model-best)... Done. 0.0s
122/122 [==============================] - 0s 1ms/step - loss: 4.5156e-04 - mae: 0.0140 - mse: 3.7885e-04 - val_loss: 4.6561e-04 - val_mae: 0.0143 - val_mse: 3.9496e-04 - lr: 0.0016
 65/122 [==============>...............] - ETA: 0s - loss: 4.5229e-04 - mae: 0.0141 - mse: 3.7894e-04e-04 - val_loss: 4.6561e-04 - val_mae: 0.0143 - val_mse: 3.9496e-04 - lr: 0.0016
 65/122 [==============>...............] - ETA: 0s - loss: 4.5229e-04 - mae: 0.0141 - mse: 3.7894e-04e-04 - val_loss: 4.6561e-04 - val_mae: 0.0143 - val_mse: 3.9496e-04 - lr: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190136-bw20wynq\files\model-best)... Done. 0.0s
122/122 [==============================] - 0s 1ms/step - loss: 4.4289e-04 - mae: 0.0138 - mse: 3.7188e-04 - val_loss: 4.6094e-04 - val_mae: 0.0142 - val_mse: 3.8985e-04 - lr: 7.7536e-04
 68/122 [===============>..............] - ETA: 0s - loss: 4.4508e-04 - mae: 0.0139 - mse: 3.7463e-04e-04 - val_loss: 4.5361e-04 - val_mae: 0.0142 - val_mse: 3.8320e-04 - lr: 3.8768e-04
 68/122 [===============>..............] - ETA: 0s - loss: 4.4508e-04 - mae: 0.0139 - mse: 3.7463e-04e-04 - val_loss: 4.5361e-04 - val_mae: 0.0142 - val_mse: 3.8320e-04 - lr: 3.8768e-04
122/122 [==============================] - 0s 1ms/step - loss: 4.3828e-04 - mae: 0.0137 - mse: 3.6728e-04 - val_loss: 4.5185e-04 - val_mae: 0.0141 - val_mse: 3.8165e-04 - lr: 1.9384e-04
122/122 [==============================] - 0s 1ms/step - loss: 4.3828e-04 - mae: 0.0137 - mse: 3.6728e-04 - val_loss: 4.5185e-04 - val_mae: 0.0141 - val_mse: 3.8165e-04 - lr: 1.9384e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190136-bw20wynq\files\model-best)... Done. 0.0s
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0028s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0011s). Check your callbacks.
162/162 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0330 - mse: 0.0018 - val_loss: 0.0018 - val_mae: 0.0316 - val_mse: 0.0016 - lr: 0.0992-04 - lr: 9.6920e-05
Epoch 9/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0040 - mae: 0.0464 - mse: 0.0031 - val_loss: 0.0034 - val_mae: 0.0423 - val_mse: 0.0026 - lr: 0.0992
Epoch 10/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0030 - mae: 0.0385 - mse: 0.0023 - val_loss: 0.0021 - val_mae: 0.0330 - val_mse: 0.0018 - lr: 0.0992
Epoch 11/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0024 - mae: 0.0352 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0310 - val_mse: 0.0016 - lr: 0.0992
Epoch 12/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0347 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0363 - val_mse: 0.0021 - lr: 0.0992
Epoch 13/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0330 - mse: 0.0018 - val_loss: 0.0018 - val_mae: 0.0316 - val_mse: 0.0016 - lr: 0.0992-04 - lr: 9.6920e-05
Epoch 14/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0325 - mse: 0.0017 - val_loss: 0.0024 - val_mae: 0.0341 - val_mse: 0.0018 - lr: 0.0992
Epoch 15/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0313 - mse: 0.0016 - val_loss: 0.0019 - val_mae: 0.0330 - val_mse: 0.0017 - lr: 0.0992
Epoch 16/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0021 - val_mae: 0.0350 - val_mse: 0.0019 - lr: 0.0992
Epoch 17/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0307 - mse: 0.0015 - val_loss: 0.0016 - val_mae: 0.0295 - val_mse: 0.0014 - lr: 0.0992
Epoch 18/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0303 - mse: 0.0015 - val_loss: 0.0022 - val_mae: 0.0357 - val_mse: 0.0020 - lr: 0.0992
Epoch 19/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0301 - mse: 0.0015 - val_loss: 0.0015 - val_mae: 0.0264 - val_mse: 0.0012 - lr: 0.0992
Epoch 20/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0314 - mse: 0.0016 - val_loss: 0.0017 - val_mae: 0.0286 - val_mse: 0.0014 - lr: 0.0992
Epoch 21/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0299 - mse: 0.0015 - val_loss: 0.0025 - val_mae: 0.0384 - val_mse: 0.0022 - lr: 0.0992
Epoch 22/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0306 - mse: 0.0015 - val_loss: 0.0021 - val_mae: 0.0298 - val_mse: 0.0014 - lr: 0.0992
Epoch 23/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0304 - mse: 0.0015 - val_loss: 0.0018 - val_mae: 0.0307 - val_mse: 0.0015 - lr: 0.0992
Epoch 24/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0291 - mse: 0.0014 - val_loss: 0.0016 - val_mae: 0.0291 - val_mse: 0.0014 - lr: 0.0992
Epoch 25/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0303 - mse: 0.0015 - val_loss: 0.0022 - val_mae: 0.0341 - val_mse: 0.0018 - lr: 0.0992
Epoch 26/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0297 - mse: 0.0014 - val_loss: 0.0029 - val_mae: 0.0382 - val_mse: 0.0022 - lr: 0.0992
Epoch 27/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0294 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0264 - val_mse: 0.0012 - lr: 0.0992
Epoch 28/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0288 - mse: 0.0013 - val_loss: 0.0017 - val_mae: 0.0314 - val_mse: 0.0015 - lr: 0.0992
Epoch 29/150
141/162 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0307 - mse: 0.0015
Epoch 29: ReduceLROnPlateau reducing learning rate to 0.049623262137174606.
162/162 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0311 - mse: 0.0016 - val_loss: 0.0029 - val_mae: 0.0325 - val_mse: 0.0016 - lr: 0.0992
Epoch 30/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0281 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0265 - val_mse: 0.0012 - lr: 0.0496
Epoch 31/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0290 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0280 - val_mse: 0.0013 - lr: 0.0496
Epoch 32/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0286 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0281 - val_mse: 0.0013 - lr: 0.0496
Epoch 33/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0286 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0282 - val_mse: 0.0013 - lr: 0.0496
Epoch 34/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0284 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0284 - val_mse: 0.0013 - lr: 0.0496
Epoch 35/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0288 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0286 - val_mse: 0.0013 - lr: 0.0496
Epoch 36/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0278 - mse: 0.0013 - val_loss: 0.0027 - val_mae: 0.0421 - val_mse: 0.0026 - lr: 0.0496
Epoch 37/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0286 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0261 - val_mse: 0.0012 - lr: 0.0496
Epoch 38/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0283 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0262 - val_mse: 0.0012 - lr: 0.0496
Epoch 39/150
143/162 [=========================>....] - ETA: 0s - loss: 0.0014 - mae: 0.0274 - mse: 0.0012
Epoch 39: ReduceLROnPlateau reducing learning rate to 0.024811631068587303.
162/162 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0274 - mse: 0.0012 - val_loss: 0.0018 - val_mae: 0.0323 - val_mse: 0.0016 - lr: 0.0496
Epoch 40/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0275 - mse: 0.0012 - val_loss: 0.0016 - val_mae: 0.0306 - val_mse: 0.0015 - lr: 0.0248
Epoch 41/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0278 - mse: 0.0013 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0248
Epoch 42/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0276 - mse: 0.0012 - val_loss: 0.0014 - val_mae: 0.0278 - val_mse: 0.0012 - lr: 0.0248
Epoch 43/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0275 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0261 - val_mse: 0.0012 - lr: 0.0248
Epoch 44/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0272 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0261 - val_mse: 0.0011 - lr: 0.0248
Epoch 45/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0270 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0262 - val_mse: 0.0011 - lr: 0.0248
Epoch 46/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0278 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0277 - val_mse: 0.0012 - lr: 0.0248
Epoch 47/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0273 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 0.0248
Epoch 48/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0271 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0267 - val_mse: 0.0012 - lr: 0.0248
Epoch 49/150
139/162 [========================>.....] - ETA: 0s - loss: 0.0013 - mae: 0.0268 - mse: 0.0012
Epoch 49: ReduceLROnPlateau reducing learning rate to 0.012405815534293652.
162/162 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0268 - mse: 0.0012 - val_loss: 0.0019 - val_mae: 0.0334 - val_mse: 0.0017 - lr: 0.0248
Epoch 50/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0273 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0124
Epoch 51/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0266 - mse: 0.0011 - val_loss: 0.0015 - val_mae: 0.0300 - val_mse: 0.0014 - lr: 0.0124
Epoch 52/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0266 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0124
Epoch 53/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0266 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0261 - val_mse: 0.0011 - lr: 0.0124
Epoch 54/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0267 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 0.0124
Epoch 55/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0268 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0124
Epoch 56/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 0.0124
Epoch 57/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0270 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0267 - val_mse: 0.0012 - lr: 0.0124
Epoch 58/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0267 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0124
Epoch 59/150
137/162 [========================>.....] - ETA: 0s - loss: 0.0013 - mae: 0.0269 - mse: 0.0012
Epoch 59: ReduceLROnPlateau reducing learning rate to 0.006202907767146826.
162/162 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0269 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.0124
Epoch 60/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0266 - val_mse: 0.0012 - lr: 0.0062
Epoch 61/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0265 - val_mse: 0.0012 - lr: 0.0062
Epoch 62/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0265 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0270 - val_mse: 0.0012 - lr: 0.0062
Epoch 63/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0265 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 0.0062
Epoch 64/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0266 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0062
Epoch 65/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0265 - val_mse: 0.0011 - lr: 0.0062
Epoch 66/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 0.0062
Epoch 67/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0255 - val_mse: 0.0011 - lr: 0.0062
Epoch 68/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0267 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0272 - val_mse: 0.0012 - lr: 0.0062
Epoch 69/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0265 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0062
Epoch 70/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0266 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0266 - val_mse: 0.0012 - lr: 0.0062
Epoch 71/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0267 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0253 - val_mse: 0.0011 - lr: 0.0062
Epoch 72/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 0.0062
Epoch 73/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 0.0062
Epoch 74/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 0.0062
Epoch 75/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0266 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 0.0062
Epoch 76/150
144/162 [=========================>....] - ETA: 0s - loss: 0.0012 - mae: 0.0261 - mse: 0.0011
Epoch 76: ReduceLROnPlateau reducing learning rate to 0.003101453883573413.
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0255 - val_mse: 0.0011 - lr: 0.0062
Epoch 77/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0260 - val_mse: 0.0011 - lr: 0.0031
Epoch 78/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0253 - val_mse: 0.0011 - lr: 0.0031
Epoch 79/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0255 - val_mse: 0.0011 - lr: 0.0031
Epoch 80/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0031
Epoch 81/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0255 - val_mse: 0.0011 - lr: 0.0031
Epoch 82/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0031
Epoch 83/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0031
Epoch 84/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0260 - val_mse: 0.0011 - lr: 0.0031
Epoch 85/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.0031
Epoch 86/150
135/162 [========================>.....] - ETA: 0s - loss: 0.0012 - mae: 0.0263 - mse: 0.0011
Epoch 86: ReduceLROnPlateau reducing learning rate to 0.0015507269417867064.
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 0.0031
Epoch 87/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0260 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 0.0016
Epoch 88/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0260 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0255 - val_mse: 0.0011 - lr: 0.0016
Epoch 89/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0260 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 0.0016
Epoch 90/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0255 - val_mse: 0.0011 - lr: 0.0016
Epoch 91/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0260 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0255 - val_mse: 0.0011 - lr: 0.0016
Epoch 92/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0260 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0262 - val_mse: 0.0011 - lr: 0.0016
Epoch 93/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0260 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0016
Epoch 94/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0260 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0016
Epoch 95/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0016
Epoch 96/150
142/162 [=========================>....] - ETA: 0s - loss: 0.0012 - mae: 0.0262 - mse: 0.0011
Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0007753634708933532.
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 0.0016
Epoch 97/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0260 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 7.7536e-04
Epoch 98/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0260 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 7.7536e-04
Epoch 99/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0255 - val_mse: 0.0011 - lr: 7.7536e-04
Epoch 100/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 7.7536e-04
Epoch 101/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 7.7536e-04
Epoch 102/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0260 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0255 - val_mse: 0.0011 - lr: 7.7536e-04
Epoch 103/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 7.7536e-04
Epoch 104/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 7.7536e-04
Epoch 105/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0255 - val_mse: 0.0011 - lr: 7.7536e-04
Epoch 106/150
139/162 [========================>.....] - ETA: 0s - loss: 0.0011 - mae: 0.0258 - mse: 0.0011
Epoch 106: ReduceLROnPlateau reducing learning rate to 0.0003876817354466766.
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 7.7536e-04
Epoch 107/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 3.8768e-04
Epoch 108/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 3.8768e-04
Epoch 109/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0260 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 3.8768e-04
Epoch 110/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 3.8768e-04
Epoch 111/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 3.8768e-04
Epoch 112/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 3.8768e-04
Epoch 113/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0260 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0255 - val_mse: 0.0011 - lr: 3.8768e-04
Epoch 114/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 3.8768e-04
Epoch 115/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0253 - val_mse: 0.0011 - lr: 3.8768e-04
Epoch 116/150
144/162 [=========================>....] - ETA: 0s - loss: 0.0012 - mae: 0.0260 - mse: 0.0011
Epoch 116: ReduceLROnPlateau reducing learning rate to 0.0001938408677233383.
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 3.8768e-04
Epoch 117/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 1.9384e-04
Epoch 118/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 1.9384e-04
Epoch 119/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 1.9384e-04
Epoch 120/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 1.9384e-04
Epoch 121/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 1.9384e-04
Epoch 122/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 1.9384e-04
Epoch 123/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 1.9384e-04
Epoch 124/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 1.9384e-04
Epoch 125/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 1.9384e-04
Epoch 126/150
135/162 [========================>.....] - ETA: 0s - loss: 0.0011 - mae: 0.0258 - mse: 0.0011
Epoch 126: ReduceLROnPlateau reducing learning rate to 9.692043386166915e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 1.9384e-04
Epoch 127/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 9.6920e-05
Epoch 128/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 9.6920e-05
Epoch 129/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 9.6920e-05
Epoch 130/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 9.6920e-05
Epoch 131/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 9.6920e-05
Epoch 132/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 9.6920e-05
Epoch 133/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 9.6920e-05
Epoch 134/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 9.6920e-05
Epoch 135/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 9.6920e-05
Epoch 136/150
162/162 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0259 - mse: 0.0011
Epoch 136: ReduceLROnPlateau reducing learning rate to 4.8460216930834576e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 9.6920e-05
Epoch 137/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 4.8460e-05
Epoch 138/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 4.8460e-05
Epoch 139/150
162/162 [==============================] - 0s 949us/step - loss: 0.0011 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 4.8460e-05
Epoch 140/150
162/162 [==============================] - 0s 941us/step - loss: 0.0011 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 4.8460e-05
Epoch 141/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 4.8460e-05
Epoch 142/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 4.8460e-05
Epoch 143/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 4.8460e-05
Epoch 144/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 4.8460e-05
Epoch 145/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 4.8460e-05
Epoch 146/150
140/162 [========================>.....] - ETA: 0s - loss: 0.0011 - mae: 0.0258 - mse: 0.0011
Epoch 146: ReduceLROnPlateau reducing learning rate to 2.4230108465417288e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 4.8460e-05
Epoch 147/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 2.4230e-05
Epoch 148/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 2.4230e-05
Epoch 149/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 2.4230e-05
Epoch 150/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 2.4230e-05
>Saved ../trained_models/models_segments_overlap_adam_0.09924652752900127LR_[30]HN_32BS_10P_val_mseM_150epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
122/122 [==============================] - 1s 2ms/step - loss: 0.0225 - mae: 0.0407 - mse: 0.0024 - val_loss: 0.0023 - val_mae: 0.0396 - val_mse: 0.0022 - lr: 0.0992
Epoch 2/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0992
Epoch 3/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0992
Epoch 4/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0992
Epoch 5/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0992
Epoch 6/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0992
Epoch 7/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0992
Epoch 8/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0992
Epoch 9/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0992
Epoch 10/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0024 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0992
Epoch 11/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 0.0992
Epoch 12/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0379 - mse: 0.0020 - val_loss: 0.0018 - val_mae: 0.0326 - val_mse: 0.0015 - lr: 0.0992
Epoch 13/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0342 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0331 - val_mse: 0.0016 - lr: 0.0992
Epoch 14/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0299 - mse: 0.0014 - val_loss: 0.0016 - val_mae: 0.0324 - val_mse: 0.0015 - lr: 0.0992
Epoch 15/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0280 - mse: 0.0012 - val_loss: 0.0014 - val_mae: 0.0263 - val_mse: 0.0011 - lr: 0.0992
Epoch 16/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0279 - mse: 0.0012 - val_loss: 0.0016 - val_mae: 0.0262 - val_mse: 0.0010 - lr: 0.0992
Epoch 17/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0267 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0246 - val_mse: 9.7407e-04 - lr: 0.0992
Epoch 18/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0267 - mse: 0.0011 - val_loss: 0.0015 - val_mae: 0.0278 - val_mse: 0.0013 - lr: 0.0992
Epoch 19/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0265 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0255 - val_mse: 9.7658e-04 - lr: 0.0992
Epoch 20/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0260 - val_mse: 0.0010 - lr: 0.0992
Epoch 21/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0256 - mse: 0.0010 - val_loss: 0.0013 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0992
Epoch 22/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0258 - mse: 0.0010 - val_loss: 0.0018 - val_mae: 0.0315 - val_mse: 0.0016 - lr: 0.0992
Epoch 23/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0257 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0242 - val_mse: 9.2734e-04 - lr: 0.0992
Epoch 24/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0253 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0242 - val_mse: 9.1789e-04 - lr: 0.0992
Epoch 25/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0251 - mse: 9.7745e-04 - val_loss: 0.0011 - val_mae: 0.0268 - val_mse: 0.0010 - lr: 0.0992
Epoch 26/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0255 - mse: 0.0010 - val_loss: 0.0013 - val_mae: 0.0279 - val_mse: 0.0011 - lr: 0.0992
Epoch 27/150
 68/122 [===============>..............] - ETA: 0s - loss: 0.0012 - mae: 0.0250 - mse: 9.8663e-04
Epoch 27: ReduceLROnPlateau reducing learning rate to 0.049623262137174606.
122/122 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0253 - mse: 0.0010 - val_loss: 0.0014 - val_mae: 0.0243 - val_mse: 9.3722e-04 - lr: 0.0992
Epoch 28/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0242 - mse: 9.2115e-04 - val_loss: 0.0011 - val_mae: 0.0239 - val_mse: 9.0722e-04 - lr: 0.0496
Epoch 29/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0242 - mse: 9.2459e-04 - val_loss: 0.0011 - val_mae: 0.0269 - val_mse: 0.0011 - lr: 0.0496
Epoch 30/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0249 - mse: 9.7982e-04 - val_loss: 0.0010 - val_mae: 0.0241 - val_mse: 9.5405e-04 - lr: 0.0496
Epoch 31/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0250 - mse: 9.8391e-04 - val_loss: 0.0010 - val_mae: 0.0242 - val_mse: 9.1186e-04 - lr: 0.0496
Epoch 32/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0240 - mse: 9.1609e-04 - val_loss: 0.0012 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0496
Epoch 33/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0245 - mse: 9.4168e-04 - val_loss: 0.0013 - val_mae: 0.0290 - val_mse: 0.0012 - lr: 0.0496
Epoch 34/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0242 - mse: 9.3001e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.0496
Epoch 35/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0245 - mse: 9.4166e-04 - val_loss: 0.0011 - val_mae: 0.0244 - val_mse: 9.8540e-04 - lr: 0.0496
Epoch 36/150
122/122 [==============================] - 0s 1ms/step - loss: 9.9715e-04 - mae: 0.0239 - mse: 9.0471e-04 - val_loss: 9.9026e-04 - val_mae: 0.0247 - val_mse: 9.2009e-04 - lr: 0.0496
Epoch 37/150
 74/122 [=================>............] - ETA: 0s - loss: 9.7334e-04 - mae: 0.0240 - mse: 8.9911e-04
Epoch 37: ReduceLROnPlateau reducing learning rate to 0.024811631068587303.
122/122 [==============================] - 0s 1ms/step - loss: 9.8905e-04 - mae: 0.0241 - mse: 9.1210e-04 - val_loss: 0.0012 - val_mae: 0.0262 - val_mse: 0.0011 - lr: 0.0496
Epoch 38/150
122/122 [==============================] - 0s 1ms/step - loss: 9.4960e-04 - mae: 0.0235 - mse: 8.7779e-04 - val_loss: 9.5470e-04 - val_mae: 0.0240 - val_mse: 8.8591e-04 - lr: 0.0248
Epoch 39/150
122/122 [==============================] - 0s 1ms/step - loss: 9.5281e-04 - mae: 0.0237 - mse: 8.8290e-04 - val_loss: 0.0013 - val_mae: 0.0268 - val_mse: 0.0012 - lr: 0.0248
Epoch 40/150
122/122 [==============================] - 0s 1ms/step - loss: 9.7125e-04 - mae: 0.0240 - mse: 9.0425e-04 - val_loss: 9.5134e-04 - val_mae: 0.0239 - val_mse: 8.8488e-04 - lr: 0.0248
Epoch 41/150
122/122 [==============================] - 0s 1ms/step - loss: 9.5140e-04 - mae: 0.0237 - mse: 8.8398e-04 - val_loss: 9.5807e-04 - val_mae: 0.0242 - val_mse: 9.1018e-04 - lr: 0.0248
Epoch 42/150
122/122 [==============================] - 0s 1ms/step - loss: 9.5471e-04 - mae: 0.0237 - mse: 8.8981e-04 - val_loss: 9.4651e-04 - val_mae: 0.0239 - val_mse: 8.8918e-04 - lr: 0.0248
Epoch 43/150
122/122 [==============================] - 0s 1ms/step - loss: 9.7012e-04 - mae: 0.0240 - mse: 9.0603e-04 - val_loss: 0.0011 - val_mae: 0.0243 - val_mse: 9.6820e-04 - lr: 0.0248
Epoch 44/150
122/122 [==============================] - 0s 1ms/step - loss: 9.8198e-04 - mae: 0.0235 - mse: 8.6988e-04 - val_loss: 0.0011 - val_mae: 0.0247 - val_mse: 0.0010 - lr: 0.0248
Epoch 45/150
122/122 [==============================] - 0s 1ms/step - loss: 9.7929e-04 - mae: 0.0238 - mse: 8.9011e-04 - val_loss: 0.0012 - val_mae: 0.0261 - val_mse: 0.0011 - lr: 0.0248
Epoch 46/150
122/122 [==============================] - 0s 1ms/step - loss: 9.3174e-04 - mae: 0.0233 - mse: 8.6274e-04 - val_loss: 0.0011 - val_mae: 0.0248 - val_mse: 0.0010 - lr: 0.0248
Epoch 47/150
 75/122 [=================>............] - ETA: 0s - loss: 9.4348e-04 - mae: 0.0237 - mse: 8.7941e-04
Epoch 47: ReduceLROnPlateau reducing learning rate to 0.012405815534293652.
122/122 [==============================] - 0s 1ms/step - loss: 9.4092e-04 - mae: 0.0236 - mse: 8.7786e-04 - val_loss: 0.0012 - val_mae: 0.0278 - val_mse: 0.0011 - lr: 0.0248
Epoch 48/150
122/122 [==============================] - 0s 1ms/step - loss: 9.1945e-04 - mae: 0.0233 - mse: 8.6275e-04 - val_loss: 9.5251e-04 - val_mae: 0.0235 - val_mse: 8.9294e-04 - lr: 0.0124
Epoch 49/150
122/122 [==============================] - 0s 1ms/step - loss: 9.1884e-04 - mae: 0.0233 - mse: 8.5997e-04 - val_loss: 9.3796e-04 - val_mae: 0.0235 - val_mse: 8.8832e-04 - lr: 0.0124
Epoch 50/150
122/122 [==============================] - 0s 1ms/step - loss: 9.0386e-04 - mae: 0.0232 - mse: 8.4985e-04 - val_loss: 9.3407e-04 - val_mae: 0.0240 - val_mse: 8.8394e-04 - lr: 0.0124
Epoch 51/150
122/122 [==============================] - 0s 1ms/step - loss: 8.8715e-04 - mae: 0.0230 - mse: 8.3557e-04 - val_loss: 9.4151e-04 - val_mae: 0.0235 - val_mse: 8.8169e-04 - lr: 0.0124
Epoch 52/150
122/122 [==============================] - 0s 1ms/step - loss: 8.9460e-04 - mae: 0.0231 - mse: 8.4235e-04 - val_loss: 9.3783e-04 - val_mae: 0.0234 - val_mse: 8.8941e-04 - lr: 0.0124
Epoch 53/150
122/122 [==============================] - 0s 1ms/step - loss: 9.2933e-04 - mae: 0.0236 - mse: 8.7681e-04 - val_loss: 9.2614e-04 - val_mae: 0.0239 - val_mse: 8.7662e-04 - lr: 0.0124
Epoch 54/150
122/122 [==============================] - 0s 1ms/step - loss: 8.9925e-04 - mae: 0.0231 - mse: 8.4877e-04 - val_loss: 9.5941e-04 - val_mae: 0.0247 - val_mse: 9.1240e-04 - lr: 0.0124
Epoch 55/150
122/122 [==============================] - 0s 1ms/step - loss: 9.2208e-04 - mae: 0.0235 - mse: 8.7123e-04 - val_loss: 9.6320e-04 - val_mae: 0.0237 - val_mse: 9.1674e-04 - lr: 0.0124
Epoch 56/150
122/122 [==============================] - 0s 1ms/step - loss: 9.2471e-04 - mae: 0.0234 - mse: 8.6790e-04 - val_loss: 9.4953e-04 - val_mae: 0.0244 - val_mse: 8.9913e-04 - lr: 0.0124
Epoch 57/150
 69/122 [===============>..............] - ETA: 0s - loss: 8.9210e-04 - mae: 0.0230 - mse: 8.4050e-04
Epoch 57: ReduceLROnPlateau reducing learning rate to 0.006202907767146826.
122/122 [==============================] - 0s 1ms/step - loss: 8.8745e-04 - mae: 0.0230 - mse: 8.3729e-04 - val_loss: 9.5833e-04 - val_mae: 0.0247 - val_mse: 9.1746e-04 - lr: 0.0124
Epoch 58/150
122/122 [==============================] - 0s 1ms/step - loss: 8.7132e-04 - mae: 0.0228 - mse: 8.2564e-04 - val_loss: 9.2848e-04 - val_mae: 0.0234 - val_mse: 8.7745e-04 - lr: 0.0062
Epoch 59/150
122/122 [==============================] - 0s 1ms/step - loss: 8.7804e-04 - mae: 0.0228 - mse: 8.3120e-04 - val_loss: 0.0010 - val_mae: 0.0240 - val_mse: 9.5131e-04 - lr: 0.0062
Epoch 60/150
122/122 [==============================] - 0s 1ms/step - loss: 9.1302e-04 - mae: 0.0234 - mse: 8.6466e-04 - val_loss: 0.0011 - val_mae: 0.0263 - val_mse: 0.0010 - lr: 0.0062
Epoch 61/150
122/122 [==============================] - 0s 1ms/step - loss: 8.9573e-04 - mae: 0.0231 - mse: 8.4463e-04 - val_loss: 9.8096e-04 - val_mae: 0.0237 - val_mse: 9.2074e-04 - lr: 0.0062
Epoch 62/150
122/122 [==============================] - 0s 1ms/step - loss: 8.7675e-04 - mae: 0.0229 - mse: 8.3133e-04 - val_loss: 9.5074e-04 - val_mae: 0.0235 - val_mse: 9.0269e-04 - lr: 0.0062
Epoch 63/150
122/122 [==============================] - 0s 1ms/step - loss: 8.8935e-04 - mae: 0.0231 - mse: 8.4369e-04 - val_loss: 9.1809e-04 - val_mae: 0.0239 - val_mse: 8.7779e-04 - lr: 0.0062
Epoch 64/150
122/122 [==============================] - 0s 1ms/step - loss: 8.8142e-04 - mae: 0.0230 - mse: 8.3658e-04 - val_loss: 9.3016e-04 - val_mae: 0.0234 - val_mse: 8.8060e-04 - lr: 0.0062
Epoch 65/150
122/122 [==============================] - 0s 1ms/step - loss: 8.8575e-04 - mae: 0.0229 - mse: 8.3888e-04 - val_loss: 9.1469e-04 - val_mae: 0.0234 - val_mse: 8.7013e-04 - lr: 0.0062
Epoch 66/150
122/122 [==============================] - 0s 1ms/step - loss: 8.8163e-04 - mae: 0.0229 - mse: 8.3817e-04 - val_loss: 9.5576e-04 - val_mae: 0.0247 - val_mse: 9.1713e-04 - lr: 0.0062
Epoch 67/150
122/122 [==============================] - 0s 1ms/step - loss: 8.7646e-04 - mae: 0.0229 - mse: 8.3235e-04 - val_loss: 9.0915e-04 - val_mae: 0.0234 - val_mse: 8.6850e-04 - lr: 0.0062
Epoch 68/150
122/122 [==============================] - 0s 1ms/step - loss: 8.7159e-04 - mae: 0.0228 - mse: 8.2877e-04 - val_loss: 9.6489e-04 - val_mae: 0.0237 - val_mse: 9.2251e-04 - lr: 0.0062
Epoch 69/150
122/122 [==============================] - 0s 1ms/step - loss: 8.7989e-04 - mae: 0.0230 - mse: 8.3471e-04 - val_loss: 9.3809e-04 - val_mae: 0.0243 - val_mse: 8.9700e-04 - lr: 0.0062
Epoch 70/150
122/122 [==============================] - 0s 1ms/step - loss: 8.8313e-04 - mae: 0.0229 - mse: 8.3704e-04 - val_loss: 9.0750e-04 - val_mae: 0.0236 - val_mse: 8.6698e-04 - lr: 0.0062
Epoch 71/150
122/122 [==============================] - 0s 1ms/step - loss: 9.1307e-04 - mae: 0.0231 - mse: 8.5756e-04 - val_loss: 9.1213e-04 - val_mae: 0.0236 - val_mse: 8.6412e-04 - lr: 0.0062
Epoch 72/150
122/122 [==============================] - 0s 1ms/step - loss: 8.9158e-04 - mae: 0.0231 - mse: 8.4482e-04 - val_loss: 9.7438e-04 - val_mae: 0.0238 - val_mse: 9.2798e-04 - lr: 0.0062
Epoch 73/150
122/122 [==============================] - 0s 1ms/step - loss: 8.9054e-04 - mae: 0.0230 - mse: 8.3776e-04 - val_loss: 9.3700e-04 - val_mae: 0.0234 - val_mse: 8.9424e-04 - lr: 0.0062
Epoch 74/150
122/122 [==============================] - 0s 1ms/step - loss: 8.6789e-04 - mae: 0.0228 - mse: 8.2513e-04 - val_loss: 9.8353e-04 - val_mae: 0.0252 - val_mse: 9.4068e-04 - lr: 0.0062
Epoch 75/150
 74/122 [=================>............] - ETA: 0s - loss: 8.8554e-04 - mae: 0.0231 - mse: 8.3967e-04
Epoch 75: ReduceLROnPlateau reducing learning rate to 0.003101453883573413.
122/122 [==============================] - 0s 1ms/step - loss: 8.8576e-04 - mae: 0.0230 - mse: 8.3856e-04 - val_loss: 9.7542e-04 - val_mae: 0.0249 - val_mse: 9.2442e-04 - lr: 0.0062
Epoch 76/150
122/122 [==============================] - 0s 1ms/step - loss: 8.6211e-04 - mae: 0.0227 - mse: 8.2075e-04 - val_loss: 9.0311e-04 - val_mae: 0.0234 - val_mse: 8.5969e-04 - lr: 0.0031
Epoch 77/150
122/122 [==============================] - 0s 1ms/step - loss: 8.5815e-04 - mae: 0.0227 - mse: 8.1732e-04 - val_loss: 9.3438e-04 - val_mae: 0.0234 - val_mse: 8.9143e-04 - lr: 0.0031
Epoch 78/150
122/122 [==============================] - 0s 1ms/step - loss: 8.5688e-04 - mae: 0.0226 - mse: 8.1891e-04 - val_loss: 9.0111e-04 - val_mae: 0.0235 - val_mse: 8.6050e-04 - lr: 0.0031
Epoch 79/150
122/122 [==============================] - 0s 1ms/step - loss: 8.5458e-04 - mae: 0.0226 - mse: 8.1561e-04 - val_loss: 9.0202e-04 - val_mae: 0.0233 - val_mse: 8.6525e-04 - lr: 0.0031
Epoch 80/150
122/122 [==============================] - 0s 1ms/step - loss: 8.5815e-04 - mae: 0.0227 - mse: 8.2084e-04 - val_loss: 9.0935e-04 - val_mae: 0.0233 - val_mse: 8.7058e-04 - lr: 0.0031
Epoch 81/150
122/122 [==============================] - 0s 1ms/step - loss: 8.5088e-04 - mae: 0.0225 - mse: 8.1419e-04 - val_loss: 8.9988e-04 - val_mae: 0.0234 - val_mse: 8.6549e-04 - lr: 0.0031
Epoch 82/150
122/122 [==============================] - 0s 1ms/step - loss: 8.5952e-04 - mae: 0.0228 - mse: 8.2211e-04 - val_loss: 9.1252e-04 - val_mae: 0.0233 - val_mse: 8.7190e-04 - lr: 0.0031
Epoch 83/150
122/122 [==============================] - 0s 1ms/step - loss: 8.5168e-04 - mae: 0.0226 - mse: 8.1474e-04 - val_loss: 9.0952e-04 - val_mae: 0.0233 - val_mse: 8.7256e-04 - lr: 0.0031
Epoch 84/150
122/122 [==============================] - 0s 1ms/step - loss: 8.5488e-04 - mae: 0.0226 - mse: 8.1888e-04 - val_loss: 9.3545e-04 - val_mae: 0.0234 - val_mse: 8.9714e-04 - lr: 0.0031
Epoch 85/150
 73/122 [================>.............] - ETA: 0s - loss: 8.5266e-04 - mae: 0.0224 - mse: 8.1665e-04
Epoch 85: ReduceLROnPlateau reducing learning rate to 0.0015507269417867064.
122/122 [==============================] - 0s 1ms/step - loss: 8.5945e-04 - mae: 0.0227 - mse: 8.2344e-04 - val_loss: 9.3655e-04 - val_mae: 0.0245 - val_mse: 9.0871e-04 - lr: 0.0031
Epoch 86/150
122/122 [==============================] - 0s 1ms/step - loss: 8.4817e-04 - mae: 0.0226 - mse: 8.1346e-04 - val_loss: 8.9620e-04 - val_mae: 0.0234 - val_mse: 8.6072e-04 - lr: 0.0016
Epoch 87/150
122/122 [==============================] - 0s 1ms/step - loss: 8.4405e-04 - mae: 0.0225 - mse: 8.0921e-04 - val_loss: 9.0125e-04 - val_mae: 0.0237 - val_mse: 8.6806e-04 - lr: 0.0016
Epoch 88/150
122/122 [==============================] - 0s 1ms/step - loss: 8.4456e-04 - mae: 0.0225 - mse: 8.0959e-04 - val_loss: 8.9687e-04 - val_mae: 0.0233 - val_mse: 8.6322e-04 - lr: 0.0016
Epoch 89/150
122/122 [==============================] - 0s 1ms/step - loss: 8.4662e-04 - mae: 0.0225 - mse: 8.1288e-04 - val_loss: 8.9558e-04 - val_mae: 0.0233 - val_mse: 8.6113e-04 - lr: 0.0016
Epoch 90/150
122/122 [==============================] - 0s 1ms/step - loss: 8.4339e-04 - mae: 0.0225 - mse: 8.0931e-04 - val_loss: 9.1437e-04 - val_mae: 0.0233 - val_mse: 8.7859e-04 - lr: 0.0016
Epoch 91/150
122/122 [==============================] - 0s 1ms/step - loss: 8.4403e-04 - mae: 0.0225 - mse: 8.0999e-04 - val_loss: 9.0849e-04 - val_mae: 0.0239 - val_mse: 8.7709e-04 - lr: 0.0016
Epoch 92/150
122/122 [==============================] - 0s 1ms/step - loss: 8.4983e-04 - mae: 0.0226 - mse: 8.1578e-04 - val_loss: 8.9439e-04 - val_mae: 0.0234 - val_mse: 8.6145e-04 - lr: 0.0016
Epoch 93/150
122/122 [==============================] - 0s 1ms/step - loss: 8.4365e-04 - mae: 0.0225 - mse: 8.0999e-04 - val_loss: 8.9830e-04 - val_mae: 0.0233 - val_mse: 8.6343e-04 - lr: 0.0016
Epoch 94/150
122/122 [==============================] - 0s 1ms/step - loss: 8.4263e-04 - mae: 0.0225 - mse: 8.0936e-04 - val_loss: 9.1328e-04 - val_mae: 0.0233 - val_mse: 8.7726e-04 - lr: 0.0016
Epoch 95/150
 74/122 [=================>............] - ETA: 0s - loss: 8.5333e-04 - mae: 0.0227 - mse: 8.1925e-04
Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0007753634708933532.
122/122 [==============================] - 0s 1ms/step - loss: 8.4844e-04 - mae: 0.0226 - mse: 8.1465e-04 - val_loss: 9.3127e-04 - val_mae: 0.0234 - val_mse: 8.9377e-04 - lr: 0.0016
Epoch 96/150
122/122 [==============================] - 0s 1ms/step - loss: 8.4319e-04 - mae: 0.0225 - mse: 8.0977e-04 - val_loss: 9.0860e-04 - val_mae: 0.0233 - val_mse: 8.7264e-04 - lr: 7.7536e-04
Epoch 97/150
122/122 [==============================] - 0s 1ms/step - loss: 8.4053e-04 - mae: 0.0225 - mse: 8.0681e-04 - val_loss: 9.0448e-04 - val_mae: 0.0232 - val_mse: 8.7118e-04 - lr: 7.7536e-04
Epoch 98/150
122/122 [==============================] - 0s 1ms/step - loss: 8.4120e-04 - mae: 0.0225 - mse: 8.0838e-04 - val_loss: 8.9446e-04 - val_mae: 0.0235 - val_mse: 8.6247e-04 - lr: 7.7536e-04
Epoch 99/150
122/122 [==============================] - 0s 1ms/step - loss: 8.4093e-04 - mae: 0.0225 - mse: 8.0759e-04 - val_loss: 8.9698e-04 - val_mae: 0.0233 - val_mse: 8.6456e-04 - lr: 7.7536e-04
Epoch 100/150
122/122 [==============================] - 0s 1ms/step - loss: 8.4384e-04 - mae: 0.0225 - mse: 8.1084e-04 - val_loss: 8.9306e-04 - val_mae: 0.0234 - val_mse: 8.6123e-04 - lr: 7.7536e-04
Epoch 101/150
122/122 [==============================] - 0s 1ms/step - loss: 8.4298e-04 - mae: 0.0225 - mse: 8.0969e-04 - val_loss: 8.9367e-04 - val_mae: 0.0233 - val_mse: 8.6262e-04 - lr: 7.7536e-04
Epoch 102/150
122/122 [==============================] - 0s 1ms/step - loss: 8.4111e-04 - mae: 0.0225 - mse: 8.0885e-04 - val_loss: 8.9269e-04 - val_mae: 0.0234 - val_mse: 8.6088e-04 - lr: 7.7536e-04
Epoch 103/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3948e-04 - mae: 0.0225 - mse: 8.0619e-04 - val_loss: 8.9243e-04 - val_mae: 0.0234 - val_mse: 8.6087e-04 - lr: 7.7536e-04
Epoch 104/150
122/122 [==============================] - 0s 1ms/step - loss: 8.4546e-04 - mae: 0.0225 - mse: 8.1293e-04 - val_loss: 8.9245e-04 - val_mae: 0.0234 - val_mse: 8.6054e-04 - lr: 7.7536e-04
Epoch 105/150
 73/122 [================>.............] - ETA: 0s - loss: 8.2908e-04 - mae: 0.0222 - mse: 7.9654e-04
Epoch 105: ReduceLROnPlateau reducing learning rate to 0.0003876817354466766.
122/122 [==============================] - 0s 1ms/step - loss: 8.4368e-04 - mae: 0.0225 - mse: 8.1097e-04 - val_loss: 8.9199e-04 - val_mae: 0.0234 - val_mse: 8.5936e-04 - lr: 7.7536e-04
Epoch 106/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3890e-04 - mae: 0.0225 - mse: 8.0590e-04 - val_loss: 8.9766e-04 - val_mae: 0.0232 - val_mse: 8.6465e-04 - lr: 3.8768e-04
Epoch 107/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3846e-04 - mae: 0.0225 - mse: 8.0663e-04 - val_loss: 9.0098e-04 - val_mae: 0.0232 - val_mse: 8.6810e-04 - lr: 3.8768e-04
Epoch 108/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3799e-04 - mae: 0.0224 - mse: 8.0587e-04 - val_loss: 8.9359e-04 - val_mae: 0.0233 - val_mse: 8.6151e-04 - lr: 3.8768e-04
Epoch 109/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3967e-04 - mae: 0.0225 - mse: 8.0813e-04 - val_loss: 8.9345e-04 - val_mae: 0.0233 - val_mse: 8.6139e-04 - lr: 3.8768e-04
Epoch 110/150
122/122 [==============================] - 0s 1ms/step - loss: 8.4119e-04 - mae: 0.0225 - mse: 8.0877e-04 - val_loss: 8.9181e-04 - val_mae: 0.0234 - val_mse: 8.6038e-04 - lr: 3.8768e-04
Epoch 111/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3755e-04 - mae: 0.0225 - mse: 8.0524e-04 - val_loss: 8.9232e-04 - val_mae: 0.0233 - val_mse: 8.6086e-04 - lr: 3.8768e-04
Epoch 112/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3626e-04 - mae: 0.0224 - mse: 8.0487e-04 - val_loss: 8.9432e-04 - val_mae: 0.0236 - val_mse: 8.6444e-04 - lr: 3.8768e-04
Epoch 113/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3875e-04 - mae: 0.0225 - mse: 8.0713e-04 - val_loss: 8.9234e-04 - val_mae: 0.0233 - val_mse: 8.6129e-04 - lr: 3.8768e-04
Epoch 114/150
122/122 [==============================] - 0s 1ms/step - loss: 8.4020e-04 - mae: 0.0225 - mse: 8.0893e-04 - val_loss: 8.9431e-04 - val_mae: 0.0233 - val_mse: 8.6230e-04 - lr: 3.8768e-04
Epoch 115/150
 69/122 [===============>..............] - ETA: 0s - loss: 8.5695e-04 - mae: 0.0228 - mse: 8.2518e-04
Epoch 115: ReduceLROnPlateau reducing learning rate to 0.0001938408677233383.
122/122 [==============================] - 0s 1ms/step - loss: 8.3676e-04 - mae: 0.0224 - mse: 8.0464e-04 - val_loss: 8.9951e-04 - val_mae: 0.0232 - val_mse: 8.6700e-04 - lr: 3.8768e-04
Epoch 116/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3642e-04 - mae: 0.0224 - mse: 8.0493e-04 - val_loss: 8.9520e-04 - val_mae: 0.0232 - val_mse: 8.6328e-04 - lr: 1.9384e-04
Epoch 117/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3731e-04 - mae: 0.0224 - mse: 8.0549e-04 - val_loss: 8.9186e-04 - val_mae: 0.0233 - val_mse: 8.6058e-04 - lr: 1.9384e-04
Epoch 118/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3620e-04 - mae: 0.0224 - mse: 8.0466e-04 - val_loss: 8.9196e-04 - val_mae: 0.0233 - val_mse: 8.6079e-04 - lr: 1.9384e-04
Epoch 119/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3617e-04 - mae: 0.0224 - mse: 8.0475e-04 - val_loss: 8.9367e-04 - val_mae: 0.0233 - val_mse: 8.6195e-04 - lr: 1.9384e-04
Epoch 120/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3655e-04 - mae: 0.0224 - mse: 8.0518e-04 - val_loss: 8.9286e-04 - val_mae: 0.0233 - val_mse: 8.6132e-04 - lr: 1.9384e-04
Epoch 121/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3623e-04 - mae: 0.0224 - mse: 8.0479e-04 - val_loss: 8.9448e-04 - val_mae: 0.0233 - val_mse: 8.6259e-04 - lr: 1.9384e-04
Epoch 122/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3672e-04 - mae: 0.0224 - mse: 8.0516e-04 - val_loss: 8.9231e-04 - val_mae: 0.0233 - val_mse: 8.6088e-04 - lr: 1.9384e-04
Epoch 123/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3752e-04 - mae: 0.0224 - mse: 8.0591e-04 - val_loss: 8.9151e-04 - val_mae: 0.0233 - val_mse: 8.6026e-04 - lr: 1.9384e-04
Epoch 124/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3712e-04 - mae: 0.0225 - mse: 8.0573e-04 - val_loss: 8.9349e-04 - val_mae: 0.0233 - val_mse: 8.6199e-04 - lr: 1.9384e-04
Epoch 125/150
 68/122 [===============>..............] - ETA: 0s - loss: 8.6767e-04 - mae: 0.0231 - mse: 8.3649e-04
Epoch 125: ReduceLROnPlateau reducing learning rate to 9.692043386166915e-05.
122/122 [==============================] - 0s 1ms/step - loss: 8.3644e-04 - mae: 0.0225 - mse: 8.0502e-04 - val_loss: 8.9634e-04 - val_mae: 0.0232 - val_mse: 8.6431e-04 - lr: 1.9384e-04
Epoch 126/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3594e-04 - mae: 0.0224 - mse: 8.0427e-04 - val_loss: 8.9213e-04 - val_mae: 0.0233 - val_mse: 8.6084e-04 - lr: 9.6920e-05
Epoch 127/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3567e-04 - mae: 0.0224 - mse: 8.0441e-04 - val_loss: 8.9269e-04 - val_mae: 0.0233 - val_mse: 8.6132e-04 - lr: 9.6920e-05
Epoch 128/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3554e-04 - mae: 0.0224 - mse: 8.0416e-04 - val_loss: 8.9071e-04 - val_mae: 0.0234 - val_mse: 8.5992e-04 - lr: 9.6920e-05
Epoch 129/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3592e-04 - mae: 0.0224 - mse: 8.0450e-04 - val_loss: 8.9114e-04 - val_mae: 0.0233 - val_mse: 8.6018e-04 - lr: 9.6920e-05
Epoch 130/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3580e-04 - mae: 0.0224 - mse: 8.0460e-04 - val_loss: 8.9122e-04 - val_mae: 0.0233 - val_mse: 8.6020e-04 - lr: 9.6920e-05
Epoch 131/150
122/122 [==============================] - 0s 2ms/step - loss: 8.3552e-04 - mae: 0.0224 - mse: 8.0417e-04 - val_loss: 8.9149e-04 - val_mae: 0.0233 - val_mse: 8.6038e-04 - lr: 9.6920e-05
Epoch 132/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3559e-04 - mae: 0.0224 - mse: 8.0442e-04 - val_loss: 8.9214e-04 - val_mae: 0.0233 - val_mse: 8.6086e-04 - lr: 9.6920e-05
Epoch 133/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3595e-04 - mae: 0.0224 - mse: 8.0450e-04 - val_loss: 8.9305e-04 - val_mae: 0.0233 - val_mse: 8.6171e-04 - lr: 9.6920e-05
Epoch 134/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3520e-04 - mae: 0.0224 - mse: 8.0377e-04 - val_loss: 8.9095e-04 - val_mae: 0.0233 - val_mse: 8.6013e-04 - lr: 9.6920e-05
Epoch 135/150
 72/122 [================>.............] - ETA: 0s - loss: 8.2868e-04 - mae: 0.0222 - mse: 7.9766e-04
Epoch 135: ReduceLROnPlateau reducing learning rate to 4.8460216930834576e-05.
122/122 [==============================] - 0s 1ms/step - loss: 8.3548e-04 - mae: 0.0224 - mse: 8.0443e-04 - val_loss: 8.9264e-04 - val_mae: 0.0233 - val_mse: 8.6145e-04 - lr: 9.6920e-05
Epoch 136/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3509e-04 - mae: 0.0224 - mse: 8.0392e-04 - val_loss: 8.9254e-04 - val_mae: 0.0233 - val_mse: 8.6131e-04 - lr: 4.8460e-05
Epoch 137/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3520e-04 - mae: 0.0224 - mse: 8.0396e-04 - val_loss: 8.9261e-04 - val_mae: 0.0233 - val_mse: 8.6141e-04 - lr: 4.8460e-05
Epoch 138/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3511e-04 - mae: 0.0224 - mse: 8.0395e-04 - val_loss: 8.9296e-04 - val_mae: 0.0233 - val_mse: 8.6168e-04 - lr: 4.8460e-05
Epoch 139/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3501e-04 - mae: 0.0224 - mse: 8.0390e-04 - val_loss: 8.9232e-04 - val_mae: 0.0233 - val_mse: 8.6118e-04 - lr: 4.8460e-05
Epoch 140/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3499e-04 - mae: 0.0224 - mse: 8.0362e-04 - val_loss: 8.9197e-04 - val_mae: 0.0233 - val_mse: 8.6081e-04 - lr: 4.8460e-05
Epoch 141/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3505e-04 - mae: 0.0224 - mse: 8.0393e-04 - val_loss: 8.9171e-04 - val_mae: 0.0233 - val_mse: 8.6065e-04 - lr: 4.8460e-05
Epoch 142/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3537e-04 - mae: 0.0224 - mse: 8.0409e-04 - val_loss: 8.9225e-04 - val_mae: 0.0233 - val_mse: 8.6103e-04 - lr: 4.8460e-05
Epoch 143/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3479e-04 - mae: 0.0224 - mse: 8.0367e-04 - val_loss: 8.9328e-04 - val_mae: 0.0233 - val_mse: 8.6195e-04 - lr: 4.8460e-05
Epoch 144/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3489e-04 - mae: 0.0224 - mse: 8.0350e-04 - val_loss: 8.9160e-04 - val_mae: 0.0233 - val_mse: 8.6058e-04 - lr: 4.8460e-05
Epoch 145/150
 72/122 [================>.............] - ETA: 0s - loss: 8.3725e-04 - mae: 0.0224 - mse: 8.0603e-04
Epoch 145: ReduceLROnPlateau reducing learning rate to 2.4230108465417288e-05.
122/122 [==============================] - 0s 1ms/step - loss: 8.3510e-04 - mae: 0.0224 - mse: 8.0392e-04 - val_loss: 8.9196e-04 - val_mae: 0.0233 - val_mse: 8.6084e-04 - lr: 4.8460e-05
Epoch 146/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3494e-04 - mae: 0.0224 - mse: 8.0379e-04 - val_loss: 8.9195e-04 - val_mae: 0.0233 - val_mse: 8.6087e-04 - lr: 2.4230e-05
Epoch 147/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3485e-04 - mae: 0.0224 - mse: 8.0370e-04 - val_loss: 8.9204e-04 - val_mae: 0.0233 - val_mse: 8.6093e-04 - lr: 2.4230e-05
Epoch 148/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3485e-04 - mae: 0.0224 - mse: 8.0380e-04 - val_loss: 8.9249e-04 - val_mae: 0.0233 - val_mse: 8.6129e-04 - lr: 2.4230e-05
Epoch 149/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3474e-04 - mae: 0.0224 - mse: 8.0356e-04 - val_loss: 8.9213e-04 - val_mae: 0.0233 - val_mse: 8.6102e-04 - lr: 2.4230e-05
Epoch 150/150
122/122 [==============================] - 0s 1ms/step - loss: 8.3475e-04 - mae: 0.0224 - mse: 8.0361e-04 - val_loss: 8.9234e-04 - val_mae: 0.0233 - val_mse: 8.6116e-04 - lr: 2.4230e-05
>Saved ../trained_models/models_segments_overlap_adam_0.09924652752900127LR_[30]HN_32BS_10P_val_mseM_150epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
122/122 [==============================] - 1s 2ms/step - loss: 0.0223 - mae: 0.0394 - mse: 0.0021 - val_loss: 0.0023 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0992
Epoch 2/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0992
Epoch 3/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0992
Epoch 4/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0029 - val_mae: 0.0419 - val_mse: 0.0025 - lr: 0.0992
Epoch 5/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0992
Epoch 6/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0992
Epoch 7/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0992
Epoch 8/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0992
Epoch 9/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0992
Epoch 10/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0992
Epoch 11/150
 67/122 [===============>..............] - ETA: 0s - loss: 0.0021 - mae: 0.0385 - mse: 0.0020
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.049623262137174606.
122/122 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0992
Epoch 12/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0496
Epoch 13/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0496
Epoch 14/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0496
Epoch 15/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0496
Epoch 16/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0496
Epoch 17/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0496
Epoch 18/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0496
Epoch 19/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0496
Epoch 20/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0496
Epoch 21/150
103/122 [========================>.....] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.024811631068587303.
122/122 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0496
Epoch 22/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0248
Epoch 23/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0248
Epoch 24/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0248
Epoch 25/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0248
Epoch 26/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0248
Epoch 27/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0248
Epoch 28/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0248
Epoch 29/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0248
Epoch 30/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0248
Epoch 31/150
102/122 [========================>.....] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0019
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.012405815534293652.
122/122 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0248
Epoch 32/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
Epoch 33/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
Epoch 34/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0124
Epoch 35/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
Epoch 36/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
Epoch 37/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
Epoch 38/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0124
Epoch 39/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
Epoch 40/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
Epoch 41/150
113/122 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.006202907767146826.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0124
Epoch 42/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0062
Epoch 43/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0062
Epoch 44/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0062
Epoch 45/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0062
Epoch 46/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0062
Epoch 47/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0062
Epoch 48/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0062
Epoch 49/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0062
Epoch 50/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0062
Epoch 51/150
 70/122 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.003101453883573413.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0062
Epoch 52/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0031
Epoch 53/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0031
Epoch 54/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0031
Epoch 55/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0031
Epoch 56/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0031
Epoch 57/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0031
Epoch 58/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0031
Epoch 59/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0031
Epoch 60/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0031
Epoch 61/150
 73/122 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0015507269417867064.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0031
Epoch 62/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0016
Epoch 63/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0016
Epoch 64/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0016
Epoch 65/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0016
Epoch 66/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0016
Epoch 67/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0016
Epoch 68/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0016
Epoch 69/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0016
Epoch 70/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0016
Epoch 71/150
 66/122 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0007753634708933532.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0016
Epoch 72/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.7536e-04
Epoch 73/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.7536e-04
Epoch 74/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.7536e-04
Epoch 75/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.7536e-04
Epoch 76/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.7536e-04
Epoch 77/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.7536e-04
Epoch 78/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.7536e-04
Epoch 79/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.7536e-04
Epoch 80/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.7536e-04
Epoch 81/150
 70/122 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0003876817354466766.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.7536e-04
Epoch 82/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.8768e-04
Epoch 83/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.8768e-04
Epoch 84/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.8768e-04
Epoch 85/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.8768e-04
Epoch 86/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.8768e-04
Epoch 87/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.8768e-04
Epoch 88/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.8768e-04
Epoch 89/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.8768e-04
Epoch 90/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.8768e-04
Epoch 91/150
 69/122 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0001938408677233383.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.8768e-04
Epoch 92/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.9384e-04
Epoch 93/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.9384e-04
Epoch 94/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.9384e-04
Epoch 95/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.9384e-04
Epoch 96/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.9384e-04
Epoch 97/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.9384e-04
Epoch 98/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.9384e-04
Epoch 99/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.9384e-04
Epoch 100/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.9384e-04
Epoch 101/150
110/122 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 101: ReduceLROnPlateau reducing learning rate to 9.692043386166915e-05.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.9384e-04
Epoch 102/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.6920e-05
Epoch 103/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.6920e-05
Epoch 104/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.6920e-05
Epoch 105/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.6920e-05
Epoch 106/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.6920e-05
Epoch 107/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.6920e-05
Epoch 108/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.6920e-05
Epoch 109/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.6920e-05
Epoch 110/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 9.6920e-05
Epoch 111/150
 69/122 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 111: ReduceLROnPlateau reducing learning rate to 4.8460216930834576e-05.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 9.6920e-05
Epoch 112/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.8460e-05
Epoch 113/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.8460e-05
Epoch 114/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.8460e-05
Epoch 115/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.8460e-05
Epoch 116/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.8460e-05
Epoch 117/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.8460e-05
Epoch 118/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.8460e-05
Epoch 119/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.8460e-05
Epoch 120/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.8460e-05
Epoch 121/150
 61/122 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 121: ReduceLROnPlateau reducing learning rate to 2.4230108465417288e-05.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.8460e-05
Epoch 122/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.4230e-05
Epoch 123/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.4230e-05
Epoch 124/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.4230e-05
Epoch 125/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.4230e-05
Epoch 126/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.4230e-05
Epoch 127/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.4230e-05
Epoch 128/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.4230e-05
Epoch 129/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.4230e-05
Epoch 130/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.4230e-05
Epoch 131/150
 69/122 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.0019
Epoch 131: ReduceLROnPlateau reducing learning rate to 1.2115054232708644e-05.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.4230e-05
Epoch 132/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.2115e-05
Epoch 133/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.2115e-05
Epoch 134/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.2115e-05
Epoch 135/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.2115e-05
Epoch 136/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.2115e-05
Epoch 137/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.2115e-05
Epoch 138/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.2115e-05
Epoch 139/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.2115e-05
Epoch 140/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.2115e-05
Epoch 141/150
104/122 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 141: ReduceLROnPlateau reducing learning rate to 1e-05.
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.2115e-05
Epoch 142/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 143/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 144/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 145/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 146/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 147/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 148/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 149/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 150/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_adam_0.09924652752900127LR_[30]HN_32BS_10P_val_mseM_150epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
122/122 [==============================] - 1s 3ms/step - loss: 0.0229 - mae: 0.0392 - mse: 0.0021 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0992
Epoch 2/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0992
Epoch 3/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0992
Epoch 4/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0992
Epoch 5/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0035 - val_mae: 0.0459 - val_mse: 0.0031 - lr: 0.0992
Epoch 6/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0024 - mae: 0.0388 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0992
Epoch 7/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0992
Epoch 8/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0992
Epoch 9/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0992
Epoch 10/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0408 - val_mse: 0.0024 - lr: 0.0992
Epoch 11/150
 65/122 [==============>...............] - ETA: 0s - loss: 0.0023 - mae: 0.0386 - mse: 0.0020
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.049623262137174606.
122/122 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0992
Epoch 12/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0496
Epoch 13/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0496
Epoch 14/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0496
Epoch 15/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0496
Epoch 16/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0496
Epoch 17/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0397 - val_mse: 0.0022 - lr: 0.0496
Epoch 18/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0496
Epoch 19/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0496
Epoch 20/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0496
Epoch 21/150
 65/122 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0373 - mse: 0.0019
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.024811631068587303.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0393 - val_mse: 0.0021 - lr: 0.0496
Epoch 22/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0248
Epoch 23/150
122/122 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0248
Epoch 24/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0248
Epoch 25/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0248
Epoch 26/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0248
Epoch 27/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0248
Epoch 28/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0248
Epoch 29/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0248
Epoch 30/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0248
Epoch 31/150
 70/122 [================>.............] - ETA: 0s - loss: 0.0020 - mae: 0.0382 - mse: 0.0019
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.012405815534293652.
122/122 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0248
Epoch 32/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0124
Epoch 33/150
 70/122 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
Epoch 34/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
Epoch 35/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0124
Epoch 36/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
Epoch 37/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
Epoch 38/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0124
Epoch 39/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
Epoch 40/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0124
Epoch 41/150
 67/122 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.006202907767146826.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
Epoch 42/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0062
Epoch 43/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0062
Epoch 44/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0062
Epoch 45/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0062
Epoch 46/150
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0062
Epoch 47/150
 71/122 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0021s). Check your callbacks.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0005s vs `on_train_batch_end` time: 0.0009s). Check your callbacks.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0013s). Check your callbacks.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0009s). Check your callbacks.
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124
122/122 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0124