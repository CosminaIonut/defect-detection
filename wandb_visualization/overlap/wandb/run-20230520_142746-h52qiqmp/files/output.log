[[6.44476848e-04 2.37706646e-04 4.52471996e-05 ... 2.02348273e-04
  3.19925716e-04 3.77142251e-04]
 [8.85885683e-04 3.26747059e-04 6.21959446e-05 ... 2.78144108e-04
  4.39763837e-04 5.18412604e-04]
 [1.59231949e-03 5.87305701e-04 1.11792996e-04 ... 4.99945190e-04
  7.90445702e-04 9.31811532e-04]
 ...
 [3.22998707e-02 1.32557450e-02 4.02004671e-03 ... 1.04794528e-02
  1.61381936e-02 1.92826274e-02]
 [4.01046158e-02 1.62200068e-02 4.63685277e-03 ... 1.27380589e-02
  1.98350931e-02 2.37787538e-02]
 [5.11503651e-02 2.04152102e-02 5.50979418e-03 ... 1.59345755e-02
  2.50671699e-02 3.01419452e-02]]
[[0.1  ]
 [0.1  ]
 [0.1  ]
 ...
 [0.098]
 [0.098]
 [0.098]]
(8818, 8)
(2205, 8)
(8818, 8, 1)
(8818, 1)
(2205, 8, 1)
(2205, 1)
Epoch 1/150
WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.
WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.

























1103/1103 [==============================] - ETA: 0s - loss: 0.0107 - mae: 0.0798 - mse: 0.0090
1103/1103 [==============================] - 62s 54ms/step - loss: 0.0107 - mae: 0.0798 - mse: 0.0090 - val_loss: 0.0100 - val_mae: 0.0835 - val_mse: 0.0100 - lr: 0.0690
Epoch 2/150
























1103/1103 [==============================] - ETA: 0s - loss: 0.0083 - mae: 0.0775 - mse: 0.0083
1103/1103 [==============================] - 59s 54ms/step - loss: 0.0083 - mae: 0.0775 - mse: 0.0083 - val_loss: 0.0082 - val_mae: 0.0780 - val_mse: 0.0082 - lr: 0.0690
Epoch 3/150

























1103/1103 [==============================] - 56s 50ms/step - loss: 0.0084 - mae: 0.0780 - mse: 0.0084 - val_loss: 0.0084 - val_mae: 0.0785 - val_mse: 0.0084 - lr: 0.0690
Epoch 4/150



























1103/1103 [==============================] - 57s 52ms/step - loss: 0.0084 - mae: 0.0784 - mse: 0.0084 - val_loss: 0.0091 - val_mae: 0.0805 - val_mse: 0.0091 - lr: 0.0690
Epoch 5/150



























1103/1103 [==============================] - ETA: 0s - loss: 0.0083 - mae: 0.0779 - mse: 0.0083
1103/1103 [==============================] - 61s 56ms/step - loss: 0.0083 - mae: 0.0779 - mse: 0.0083 - val_loss: 0.0081 - val_mae: 0.0776 - val_mse: 0.0081 - lr: 0.0690
Epoch 6/150

























1103/1103 [==============================] - 55s 50ms/step - loss: 0.0085 - mae: 0.0783 - mse: 0.0085 - val_loss: 0.0082 - val_mae: 0.0776 - val_mse: 0.0082 - lr: 0.0690
Epoch 7/150


























1103/1103 [==============================] - 56s 51ms/step - loss: 0.0084 - mae: 0.0783 - mse: 0.0084 - val_loss: 0.0102 - val_mae: 0.0840 - val_mse: 0.0102 - lr: 0.0690
Epoch 8/150


























1103/1103 [==============================] - ETA: 0s - loss: 0.0084 - mae: 0.0781 - mse: 0.0084
1103/1103 [==============================] - 61s 56ms/step - loss: 0.0084 - mae: 0.0781 - mse: 0.0084 - val_loss: 0.0076 - val_mae: 0.0759 - val_mse: 0.0076 - lr: 0.0690
Epoch 9/150

























1103/1103 [==============================] - 57s 51ms/step - loss: 0.0084 - mae: 0.0780 - mse: 0.0084 - val_loss: 0.0078 - val_mae: 0.0764 - val_mse: 0.0078 - lr: 0.0690
Epoch 10/150



























1103/1103 [==============================] - 56s 51ms/step - loss: 0.0085 - mae: 0.0784 - mse: 0.0085 - val_loss: 0.0085 - val_mae: 0.0789 - val_mse: 0.0085 - lr: 0.0690
Epoch 11/150



























1103/1103 [==============================] - 56s 51ms/step - loss: 0.0084 - mae: 0.0777 - mse: 0.0084 - val_loss: 0.0091 - val_mae: 0.0806 - val_mse: 0.0091 - lr: 0.0690
Epoch 12/150



























1103/1103 [==============================] - 57s 51ms/step - loss: 0.0085 - mae: 0.0782 - mse: 0.0085 - val_loss: 0.0079 - val_mae: 0.0769 - val_mse: 0.0079 - lr: 0.0690
Epoch 13/150



























1103/1103 [==============================] - 57s 51ms/step - loss: 0.0084 - mae: 0.0781 - mse: 0.0084 - val_loss: 0.0083 - val_mae: 0.0782 - val_mse: 0.0083 - lr: 0.0690
Epoch 14/150


























1103/1103 [==============================] - 56s 51ms/step - loss: 0.0083 - mae: 0.0778 - mse: 0.0083 - val_loss: 0.0094 - val_mae: 0.0818 - val_mse: 0.0094 - lr: 0.0690
Epoch 15/150



























1103/1103 [==============================] - 57s 52ms/step - loss: 0.0084 - mae: 0.0779 - mse: 0.0084 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - lr: 0.0690
Epoch 16/150


























1103/1103 [==============================] - 56s 51ms/step - loss: 0.0083 - mae: 0.0775 - mse: 0.0083 - val_loss: 0.0099 - val_mae: 0.0831 - val_mse: 0.0099 - lr: 0.0690
Epoch 17/150



























1103/1103 [==============================] - 57s 51ms/step - loss: 0.0083 - mae: 0.0775 - mse: 0.0083 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - lr: 0.0690
Epoch 18/150



























1103/1103 [==============================] - 57s 52ms/step - loss: 0.0085 - mae: 0.0783 - mse: 0.0085 - val_loss: 0.0085 - val_mae: 0.0787 - val_mse: 0.0085 - lr: 0.0690
Epoch 19/150



























1103/1103 [==============================] - 57s 52ms/step - loss: 0.0084 - mae: 0.0777 - mse: 0.0084 - val_loss: 0.0085 - val_mae: 0.0786 - val_mse: 0.0085 - lr: 0.0690
Epoch 20/150



























1103/1103 [==============================] - 58s 52ms/step - loss: 0.0085 - mae: 0.0786 - mse: 0.0085 - val_loss: 0.0090 - val_mae: 0.0803 - val_mse: 0.0090 - lr: 0.0690
Epoch 21/150



























1103/1103 [==============================] - 57s 51ms/step - loss: 0.0084 - mae: 0.0782 - mse: 0.0084 - val_loss: 0.0084 - val_mae: 0.0782 - val_mse: 0.0084 - lr: 0.0690
Epoch 22/150



























1103/1103 [==============================] - 57s 52ms/step - loss: 0.0084 - mae: 0.0783 - mse: 0.0084 - val_loss: 0.0084 - val_mae: 0.0785 - val_mse: 0.0084 - lr: 0.0690
Epoch 23/150



























1103/1103 [==============================] - ETA: 0s - loss: 0.0084 - mae: 0.0781 - mse: 0.0084
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.03448000177741051.
1103/1103 [==============================] - 57s 51ms/step - loss: 0.0084 - mae: 0.0781 - mse: 0.0084 - val_loss: 0.0109 - val_mae: 0.0864 - val_mse: 0.0109 - lr: 0.0690
Epoch 24/150



























1103/1103 [==============================] - 57s 51ms/step - loss: 0.0081 - mae: 0.0768 - mse: 0.0081 - val_loss: 0.0082 - val_mae: 0.0775 - val_mse: 0.0082 - lr: 0.0345
Epoch 25/150



























1103/1103 [==============================] - 58s 52ms/step - loss: 0.0080 - mae: 0.0766 - mse: 0.0080 - val_loss: 0.0076 - val_mae: 0.0760 - val_mse: 0.0076 - lr: 0.0345
Epoch 26/150



























1103/1103 [==============================] - 58s 52ms/step - loss: 0.0081 - mae: 0.0771 - mse: 0.0081 - val_loss: 0.0096 - val_mae: 0.0820 - val_mse: 0.0096 - lr: 0.0345
Epoch 27/150


























1103/1103 [==============================] - 57s 51ms/step - loss: 0.0080 - mae: 0.0768 - mse: 0.0080 - val_loss: 0.0079 - val_mae: 0.0767 - val_mse: 0.0079 - lr: 0.0345
Epoch 28/150



























1103/1103 [==============================] - 57s 52ms/step - loss: 0.0081 - mae: 0.0771 - mse: 0.0081 - val_loss: 0.0077 - val_mae: 0.0760 - val_mse: 0.0077 - lr: 0.0345
Epoch 29/150



























1103/1103 [==============================] - 56s 51ms/step - loss: 0.0081 - mae: 0.0773 - mse: 0.0081 - val_loss: 0.0077 - val_mae: 0.0762 - val_mse: 0.0077 - lr: 0.0345
Epoch 30/150



























1103/1103 [==============================] - 57s 51ms/step - loss: 0.0079 - mae: 0.0764 - mse: 0.0079 - val_loss: 0.0077 - val_mae: 0.0760 - val_mse: 0.0077 - lr: 0.0345
Epoch 31/150



























1103/1103 [==============================] - 58s 52ms/step - loss: 0.0081 - mae: 0.0771 - mse: 0.0081 - val_loss: 0.0089 - val_mae: 0.0800 - val_mse: 0.0089 - lr: 0.0345
Epoch 32/150


























1103/1103 [==============================] - 56s 51ms/step - loss: 0.0081 - mae: 0.0771 - mse: 0.0081 - val_loss: 0.0077 - val_mae: 0.0761 - val_mse: 0.0077 - lr: 0.0345
Epoch 33/150



























1103/1103 [==============================] - 57s 52ms/step - loss: 0.0080 - mae: 0.0770 - mse: 0.0080 - val_loss: 0.0083 - val_mae: 0.0782 - val_mse: 0.0083 - lr: 0.0345
Epoch 34/150



























1103/1103 [==============================] - 56s 51ms/step - loss: 0.0080 - mae: 0.0769 - mse: 0.0080 - val_loss: 0.0078 - val_mae: 0.0766 - val_mse: 0.0078 - lr: 0.0345
Epoch 35/150



























1103/1103 [==============================] - 57s 52ms/step - loss: 0.0080 - mae: 0.0769 - mse: 0.0080 - val_loss: 0.0093 - val_mae: 0.0813 - val_mse: 0.0093 - lr: 0.0345
Epoch 36/150



























1103/1103 [==============================] - 58s 52ms/step - loss: 0.0080 - mae: 0.0767 - mse: 0.0080 - val_loss: 0.0128 - val_mae: 0.0926 - val_mse: 0.0128 - lr: 0.0345
Epoch 37/150
  60/1103 [>.............................] - ETA: 49s - loss: 0.0080 - mae: 0.0754 - mse: 0.0080
 104/1103 [=>............................] - ETA: 46s - loss: 0.0079 - mae: 0.0753 - mse: 0.0079
 136/1103 [==>...........................] - ETA: 45s - loss: 0.0080 - mae: 0.0756 - mse: 0.0080
 180/1103 [===>..........................] - ETA: 43s - loss: 0.0079 - mae: 0.0754 - mse: 0.0079
 223/1103 [=====>........................] - ETA: 41s - loss: 0.0081 - mae: 0.0766 - mse: 0.0081
 268/1103 [======>.......................] - ETA: 39s - loss: 0.0081 - mae: 0.0766 - mse: 0.0081
 311/1103 [=======>......................] - ETA: 37s - loss: 0.0081 - mae: 0.0770 - mse: 0.0081
 355/1103 [========>.....................] - ETA: 34s - loss: 0.0081 - mae: 0.0771 - mse: 0.0081
 400/1103 [=========>....................] - ETA: 32s - loss: 0.0082 - mae: 0.0775 - mse: 0.0082
 443/1103 [===========>..................] - ETA: 30s - loss: 0.0081 - mae: 0.0770 - mse: 0.0081
 481/1103 [============>.................] - ETA: 29s - loss: 0.0080 - mae: 0.0766 - mse: 0.0080
 514/1103 [============>.................] - ETA: 28s - loss: 0.0080 - mae: 0.0768 - mse: 0.0080
 556/1103 [==============>...............] - ETA: 26s - loss: 0.0080 - mae: 0.0767 - mse: 0.0080
 600/1103 [===============>..............] - ETA: 24s - loss: 0.0081 - mae: 0.0771 - mse: 0.0081
 644/1103 [================>.............] - ETA: 22s - loss: 0.0081 - mae: 0.0771 - mse: 0.0081
 687/1103 [=================>............] - ETA: 19s - loss: 0.0080 - mae: 0.0769 - mse: 0.0080
 732/1103 [==================>...........] - ETA: 17s - loss: 0.0080 - mae: 0.0766 - mse: 0.0080
 775/1103 [====================>.........] - ETA: 15s - loss: 0.0080 - mae: 0.0768 - mse: 0.0080
 818/1103 [=====================>........] - ETA: 13s - loss: 0.0079 - mae: 0.0765 - mse: 0.0079
 857/1103 [======================>.......] - ETA: 11s - loss: 0.0080 - mae: 0.0767 - mse: 0.0080
 884/1103 [=======================>......] - ETA: 10s - loss: 0.0080 - mae: 0.0769 - mse: 0.0080
 925/1103 [========================>.....] - ETA: 8s - loss: 0.0080 - mae: 0.0770 - mse: 0.0080
 969/1103 [=========================>....] - ETA: 6s - loss: 0.0081 - mae: 0.0770 - mse: 0.0081
1013/1103 [==========================>...] - ETA: 4s - loss: 0.0080 - mae: 0.0769 - mse: 0.0080
1057/1103 [===========================>..] - ETA: 2s - loss: 0.0080 - mae: 0.0769 - mse: 0.0080
1101/1103 [============================>.] - ETA: 0s - loss: 0.0080 - mae: 0.0769 - mse: 0.0080
1103/1103 [==============================] - ETA: 0s - loss: 0.0080 - mae: 0.0769 - mse: 0.0080
  20/1103 [..............................] - ETA: 52s - loss: 0.0076 - mae: 0.0741 - mse: 0.0076.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
  58/1103 [>.............................] - ETA: 55s - loss: 0.0074 - mae: 0.0737 - mse: 0.0074.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 100/1103 [=>............................] - ETA: 50s - loss: 0.0076 - mae: 0.0749 - mse: 0.0076.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 143/1103 [==>...........................] - ETA: 47s - loss: 0.0079 - mae: 0.0766 - mse: 0.0079.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 187/1103 [====>.........................] - ETA: 44s - loss: 0.0079 - mae: 0.0766 - mse: 0.0079.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 232/1103 [=====>........................] - ETA: 42s - loss: 0.0078 - mae: 0.0762 - mse: 0.0078.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 275/1103 [======>.......................] - ETA: 39s - loss: 0.0079 - mae: 0.0766 - mse: 0.0079.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 312/1103 [=======>......................] - ETA: 38s - loss: 0.0079 - mae: 0.0767 - mse: 0.0079.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 351/1103 [========>.....................] - ETA: 37s - loss: 0.0080 - mae: 0.0768 - mse: 0.0080.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 396/1103 [=========>....................] - ETA: 34s - loss: 0.0079 - mae: 0.0763 - mse: 0.0079.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 439/1103 [==========>...................] - ETA: 32s - loss: 0.0079 - mae: 0.0762 - mse: 0.0079.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 484/1103 [============>.................] - ETA: 30s - loss: 0.0079 - mae: 0.0764 - mse: 0.0079.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 517/1103 [=============>................] - ETA: 28s - loss: 0.0080 - mae: 0.0766 - mse: 0.0080.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 560/1103 [==============>...............] - ETA: 26s - loss: 0.0080 - mae: 0.0766 - mse: 0.0080.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 598/1103 [===============>..............] - ETA: 24s - loss: 0.0080 - mae: 0.0766 - mse: 0.0080.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 633/1103 [================>.............] - ETA: 23s - loss: 0.0080 - mae: 0.0765 - mse: 0.0080.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 677/1103 [=================>............] - ETA: 20s - loss: 0.0080 - mae: 0.0767 - mse: 0.0080.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 721/1103 [==================>...........] - ETA: 18s - loss: 0.0080 - mae: 0.0768 - mse: 0.0080.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 764/1103 [===================>..........] - ETA: 16s - loss: 0.0080 - mae: 0.0767 - mse: 0.0080.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 809/1103 [=====================>........] - ETA: 14s - loss: 0.0080 - mae: 0.0768 - mse: 0.0080.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 853/1103 [======================>.......] - ETA: 12s - loss: 0.0080 - mae: 0.0767 - mse: 0.0080.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 896/1103 [=======================>......] - ETA: 10s - loss: 0.0080 - mae: 0.0766 - mse: 0.0080.0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 939/1103 [========================>.....] - ETA: 7s - loss: 0.0080 - mae: 0.0766 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 973/1103 [=========================>....] - ETA: 6s - loss: 0.0080 - mae: 0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 973/1103 [=========================>....] - ETA: 6s - loss: 0.0080 - mae: 0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 973/1103 [=========================>....] - ETA: 6s - loss: 0.0080 - mae: 0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
 973/1103 [=========================>....] - ETA: 6s - loss: 0.0080 - mae: 0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 39/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 40/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 41/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 42/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 43/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 44/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 45/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 46/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 47/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 48/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 49/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 50/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 51/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 52/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 53/150duceLROnPlateau reducing learning rate to 0.017240000888705254.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 54/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 55/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 56/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 57/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 58/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 59/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 60/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 61/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 62/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 63/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 64/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 65/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 66/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 67/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 68/150duceLROnPlateau reducing learning rate to 0.008620000444352627.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 69/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 70/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 71/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 72/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 73/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 74/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 75/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 76/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 77/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 78/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 79/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 80/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 81/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 82/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 83/150duceLROnPlateau reducing learning rate to 0.004310000222176313.0.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 84/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 85/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 86/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 87/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 88/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 89/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 90/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 91/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 92/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 93/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 94/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 95/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 96/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 97/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98/150duceLROnPlateau reducing learning rate to 0.0021550001110881567..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 99/150duceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 100/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 101/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 102/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 103/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 104/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 105/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 106/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 107/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 108/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 109/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 110/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 111/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 112/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 113/150uceLROnPlateau reducing learning rate to 0.0010775000555440784..0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 114/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 115/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 116/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 118/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 120/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 121/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 122/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 123/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 124/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 125/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 127/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0005387500277720392.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 129/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 130/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 132/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 133/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 134/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 135/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 136/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 137/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 138/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 139/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 140/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 141/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 142/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 143/150duceLROnPlateau reducing learning rate to 0.0002693750138860196.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 144/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 145/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 146/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 147/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 148/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 149/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
Epoch 150/150duceLROnPlateau reducing learning rate to 0.0001346875069430098.0767 - mse: 0.0080 .0080 - val_loss: 0.0092 - val_mae: 0.0809 - val_mse: 0.0092 - lr: 0.0345
>Saved ../../trained_models/RNN/models_segments_overlap-regulizers0.001-LSTM-BI_adam_0.06896LR_[10]HL8DU_8BS_['sigmoid', 'tanh', 'tanh']_15P_val_mseM_8DU_150epochs/model_4.h5
>Saved ../../trained_models/RNN/models_segments_overlap-regulizers0.001-LSTM-BI_adam_0.06896LR_[10]HL8DU_8BS_['sigmoid', 'tanh', 'tanh']_15P_val_mseM_8DU_150epochs/model_4.h5