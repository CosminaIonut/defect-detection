Epoch 1/200
 1/33 [..............................] - ETA: 7s - loss: 0.7970 - mae: 0.4503 - mse: 0.2047
33/33 [==============================] - 1s 22ms/step - loss: 0.1905 - mae: 0.0945 - mse: 0.0239 - val_loss: 0.0176 - val_mae: 0.0380 - val_mse: 0.0020 - lr: 0.0283
Epoch 2/200
 1/33 [..............................] - ETA: 0s - loss: 0.0175 - mae: 0.0370 - mse: 0.0019
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
33/33 [==============================] - 1s 20ms/step - loss: 0.0099 - mae: 0.0414 - mse: 0.0022 - val_loss: 0.0052 - val_mae: 0.0406 - val_mse: 0.0021 - lr: 0.0283
Epoch 3/200
 1/33 [..............................] - ETA: 0s - loss: 0.0051 - mae: 0.0387 - mse: 0.0019
33/33 [==============================] - 1s 22ms/step - loss: 0.0039 - mae: 0.0394 - mse: 0.0020 - val_loss: 0.0032 - val_mae: 0.0398 - val_mse: 0.0021 - lr: 0.0283
Epoch 4/200
33/33 [==============================] - 1s 20ms/step - loss: 0.0029 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0283
Epoch 5/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0025 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0027 - val_mae: 0.0428 - val_mse: 0.0023 - lr: 0.0283
Epoch 6/200
 1/33 [..............................] - ETA: 0s - loss: 0.0028 - mae: 0.0441 - mse: 0.0024
33/33 [==============================] - 1s 27ms/step - loss: 0.0024 - mae: 0.0377 - mse: 0.0020 - val_loss: 0.0024 - val_mae: 0.0379 - val_mse: 0.0020 - lr: 0.0283
Epoch 7/200
 1/33 [..............................] - ETA: 0s - loss: 0.0022 - mae: 0.0356 - mse: 0.0018
33/33 [==============================] - 1s 22ms/step - loss: 0.0023 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0367 - val_mse: 0.0020 - lr: 0.0283
Epoch 8/200
 1/33 [..............................] - ETA: 0s - loss: 0.0021 - mae: 0.0339 - mse: 0.0017
33/33 [==============================] - 1s 21ms/step - loss: 0.0023 - mae: 0.0376 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0367 - val_mse: 0.0020 - lr: 0.0283
Epoch 9/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0374 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0403 - val_mse: 0.0021 - lr: 0.0283
Epoch 10/200
 1/33 [..............................] - ETA: 0s - loss: 0.0025 - mae: 0.0419 - mse: 0.0022
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
33/33 [==============================] - 1s 20ms/step - loss: 0.0022 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0283
Epoch 11/200
 1/33 [..............................] - ETA: 0s - loss: 0.0021 - mae: 0.0368 - mse: 0.0018
33/33 [==============================] - 1s 21ms/step - loss: 0.0021 - mae: 0.0369 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0372 - val_mse: 0.0019 - lr: 0.0283
Epoch 12/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0378 - mse: 0.0021 - val_loss: 0.0024 - val_mae: 0.0357 - val_mse: 0.0021 - lr: 0.0283
Epoch 13/200
33/33 [==============================] - 1s 22ms/step - loss: 0.0021 - mae: 0.0368 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0363 - val_mse: 0.0019 - lr: 0.0283
Epoch 14/200
 1/33 [..............................] - ETA: 0s - loss: 0.0020 - mae: 0.0354 - mse: 0.0018
33/33 [==============================] - 1s 20ms/step - loss: 0.0021 - mae: 0.0365 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 0.0283
Epoch 15/200
 1/33 [..............................] - ETA: 0s - loss: 0.0020 - mae: 0.0359 - mse: 0.0018
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.014168468303978443.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
33/33 [==============================] - 1s 21ms/step - loss: 0.0020 - mae: 0.0363 - mse: 0.0018 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0283
Epoch 16/200
 1/33 [..............................] - ETA: 0s - loss: 0.0021 - mae: 0.0380 - mse: 0.0019
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
33/33 [==============================] - 1s 20ms/step - loss: 0.0020 - mae: 0.0361 - mse: 0.0018 - val_loss: 0.0020 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 0.0142
Epoch 17/200
33/33 [==============================] - 1s 22ms/step - loss: 0.0020 - mae: 0.0359 - mse: 0.0018 - val_loss: 0.0020 - val_mae: 0.0371 - val_mse: 0.0019 - lr: 0.0142
Epoch 18/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0360 - mse: 0.0018 - val_loss: 0.0021 - val_mae: 0.0351 - val_mse: 0.0019 - lr: 0.0142
Epoch 19/200
 1/33 [..............................] - ETA: 0s - loss: 0.0019 - mae: 0.0334 - mse: 0.0017
33/33 [==============================] - 1s 21ms/step - loss: 0.0020 - mae: 0.0357 - mse: 0.0018 - val_loss: 0.0020 - val_mae: 0.0358 - val_mse: 0.0018 - lr: 0.0142
Epoch 20/200
 1/33 [..............................] - ETA: 0s - loss: 0.0017 - mae: 0.0335 - mse: 0.0016
33/33 [==============================] - 1s 27ms/step - loss: 0.0020 - mae: 0.0356 - mse: 0.0018 - val_loss: 0.0020 - val_mae: 0.0363 - val_mse: 0.0018 - lr: 0.0142
Epoch 21/200
 1/33 [..............................] - ETA: 0s - loss: 0.0019 - mae: 0.0359 - mse: 0.0018
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.007084234151989222.
33/33 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0356 - mse: 0.0018 - val_loss: 0.0020 - val_mae: 0.0352 - val_mse: 0.0018 - lr: 0.0142
Epoch 22/200
 1/33 [..............................] - ETA: 0s - loss: 0.0020 - mae: 0.0359 - mse: 0.0018
33/33 [==============================] - 1s 24ms/step - loss: 0.0019 - mae: 0.0353 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0362 - val_mse: 0.0018 - lr: 0.0071
Epoch 23/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0353 - val_mse: 0.0018 - lr: 0.0071
Epoch 24/200
 1/33 [..............................] - ETA: 0s - loss: 0.0019 - mae: 0.0348 - mse: 0.0018
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
33/33 [==============================] - 1s 22ms/step - loss: 0.0019 - mae: 0.0353 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0357 - val_mse: 0.0018 - lr: 0.0071
Epoch 25/200
 1/33 [..............................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.0017
33/33 [==============================] - 1s 21ms/step - loss: 0.0019 - mae: 0.0352 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0355 - val_mse: 0.0018 - lr: 0.0071
Epoch 26/200
33/33 [==============================] - 1s 21ms/step - loss: 0.0019 - mae: 0.0352 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0365 - val_mse: 0.0018 - lr: 0.0071
Epoch 27/200
 1/33 [..............................] - ETA: 0s - loss: 0.0019 - mae: 0.0364 - mse: 0.0018
33/33 [==============================] - 1s 20ms/step - loss: 0.0019 - mae: 0.0352 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0357 - val_mse: 0.0018 - lr: 0.0071
Epoch 28/200
 1/33 [..............................] - ETA: 0s - loss: 0.0017 - mae: 0.0326 - mse: 0.0015
33/33 [==============================] - 1s 20ms/step - loss: 0.0019 - mae: 0.0352 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0018 - lr: 0.0071
Epoch 29/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0350 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0371 - val_mse: 0.0018 - lr: 0.0071
Epoch 30/200
 1/33 [..............................] - ETA: 0s - loss: 0.0018 - mae: 0.0363 - mse: 0.0017
33/33 [==============================] - 1s 21ms/step - loss: 0.0019 - mae: 0.0352 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0365 - val_mse: 0.0018 - lr: 0.0071
Epoch 31/200
 1/33 [..............................] - ETA: 0s - loss: 0.0019 - mae: 0.0354 - mse: 0.0017
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.003542117075994611.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
33/33 [==============================] - 1s 22ms/step - loss: 0.0019 - mae: 0.0351 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0363 - val_mse: 0.0018 - lr: 0.0071
Epoch 32/200
 1/33 [..............................] - ETA: 0s - loss: 0.0019 - mae: 0.0364 - mse: 0.0018
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
33/33 [==============================] - 1s 20ms/step - loss: 0.0018 - mae: 0.0352 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0018 - lr: 0.0035
Epoch 33/200
 1/33 [..............................] - ETA: 0s - loss: 0.0017 - mae: 0.0339 - mse: 0.0016
33/33 [==============================] - 1s 21ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 0.0035
Epoch 34/200
33/33 [==============================] - 1s 27ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0359 - val_mse: 0.0018 - lr: 0.0035
Epoch 35/200
 1/33 [..............................] - ETA: 0s - loss: 0.0020 - mae: 0.0373 - mse: 0.0019
33/33 [==============================] - 1s 19ms/step - loss: 0.0018 - mae: 0.0350 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0358 - val_mse: 0.0017 - lr: 0.0035
Epoch 36/200
 1/33 [..............................] - ETA: 0s - loss: 0.0017 - mae: 0.0335 - mse: 0.0016
Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0017710585379973054.
33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0349 - val_mse: 0.0018 - lr: 0.0035
Epoch 37/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0363 - val_mse: 0.0018 - lr: 0.0018
Epoch 38/200
 1/33 [..............................] - ETA: 0s - loss: 0.0018 - mae: 0.0356 - mse: 0.0017
33/33 [==============================] - 1s 21ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 0.0018
Epoch 39/200
 1/33 [..............................] - ETA: 0s - loss: 0.0017 - mae: 0.0332 - mse: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
33/33 [==============================] - 1s 21ms/step - loss: 0.0018 - mae: 0.0350 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0355 - val_mse: 0.0017 - lr: 0.0018
Epoch 40/200
 1/33 [..............................] - ETA: 0s - loss: 0.0017 - mae: 0.0349 - mse: 0.0016
33/33 [==============================] - 1s 24ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0357 - val_mse: 0.0017 - lr: 0.0018
Epoch 41/200
 1/33 [..............................] - ETA: 0s - loss: 0.0019 - mae: 0.0362 - mse: 0.0018
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0008855292689986527.
33/33 [==============================] - 1s 20ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0358 - val_mse: 0.0017 - lr: 0.0018
Epoch 42/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0354 - val_mse: 0.0017 - lr: 8.8553e-04
Epoch 43/200
 1/33 [..............................] - ETA: 0s - loss: 0.0018 - mae: 0.0347 - mse: 0.0017
33/33 [==============================] - 1s 20ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 8.8553e-04
Epoch 44/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0358 - val_mse: 0.0017 - lr: 8.8553e-04
Epoch 45/200
 1/33 [..............................] - ETA: 0s - loss: 0.0019 - mae: 0.0357 - mse: 0.0018
33/33 [==============================] - 1s 21ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0355 - val_mse: 0.0017 - lr: 8.8553e-04
Epoch 46/200
 1/33 [..............................] - ETA: 0s - loss: 0.0017 - mae: 0.0325 - mse: 0.0015
Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00044276463449932635.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
33/33 [==============================] - 1s 20ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0355 - val_mse: 0.0017 - lr: 8.8553e-04
Epoch 47/200
 1/33 [..............................] - ETA: 0s - loss: 0.0018 - mae: 0.0356 - mse: 0.0017
33/33 [==============================] - 1s 20ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0357 - val_mse: 0.0017 - lr: 4.4276e-04
Epoch 48/200
33/33 [==============================] - 1s 21ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 4.4276e-04
Epoch 49/200
 1/33 [..............................] - ETA: 0s - loss: 0.0016 - mae: 0.0329 - mse: 0.0015
33/33 [==============================] - 2s 62ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0357 - val_mse: 0.0017 - lr: 4.4276e-04
Epoch 50/200
 1/33 [..............................] - ETA: 0s - loss: 0.0018 - mae: 0.0339 - mse: 0.0017
33/33 [==============================] - 1s 20ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0357 - val_mse: 0.0017 - lr: 4.4276e-04
Epoch 51/200
 1/33 [..............................] - ETA: 0s - loss: 0.0018 - mae: 0.0345 - mse: 0.0017
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.00022138231724966317.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
33/33 [==============================] - 1s 23ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 4.4276e-04
Epoch 52/200
 1/33 [..............................] - ETA: 0s - loss: 0.0018 - mae: 0.0347 - mse: 0.0017
33/33 [==============================] - 1s 21ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0357 - val_mse: 0.0017 - lr: 2.2138e-04
Epoch 53/200
 1/33 [..............................] - ETA: 0s - loss: 0.0019 - mae: 0.0367 - mse: 0.0018
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
33/33 [==============================] - 1s 21ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0357 - val_mse: 0.0017 - lr: 2.2138e-04
Epoch 54/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0355 - val_mse: 0.0017 - lr: 2.2138e-04
Epoch 55/200
 1/33 [..............................] - ETA: 0s - loss: 0.0018 - mae: 0.0345 - mse: 0.0016
33/33 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0358 - val_mse: 0.0017 - lr: 2.2138e-044
Epoch 56/200
 1/33 [..............................] - ETA: 0s - loss: 0.0018 - mae: 0.0353 - mse: 0.0017
Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00011069115862483159.
33/33 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0358 - val_mse: 0.0017 - lr: 2.2138e-044
Epoch 57/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0350 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0355 - val_mse: 0.0017 - lr: 1.1069e-04
Epoch 58/200
33/33 [==============================] - 1s 24ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.1069e-04
Epoch 59/200
 1/33 [..............................] - ETA: 0s - loss: 0.0019 - mae: 0.0352 - mse: 0.0017
33/33 [==============================] - 1s 24ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.1069e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
33/33 [==============================] - 1s 24ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.1069e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
33/33 [==============================] - 1s 24ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.1069e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
33/33 [==============================] - 1s 20ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.1069e-04
33/33 [==============================] - 1s 20ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.1069e-04
33/33 [==============================] - 1s 20ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.1069e-04
33/33 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 5.5346e-054
33/33 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 5.5346e-054
33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 2.7673e-054
33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 2.7673e-054
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 2.7673e-054
33/33 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 2.7673e-054
33/33 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 2.7673e-054
33/33 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 2.7673e-054
 1/33 [..............................] - ETA: 0s - loss: 0.0016 - mae: 0.0326 - mse: 0.00150017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 2.7673e-054
 1/33 [..............................] - ETA: 0s - loss: 0.0016 - mae: 0.0326 - mse: 0.00150017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 2.7673e-054
33/33 [==============================] - 1s 21ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.3836e-05
33/33 [==============================] - 1s 21ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.3836e-05
 1/33 [..............................] - ETA: 0s - loss: 0.0019 - mae: 0.0361 - mse: 0.0017.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.3836e-05
 1/33 [..............................] - ETA: 0s - loss: 0.0019 - mae: 0.0361 - mse: 0.0017.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.3836e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
33/33 [==============================] - 1s 22ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-05
33/33 [==============================] - 1s 22ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
33/33 [==============================] - 1s 22ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-05
33/33 [==============================] - 1s 22ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-05
33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
33/33 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
 1/33 [..............................] - ETA: 0s - loss: 0.0019 - mae: 0.0358 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
 1/33 [..............................] - ETA: 0s - loss: 0.0019 - mae: 0.0358 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
33/33 [==============================] - 1s 22ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-05
33/33 [==============================] - 1s 22ms/step - loss: 0.0018 - mae: 0.0349 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-05
33/33 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
33/33 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
33/33 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
33/33 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 99/200=========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 99/200=========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 103/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 103/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
Epoch 103/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
Epoch 106/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 106/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 110/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 112/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 112/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
Epoch 112/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
Epoch 112/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
Epoch 112/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 117/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 117/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
Epoch 120/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 120/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 124/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 126/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 126/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 128/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 128/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 131/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 131/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 134/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 134/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 136/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 136/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
Epoch 140/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 142/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 142/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 145/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 145/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 148/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 148/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
Epoch 148/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
Epoch 153/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 153/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 156/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 156/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 158/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 158/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
Epoch 158/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
Epoch 158/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
Epoch 163/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 163/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 166/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 166/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 166/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 170/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 170/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 172/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 172/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
Epoch 175/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 175/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
Epoch 175/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 179/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 179/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
Epoch 179/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 184/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 184/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 186/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 186/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 190/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 190/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
Epoch 190/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
Epoch 190/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 190/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
Epoch 190/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 196/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 196/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 199/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 199/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_142552-21qbuwxq\files\model-best)... Done. 0.0s
Epoch 199/200========================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
Epoch 47/200duceLROnPlateau reducing learning rate to 0.00044276463449932635.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0904 - val_mse: 0.0097 - lr: 8.8553e-04
Epoch 44/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0902 - val_mse: 0.0097 - lr: 4.4276e-04
Epoch 45/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0904 - val_mse: 0.0097 - lr: 4.4276e-04
Epoch 46/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 4.4276e-04
Epoch 47/200duceLROnPlateau reducing learning rate to 0.00044276463449932635.0348 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0356 - val_mse: 0.0017 - lr: 1.0000e-055
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0904 - val_mse: 0.0097 - lr: 4.4276e-04
Epoch 48/200
 1/44 [..............................] - ETA: 0s - loss: 0.0098 - mae: 0.0901 - mse: 0.0096
Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00022138231724966317.
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0904 - val_mse: 0.0097 - lr: 4.4276e-04
Epoch 49/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0902 - val_mse: 0.0097 - lr: 2.2138e-04
Epoch 50/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0902 - val_mse: 0.0097 - lr: 2.2138e-04
Epoch 51/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 2.2138e-04
Epoch 52/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 2.2138e-04
Epoch 53/200
 1/44 [..............................] - ETA: 0s - loss: 0.0099 - mae: 0.0915 - mse: 0.0098
Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00011069115862483159.
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0904 - val_mse: 0.0097 - lr: 2.2138e-04
Epoch 54/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.1069e-04
Epoch 55/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.1069e-04
Epoch 56/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.1069e-04
Epoch 57/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.1069e-04
Epoch 58/200
 1/44 [..............................] - ETA: 0s - loss: 0.0094 - mae: 0.0882 - mse: 0.0093
Epoch 58: ReduceLROnPlateau reducing learning rate to 5.5345579312415794e-05.
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.1069e-04
Epoch 59/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 5.5346e-05
Epoch 60/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 5.5346e-05
Epoch 61/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 5.5346e-05
Epoch 62/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 5.5346e-05
Epoch 63/200
 1/44 [..............................] - ETA: 0s - loss: 0.0097 - mae: 0.0891 - mse: 0.0095
Epoch 63: ReduceLROnPlateau reducing learning rate to 2.7672789656207897e-05.
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 5.5346e-05
Epoch 64/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 2.7673e-05
Epoch 65/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 2.7673e-05
Epoch 66/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 2.7673e-05
Epoch 67/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 2.7673e-05
Epoch 68/200
 1/44 [..............................] - ETA: 0s - loss: 0.0099 - mae: 0.0906 - mse: 0.0097
Epoch 68: ReduceLROnPlateau reducing learning rate to 1.3836394828103948e-05.
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 2.7673e-05
Epoch 69/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.3836e-05
Epoch 70/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.3836e-05
Epoch 71/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.3836e-05
Epoch 72/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.3836e-05
Epoch 73/200
 1/44 [..............................] - ETA: 0s - loss: 0.0098 - mae: 0.0888 - mse: 0.0096
Epoch 73: ReduceLROnPlateau reducing learning rate to 1e-05.
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.3836e-05
Epoch 74/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 75/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 76/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 77/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 78/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 79/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 80/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 81/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 82/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 83/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 84/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 85/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 86/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 87/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 88/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 89/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 90/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 91/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 92/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 93/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 94/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 95/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 96/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 97/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 98/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 99/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 100/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 101/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 102/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 103/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 104/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 105/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 106/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 107/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 108/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 109/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 110/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 111/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 112/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 113/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 114/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 115/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 116/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 117/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 118/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 119/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 120/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 121/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 122/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 123/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 124/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 125/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 126/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 127/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 128/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 129/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 130/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 131/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 132/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 133/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 134/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 135/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 136/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 137/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 138/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 139/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 140/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 141/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 142/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 143/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 144/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 145/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 146/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 147/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 148/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 149/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 150/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 151/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 152/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 153/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 154/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 155/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 156/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 157/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 158/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 159/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 160/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 161/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 162/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 163/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 164/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 165/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 166/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 167/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 168/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 169/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 170/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 171/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 172/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 173/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 174/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 175/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 176/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 177/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 178/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 179/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 180/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 181/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 182/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 183/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 184/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 185/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 186/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 187/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 188/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 189/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 190/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 191/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 192/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 193/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 194/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0904 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 195/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 196/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 197/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 198/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 199/200
44/44 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
Epoch 200/200
44/44 [==============================] - 0s 1ms/step - loss: 0.0099 - mae: 0.0903 - mse: 0.0097 - val_loss: 0.0099 - val_mae: 0.0903 - val_mse: 0.0097 - lr: 1.0000e-05
>Saved ../trained_models/severity/models__adam_0.02833693606572554LR_[33]HN_120BS_5P_val_lossM_200epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/200
33/33 [==============================] - 0s 4ms/step - loss: 0.2184 - mae: 0.1678 - mse: 0.0358 - val_loss: 0.0345 - val_mae: 0.1532 - val_mse: 0.0247 - lr: 0.0283
Epoch 2/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0294 - mae: 0.1525 - mse: 0.0245 - val_loss: 0.0260 - val_mae: 0.1532 - val_mse: 0.0247 - lr: 0.0283
Epoch 3/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0252 - mae: 0.1525 - mse: 0.0245 - val_loss: 0.0252 - val_mae: 0.1532 - val_mse: 0.0248 - lr: 0.0283
Epoch 4/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0249 - mae: 0.1525 - mse: 0.0245 - val_loss: 0.0250 - val_mae: 0.1532 - val_mse: 0.0247 - lr: 0.0283
Epoch 5/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0248 - mae: 0.1525 - mse: 0.0245 - val_loss: 0.0249 - val_mae: 0.1532 - val_mse: 0.0247 - lr: 0.0283
Epoch 6/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0247 - mae: 0.1525 - mse: 0.0245 - val_loss: 0.0249 - val_mae: 0.1532 - val_mse: 0.0247 - lr: 0.0283
Epoch 7/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0247 - mae: 0.1525 - mse: 0.0245 - val_loss: 0.0249 - val_mae: 0.1532 - val_mse: 0.0247 - lr: 0.0283
Epoch 8/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0246 - mae: 0.1525 - mse: 0.0245 - val_loss: 0.0248 - val_mae: 0.1532 - val_mse: 0.0247 - lr: 0.0283
Epoch 9/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0247 - mae: 0.1525 - mse: 0.0245 - val_loss: 0.0248 - val_mae: 0.1532 - val_mse: 0.0246 - lr: 0.0283
Epoch 10/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0247 - mae: 0.1525 - mse: 0.0245 - val_loss: 0.0248 - val_mae: 0.1532 - val_mse: 0.0247 - lr: 0.0283
Epoch 11/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0246 - mae: 0.1525 - mse: 0.0245 - val_loss: 0.0248 - val_mae: 0.1532 - val_mse: 0.0247 - lr: 0.0283
Epoch 12/200
 1/33 [..............................] - ETA: 0s - loss: 0.0244 - mae: 0.1520 - mse: 0.0243
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.014168468303978443.
33/33 [==============================] - 0s 2ms/step - loss: 0.0246 - mae: 0.1525 - mse: 0.0245 - val_loss: 0.0252 - val_mae: 0.1532 - val_mse: 0.0250 - lr: 0.0283
Epoch 13/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0247 - mae: 0.1525 - mse: 0.0246 - val_loss: 0.0248 - val_mae: 0.1532 - val_mse: 0.0246 - lr: 0.0142
Epoch 14/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0245 - mae: 0.1525 - mse: 0.0244 - val_loss: 0.0249 - val_mae: 0.1532 - val_mse: 0.0248 - lr: 0.0142
Epoch 15/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0246 - mae: 0.1525 - mse: 0.0245 - val_loss: 0.0247 - val_mae: 0.1532 - val_mse: 0.0246 - lr: 0.0142
Epoch 16/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0245 - mae: 0.1525 - mse: 0.0244 - val_loss: 0.0247 - val_mae: 0.1532 - val_mse: 0.0246 - lr: 0.0142
Epoch 17/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0245 - mae: 0.1525 - mse: 0.0244 - val_loss: 0.0247 - val_mae: 0.1532 - val_mse: 0.0246 - lr: 0.0142
Epoch 18/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0245 - mae: 0.1525 - mse: 0.0244 - val_loss: 0.0247 - val_mae: 0.1532 - val_mse: 0.0246 - lr: 0.0142
Epoch 19/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0245 - mae: 0.1525 - mse: 0.0244 - val_loss: 0.0247 - val_mae: 0.1532 - val_mse: 0.0246 - lr: 0.0142
Epoch 20/200
 1/33 [..............................] - ETA: 0s - loss: 0.0255 - mae: 0.1552 - mse: 0.0254
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.007084234151989222.
33/33 [==============================] - 0s 2ms/step - loss: 0.0245 - mae: 0.1525 - mse: 0.0244 - val_loss: 0.0247 - val_mae: 0.1532 - val_mse: 0.0246 - lr: 0.0142
Epoch 21/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0245 - mae: 0.1525 - mse: 0.0244 - val_loss: 0.0247 - val_mae: 0.1532 - val_mse: 0.0246 - lr: 0.0071
Epoch 22/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0245 - mae: 0.1525 - mse: 0.0244 - val_loss: 0.0247 - val_mae: 0.1532 - val_mse: 0.0246 - lr: 0.0071
Epoch 23/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0247 - val_mae: 0.1532 - val_mse: 0.0246 - lr: 0.0071
Epoch 24/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0247 - val_mae: 0.1532 - val_mse: 0.0246 - lr: 0.0071
Epoch 25/200
 1/33 [..............................] - ETA: 0s - loss: 0.0244 - mae: 0.1523 - mse: 0.0243
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.003542117075994611.
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0247 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 0.0071
Epoch 26/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0247 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 0.0035
Epoch 27/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 0.0035
Epoch 28/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0247 - val_mae: 0.1532 - val_mse: 0.0246 - lr: 0.0035
Epoch 29/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 0.0035
Epoch 30/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 0.0035
Epoch 31/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 0.0035
Epoch 32/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 0.0035
Epoch 33/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 0.0035
Epoch 34/200
 1/33 [..............................] - ETA: 0s - loss: 0.0238 - mae: 0.1510 - mse: 0.0237
Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0017710585379973054.
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 0.0035
Epoch 35/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 0.0018
Epoch 36/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 0.0018
Epoch 37/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 0.0018
Epoch 38/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 0.0018
Epoch 39/200
 1/33 [..............................] - ETA: 0s - loss: 0.0245 - mae: 0.1527 - mse: 0.0244
Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0008855292689986527.
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 0.0018
Epoch 40/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 8.8553e-04
Epoch 41/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 8.8553e-04
Epoch 42/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 8.8553e-04
Epoch 43/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 8.8553e-04
Epoch 44/200
 1/33 [..............................] - ETA: 0s - loss: 0.0230 - mae: 0.1482 - mse: 0.0229
Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00044276463449932635.
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 8.8553e-04
Epoch 45/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 4.4276e-04
Epoch 46/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 4.4276e-04
Epoch 47/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 4.4276e-04
Epoch 48/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 4.4276e-04
Epoch 49/200
 1/33 [..............................] - ETA: 0s - loss: 0.0243 - mae: 0.1519 - mse: 0.0242
Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00022138231724966317.
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 4.4276e-04
Epoch 50/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 2.2138e-04
Epoch 51/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 2.2138e-04
Epoch 52/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 2.2138e-04
Epoch 53/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 2.2138e-04
Epoch 54/200
 1/33 [..............................] - ETA: 0s - loss: 0.0242 - mae: 0.1524 - mse: 0.0241
Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00011069115862483159.
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 2.2138e-04
Epoch 55/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.1069e-04
Epoch 56/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.1069e-04
Epoch 57/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.1069e-04
Epoch 58/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.1069e-04
Epoch 59/200
 1/33 [..............................] - ETA: 0s - loss: 0.0250 - mae: 0.1546 - mse: 0.0249
Epoch 59: ReduceLROnPlateau reducing learning rate to 5.5345579312415794e-05.
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.1069e-04
Epoch 60/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 5.5346e-05
Epoch 61/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 5.5346e-05
Epoch 62/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 5.5346e-05
Epoch 63/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 5.5346e-05
Epoch 64/200
 1/33 [..............................] - ETA: 0s - loss: 0.0249 - mae: 0.1539 - mse: 0.0248
Epoch 64: ReduceLROnPlateau reducing learning rate to 2.7672789656207897e-05.
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 5.5346e-05
Epoch 65/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 2.7673e-05
Epoch 66/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 2.7673e-05
Epoch 67/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 2.7673e-05
Epoch 68/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 2.7673e-05
Epoch 69/200
 1/33 [..............................] - ETA: 0s - loss: 0.0234 - mae: 0.1490 - mse: 0.0233
Epoch 69: ReduceLROnPlateau reducing learning rate to 1.3836394828103948e-05.
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 2.7673e-05
Epoch 70/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.3836e-05
Epoch 71/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.3836e-05
Epoch 72/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.3836e-05
Epoch 73/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.3836e-05
Epoch 74/200
 1/33 [..............................] - ETA: 0s - loss: 0.0239 - mae: 0.1510 - mse: 0.0238
Epoch 74: ReduceLROnPlateau reducing learning rate to 1e-05.
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.3836e-05
Epoch 75/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 76/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 77/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 78/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 79/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 80/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 81/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 82/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 83/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 84/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 85/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 86/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 87/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 88/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 89/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 90/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 91/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 92/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 93/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 94/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 95/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 96/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 97/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 98/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 99/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 100/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 101/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 102/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 103/200
33/33 [==============================] - 0s 977us/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 104/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 105/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 106/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 107/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 108/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 109/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 110/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 111/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 112/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 113/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 114/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 115/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 116/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 117/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 118/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 119/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 120/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 121/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 122/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 123/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 124/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 125/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 126/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 127/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 128/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 129/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 130/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 131/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 132/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 133/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 134/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 135/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 136/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 137/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 138/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 139/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 140/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 141/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 142/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 143/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 144/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 145/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 146/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 147/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 148/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 149/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 150/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 151/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 152/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 153/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 154/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 155/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 156/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 157/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 158/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 159/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 160/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 161/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 162/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 163/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 164/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 165/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 166/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 167/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 168/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 169/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 170/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 171/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 172/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 173/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 174/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 175/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 176/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 177/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 178/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 179/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 180/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 181/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 182/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 183/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 184/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 185/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 186/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 187/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 188/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 189/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 190/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 191/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 192/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 193/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 194/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 195/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 196/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 197/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 198/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 199/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
Epoch 200/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 1.0000e-05
>Saved ../trained_models/severity/models__adam_0.02833693606572554LR_[33]HN_120BS_5P_val_lossM_200epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/200
33/33 [==============================] - 0s 4ms/step - loss: 0.2524 - mae: 0.2078 - mse: 0.0517 - val_loss: 0.0508 - val_mae: 0.2032 - val_mse: 0.0425 - lr: 0.0283
Epoch 2/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0465 - mae: 0.2025 - mse: 0.0422 - val_loss: 0.0435 - val_mae: 0.2032 - val_mse: 0.0425 - lr: 0.0283
Epoch 3/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0428 - mae: 0.2025 - mse: 0.0422 - val_loss: 0.0433 - val_mae: 0.2032 - val_mse: 0.0431 - lr: 0.0283
Epoch 4/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0425 - mae: 0.2025 - mse: 0.0422 - val_loss: 0.0427 - val_mae: 0.2032 - val_mse: 0.0425 - lr: 0.0283
Epoch 5/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0424 - mae: 0.2025 - mse: 0.0422 - val_loss: 0.0427 - val_mae: 0.2032 - val_mse: 0.0425 - lr: 0.0283
Epoch 6/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0424 - mae: 0.2025 - mse: 0.0423 - val_loss: 0.0431 - val_mae: 0.2032 - val_mse: 0.0428 - lr: 0.0283
Epoch 7/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0424 - mae: 0.2025 - mse: 0.0422 - val_loss: 0.0426 - val_mae: 0.2032 - val_mse: 0.0424 - lr: 0.0283
Epoch 8/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0422 - mae: 0.2025 - mse: 0.0421 - val_loss: 0.0424 - val_mae: 0.2032 - val_mse: 0.0423 - lr: 0.0283
Epoch 9/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0422 - mae: 0.2025 - mse: 0.0420 - val_loss: 0.0425 - val_mae: 0.2032 - val_mse: 0.0423 - lr: 0.0283
Epoch 10/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0421 - mae: 0.2025 - mse: 0.0420 - val_loss: 0.0427 - val_mae: 0.2032 - val_mse: 0.0426 - lr: 0.0283
Epoch 11/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0421 - mae: 0.2025 - mse: 0.0420 - val_loss: 0.0424 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0283
Epoch 12/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0421 - mae: 0.2025 - mse: 0.0420 - val_loss: 0.0427 - val_mae: 0.2032 - val_mse: 0.0426 - lr: 0.0283
Epoch 13/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0421 - mae: 0.2025 - mse: 0.0420 - val_loss: 0.0423 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0283
Epoch 14/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0421 - mae: 0.2025 - mse: 0.0420 - val_loss: 0.0427 - val_mae: 0.2032 - val_mse: 0.0426 - lr: 0.0283
Epoch 15/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0421 - mae: 0.2025 - mse: 0.0420 - val_loss: 0.0423 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0283
Epoch 16/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0421 - mae: 0.2025 - mse: 0.0420 - val_loss: 0.0423 - val_mae: 0.2032 - val_mse: 0.0423 - lr: 0.0283
Epoch 17/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0420 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0423 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0283
Epoch 18/200
 1/33 [..............................] - ETA: 0s - loss: 0.0420 - mae: 0.2022 - mse: 0.0419
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.014168468303978443.
33/33 [==============================] - 0s 2ms/step - loss: 0.0420 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0423 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0283
Epoch 19/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0420 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0423 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0142
Epoch 20/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0420 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0423 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0142
Epoch 21/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0420 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0142
Epoch 22/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0420 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0423 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0142
Epoch 23/200
 1/33 [..............................] - ETA: 0s - loss: 0.0425 - mae: 0.2039 - mse: 0.0424
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.007084234151989222.
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0423 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0142
Epoch 24/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0071
Epoch 25/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0423 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0071
Epoch 26/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0420 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0071
Epoch 27/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0071
Epoch 28/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0423 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0071
Epoch 29/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0071
Epoch 30/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0071
Epoch 31/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0423 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0071
Epoch 32/200
 1/33 [..............................] - ETA: 0s - loss: 0.0419 - mae: 0.2027 - mse: 0.0418
Epoch 32: ReduceLROnPlateau reducing learning rate to 0.003542117075994611.
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0071
Epoch 33/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0035
Epoch 34/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0035
Epoch 35/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 0.0035
Epoch 36/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0035
Epoch 37/200
 1/33 [..............................] - ETA: 0s - loss: 0.0422 - mae: 0.2034 - mse: 0.0422
Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0017710585379973054.
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0035
Epoch 38/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0018
Epoch 39/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 0.0018
Epoch 40/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0018
Epoch 41/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0018
Epoch 42/200
 1/33 [..............................] - ETA: 0s - loss: 0.0408 - mae: 0.1996 - mse: 0.0407
Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0008855292689986527.
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 0.0018
Epoch 43/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 8.8553e-04
Epoch 44/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 8.8553e-04
Epoch 45/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 8.8553e-04
Epoch 46/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 8.8553e-04
Epoch 47/200
 1/33 [..............................] - ETA: 0s - loss: 0.0413 - mae: 0.2008 - mse: 0.0412
Epoch 47: ReduceLROnPlateau reducing learning rate to 0.00044276463449932635.
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 8.8553e-04
Epoch 48/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 4.4276e-04
Epoch 49/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 4.4276e-04
Epoch 50/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 4.4276e-04
Epoch 51/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 4.4276e-04
Epoch 52/200
 1/33 [..............................] - ETA: 0s - loss: 0.0430 - mae: 0.2054 - mse: 0.0430
Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00022138231724966317.
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 4.4276e-04
Epoch 53/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 2.2138e-04
Epoch 54/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 2.2138e-04
Epoch 55/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 2.2138e-04
Epoch 56/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 2.2138e-04
Epoch 57/200
 1/33 [..............................] - ETA: 0s - loss: 0.0429 - mae: 0.2051 - mse: 0.0428
Epoch 57: ReduceLROnPlateau reducing learning rate to 0.00011069115862483159.
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 2.2138e-04
Epoch 58/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.1069e-04
Epoch 59/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.1069e-04
Epoch 60/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.1069e-04
Epoch 61/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.1069e-04
Epoch 62/200
 1/33 [..............................] - ETA: 0s - loss: 0.0409 - mae: 0.2000 - mse: 0.0408
Epoch 62: ReduceLROnPlateau reducing learning rate to 5.5345579312415794e-05.
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.1069e-04
Epoch 63/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 5.5346e-05
Epoch 64/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 5.5346e-05
Epoch 65/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 5.5346e-05
Epoch 66/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 5.5346e-05
Epoch 67/200
 1/33 [..............................] - ETA: 0s - loss: 0.0422 - mae: 0.2030 - mse: 0.0421
Epoch 67: ReduceLROnPlateau reducing learning rate to 2.7672789656207897e-05.
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 5.5346e-05
Epoch 68/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 2.7673e-05
Epoch 69/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 2.7673e-05
Epoch 70/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 2.7673e-05
Epoch 71/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 2.7673e-05
Epoch 72/200
 1/33 [..............................] - ETA: 0s - loss: 0.0396 - mae: 0.1965 - mse: 0.0395
Epoch 72: ReduceLROnPlateau reducing learning rate to 1.3836394828103948e-05.
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 2.7673e-05
Epoch 73/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.3836e-05
Epoch 74/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.3836e-05
Epoch 75/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.3836e-05
Epoch 76/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.3836e-05
Epoch 77/200
 1/33 [..............................] - ETA: 0s - loss: 0.0402 - mae: 0.1982 - mse: 0.0401
Epoch 77: ReduceLROnPlateau reducing learning rate to 1e-05.
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.3836e-05
Epoch 78/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 79/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 80/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 81/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 82/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 83/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 84/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 85/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 86/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 87/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 88/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 89/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 90/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 91/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 92/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 93/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 94/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 95/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 96/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 97/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 98/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 99/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 100/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 101/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 102/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 103/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 104/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 105/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 106/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 107/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 108/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 109/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 110/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 111/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 112/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 113/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 114/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 115/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 116/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 117/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 118/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 119/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 120/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 121/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 122/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 123/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 124/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 125/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 126/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 127/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 128/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 129/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 130/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 131/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 132/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 133/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 134/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 135/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 136/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 137/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 138/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 139/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 140/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 141/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 142/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 143/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 144/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 145/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 146/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 147/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 148/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 149/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 150/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 151/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 152/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 153/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 154/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 155/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 156/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 157/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 158/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 159/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 160/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 161/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 162/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 163/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 164/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 165/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 166/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 167/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 168/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 169/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 170/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 171/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 172/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 173/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 174/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 175/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 176/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 177/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 178/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 179/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 180/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 181/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 182/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 183/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 184/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 185/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 186/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 187/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 188/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 189/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 190/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 191/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 192/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 193/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 194/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 195/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 196/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 197/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 198/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 199/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 200/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
>Saved ../trained_models/severity/models__adam_0.02833693606572554LR_[33]HN_120BS_5P_val_lossM_200epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/200
33/33 [==============================] - 0s 4ms/step - loss: 0.2603 - mae: 0.2529 - mse: 0.0709 - val_loss: 0.0724 - val_mae: 0.2532 - val_mse: 0.0653 - lr: 0.0283
Epoch 2/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0686 - mae: 0.2525 - mse: 0.0650 - val_loss: 0.0660 - val_mae: 0.2532 - val_mse: 0.0653 - lr: 0.0283
Epoch 3/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0653 - mae: 0.2525 - mse: 0.0650 - val_loss: 0.0657 - val_mae: 0.2532 - val_mse: 0.0656 - lr: 0.0283
Epoch 4/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0652 - mae: 0.2525 - mse: 0.0650 - val_loss: 0.0654 - val_mae: 0.2532 - val_mse: 0.0653 - lr: 0.0283
Epoch 5/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0651 - mae: 0.2525 - mse: 0.0650 - val_loss: 0.0654 - val_mae: 0.2532 - val_mse: 0.0653 - lr: 0.0283
Epoch 6/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0650 - mae: 0.2525 - mse: 0.0650 - val_loss: 0.0654 - val_mae: 0.2532 - val_mse: 0.0653 - lr: 0.0283
Epoch 7/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0650 - mae: 0.2525 - mse: 0.0650 - val_loss: 0.0654 - val_mae: 0.2532 - val_mse: 0.0653 - lr: 0.0283
Epoch 8/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0650 - mae: 0.2525 - mse: 0.0650 - val_loss: 0.0654 - val_mae: 0.2532 - val_mse: 0.0654 - lr: 0.0283
Epoch 9/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0651 - mae: 0.2525 - mse: 0.0650 - val_loss: 0.0653 - val_mae: 0.2532 - val_mse: 0.0652 - lr: 0.0283
Epoch 10/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0650 - mae: 0.2525 - mse: 0.0650 - val_loss: 0.0653 - val_mae: 0.2532 - val_mse: 0.0652 - lr: 0.0283
Epoch 11/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0650 - mae: 0.2525 - mse: 0.0649 - val_loss: 0.0654 - val_mae: 0.2532 - val_mse: 0.0653 - lr: 0.0283
Epoch 12/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0650 - mae: 0.2525 - mse: 0.0649 - val_loss: 0.0653 - val_mae: 0.2532 - val_mse: 0.0652 - lr: 0.0283
Epoch 13/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0649 - mae: 0.2525 - mse: 0.0649 - val_loss: 0.0653 - val_mae: 0.2532 - val_mse: 0.0652 - lr: 0.0283
Epoch 14/200
 1/33 [..............................] - ETA: 0s - loss: 0.0647 - mae: 0.2521 - mse: 0.0646
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.014168468303978443.
33/33 [==============================] - 0s 1ms/step - loss: 0.0649 - mae: 0.2525 - mse: 0.0648 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0652 - lr: 0.0283
Epoch 15/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0649 - mae: 0.2525 - mse: 0.0648 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0652 - lr: 0.0142
Epoch 16/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0649 - mae: 0.2525 - mse: 0.0648 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0652 - lr: 0.0142
Epoch 17/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0649 - mae: 0.2525 - mse: 0.0648 - val_loss: 0.0654 - val_mae: 0.2532 - val_mse: 0.0653 - lr: 0.0142
Epoch 18/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0649 - mae: 0.2525 - mse: 0.0648 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0652 - lr: 0.0142
Epoch 19/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0649 - mae: 0.2525 - mse: 0.0648 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0142
Epoch 20/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0648 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0652 - lr: 0.0142
Epoch 21/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0648 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0142
Epoch 22/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0648 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0142
Epoch 23/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0648 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0142
Epoch 24/200
 1/33 [..............................] - ETA: 0s - loss: 0.0650 - mae: 0.2531 - mse: 0.0650
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.007084234151989222.
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0648 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0142
Epoch 25/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0648 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0071
Epoch 26/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0071
Epoch 27/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0071
Epoch 28/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0071
Epoch 29/200
 1/33 [..............................] - ETA: 0s - loss: 0.0648 - mae: 0.2523 - mse: 0.0647
Epoch 29: ReduceLROnPlateau reducing learning rate to 0.003542117075994611.
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0071
Epoch 30/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0035
Epoch 31/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0035
Epoch 32/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0035
Epoch 33/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0035
Epoch 34/200
 1/33 [..............................] - ETA: 0s - loss: 0.0637 - mae: 0.2504 - mse: 0.0636
Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0017710585379973054.
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0035
Epoch 35/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0018
Epoch 36/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0018
Epoch 37/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0018
Epoch 38/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0018
Epoch 39/200
 1/33 [..............................] - ETA: 0s - loss: 0.0668 - mae: 0.2565 - mse: 0.0668
Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0008855292689986527.
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0018
Epoch 40/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 8.8553e-04
Epoch 41/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 8.8553e-04
Epoch 42/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 8.8553e-04
Epoch 43/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 8.8553e-04
Epoch 44/200
 1/33 [..............................] - ETA: 0s - loss: 0.0641 - mae: 0.2511 - mse: 0.0640
Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00044276463449932635.
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 8.8553e-04
Epoch 45/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 4.4276e-04
Epoch 46/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 4.4276e-04
Epoch 47/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 4.4276e-04
Epoch 48/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 4.4276e-04
Epoch 49/200
 1/33 [..............................] - ETA: 0s - loss: 0.0647 - mae: 0.2522 - mse: 0.0646
Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00022138231724966317.
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 4.4276e-04
Epoch 50/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 2.2138e-04
Epoch 51/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 2.2138e-04
Epoch 52/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 2.2138e-04
Epoch 53/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 2.2138e-04
Epoch 54/200
 1/33 [..............................] - ETA: 0s - loss: 0.0641 - mae: 0.2513 - mse: 0.0641
Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00011069115862483159.
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 2.2138e-04
Epoch 55/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.1069e-04
Epoch 56/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.1069e-04
Epoch 57/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.1069e-04
Epoch 58/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.1069e-04
Epoch 59/200
 1/33 [..............................] - ETA: 0s - loss: 0.0652 - mae: 0.2532 - mse: 0.0651
Epoch 59: ReduceLROnPlateau reducing learning rate to 5.5345579312415794e-05.
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.1069e-04
Epoch 60/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 5.5346e-05
Epoch 61/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 5.5346e-05
Epoch 62/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 5.5346e-05
Epoch 63/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 5.5346e-05
Epoch 64/200
 1/33 [..............................] - ETA: 0s - loss: 0.0643 - mae: 0.2520 - mse: 0.0643
Epoch 64: ReduceLROnPlateau reducing learning rate to 2.7672789656207897e-05.
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 5.5346e-05
Epoch 65/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 2.7673e-05
Epoch 66/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 2.7673e-05
Epoch 67/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 2.7673e-05
Epoch 68/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 2.7673e-05
Epoch 69/200
 1/33 [..............................] - ETA: 0s - loss: 0.0638 - mae: 0.2504 - mse: 0.0637
Epoch 69: ReduceLROnPlateau reducing learning rate to 1.3836394828103948e-05.
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 2.7673e-05
Epoch 70/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.3836e-05
Epoch 71/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.3836e-05
Epoch 72/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.3836e-05
Epoch 73/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.3836e-05
Epoch 74/200
 1/33 [..............................] - ETA: 0s - loss: 0.0657 - mae: 0.2544 - mse: 0.0657
Epoch 74: ReduceLROnPlateau reducing learning rate to 1e-05.
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.3836e-05
Epoch 75/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 76/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 77/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 78/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 79/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 80/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 81/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 82/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 83/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 84/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 85/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 86/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 87/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 88/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 89/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 90/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 91/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 92/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 93/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 94/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 95/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 96/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 97/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 98/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 99/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 100/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 101/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 102/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 103/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 104/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 105/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 106/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 107/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 108/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 109/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 110/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 111/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 112/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 113/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 114/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 115/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 116/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 117/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 118/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 119/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 120/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 121/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 122/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 123/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 124/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 125/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 126/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 127/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 128/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 129/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 130/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 131/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 132/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 133/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 134/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 135/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 136/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 137/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 138/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 139/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 140/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 141/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 142/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 143/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 144/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 145/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 146/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 147/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 148/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 149/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 150/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 151/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 152/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 153/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 154/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 155/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 156/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 157/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 158/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 159/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 160/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 161/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 162/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 163/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 164/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 165/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 166/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 167/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 168/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 169/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 170/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 171/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 172/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 173/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 174/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 175/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 176/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 177/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 178/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 179/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 180/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 181/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 182/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 183/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 184/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 185/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 186/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 187/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 188/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 189/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 190/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 191/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 192/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 193/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 194/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 195/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 196/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 197/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 198/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 199/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 200/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
>Saved ../trained_models/severity/models__adam_0.02833693606572554LR_[33]HN_120BS_5P_val_lossM_200epochs/model_5.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/200
33/33 [==============================] - 0s 4ms/step - loss: 0.2833 - mae: 0.3025 - mse: 0.0961 - val_loss: 0.0989 - val_mae: 0.3032 - val_mse: 0.0933 - lr: 0.0283
Epoch 2/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0956 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0936 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0283
Epoch 3/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0929 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0933 - val_mae: 0.3032 - val_mse: 0.0933 - lr: 0.0283
Epoch 4/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0928 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0283
Epoch 5/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0283
Epoch 6/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0928 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0932 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0283
Epoch 7/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0283
Epoch 8/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0283
Epoch 9/200
 1/33 [..............................] - ETA: 0s - loss: 0.0920 - mae: 0.3013 - mse: 0.0919
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.014168468303978443.
33/33 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0283
Epoch 10/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0142
Epoch 11/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0142
Epoch 12/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0926 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0930 - lr: 0.0142
Epoch 13/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0926 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0930 - lr: 0.0142
Epoch 14/200
 1/33 [..............................] - ETA: 0s - loss: 0.0931 - mae: 0.3031 - mse: 0.0930
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.007084234151989222.
33/33 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0926 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0930 - lr: 0.0142
Epoch 15/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0926 - mae: 0.3025 - mse: 0.0926 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0930 - lr: 0.0071
Epoch 16/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0926 - mae: 0.3025 - mse: 0.0926 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0930 - lr: 0.0071
Epoch 17/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0926 - mae: 0.3025 - mse: 0.0926 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0930 - lr: 0.0071
Epoch 18/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0926 - mae: 0.3025 - mse: 0.0926 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0930 - lr: 0.0071
Epoch 19/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0926 - mae: 0.3025 - mse: 0.0926 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0930 - lr: 0.0071
Epoch 20/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0926 - mae: 0.3025 - mse: 0.0926 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0930 - lr: 0.0071
Epoch 21/200
 1/33 [..............................] - ETA: 0s - loss: 0.0921 - mae: 0.3020 - mse: 0.0921
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.003542117075994611.
33/33 [==============================] - 0s 1ms/step - loss: 0.0926 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0930 - lr: 0.0071
Epoch 22/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0926 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0930 - lr: 0.0035
Epoch 23/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0926 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 0.0035
Epoch 24/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0926 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 0.0035
Epoch 25/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0926 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 0.0035
Epoch 26/200
 1/33 [..............................] - ETA: 0s - loss: 0.0932 - mae: 0.3034 - mse: 0.0932
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0017710585379973054.
33/33 [==============================] - 0s 1ms/step - loss: 0.0926 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 0.0035
Epoch 27/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0926 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 0.0018
Epoch 28/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0926 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 0.0018
Epoch 29/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0926 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 0.0018
Epoch 30/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 0.0018
Epoch 31/200
 1/33 [..............................] - ETA: 0s - loss: 0.0909 - mae: 0.2999 - mse: 0.0908
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0008855292689986527.
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 0.0018
Epoch 32/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 8.8553e-04
Epoch 33/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 8.8553e-04
Epoch 34/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 8.8553e-04
Epoch 35/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 8.8553e-04
Epoch 36/200
 1/33 [..............................] - ETA: 0s - loss: 0.0921 - mae: 0.3019 - mse: 0.0921
Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00044276463449932635.
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 8.8553e-04
Epoch 37/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 4.4276e-04
Epoch 38/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 4.4276e-04
Epoch 39/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 4.4276e-04
Epoch 40/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 4.4276e-04
Epoch 41/200
 1/33 [..............................] - ETA: 0s - loss: 0.0928 - mae: 0.3033 - mse: 0.0928
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00022138231724966317.
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 4.4276e-04
Epoch 42/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 2.2138e-04
Epoch 43/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 2.2138e-04
Epoch 44/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 2.2138e-04
Epoch 45/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 2.2138e-04
Epoch 46/200
 1/33 [..............................] - ETA: 0s - loss: 0.0929 - mae: 0.3031 - mse: 0.0928
Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00011069115862483159.
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 2.2138e-04
Epoch 47/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.1069e-04
Epoch 48/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.1069e-04
Epoch 49/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.1069e-04
Epoch 50/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.1069e-04
Epoch 51/200
 1/33 [..............................] - ETA: 0s - loss: 0.0944 - mae: 0.3056 - mse: 0.0944
Epoch 51: ReduceLROnPlateau reducing learning rate to 5.5345579312415794e-05.
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.1069e-04
Epoch 52/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 5.5346e-05
Epoch 53/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 5.5346e-05
Epoch 54/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 5.5346e-05
Epoch 55/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 5.5346e-05
Epoch 56/200
 1/33 [..............................] - ETA: 0s - loss: 0.0908 - mae: 0.2997 - mse: 0.0908
Epoch 56: ReduceLROnPlateau reducing learning rate to 2.7672789656207897e-05.
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 5.5346e-05
Epoch 57/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 2.7673e-05
Epoch 58/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 2.7673e-05
Epoch 59/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 2.7673e-05
Epoch 60/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 2.7673e-05
Epoch 61/200
 1/33 [..............................] - ETA: 0s - loss: 0.0904 - mae: 0.2990 - mse: 0.0903
Epoch 61: ReduceLROnPlateau reducing learning rate to 1.3836394828103948e-05.
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 2.7673e-05
Epoch 62/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.3836e-05
Epoch 63/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.3836e-05
Epoch 64/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.3836e-05
Epoch 65/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.3836e-05
Epoch 66/200
 1/33 [..............................] - ETA: 0s - loss: 0.0928 - mae: 0.3031 - mse: 0.0928
Epoch 66: ReduceLROnPlateau reducing learning rate to 1e-05.
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.3836e-05
Epoch 67/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.0000e-05
Epoch 68/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.0000e-05
Epoch 69/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.0000e-05
Epoch 70/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.0000e-05
Epoch 71/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.0000e-05
Epoch 72/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.0000e-05
Epoch 73/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.0000e-05
Epoch 74/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.0000e-05
Epoch 75/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.0000e-05
Epoch 76/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.0000e-05
Epoch 77/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.0000e-05
Epoch 78/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.0000e-05
Epoch 79/200
33/33 [==============================] - 0s 2ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.0000e-05
Epoch 80/200
33/33 [==============================] - 0s 1ms/step - loss: 0.0925 - mae: 0.3025 - mse: 0.0925 - val_loss: 0.0930 - val_mae: 0.3032 - val_mse: 0.0929 - lr: 1.0000e-05
Epoch 81/200
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0013s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0030s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0001s). Check your callbacks.
Epoch 132/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 133/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 134/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 135/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 136/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 137/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 138/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 139/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 140/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 141/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 142/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 143/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 144/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 145/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 146/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 147/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 148/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 149/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 150/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 151/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 152/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 153/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 154/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 155/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 156/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 157/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 158/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 159/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 160/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 161/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 162/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 163/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 164/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 165/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 166/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 167/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 168/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 169/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 170/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 171/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 172/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 173/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 174/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 175/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 176/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 177/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 178/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 179/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 180/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 181/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 182/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 183/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 184/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 185/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 186/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 187/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 188/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 189/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 190/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 191/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 192/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 193/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 194/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 195/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 196/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 197/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 198/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 199/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 200/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
>Saved ../trained_models/severity/models__adam_0.02833693606572554LR_[33]HN_120BS_5P_val_lossM_200epochs/model_7.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/200
33/33 [==============================] - 0s 4ms/step - loss: 0.3411 - mae: 0.4025 - mse: 0.1636 - val_loss: 0.1693 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0283
Epoch 2/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1658 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1641 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0283
Epoch 3/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1633 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1638 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0283
Epoch 4/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0283
Epoch 5/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0283
Epoch 6/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0283
Epoch 7/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1638 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0283
Epoch 8/200
 1/33 [..............................] - ETA: 0s - loss: 0.1621 - mae: 0.4012 - mse: 0.1621
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.014168468303978443.
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0283
Epoch 9/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0142
Epoch 10/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0142
Epoch 11/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0142
Epoch 12/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0142
Epoch 13/200
 1/33 [..............................] - ETA: 0s - loss: 0.1634 - mae: 0.4029 - mse: 0.1634
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.007084234151989222.
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0142
Epoch 14/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0071
Epoch 15/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0071
Epoch 16/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0071
Epoch 17/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0071
Epoch 18/200
 1/33 [..............................] - ETA: 0s - loss: 0.1623 - mae: 0.4015 - mse: 0.1623
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.003542117075994611.
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0071
Epoch 19/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0035
Epoch 20/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0035
Epoch 21/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0035
Epoch 22/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0035
Epoch 23/200
 1/33 [..............................] - ETA: 0s - loss: 0.1606 - mae: 0.3991 - mse: 0.1606
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0017710585379973054.
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0035
Epoch 24/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0018
Epoch 25/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0018
Epoch 26/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0018
Epoch 27/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0018
Epoch 28/200
 1/33 [..............................] - ETA: 0s - loss: 0.1621 - mae: 0.4012 - mse: 0.1621
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0008855292689986527.
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0018
Epoch 29/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 8.8553e-04
Epoch 30/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 8.8553e-04
Epoch 31/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 8.8553e-04
Epoch 32/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 8.8553e-04
Epoch 33/200
 1/33 [..............................] - ETA: 0s - loss: 0.1644 - mae: 0.4041 - mse: 0.1644
Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00044276463449932635.
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 8.8553e-04
Epoch 34/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 4.4276e-04
Epoch 35/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 4.4276e-04
Epoch 36/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 4.4276e-04
Epoch 37/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 4.4276e-04
Epoch 38/200
 1/33 [..............................] - ETA: 0s - loss: 0.1630 - mae: 0.4022 - mse: 0.1630
Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00022138231724966317.
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 4.4276e-04
Epoch 39/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 2.2138e-04
Epoch 40/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 2.2138e-04
Epoch 41/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 2.2138e-04
Epoch 42/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 2.2138e-04
Epoch 43/200
 1/33 [..............................] - ETA: 0s - loss: 0.1622 - mae: 0.4012 - mse: 0.1622
Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00011069115862483159.
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 2.2138e-04
Epoch 44/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.1069e-04
Epoch 45/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.1069e-04
Epoch 46/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.1069e-04
Epoch 47/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.1069e-04
Epoch 48/200
 1/33 [..............................] - ETA: 0s - loss: 0.1604 - mae: 0.3991 - mse: 0.1604
Epoch 48: ReduceLROnPlateau reducing learning rate to 5.5345579312415794e-05.
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.1069e-04
Epoch 49/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 5.5346e-05
Epoch 50/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 5.5346e-05
Epoch 51/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 5.5346e-05
Epoch 52/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 5.5346e-05
Epoch 53/200
 1/33 [..............................] - ETA: 0s - loss: 0.1597 - mae: 0.3982 - mse: 0.1597
Epoch 53: ReduceLROnPlateau reducing learning rate to 2.7672789656207897e-05.
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 5.5346e-05
Epoch 54/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 2.7673e-05
Epoch 55/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 2.7673e-05
Epoch 56/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 2.7673e-05
Epoch 57/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 2.7673e-05
Epoch 58/200
 1/33 [..............................] - ETA: 0s - loss: 0.1604 - mae: 0.3991 - mse: 0.1604
Epoch 58: ReduceLROnPlateau reducing learning rate to 1.3836394828103948e-05.
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 2.7673e-05
Epoch 59/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.3836e-05
Epoch 60/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.3836e-05
Epoch 61/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.3836e-05
Epoch 62/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.3836e-05
Epoch 63/200
 1/33 [..............................] - ETA: 0s - loss: 0.1640 - mae: 0.4036 - mse: 0.1640
Epoch 63: ReduceLROnPlateau reducing learning rate to 1e-05.
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.3836e-05
Epoch 64/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 65/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 66/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 67/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 68/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 69/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 70/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 71/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 72/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 73/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 74/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 75/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 76/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 77/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 78/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 79/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 80/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 81/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 82/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 83/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 84/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 85/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 86/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 87/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 88/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 89/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 90/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 91/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 92/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 93/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 94/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 95/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 96/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 97/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 98/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 99/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 100/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 101/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 102/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 103/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 104/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 105/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 106/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 107/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 108/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 109/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 110/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 111/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 112/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 113/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 114/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 115/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 116/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 117/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 118/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 119/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 120/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 121/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 122/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 123/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 124/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 125/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 126/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 127/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 128/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 129/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 130/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 131/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 132/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 133/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 134/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 135/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 136/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 137/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 138/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 139/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 140/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 141/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 142/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 143/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 144/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 145/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 146/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 147/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 148/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 149/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 150/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 151/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 152/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 153/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 154/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 155/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 156/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 157/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 158/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 159/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 160/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 161/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 162/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 163/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 164/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 165/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 166/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 167/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 168/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 169/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 170/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 171/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 172/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 173/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 174/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 175/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 176/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 177/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 178/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 179/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 180/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 181/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 182/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 183/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 184/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 185/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 186/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 187/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 188/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 189/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 190/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 191/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 192/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 193/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 194/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 195/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 196/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 197/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 198/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 199/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 200/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
>Saved ../trained_models/severity/models__adam_0.02833693606572554LR_[33]HN_120BS_5P_val_lossM_200epochs/model_8.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/200
33/33 [==============================] - 0s 4ms/step - loss: 0.3739 - mae: 0.4525 - mse: 0.2060 - val_loss: 0.2112 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 0.0283
Epoch 2/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2085 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2069 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 0.0283
Epoch 3/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2060 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2066 - val_mae: 0.4532 - val_mse: 0.2066 - lr: 0.0283
Epoch 4/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2066 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 0.0283
Epoch 5/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2066 - val_mae: 0.4532 - val_mse: 0.2066 - lr: 0.0283
Epoch 6/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2066 - val_mae: 0.4532 - val_mse: 0.2066 - lr: 0.0283
Epoch 7/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2066 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 0.0283
Epoch 8/200
 1/33 [..............................] - ETA: 0s - loss: 0.2060 - mae: 0.4526 - mse: 0.2060
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.014168468303978443.
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2066 - val_mae: 0.4532 - val_mse: 0.2066 - lr: 0.0283
Epoch 9/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2066 - val_mae: 0.4532 - val_mse: 0.2066 - lr: 0.0142
Epoch 10/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2066 - val_mae: 0.4532 - val_mse: 0.2066 - lr: 0.0142
Epoch 11/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2066 - val_mae: 0.4532 - val_mse: 0.2066 - lr: 0.0142
Epoch 12/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2066 - val_mae: 0.4532 - val_mse: 0.2066 - lr: 0.0142
Epoch 13/200
 1/33 [..............................] - ETA: 0s - loss: 0.2049 - mae: 0.4515 - mse: 0.2049
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.007084234151989222.
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2066 - val_mae: 0.4532 - val_mse: 0.2066 - lr: 0.0142
Epoch 14/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2066 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 0.0071
Epoch 15/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2066 - val_mae: 0.4532 - val_mse: 0.2066 - lr: 0.0071
Epoch 16/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2066 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 0.0071
Epoch 17/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2066 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 0.0071
Epoch 18/200
 1/33 [..............................] - ETA: 0s - loss: 0.2043 - mae: 0.4508 - mse: 0.2043
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.003542117075994611.
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2066 - val_mae: 0.4532 - val_mse: 0.2066 - lr: 0.0071
Epoch 19/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 0.0035
Epoch 20/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2066 - val_mae: 0.4532 - val_mse: 0.2066 - lr: 0.0035
Epoch 21/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 0.0035
Epoch 22/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2066 - val_mae: 0.4532 - val_mse: 0.2066 - lr: 0.0035
Epoch 23/200
 1/33 [..............................] - ETA: 0s - loss: 0.2057 - mae: 0.4523 - mse: 0.2057
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0017710585379973054.
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 0.0035
Epoch 24/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 0.0018
Epoch 25/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 0.0018
Epoch 26/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 0.0018
Epoch 27/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 0.0018
Epoch 28/200
 1/33 [..............................] - ETA: 0s - loss: 0.2063 - mae: 0.4529 - mse: 0.2063
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0008855292689986527.
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 0.0018
Epoch 29/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 8.8553e-04
Epoch 30/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 8.8553e-04
Epoch 31/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 8.8553e-04
Epoch 32/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 8.8553e-04
Epoch 33/200
 1/33 [..............................] - ETA: 0s - loss: 0.2085 - mae: 0.4555 - mse: 0.2085
Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00044276463449932635.
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 8.8553e-04
Epoch 34/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 4.4276e-04
Epoch 35/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 4.4276e-04
Epoch 36/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 4.4276e-04
Epoch 37/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 4.4276e-04
Epoch 38/200
 1/33 [..............................] - ETA: 0s - loss: 0.2113 - mae: 0.4582 - mse: 0.2113
Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00022138231724966317.
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 4.4276e-04
Epoch 39/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 2.2138e-04
Epoch 40/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 2.2138e-04
Epoch 41/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 2.2138e-04
Epoch 42/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 2.2138e-04
Epoch 43/200
 1/33 [..............................] - ETA: 0s - loss: 0.2049 - mae: 0.4515 - mse: 0.2049
Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00011069115862483159.
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 2.2138e-04
Epoch 44/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.1069e-04
Epoch 45/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.1069e-04
Epoch 46/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.1069e-04
Epoch 47/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.1069e-04
Epoch 48/200
 1/33 [..............................] - ETA: 0s - loss: 0.2068 - mae: 0.4535 - mse: 0.2068
Epoch 48: ReduceLROnPlateau reducing learning rate to 5.5345579312415794e-05.
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.1069e-04
Epoch 49/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 5.5346e-05
Epoch 50/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 5.5346e-05
Epoch 51/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 5.5346e-05
Epoch 52/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 5.5346e-05
Epoch 53/200
 1/33 [..............................] - ETA: 0s - loss: 0.2062 - mae: 0.4528 - mse: 0.2062
Epoch 53: ReduceLROnPlateau reducing learning rate to 2.7672789656207897e-05.
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 5.5346e-05
Epoch 54/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 2.7673e-05
Epoch 55/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 2.7673e-05
Epoch 56/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 2.7673e-05
Epoch 57/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 2.7673e-05
Epoch 58/200
 1/33 [..............................] - ETA: 0s - loss: 0.2038 - mae: 0.4502 - mse: 0.2038
Epoch 58: ReduceLROnPlateau reducing learning rate to 1.3836394828103948e-05.
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 2.7673e-05
Epoch 59/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.3836e-05
Epoch 60/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.3836e-05
Epoch 61/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.3836e-05
Epoch 62/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.3836e-05
Epoch 63/200
 1/33 [..............................] - ETA: 0s - loss: 0.2084 - mae: 0.4553 - mse: 0.2084
Epoch 63: ReduceLROnPlateau reducing learning rate to 1e-05.
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.3836e-05
Epoch 64/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 65/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 66/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 67/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 68/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 69/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 70/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 71/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 72/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 73/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 74/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 75/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 76/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 77/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 78/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 79/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 80/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 81/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 82/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 83/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 84/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 85/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 86/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 87/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 88/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 89/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 90/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 91/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 92/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 93/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 94/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 95/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 96/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 97/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 98/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 99/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 100/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 101/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 102/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 103/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 104/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 105/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 106/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 107/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 108/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 109/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 110/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 111/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 112/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 113/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 114/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 115/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 116/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 117/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 118/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 119/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 120/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 121/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 122/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 123/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 124/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 125/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 126/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 127/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 128/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 129/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 130/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 131/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 132/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 133/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 134/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 135/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 136/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 137/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 138/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 139/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 140/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 141/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 142/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 143/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 144/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 145/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 146/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 147/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 148/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 149/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 150/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 151/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 152/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 153/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 154/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 155/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 156/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 157/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 158/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 159/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 160/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 161/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 162/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 163/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 164/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 165/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 166/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 167/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 168/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 169/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 170/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 171/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 172/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 173/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 174/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 175/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 176/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 177/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 178/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 179/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 180/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 181/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 182/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 183/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 184/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 185/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 186/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 187/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 188/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 189/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 190/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 191/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 192/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 193/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 194/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 195/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 196/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 197/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 198/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 199/200
33/33 [==============================] - 0s 1ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
Epoch 200/200
33/33 [==============================] - 0s 2ms/step - loss: 0.2059 - mae: 0.4525 - mse: 0.2059 - val_loss: 0.2065 - val_mae: 0.4532 - val_mse: 0.2065 - lr: 1.0000e-05
>Saved ../trained_models/severity/models__adam_0.02833693606572554LR_[33]HN_120BS_5P_val_lossM_200epochs/model_9.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 85/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 86/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 87/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 88/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 89/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 90/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 91/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 92/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 93/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 94/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 95/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 96/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 97/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 98/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 99/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 100/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 101/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 102/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 103/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 104/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 105/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 106/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 107/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 108/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 109/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 110/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 111/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 112/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 113/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 114/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 115/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 116/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 117/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 118/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 119/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 120/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 121/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 122/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 123/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 124/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 125/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 126/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 127/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 128/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 129/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 130/200
33/33 [==============================] - 0s 2ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05
Epoch 131/200
33/33 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 1.0000e-05