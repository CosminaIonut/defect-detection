Epoch 1/50
56/61 [==========================>...] - ETA: 0s - loss: 0.8575 - mae: 0.9250 - mse: 0.8575 - root_mean_squared_error: 0.9260
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0003s vs `on_train_batch_end` time: 0.0029s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0003s vs `on_train_batch_end` time: 0.0029s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
61/61 [==============================] - 2s 24ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0057
Epoch 2/50
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0057
Epoch 3/50
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0057
Epoch 4/50
50/61 [=======================>......] - ETA: 0s - loss: 0.8572 - mae: 0.9248 - mse: 0.8572 - root_mean_squared_error: 0.9258
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0028538969345390797.
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0057
Epoch 5/50
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0029
Epoch 6/50
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0029
Epoch 7/50
49/61 [=======================>......] - ETA: 0s - loss: 0.8572 - mae: 0.9248 - mse: 0.8572 - root_mean_squared_error: 0.9259
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0014269484672695398.
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0029
Epoch 8/50
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0014
Epoch 9/50
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0014
Epoch 10/50
49/61 [=======================>......] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0007134742336347699.
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0014
Epoch 11/50
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 7.1347e-04
Epoch 12/50
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 7.1347e-04
Epoch 13/50
48/61 [======================>.......] - ETA: 0s - loss: 0.8580 - mae: 0.9252 - mse: 0.8580 - root_mean_squared_error: 0.9263
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00035673711681738496.
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 7.1347e-04
Epoch 14/50
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.5674e-04
Epoch 15/50
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.5674e-04
Epoch 16/50
52/61 [========================>.....] - ETA: 0s - loss: 0.8578 - mae: 0.9252 - mse: 0.8578 - root_mean_squared_error: 0.9262
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00017836855840869248.
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.5674e-04
Epoch 17/50
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.7837e-04
Epoch 18/50
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.7837e-04
Epoch 19/50
49/61 [=======================>......] - ETA: 0s - loss: 0.8582 - mae: 0.9254 - mse: 0.8582 - root_mean_squared_error: 0.9264
Epoch 19: ReduceLROnPlateau reducing learning rate to 8.918427920434624e-05.
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.7837e-04
Epoch 20/50
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 8.9184e-05
Epoch 21/50
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 8.9184e-05
Epoch 22/50
51/61 [========================>.....] - ETA: 0s - loss: 0.8590 - mae: 0.9258 - mse: 0.8590 - root_mean_squared_error: 0.9268
Epoch 22: ReduceLROnPlateau reducing learning rate to 4.459213960217312e-05.
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 8.9184e-05
Epoch 23/50
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 4.4592e-05
Epoch 24/50
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 4.4592e-05
Epoch 25/50
50/61 [=======================>......] - ETA: 0s - loss: 0.8572 - mae: 0.9248 - mse: 0.8572 - root_mean_squared_error: 0.9258
Epoch 25: ReduceLROnPlateau reducing learning rate to 2.229606980108656e-05.
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 4.4592e-05
Epoch 26/50
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 2.2296e-05
Epoch 27/50
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 2.2296e-05
Epoch 28/50
50/61 [=======================>......] - ETA: 0s - loss: 0.8588 - mae: 0.9257 - mse: 0.8588 - root_mean_squared_error: 0.9267
Epoch 28: ReduceLROnPlateau reducing learning rate to 1.114803490054328e-05.
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 2.2296e-05
Epoch 29/50
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.1148e-05
Epoch 30/50
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.1148e-05
Epoch 31/50
58/61 [===========================>..] - ETA: 0s - loss: 0.8582 - mae: 0.9254 - mse: 0.8582 - root_mean_squared_error: 0.9264
Epoch 31: ReduceLROnPlateau reducing learning rate to 1e-05.
61/61 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.1148e-05
Epoch 32/50
61/61 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 33/50
61/61 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 34/50
61/61 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 35/50
61/61 [==============================] - 0s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 36/50
61/61 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 37/50
61/61 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 38/50
61/61 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 39/50
61/61 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 40/50
61/61 [==============================] - 0s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 41/50
61/61 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 42/50
61/61 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 43/50
61/61 [==============================] - 0s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 44/50
61/61 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 45/50
61/61 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 46/50
61/61 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 47/50
61/61 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 48/50
61/61 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 49/50
61/61 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 50/50
61/61 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn_sgd_0.0057077939556127505LR_[22]CHN_64CNNI_64BS_1DU_3P_val_mseM_50epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])
Epoch 1/50
81/81 [==============================] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019
61/61 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
81/81 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0014e-05
Epoch 5/50
81/81 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0029
Epoch 6/50
81/81 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0029
Epoch 7/50
64/81 [======================>.......] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0014269484672695398.
81/81 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0029
Epoch 8/50
81/81 [==============================] - 0s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0014
Epoch 9/50
81/81 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0014e-05
Epoch 10/50
71/81 [=========================>....] - ETA: 0s - loss: 0.6427 - mae: 0.7996 - mse: 0.6427 - root_mean_squared_error: 0.8017
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0007134742336347699.
81/81 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0014
Epoch 11/50
81/81 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 7.1347e-04
Epoch 12/50
81/81 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 7.1347e-04
Epoch 13/50
74/81 [==========================>...] - ETA: 0s - loss: 0.6437 - mae: 0.8002 - mse: 0.6437 - root_mean_squared_error: 0.8023
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00035673711681738496.
81/81 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 7.1347e-04
Epoch 14/50
81/81 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 3.5674e-04
Epoch 15/50
81/81 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 3.5674e-04
Epoch 16/50
27/81 [=========>....................] - ETA: 0s - loss: 0.6430 - mae: 0.7997 - mse: 0.6430 - root_mean_squared_error: 0.8019
81/81 [==============================] - 0s 6ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.7837e-04
Epoch 19/50
69/81 [========================>.....] - ETA: 0s - loss: 0.6436 - mae: 0.8001 - mse: 0.6436 - root_mean_squared_error: 0.8023
81/81 [==============================] - 0s 6ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.7837e-04
77/81 [===========================>..] - ETA: 0s - loss: 0.6429 - mae: 0.7997 - mse: 0.6429 - root_mean_squared_error: 0.80188019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.7837e-04
81/81 [==============================] - 1s 6ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.1148e-05
81/81 [==============================] - 1s 6ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.1148e-05
81/81 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
81/81 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
81/81 [==============================] - 0s 6ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
81/81 [==============================] - 0s 6ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
81/81 [==============================] - 0s 6ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
61/61 [==============================] - 0s 6ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 0.0029e-05
48/61 [======================>.......] - ETA: 0s - loss: 0.4575 - mae: 0.6750 - mse: 0.4575 - root_mean_squared_error: 0.67646766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 0.0029e-05
61/61 [==============================] - 0s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.7837e-04
61/61 [==============================] - 0s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 2.2296e-05
61/61 [==============================] - 0s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
61/61 [==============================] - 0s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
61/61 [==============================] - 0s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - root_mean_squared_error: 0.6766 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 5/50['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 12/50'loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 18/50'loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 22/50'loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 28/50'loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 35/50'loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 40/50'loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 47/50'loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 47/50'loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 47/50'loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 5/500'loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 12/50'loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 19/50'loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 25: ReduceLROnPlateau reducing learning rate to 2.229606980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 31: ReduceLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 39/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 45/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 45/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 45/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 45/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 45/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 5/500educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 12/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 12/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 25/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 25/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 34/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 34/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 34/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 34/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 34/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 34/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 34/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 34/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 5/500educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 12/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 22: ReduceLROnPlateau reducing learning rate to 4.459213960217312e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 27/50educeLROnPlateau reducing learning rate to 4.459213960217312e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 31/50educeLROnPlateau reducing learning rate to 4.459213960217312e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 31/50educeLROnPlateau reducing learning rate to 4.459213960217312e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 31/50educeLROnPlateau reducing learning rate to 4.459213960217312e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 31/50educeLROnPlateau reducing learning rate to 4.459213960217312e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 48/50educeLROnPlateau reducing learning rate to 4.459213960217312e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 48/50educeLROnPlateau reducing learning rate to 4.459213960217312e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 48/50educeLROnPlateau reducing learning rate to 4.459213960217312e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 48/50educeLROnPlateau reducing learning rate to 4.459213960217312e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 5/500educeLROnPlateau reducing learning rate to 4.459213960217312e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 12/50educeLROnPlateau reducing learning rate to 4.459213960217312e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 12/50educeLROnPlateau reducing learning rate to 4.459213960217312e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 4.459213960217312e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 4.459213960217312e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 25: ReduceLROnPlateau reducing learning rate to 2.229606980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 30/50educeLROnPlateau reducing learning rate to 2.229606980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 30/50educeLROnPlateau reducing learning rate to 2.229606980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 30/50educeLROnPlateau reducing learning rate to 2.229606980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 30/50educeLROnPlateau reducing learning rate to 2.229606980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 30/50educeLROnPlateau reducing learning rate to 2.229606980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 49/50educeLROnPlateau reducing learning rate to 2.229606980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 49/50educeLROnPlateau reducing learning rate to 2.229606980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 49/50educeLROnPlateau reducing learning rate to 2.229606980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 49/50educeLROnPlateau reducing learning rate to 2.229606980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 12/50educeLROnPlateau reducing learning rate to 2.229606980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 2.229606980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 19/50educeLROnPlateau reducing learning rate to 2.229606980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 25: ReduceLROnPlateau reducing learning rate to 2.229606980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 31: ReduceLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 31: ReduceLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 31: ReduceLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 31: ReduceLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 48/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 48/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05
Epoch 48/50educeLROnPlateau reducing learning rate to 1e-05.06980108656e-05._mae', 'val_mse', 'val_root_mean_squared_error', 'lr']) val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - val_root_mean_squared_error: 0.6760 - lr: 1.0000e-05