WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
Epoch 1/150
98/98 [==============================] - 5s 50ms/step - loss: 0.0749 - mae: 0.0518 - mse: 0.0060 - val_loss: 0.0042 - val_mae: 0.0477 - val_mse: 0.0034 - lr: 0.0870
Epoch 2/150
65/98 [==================>...........] - ETA: 0s - loss: 0.0041 - mae: 0.0454 - mse: 0.0031
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 1s 12ms/step - loss: 0.0037 - mae: 0.0436 - mse: 0.0028 - val_loss: 0.0042 - val_mae: 0.0518 - val_mse: 0.0040 - lr: 0.0870
Epoch 3/150
60/98 [=================>............] - ETA: 0s - loss: 0.0026 - mae: 0.0392 - mse: 0.0021
98/98 [==============================] - 1s 10ms/step - loss: 0.0026 - mae: 0.0397 - mse: 0.0022 - val_loss: 0.0027 - val_mae: 0.0404 - val_mse: 0.0023 - lr: 0.0870
Epoch 4/150
98/98 [==============================] - 1s 9ms/step - loss: 0.0025 - mae: 0.0396 - mse: 0.0022 - val_loss: 0.0021 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0870
Epoch 5/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0390 - mse: 0.0021 - val_loss: 0.0023 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0870
Epoch 6/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0870
Epoch 7/150
70/98 [====================>.........] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020
98/98 [==============================] - 1s 9ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0870
Epoch 8/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0870
Epoch 9/150
64/98 [==================>...........] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019
98/98 [==============================] - 1s 8ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0870
Epoch 10/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0870
Epoch 11/150
64/98 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 1s 9ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0870
Epoch 12/150
58/98 [================>.............] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0019
98/98 [==============================] - 1s 9ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0870
Epoch 13/150
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0870
Epoch 14/150
57/98 [================>.............] - ETA: 0s - loss: 0.0020 - mae: 0.0387 - mse: 0.0020
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0434899628162384.
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0870
Epoch 15/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0435
Epoch 16/150
66/98 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
98/98 [==============================] - 1s 11ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0435
Epoch 17/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0435
Epoch 18/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0435
Epoch 19/150
66/98 [===================>..........] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0020
98/98 [==============================] - 1s 8ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0435
Epoch 20/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0435
Epoch 21/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0435
Epoch 22/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0435
Epoch 23/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0435
Epoch 24/150
67/98 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0217449814081192.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0435
Epoch 25/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0217
Epoch 26/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0217
Epoch 27/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0217
Epoch 28/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0217
Epoch 29/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0217
Epoch 30/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0217
Epoch 31/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0217
Epoch 32/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0217
Epoch 33/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0217
Epoch 34/150
68/98 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0108724907040596.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0217
Epoch 35/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0109
Epoch 36/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0109
Epoch 37/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0109
Epoch 38/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0109
Epoch 39/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0109
Epoch 40/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0109
Epoch 41/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0109
Epoch 42/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0109
Epoch 43/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0109
Epoch 44/150
63/98 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0054362453520298.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 1s 9ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0109
Epoch 45/150
54/98 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
98/98 [==============================] - 1s 9ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0054
Epoch 46/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 47/150
67/98 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 48/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 49/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 50/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 51/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 52/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 53/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 54/150
61/98 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0027181226760149.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 55/150
63/98 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
98/98 [==============================] - 1s 9ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0027
Epoch 56/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0027
Epoch 57/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0027
Epoch 58/150
66/98 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
98/98 [==============================] - 1s 9ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0027
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 1s 9ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0027
59/98 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0027
59/98 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0027
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6988e-04
Epoch 97/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6988e-04
Epoch 98/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6988e-04
Epoch 99/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6988e-04
Epoch 100/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.6988e-04
Epoch 101/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6988e-04
Epoch 102/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6988e-04
Epoch 103/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6988e-04
Epoch 104/150
64/98 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 104: ReduceLROnPlateau reducing learning rate to 8.494133362546563e-05.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6988e-04
Epoch 105/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.4941e-05
Epoch 106/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.4941e-05
Epoch 107/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.4941e-05
Epoch 108/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.4941e-05
Epoch 109/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.4941e-05
Epoch 110/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.4941e-05
Epoch 111/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.4941e-05
Epoch 112/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 8.4941e-05
Epoch 113/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 8.4941e-05
Epoch 114/150
71/98 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.0019
Epoch 114: ReduceLROnPlateau reducing learning rate to 4.2470666812732816e-05.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 8.4941e-05
Epoch 115/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.2471e-05
Epoch 116/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.2471e-05
Epoch 117/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2471e-05
Epoch 118/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.2471e-05
Epoch 119/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.2471e-05
Epoch 120/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.2471e-05
Epoch 121/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2471e-05
Epoch 122/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2471e-05
Epoch 123/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2471e-05
Epoch 124/150
64/98 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 124: ReduceLROnPlateau reducing learning rate to 2.1235333406366408e-05.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2471e-05
Epoch 125/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 126/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 127/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 128/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 129/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 130/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 131/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 132/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 133/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 134/150
65/98 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 134: ReduceLROnPlateau reducing learning rate to 1.0617666703183204e-05.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 135/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
Epoch 136/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
Epoch 137/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
Epoch 138/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
Epoch 139/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
Epoch 140/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
Epoch 141/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
Epoch 142/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
Epoch 143/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
Epoch 144/150
66/98 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0374 - mse: 0.0019
Epoch 144: ReduceLROnPlateau reducing learning rate to 1e-05.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
Epoch 145/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 146/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 147/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 148/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 149/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 150/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_adam_0.08697992935283343LR_[70]HN_40BS_10P_val_mseM_150epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
130/130 [==============================] - 1s 2ms/step - loss: 0.0494 - mae: 0.0566 - mse: 0.0050 - val_loss: 0.0052 - val_mae: 0.0567 - val_mse: 0.0047 - lr: 0.0870
Epoch 2/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0509 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0870
Epoch 3/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0870
Epoch 4/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0870
Epoch 5/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0870
Epoch 6/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0040 - val_mae: 0.0522 - val_mse: 0.0038 - lr: 0.0870
Epoch 7/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0510 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0870
Epoch 8/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0041 - val_mae: 0.0525 - val_mse: 0.0039 - lr: 0.0870
Epoch 9/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0509 - mse: 0.0035 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0870
Epoch 10/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0515 - val_mse: 0.0036 - lr: 0.0870
Epoch 11/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0511 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0870
Epoch 12/150
 65/130 [==============>...............] - ETA: 0s - loss: 0.0035 - mae: 0.0506 - mse: 0.0034
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0434899628162384.
130/130 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0510 - val_mse: 0.0035 - lr: 0.0870
Epoch 13/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0513 - val_mse: 0.0036 - lr: 0.0435
Epoch 14/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0435
Epoch 15/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0435
Epoch 16/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0435
Epoch 17/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0435
Epoch 18/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0038 - val_mae: 0.0508 - val_mse: 0.0035 - lr: 0.0435
Epoch 19/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0509 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0509 - val_mse: 0.0035 - lr: 0.0435
Epoch 20/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0506 - val_mse: 0.0034 - lr: 0.0435
Epoch 21/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0507 - val_mse: 0.0035 - lr: 0.0435
Epoch 22/150
 64/130 [=============>................] - ETA: 0s - loss: 0.0035 - mae: 0.0506 - mse: 0.0034
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0217449814081192.
130/130 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0435
Epoch 23/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0217
Epoch 24/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0217
Epoch 25/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0217
Epoch 26/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0217
Epoch 27/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0217
Epoch 28/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0217
Epoch 29/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0217
Epoch 30/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0217
Epoch 31/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0217
Epoch 32/150
103/130 [======================>.......] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0108724907040596.
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0217
Epoch 33/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0109
Epoch 34/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0109
Epoch 35/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0109
Epoch 36/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0109
Epoch 37/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0109
Epoch 38/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0109
Epoch 39/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0109
Epoch 40/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0109
Epoch 41/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0109
Epoch 42/150
 96/130 [=====================>........] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0054362453520298.
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0109
Epoch 43/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0054
Epoch 44/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0054
Epoch 45/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0054
Epoch 46/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0054
Epoch 47/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0054
Epoch 48/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0054
Epoch 49/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0054
Epoch 50/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0054
Epoch 51/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0054
Epoch 52/150
129/130 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0027181226760149.
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0054
Epoch 53/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0027
Epoch 54/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0027
Epoch 55/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0027
Epoch 56/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0027
Epoch 57/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0027
Epoch 58/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0027
Epoch 59/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0027
Epoch 60/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0027
Epoch 61/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0027
Epoch 62/150
 97/130 [=====================>........] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 62: ReduceLROnPlateau reducing learning rate to 0.00135906133800745.
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0027
Epoch 63/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0014
Epoch 64/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0014
Epoch 65/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0014
Epoch 66/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0014
Epoch 67/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0014
Epoch 68/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0014
Epoch 69/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0014
Epoch 70/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0014
Epoch 71/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0014
Epoch 72/150
 69/130 [==============>...............] - ETA: 0s - loss: 0.0034 - mae: 0.0502 - mse: 0.0034
Epoch 72: ReduceLROnPlateau reducing learning rate to 0.000679530669003725.
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0014
Epoch 73/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.7953e-04
Epoch 74/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.7953e-04
Epoch 75/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.7953e-04
Epoch 76/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.7953e-04
Epoch 77/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.7953e-04
Epoch 78/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.7953e-04
Epoch 79/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.7953e-04
Epoch 80/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.7953e-04
Epoch 81/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.7953e-04
Epoch 82/150
121/130 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0003397653345018625.
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.7953e-04
Epoch 83/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.3977e-04
Epoch 84/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.3977e-04
Epoch 85/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.3977e-04
Epoch 86/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.3977e-04
Epoch 87/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.3977e-04
Epoch 88/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.3977e-04
Epoch 89/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.3977e-04
Epoch 90/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.3977e-04
Epoch 91/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.3977e-04
Epoch 92/150
 71/130 [===============>..............] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 92: ReduceLROnPlateau reducing learning rate to 0.00016988266725093126.
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.3977e-04
Epoch 93/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6988e-04
Epoch 94/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6988e-04
Epoch 95/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6988e-04
Epoch 96/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6988e-04
Epoch 97/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6988e-04
Epoch 98/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6988e-04
Epoch 99/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6988e-04
Epoch 100/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6988e-04
Epoch 101/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6988e-04
Epoch 102/150
100/130 [======================>.......] - ETA: 0s - loss: 0.0034 - mae: 0.0509 - mse: 0.0034
Epoch 102: ReduceLROnPlateau reducing learning rate to 8.494133362546563e-05.
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.6988e-04
Epoch 103/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
Epoch 104/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
Epoch 105/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
Epoch 106/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
Epoch 107/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
Epoch 108/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
Epoch 109/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
Epoch 110/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
Epoch 111/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
Epoch 112/150
 97/130 [=====================>........] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034
Epoch 112: ReduceLROnPlateau reducing learning rate to 4.2470666812732816e-05.
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
Epoch 113/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 4.2471e-05
Epoch 114/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 4.2471e-05
Epoch 115/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 4.2471e-05
Epoch 116/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 4.2471e-05
Epoch 117/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 4.2471e-05
Epoch 118/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 4.2471e-05
Epoch 119/150
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 4.2471e-05
Epoch 120/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 4.2471e-05
Epoch 121/150
  1/130 [..............................] - ETA: 0s - loss: 0.0028 - mae: 0.0464 - mse: 0.0028
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0012s vs `on_train_batch_end` time: 0.0023s). Check your callbacks.
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
130/130 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
Epoch 56/150===========================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 0.0109
Epoch 41/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0381 - val_mse: 0.0020 - lr: 0.0109
Epoch 42/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0373 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0371 - val_mse: 0.0019 - lr: 0.0109
Epoch 43/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0340 - mse: 0.0016 - val_loss: 0.0015 - val_mae: 0.0299 - val_mse: 0.0013 - lr: 0.0109
Epoch 44/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0288 - mse: 0.0013 - val_loss: 0.0013 - val_mae: 0.0270 - val_mse: 0.0011 - lr: 0.0109
Epoch 45/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0268 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 0.0109
Epoch 46/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0019 - val_mae: 0.0347 - val_mse: 0.0018 - lr: 0.0109
Epoch 47/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0258 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0253 - val_mse: 0.0010 - lr: 0.0109
Epoch 48/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0246 - mse: 9.8542e-04 - val_loss: 0.0012 - val_mae: 0.0252 - val_mse: 0.0010 - lr: 0.0109
Epoch 49/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0245 - mse: 9.7139e-04 - val_loss: 0.0011 - val_mae: 0.0248 - val_mse: 9.8604e-04 - lr: 0.0109
Epoch 50/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0247 - mse: 9.8621e-04 - val_loss: 0.0013 - val_mae: 0.0278 - val_mse: 0.0012 - lr: 0.0109
Epoch 51/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0243 - mse: 9.5395e-04 - val_loss: 0.0011 - val_mae: 0.0243 - val_mse: 9.5566e-04 - lr: 0.0109
Epoch 52/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0243 - mse: 9.4433e-04 - val_loss: 0.0011 - val_mae: 0.0246 - val_mse: 9.6853e-04 - lr: 0.0109
Epoch 53/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0240 - mse: 9.2501e-04 - val_loss: 0.0010 - val_mae: 0.0241 - val_mse: 9.3592e-04 - lr: 0.0109
Epoch 54/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0245 - mse: 9.6113e-04 - val_loss: 0.0011 - val_mae: 0.0239 - val_mse: 9.3252e-04 - lr: 0.0109
Epoch 55/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0237 - mse: 9.1031e-04 - val_loss: 0.0013 - val_mae: 0.0273 - val_mse: 0.0012 - lr: 0.0109
Epoch 56/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0239 - mse: 9.1741e-04 - val_loss: 0.0010 - val_mae: 0.0238 - val_mse: 9.2473e-04 - lr: 0.0109
Epoch 57/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0237 - mse: 9.0121e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.0109
Epoch 58/150
98/98 [==============================] - 0s 1ms/step - loss: 9.9941e-04 - mae: 0.0235 - mse: 8.9446e-04 - val_loss: 0.0010 - val_mae: 0.0236 - val_mse: 9.1243e-04 - lr: 0.0109
Epoch 59/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0241 - mse: 9.3177e-04 - val_loss: 0.0010 - val_mae: 0.0235 - val_mse: 8.9098e-04 - lr: 0.0109
Epoch 60/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6350e-04 - mae: 0.0230 - mse: 8.6176e-04 - val_loss: 0.0012 - val_mae: 0.0261 - val_mse: 0.0011 - lr: 0.0109
Epoch 61/150
98/98 [==============================] - 0s 1ms/step - loss: 9.8113e-04 - mae: 0.0234 - mse: 8.8770e-04 - val_loss: 0.0014 - val_mae: 0.0291 - val_mse: 0.0013 - lr: 0.0109
Epoch 62/150
98/98 [==============================] - 0s 1ms/step - loss: 9.9199e-04 - mae: 0.0237 - mse: 8.9572e-04 - val_loss: 9.9461e-04 - val_mae: 0.0237 - val_mse: 8.9293e-04 - lr: 0.0109
Epoch 63/150
98/98 [==============================] - 0s 1ms/step - loss: 9.4864e-04 - mae: 0.0230 - mse: 8.5592e-04 - val_loss: 9.9316e-04 - val_mae: 0.0233 - val_mse: 8.8530e-04 - lr: 0.0109
Epoch 64/150
98/98 [==============================] - 0s 1ms/step - loss: 9.9435e-04 - mae: 0.0235 - mse: 8.9021e-04 - val_loss: 0.0011 - val_mae: 0.0248 - val_mse: 9.5069e-04 - lr: 0.0109
Epoch 65/150
98/98 [==============================] - 0s 1ms/step - loss: 9.9778e-04 - mae: 0.0233 - mse: 8.8026e-04 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 0.0109
Epoch 66/150
98/98 [==============================] - 0s 1ms/step - loss: 9.5912e-04 - mae: 0.0228 - mse: 8.5325e-04 - val_loss: 9.9075e-04 - val_mae: 0.0233 - val_mse: 8.9506e-04 - lr: 0.0109
Epoch 67/150
98/98 [==============================] - 0s 1ms/step - loss: 9.4209e-04 - mae: 0.0230 - mse: 8.5719e-04 - val_loss: 9.8768e-04 - val_mae: 0.0240 - val_mse: 9.0308e-04 - lr: 0.0109
Epoch 68/150
68/98 [===================>..........] - ETA: 0s - loss: 9.1644e-04 - mae: 0.0227 - mse: 8.3491e-04
Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0054362453520298.
98/98 [==============================] - 0s 1ms/step - loss: 9.2488e-04 - mae: 0.0228 - mse: 8.4414e-04 - val_loss: 9.4972e-04 - val_mae: 0.0230 - val_mse: 8.6317e-04 - lr: 0.0109
Epoch 69/150
98/98 [==============================] - 0s 1ms/step - loss: 9.1997e-04 - mae: 0.0227 - mse: 8.4235e-04 - val_loss: 9.6874e-04 - val_mae: 0.0232 - val_mse: 8.8741e-04 - lr: 0.0054
Epoch 70/150
98/98 [==============================] - 0s 1ms/step - loss: 9.1762e-04 - mae: 0.0227 - mse: 8.3995e-04 - val_loss: 9.4143e-04 - val_mae: 0.0233 - val_mse: 8.6473e-04 - lr: 0.0054
Epoch 71/150
98/98 [==============================] - 0s 1ms/step - loss: 9.3575e-04 - mae: 0.0231 - mse: 8.5520e-04 - val_loss: 0.0010 - val_mae: 0.0248 - val_mse: 9.4552e-04 - lr: 0.0054
Epoch 72/150
98/98 [==============================] - 0s 1ms/step - loss: 9.1290e-04 - mae: 0.0226 - mse: 8.3368e-04 - val_loss: 9.3923e-04 - val_mae: 0.0229 - val_mse: 8.5482e-04 - lr: 0.0054
Epoch 73/150
98/98 [==============================] - 0s 1ms/step - loss: 9.2025e-04 - mae: 0.0227 - mse: 8.4087e-04 - val_loss: 9.4127e-04 - val_mae: 0.0232 - val_mse: 8.5767e-04 - lr: 0.0054
Epoch 74/150
98/98 [==============================] - 0s 1ms/step - loss: 9.0899e-04 - mae: 0.0225 - mse: 8.2856e-04 - val_loss: 9.7424e-04 - val_mae: 0.0233 - val_mse: 8.9996e-04 - lr: 0.0054
Epoch 75/150
98/98 [==============================] - 0s 1ms/step - loss: 9.1262e-04 - mae: 0.0227 - mse: 8.3508e-04 - val_loss: 9.7037e-04 - val_mae: 0.0232 - val_mse: 8.9173e-04 - lr: 0.0054
Epoch 76/150
98/98 [==============================] - 0s 1ms/step - loss: 9.0373e-04 - mae: 0.0225 - mse: 8.2971e-04 - val_loss: 9.4700e-04 - val_mae: 0.0229 - val_mse: 8.6652e-04 - lr: 0.0054
Epoch 77/150
98/98 [==============================] - 0s 1ms/step - loss: 8.9640e-04 - mae: 0.0224 - mse: 8.1946e-04 - val_loss: 9.2455e-04 - val_mae: 0.0229 - val_mse: 8.4598e-04 - lr: 0.0054
Epoch 78/150
67/98 [===================>..........] - ETA: 0s - loss: 9.1135e-04 - mae: 0.0227 - mse: 8.3754e-04
Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0027181226760149.
98/98 [==============================] - 0s 1ms/step - loss: 9.0536e-04 - mae: 0.0226 - mse: 8.3049e-04 - val_loss: 9.3596e-04 - val_mae: 0.0228 - val_mse: 8.5870e-04 - lr: 0.0054
Epoch 79/150
98/98 [==============================] - 0s 1ms/step - loss: 8.8203e-04 - mae: 0.0222 - mse: 8.0997e-04 - val_loss: 9.4405e-04 - val_mae: 0.0236 - val_mse: 8.7562e-04 - lr: 0.0027
Epoch 80/150
98/98 [==============================] - 0s 1ms/step - loss: 8.9125e-04 - mae: 0.0224 - mse: 8.1828e-04 - val_loss: 9.3693e-04 - val_mae: 0.0229 - val_mse: 8.6959e-04 - lr: 0.0027
Epoch 81/150
98/98 [==============================] - 0s 1ms/step - loss: 8.8771e-04 - mae: 0.0223 - mse: 8.1806e-04 - val_loss: 9.2437e-04 - val_mae: 0.0231 - val_mse: 8.5377e-04 - lr: 0.0027
Epoch 82/150
98/98 [==============================] - 0s 1ms/step - loss: 8.8697e-04 - mae: 0.0224 - mse: 8.1392e-04 - val_loss: 9.7248e-04 - val_mae: 0.0233 - val_mse: 8.9612e-04 - lr: 0.0027
Epoch 83/150
98/98 [==============================] - 0s 1ms/step - loss: 8.9202e-04 - mae: 0.0225 - mse: 8.2022e-04 - val_loss: 9.4492e-04 - val_mae: 0.0229 - val_mse: 8.6911e-04 - lr: 0.0027
Epoch 84/150
98/98 [==============================] - 0s 1ms/step - loss: 8.7650e-04 - mae: 0.0222 - mse: 8.0623e-04 - val_loss: 9.2238e-04 - val_mae: 0.0227 - val_mse: 8.4939e-04 - lr: 0.0027
Epoch 85/150
98/98 [==============================] - 0s 1ms/step - loss: 8.7773e-04 - mae: 0.0222 - mse: 8.0689e-04 - val_loss: 9.3767e-04 - val_mae: 0.0235 - val_mse: 8.7440e-04 - lr: 0.0027
Epoch 86/150
98/98 [==============================] - 0s 1ms/step - loss: 8.9958e-04 - mae: 0.0226 - mse: 8.2806e-04 - val_loss: 0.0012 - val_mae: 0.0260 - val_mse: 0.0011 - lr: 0.0027
Epoch 87/150
98/98 [==============================] - 0s 1ms/step - loss: 8.9299e-04 - mae: 0.0224 - mse: 8.1984e-04 - val_loss: 9.1678e-04 - val_mae: 0.0229 - val_mse: 8.4659e-04 - lr: 0.0027
Epoch 88/150
66/98 [===================>..........] - ETA: 0s - loss: 8.9050e-04 - mae: 0.0224 - mse: 8.2426e-04
Epoch 88: ReduceLROnPlateau reducing learning rate to 0.00135906133800745.
98/98 [==============================] - 0s 1ms/step - loss: 8.7837e-04 - mae: 0.0223 - mse: 8.1154e-04 - val_loss: 9.2576e-04 - val_mae: 0.0227 - val_mse: 8.5696e-04 - lr: 0.0027
Epoch 89/150
98/98 [==============================] - 0s 1ms/step - loss: 8.7067e-04 - mae: 0.0221 - mse: 8.0385e-04 - val_loss: 9.1182e-04 - val_mae: 0.0227 - val_mse: 8.4451e-04 - lr: 0.0014
Epoch 90/150
98/98 [==============================] - 0s 1ms/step - loss: 8.7460e-04 - mae: 0.0222 - mse: 8.0621e-04 - val_loss: 9.0931e-04 - val_mae: 0.0228 - val_mse: 8.4339e-04 - lr: 0.0014
Epoch 91/150
98/98 [==============================] - 0s 1ms/step - loss: 8.8113e-04 - mae: 0.0223 - mse: 8.1453e-04 - val_loss: 9.2291e-04 - val_mae: 0.0227 - val_mse: 8.5547e-04 - lr: 0.0014
Epoch 92/150
98/98 [==============================] - 0s 1ms/step - loss: 8.7527e-04 - mae: 0.0223 - mse: 8.0960e-04 - val_loss: 9.1371e-04 - val_mae: 0.0230 - val_mse: 8.4905e-04 - lr: 0.0014
Epoch 93/150
98/98 [==============================] - 0s 1ms/step - loss: 8.7190e-04 - mae: 0.0222 - mse: 8.0564e-04 - val_loss: 9.2341e-04 - val_mae: 0.0233 - val_mse: 8.5890e-04 - lr: 0.0014
Epoch 94/150
98/98 [==============================] - 0s 1ms/step - loss: 8.7216e-04 - mae: 0.0221 - mse: 8.0512e-04 - val_loss: 9.0683e-04 - val_mae: 0.0227 - val_mse: 8.4092e-04 - lr: 0.0014
Epoch 95/150
98/98 [==============================] - 0s 1ms/step - loss: 8.6472e-04 - mae: 0.0221 - mse: 7.9814e-04 - val_loss: 9.0846e-04 - val_mae: 0.0229 - val_mse: 8.4353e-04 - lr: 0.0014
Epoch 96/150
98/98 [==============================] - 0s 1ms/step - loss: 8.7040e-04 - mae: 0.0221 - mse: 8.0381e-04 - val_loss: 9.3453e-04 - val_mae: 0.0229 - val_mse: 8.6563e-04 - lr: 0.0014
Epoch 97/150
98/98 [==============================] - 0s 1ms/step - loss: 8.7020e-04 - mae: 0.0222 - mse: 8.0225e-04 - val_loss: 9.1240e-04 - val_mae: 0.0230 - val_mse: 8.4866e-04 - lr: 0.0014
Epoch 98/150
68/98 [===================>..........] - ETA: 0s - loss: 8.6417e-04 - mae: 0.0220 - mse: 7.9752e-04
Epoch 98: ReduceLROnPlateau reducing learning rate to 0.000679530669003725.
98/98 [==============================] - 0s 1ms/step - loss: 8.6675e-04 - mae: 0.0221 - mse: 8.0006e-04 - val_loss: 9.0583e-04 - val_mae: 0.0227 - val_mse: 8.3889e-04 - lr: 0.0014
Epoch 99/150
98/98 [==============================] - 0s 1ms/step - loss: 8.6198e-04 - mae: 0.0220 - mse: 7.9584e-04 - val_loss: 9.0336e-04 - val_mae: 0.0227 - val_mse: 8.3861e-04 - lr: 6.7953e-04
Epoch 100/150
98/98 [==============================] - 0s 1ms/step - loss: 8.6040e-04 - mae: 0.0220 - mse: 7.9570e-04 - val_loss: 9.0346e-04 - val_mae: 0.0227 - val_mse: 8.3860e-04 - lr: 6.7953e-04
Epoch 101/150
98/98 [==============================] - 0s 2ms/step - loss: 8.6483e-04 - mae: 0.0221 - mse: 7.9893e-04 - val_loss: 9.0798e-04 - val_mae: 0.0226 - val_mse: 8.4387e-04 - lr: 6.7953e-04
Epoch 102/150
98/98 [==============================] - 0s 2ms/step - loss: 8.6339e-04 - mae: 0.0221 - mse: 7.9909e-04 - val_loss: 9.0991e-04 - val_mae: 0.0226 - val_mse: 8.4451e-04 - lr: 6.7953e-04
Epoch 103/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5905e-04 - mae: 0.0220 - mse: 7.9439e-04 - val_loss: 9.0387e-04 - val_mae: 0.0228 - val_mse: 8.4137e-04 - lr: 6.7953e-04
Epoch 104/150
98/98 [==============================] - 0s 2ms/step - loss: 8.6305e-04 - mae: 0.0221 - mse: 7.9891e-04 - val_loss: 9.0805e-04 - val_mae: 0.0226 - val_mse: 8.4305e-04 - lr: 6.7953e-04
Epoch 105/150
98/98 [==============================] - 0s 2ms/step - loss: 8.6112e-04 - mae: 0.0221 - mse: 7.9662e-04 - val_loss: 9.0459e-04 - val_mae: 0.0226 - val_mse: 8.4116e-04 - lr: 6.7953e-04
Epoch 106/150
98/98 [==============================] - 0s 2ms/step - loss: 8.6025e-04 - mae: 0.0220 - mse: 7.9730e-04 - val_loss: 9.1886e-04 - val_mae: 0.0227 - val_mse: 8.5278e-04 - lr: 6.7953e-04
Epoch 107/150
98/98 [==============================] - 0s 2ms/step - loss: 8.6299e-04 - mae: 0.0220 - mse: 7.9847e-04 - val_loss: 9.0108e-04 - val_mae: 0.0226 - val_mse: 8.3669e-04 - lr: 6.7953e-04
Epoch 108/150
51/98 [==============>...............] - ETA: 0s - loss: 8.3368e-04 - mae: 0.0216 - mse: 7.6964e-04
Epoch 108: ReduceLROnPlateau reducing learning rate to 0.0003397653345018625.
98/98 [==============================] - 0s 2ms/step - loss: 8.5943e-04 - mae: 0.0220 - mse: 7.9530e-04 - val_loss: 9.2079e-04 - val_mae: 0.0227 - val_mse: 8.5463e-04 - lr: 6.7953e-04
Epoch 109/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5944e-04 - mae: 0.0220 - mse: 7.9482e-04 - val_loss: 9.0543e-04 - val_mae: 0.0226 - val_mse: 8.4038e-04 - lr: 3.3977e-04
Epoch 110/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5903e-04 - mae: 0.0220 - mse: 7.9429e-04 - val_loss: 9.0401e-04 - val_mae: 0.0226 - val_mse: 8.4001e-04 - lr: 3.3977e-04
Epoch 111/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5754e-04 - mae: 0.0220 - mse: 7.9412e-04 - val_loss: 9.0062e-04 - val_mae: 0.0226 - val_mse: 8.3755e-04 - lr: 3.3977e-04
Epoch 112/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5671e-04 - mae: 0.0220 - mse: 7.9277e-04 - val_loss: 9.0010e-04 - val_mae: 0.0227 - val_mse: 8.3767e-04 - lr: 3.3977e-04
Epoch 113/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5892e-04 - mae: 0.0220 - mse: 7.9527e-04 - val_loss: 9.1222e-04 - val_mae: 0.0226 - val_mse: 8.4732e-04 - lr: 3.3977e-04
Epoch 114/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5770e-04 - mae: 0.0220 - mse: 7.9448e-04 - val_loss: 8.9919e-04 - val_mae: 0.0227 - val_mse: 8.3623e-04 - lr: 3.3977e-04
Epoch 115/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5867e-04 - mae: 0.0220 - mse: 7.9508e-04 - val_loss: 9.0728e-04 - val_mae: 0.0226 - val_mse: 8.4312e-04 - lr: 3.3977e-04
Epoch 116/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5784e-04 - mae: 0.0220 - mse: 7.9353e-04 - val_loss: 9.0351e-04 - val_mae: 0.0226 - val_mse: 8.3941e-04 - lr: 3.3977e-04
Epoch 117/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5767e-04 - mae: 0.0220 - mse: 7.9466e-04 - val_loss: 9.0064e-04 - val_mae: 0.0226 - val_mse: 8.3737e-04 - lr: 3.3977e-04
Epoch 118/150
95/98 [============================>.] - ETA: 0s - loss: 8.5563e-04 - mae: 0.0219 - mse: 7.9165e-04
Epoch 118: ReduceLROnPlateau reducing learning rate to 0.00016988266725093126.
98/98 [==============================] - 0s 2ms/step - loss: 8.5607e-04 - mae: 0.0220 - mse: 7.9210e-04 - val_loss: 9.0032e-04 - val_mae: 0.0226 - val_mse: 8.3655e-04 - lr: 3.3977e-04
Epoch 119/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5502e-04 - mae: 0.0220 - mse: 7.9162e-04 - val_loss: 9.0511e-04 - val_mae: 0.0226 - val_mse: 8.4115e-04 - lr: 1.6988e-04
Epoch 120/150
98/98 [==============================] - 0s 3ms/step - loss: 8.5481e-04 - mae: 0.0219 - mse: 7.9104e-04 - val_loss: 9.0310e-04 - val_mae: 0.0226 - val_mse: 8.3917e-04 - lr: 1.6988e-04
Epoch 121/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5614e-04 - mae: 0.0220 - mse: 7.9321e-04 - val_loss: 9.0475e-04 - val_mae: 0.0226 - val_mse: 8.4104e-04 - lr: 1.6988e-04
Epoch 122/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5486e-04 - mae: 0.0220 - mse: 7.9183e-04 - val_loss: 9.0308e-04 - val_mae: 0.0226 - val_mse: 8.3956e-04 - lr: 1.6988e-04
Epoch 123/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5504e-04 - mae: 0.0220 - mse: 7.9184e-04 - val_loss: 8.9851e-04 - val_mae: 0.0226 - val_mse: 8.3595e-04 - lr: 1.6988e-04
Epoch 124/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5523e-04 - mae: 0.0220 - mse: 7.9227e-04 - val_loss: 8.9922e-04 - val_mae: 0.0226 - val_mse: 8.3631e-04 - lr: 1.6988e-04
Epoch 125/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5502e-04 - mae: 0.0220 - mse: 7.9212e-04 - val_loss: 8.9985e-04 - val_mae: 0.0226 - val_mse: 8.3670e-04 - lr: 1.6988e-04
Epoch 126/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5432e-04 - mae: 0.0220 - mse: 7.9096e-04 - val_loss: 9.0498e-04 - val_mae: 0.0226 - val_mse: 8.4079e-04 - lr: 1.6988e-04
Epoch 127/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5467e-04 - mae: 0.0219 - mse: 7.9117e-04 - val_loss: 8.9772e-04 - val_mae: 0.0226 - val_mse: 8.3488e-04 - lr: 1.6988e-04
Epoch 128/150
52/98 [==============>...............] - ETA: 0s - loss: 8.2622e-04 - mae: 0.0214 - mse: 7.6335e-04
Epoch 128: ReduceLROnPlateau reducing learning rate to 8.494133362546563e-05.
98/98 [==============================] - 0s 2ms/step - loss: 8.5393e-04 - mae: 0.0220 - mse: 7.9077e-04 - val_loss: 8.9883e-04 - val_mae: 0.0226 - val_mse: 8.3570e-04 - lr: 1.6988e-04
Epoch 129/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5464e-04 - mae: 0.0220 - mse: 7.9124e-04 - val_loss: 9.0168e-04 - val_mae: 0.0226 - val_mse: 8.3812e-04 - lr: 8.4941e-05
Epoch 130/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5365e-04 - mae: 0.0219 - mse: 7.9044e-04 - val_loss: 9.0005e-04 - val_mae: 0.0226 - val_mse: 8.3671e-04 - lr: 8.4941e-05
Epoch 131/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5392e-04 - mae: 0.0219 - mse: 7.9066e-04 - val_loss: 8.9979e-04 - val_mae: 0.0226 - val_mse: 8.3639e-04 - lr: 8.4941e-05
Epoch 132/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5371e-04 - mae: 0.0219 - mse: 7.9058e-04 - val_loss: 8.9901e-04 - val_mae: 0.0226 - val_mse: 8.3595e-04 - lr: 8.4941e-05
Epoch 133/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5426e-04 - mae: 0.0220 - mse: 7.9116e-04 - val_loss: 8.9821e-04 - val_mae: 0.0226 - val_mse: 8.3518e-04 - lr: 8.4941e-05
Epoch 134/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5388e-04 - mae: 0.0219 - mse: 7.9062e-04 - val_loss: 8.9965e-04 - val_mae: 0.0226 - val_mse: 8.3650e-04 - lr: 8.4941e-05
Epoch 135/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5452e-04 - mae: 0.0220 - mse: 7.9158e-04 - val_loss: 8.9875e-04 - val_mae: 0.0226 - val_mse: 8.3573e-04 - lr: 8.4941e-05
Epoch 136/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5341e-04 - mae: 0.0220 - mse: 7.9040e-04 - val_loss: 9.0142e-04 - val_mae: 0.0226 - val_mse: 8.3782e-04 - lr: 8.4941e-05
Epoch 137/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5401e-04 - mae: 0.0219 - mse: 7.9086e-04 - val_loss: 9.0216e-04 - val_mae: 0.0226 - val_mse: 8.3845e-04 - lr: 8.4941e-05
Epoch 138/150
54/98 [===============>..............] - ETA: 0s - loss: 8.6228e-04 - mae: 0.0221 - mse: 7.9906e-04
Epoch 138: ReduceLROnPlateau reducing learning rate to 4.2470666812732816e-05.
98/98 [==============================] - 0s 2ms/step - loss: 8.5393e-04 - mae: 0.0219 - mse: 7.9069e-04 - val_loss: 8.9927e-04 - val_mae: 0.0226 - val_mse: 8.3600e-04 - lr: 8.4941e-05
Epoch 139/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5327e-04 - mae: 0.0219 - mse: 7.9004e-04 - val_loss: 8.9840e-04 - val_mae: 0.0226 - val_mse: 8.3530e-04 - lr: 4.2471e-05
Epoch 140/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5313e-04 - mae: 0.0219 - mse: 7.9005e-04 - val_loss: 8.9974e-04 - val_mae: 0.0226 - val_mse: 8.3628e-04 - lr: 4.2471e-05
Epoch 141/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5326e-04 - mae: 0.0219 - mse: 7.8987e-04 - val_loss: 8.9906e-04 - val_mae: 0.0226 - val_mse: 8.3565e-04 - lr: 4.2471e-05
Epoch 142/150
98/98 [==============================] - 0s 1ms/step - loss: 8.5303e-04 - mae: 0.0219 - mse: 7.8970e-04 - val_loss: 8.9882e-04 - val_mae: 0.0226 - val_mse: 8.3546e-04 - lr: 4.2471e-05
Epoch 143/150
98/98 [==============================] - 0s 1ms/step - loss: 8.5304e-04 - mae: 0.0219 - mse: 7.8965e-04 - val_loss: 8.9767e-04 - val_mae: 0.0226 - val_mse: 8.3462e-04 - lr: 4.2471e-05
Epoch 144/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5313e-04 - mae: 0.0219 - mse: 7.8977e-04 - val_loss: 8.9857e-04 - val_mae: 0.0226 - val_mse: 8.3538e-04 - lr: 4.2471e-05
Epoch 145/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5303e-04 - mae: 0.0219 - mse: 7.8986e-04 - val_loss: 8.9938e-04 - val_mae: 0.0226 - val_mse: 8.3605e-04 - lr: 4.2471e-05
Epoch 146/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5346e-04 - mae: 0.0219 - mse: 7.9015e-04 - val_loss: 9.0017e-04 - val_mae: 0.0226 - val_mse: 8.3680e-04 - lr: 4.2471e-05
Epoch 147/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5304e-04 - mae: 0.0219 - mse: 7.8982e-04 - val_loss: 8.9887e-04 - val_mae: 0.0226 - val_mse: 8.3568e-04 - lr: 4.2471e-05
Epoch 148/150
51/98 [==============>...............] - ETA: 0s - loss: 8.4613e-04 - mae: 0.0218 - mse: 7.8288e-04
Epoch 148: ReduceLROnPlateau reducing learning rate to 2.1235333406366408e-05.
98/98 [==============================] - 0s 2ms/step - loss: 8.5298e-04 - mae: 0.0219 - mse: 7.8973e-04 - val_loss: 8.9902e-04 - val_mae: 0.0226 - val_mse: 8.3577e-04 - lr: 4.2471e-05
Epoch 149/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5286e-04 - mae: 0.0219 - mse: 7.8968e-04 - val_loss: 8.9907e-04 - val_mae: 0.0226 - val_mse: 8.3580e-04 - lr: 2.1235e-05
Epoch 150/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5286e-04 - mae: 0.0219 - mse: 7.8957e-04 - val_loss: 8.9906e-04 - val_mae: 0.0226 - val_mse: 8.3583e-04 - lr: 2.1235e-05
>Saved ../trained_models/models_segments_overlap_adam_0.08697992935283343LR_[70]HN_40BS_10P_val_mseM_150epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
98/98 [==============================] - 1s 3ms/step - loss: 0.0648 - mae: 0.0391 - mse: 0.0021 - val_loss: 0.0021 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0870
Epoch 2/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 0.0870
Epoch 3/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0870
Epoch 4/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0870
Epoch 5/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0395 - val_mse: 0.0022 - lr: 0.0870
Epoch 6/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0870
Epoch 7/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0024 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0870
Epoch 8/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0027 - mae: 0.0396 - mse: 0.0021 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0870
Epoch 9/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0870
Epoch 10/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0870
Epoch 11/150
67/98 [===================>..........] - ETA: 0s - loss: 0.0021 - mae: 0.0381 - mse: 0.0020
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0434899628162384.
98/98 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0870
Epoch 12/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0435
Epoch 13/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0435
Epoch 14/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0435
Epoch 15/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0435
Epoch 16/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0435
Epoch 17/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0435
Epoch 18/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0435
Epoch 19/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0435
Epoch 20/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0435
Epoch 21/150
70/98 [====================>.........] - ETA: 0s - loss: 0.0020 - mae: 0.0382 - mse: 0.0020
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0217449814081192.
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0435
Epoch 22/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0217
Epoch 23/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0217
Epoch 24/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0217
Epoch 25/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0217
Epoch 26/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0217
Epoch 27/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0217
Epoch 28/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0217
Epoch 29/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0217
Epoch 30/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0217
Epoch 31/150
64/98 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0108724907040596.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0389 - val_mse: 0.0020 - lr: 0.0217
Epoch 32/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0109
Epoch 33/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0109
Epoch 34/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0109
Epoch 35/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0109
Epoch 36/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0109
Epoch 37/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0109
Epoch 38/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0109
Epoch 39/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0109
Epoch 40/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0109
Epoch 41/150
70/98 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0054362453520298.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0109
Epoch 42/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 43/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0054
Epoch 44/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0054
Epoch 45/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0054
Epoch 46/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 47/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 48/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 49/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0054
Epoch 50/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 51/150
64/98 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0027181226760149.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0054
Epoch 52/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0027
Epoch 53/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0027
Epoch 54/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0027
Epoch 55/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0027
Epoch 56/150===========================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 8.4941e-05
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0027
Epoch 57/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0027
Epoch 58/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0027
Epoch 59/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0027
Epoch 60/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0027
Epoch 61/150
72/98 [=====================>........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00135906133800745.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0027
Epoch 62/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 63/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 64/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 65/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 66/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 67/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 68/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 69/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 70/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 71/150
62/98 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 71: ReduceLROnPlateau reducing learning rate to 0.000679530669003725.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 72/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.7953e-04
Epoch 73/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7953e-04
Epoch 74/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7953e-04
Epoch 75/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.7953e-04
Epoch 76/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.7953e-04
Epoch 77/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7953e-04
Epoch 78/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.7953e-04
Epoch 79/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7953e-04
Epoch 80/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7953e-04
Epoch 81/150
50/98 [==============>...............] - ETA: 0s - loss: 0.0020 - mae: 0.0384 - mse: 0.0020
Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0003397653345018625.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.7953e-04
Epoch 82/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.3977e-04
Epoch 83/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.3977e-04
Epoch 84/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.3977e-04
Epoch 85/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.3977e-04
Epoch 86/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.3977e-04
Epoch 87/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.3977e-04
Epoch 88/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.3977e-04
Epoch 89/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.3977e-04
Epoch 90/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.3977e-04
Epoch 91/150
98/98 [==============================] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 91: ReduceLROnPlateau reducing learning rate to 0.00016988266725093126.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.3977e-04
Epoch 92/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.6988e-04
Epoch 93/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.6988e-04
Epoch 94/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.6988e-04
Epoch 95/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.6988e-04
Epoch 96/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.6988e-04
Epoch 97/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6988e-04
Epoch 98/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.6988e-04
Epoch 99/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.6988e-04
Epoch 100/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6988e-04
Epoch 101/150
50/98 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.0019
Epoch 101: ReduceLROnPlateau reducing learning rate to 8.494133362546563e-05.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6988e-04
Epoch 102/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.4941e-05
Epoch 103/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.4941e-05
Epoch 104/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.4941e-05
Epoch 105/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 8.4941e-05
Epoch 106/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 8.4941e-05
Epoch 107/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 8.4941e-05
Epoch 108/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 8.4941e-05
Epoch 109/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 8.4941e-05
Epoch 110/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 8.4941e-05
Epoch 111/150
53/98 [===============>..............] - ETA: 0s - loss: 0.0020 - mae: 0.0384 - mse: 0.0020
Epoch 111: ReduceLROnPlateau reducing learning rate to 4.2470666812732816e-05.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.4941e-05
Epoch 112/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2471e-05
Epoch 113/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2471e-05
Epoch 114/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2471e-05
Epoch 115/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2471e-05
Epoch 116/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.2471e-05
Epoch 117/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.2471e-05
Epoch 118/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2471e-05
Epoch 119/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2471e-05
Epoch 120/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2471e-05
Epoch 121/150
66/98 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 121: ReduceLROnPlateau reducing learning rate to 2.1235333406366408e-05.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2471e-05
Epoch 122/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 123/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 124/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 125/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.1235e-05
Epoch 126/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 127/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.1235e-05
Epoch 128/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.1235e-05
Epoch 129/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.1235e-05
Epoch 130/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 131/150
65/98 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 131: ReduceLROnPlateau reducing learning rate to 1.0617666703183204e-05.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 132/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
Epoch 133/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0618e-05
Epoch 134/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
Epoch 135/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
Epoch 136/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
Epoch 137/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
Epoch 138/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
Epoch 139/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
Epoch 140/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
Epoch 141/150
62/98 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 141: ReduceLROnPlateau reducing learning rate to 1e-05.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0618e-05
Epoch 142/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 143/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 144/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 145/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 146/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 147/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 148/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 149/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 150/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_adam_0.08697992935283343LR_[70]HN_40BS_10P_val_mseM_150epochs/model_5.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191732-0fnqzb3d\files\model-best)... Done. 0.0s
Epoch 37/150=========================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0109
Epoch 38/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0109
Epoch 39/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0109
Epoch 40/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0109
Epoch 41/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0109
Epoch 42/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0109
Epoch 43/150
93/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0054362453520298.
98/98 [==============================] - 0s 982us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0109
Epoch 44/150
98/98 [==============================] - 0s 967us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0054
Epoch 45/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 46/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 47/150
98/98 [==============================] - 0s 994us/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0054
Epoch 48/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0054
Epoch 49/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 50/150
98/98 [==============================] - 0s 969us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 51/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0054
Epoch 52/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 53/150
87/98 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0027181226760149.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 54/150
98/98 [==============================] - 0s 969us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0027
Epoch 55/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0027
Epoch 56/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0027
Epoch 57/150
98/98 [==============================] - 0s 969us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0027
Epoch 58/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0027
Epoch 59/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0027
Epoch 60/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0027
Epoch 61/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0027
Epoch 62/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0027
Epoch 63/150
73/98 [=====================>........] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00135906133800745.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0027
Epoch 64/150
98/98 [==============================] - 0s 988us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 65/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 66/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 67/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 68/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 69/150
98/98 [==============================] - 0s 984us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 70/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 71/150
98/98 [==============================] - 0s 987us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 72/150
98/98 [==============================] - 0s 893us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 73/150
98/98 [==============================] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 73: ReduceLROnPlateau reducing learning rate to 0.000679530669003725.
98/98 [==============================] - 0s 968us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 74/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.7953e-04
Epoch 75/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7953e-04
Epoch 76/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7953e-04
Epoch 77/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.7953e-04
Epoch 78/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.7953e-04
Epoch 79/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7953e-04
Epoch 80/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7953e-04
Epoch 81/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.7953e-04
Epoch 82/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.7953e-04
Epoch 83/150
72/98 [=====================>........] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0003397653345018625.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.7953e-04
Epoch 84/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.3977e-04
Epoch 85/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.3977e-04
Epoch 86/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.3977e-04
Epoch 87/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.3977e-04
Epoch 88/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.3977e-04
Epoch 89/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.3977e-04
Epoch 90/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.3977e-04
Epoch 91/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.3977e-04
Epoch 92/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.3977e-04
Epoch 93/150
61/98 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 93: ReduceLROnPlateau reducing learning rate to 0.00016988266725093126.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.3977e-04
Epoch 94/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6988e-04
Epoch 95/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.6988e-04
Epoch 96/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.6988e-04
Epoch 97/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.6988e-04
Epoch 98/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6988e-04
Epoch 99/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6988e-04
Epoch 100/150
98/98 [==============================] - 0s 991us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6988e-04
Epoch 101/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.6988e-04
Epoch 102/150
98/98 [==============================] - 0s 994us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6988e-04
Epoch 103/150
 1/98 [..............................] - ETA: 1s - loss: 0.0021 - mae: 0.0401 - mse: 0.0021
Epoch 103: ReduceLROnPlateau reducing learning rate to 8.494133362546563e-05.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.6988e-04
Epoch 104/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.4941e-05
Epoch 105/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.4941e-05
Epoch 106/150
98/98 [==============================] - 0s 976us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.4941e-05
Epoch 107/150
98/98 [==============================] - 0s 967us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 8.4941e-05
Epoch 108/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 8.4941e-05
Epoch 109/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 8.4941e-05
Epoch 110/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 8.4941e-05
Epoch 111/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 8.4941e-05
Epoch 112/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.4941e-05
Epoch 113/150
88/98 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 113: ReduceLROnPlateau reducing learning rate to 4.2470666812732816e-05.
98/98 [==============================] - 0s 922us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.4941e-05
Epoch 114/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2471e-05
Epoch 115/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2471e-05
Epoch 116/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2471e-05
Epoch 117/150
98/98 [==============================] - 0s 968us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.2471e-05
Epoch 118/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2471e-05
Epoch 119/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2471e-05
Epoch 120/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2471e-05
Epoch 121/150
98/98 [==============================] - 0s 950us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2471e-05
Epoch 122/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.2471e-05
Epoch 123/150
93/98 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 123: ReduceLROnPlateau reducing learning rate to 2.1235333406366408e-05.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.2471e-05
Epoch 124/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.1235e-05
Epoch 125/150
98/98 [==============================] - 0s 972us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.1235e-05
Epoch 126/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 127/150
98/98 [==============================] - 0s 974us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 128/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 129/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 130/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 131/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 132/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.1235e-05
Epoch 133/150
58/98 [================>.............] - ETA: 0s - loss: 0.0020 - mae: 0.0384 - mse: 0.0020
Epoch 133: ReduceLROnPlateau reducing learning rate to 1.0617666703183204e-05.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.1235e-05
Epoch 134/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0618e-05
Epoch 135/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0618e-05
Epoch 136/150
98/98 [==============================] - 0s 971us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0618e-05
Epoch 137/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0618e-05
Epoch 138/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0618e-05
Epoch 139/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0618e-05
Epoch 140/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0618e-05
Epoch 141/150
98/98 [==============================] - 0s 989us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0618e-05
Epoch 142/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0618e-05
Epoch 143/150
 1/98 [..............................] - ETA: 1s - loss: 0.0020 - mae: 0.0378 - mse: 0.0020
Epoch 143: ReduceLROnPlateau reducing learning rate to 1e-05.
98/98 [==============================] - 0s 1000us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0618e-05
Epoch 144/150
98/98 [==============================] - 0s 972us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 145/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 146/150
98/98 [==============================] - 0s 991us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 147/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 148/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 149/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 150/150
98/98 [==============================] - 0s 934us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_adam_0.08697992935283343LR_[70]HN_40BS_10P_val_mseM_150epochs/model_7.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0652 - mae: 0.0475 - mse: 0.0042 - val_loss: 0.0023 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 0.0870
Epoch 2/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0024 - mae: 0.0390 - mse: 0.0021 - val_loss: 0.0029 - val_mae: 0.0445 - val_mse: 0.0029 - lr: 0.0870
Epoch 3/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0394 - val_mse: 0.0021 - lr: 0.0870
Epoch 4/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0375 - mse: 0.0019 - val_loss: 0.0030 - val_mae: 0.0417 - val_mse: 0.0025 - lr: 0.0870
Epoch 5/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0371 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 0.0870
Epoch 6/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0346 - mse: 0.0017 - val_loss: 0.0018 - val_mae: 0.0326 - val_mse: 0.0015 - lr: 0.0870
Epoch 7/150
98/98 [==============================] - 0s 975us/step - loss: 0.0018 - mae: 0.0315 - mse: 0.0015 - val_loss: 0.0027 - val_mae: 0.0350 - val_mse: 0.0017 - lr: 0.0870
Epoch 8/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0313 - mse: 0.0015 - val_loss: 0.0016 - val_mae: 0.0265 - val_mse: 0.0011 - lr: 0.0870
Epoch 9/150
98/98 [==============================] - 0s 993us/step - loss: 0.0015 - mae: 0.0273 - mse: 0.0012 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0022 - lr: 0.0870
Epoch 10/150
98/98 [==============================] - 0s 996us/step - loss: 0.0013 - mae: 0.0267 - mse: 0.0011 - val_loss: 0.0015 - val_mae: 0.0284 - val_mse: 0.0013 - lr: 0.0870
Epoch 11/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0283 - mse: 0.0012 - val_loss: 0.0018 - val_mae: 0.0318 - val_mse: 0.0015 - lr: 0.0870
Epoch 12/150
98/98 [==============================] - 0s 959us/step - loss: 0.0012 - mae: 0.0254 - mse: 0.0010 - val_loss: 0.0019 - val_mae: 0.0326 - val_mse: 0.0016 - lr: 0.0870
Epoch 13/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0266 - mse: 0.0011 - val_loss: 0.0035 - val_mae: 0.0475 - val_mse: 0.0030 - lr: 0.0870
Epoch 14/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0323 - mse: 0.0016 - val_loss: 0.0038 - val_mae: 0.0502 - val_mse: 0.0036 - lr: 0.0870
Epoch 15/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0275 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0254 - val_mse: 0.0010 - lr: 0.0870
Epoch 16/150
98/98 [==============================] - 0s 980us/step - loss: 0.0013 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0015 - val_mae: 0.0291 - val_mse: 0.0013 - lr: 0.0870
Epoch 17/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0254 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0237 - val_mse: 9.0452e-04 - lr: 0.0870
Epoch 18/150
98/98 [==============================] - 0s 998us/step - loss: 0.0012 - mae: 0.0255 - mse: 0.0010 - val_loss: 0.0014 - val_mae: 0.0286 - val_mse: 0.0013 - lr: 0.0870
Epoch 19/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0253 - mse: 0.0010 - val_loss: 0.0040 - val_mae: 0.0497 - val_mse: 0.0035 - lr: 0.0870
Epoch 20/150
98/98 [==============================] - 0s 978us/step - loss: 0.0013 - mae: 0.0252 - mse: 0.0010 - val_loss: 0.0014 - val_mae: 0.0298 - val_mse: 0.0013 - lr: 0.0870
Epoch 21/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0260 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0269 - val_mse: 0.0011 - lr: 0.0870
Epoch 22/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0246 - mse: 9.7758e-04 - val_loss: 0.0010 - val_mae: 0.0234 - val_mse: 8.8789e-04 - lr: 0.0870
Epoch 23/150
98/98 [==============================] - 0s 988us/step - loss: 0.0012 - mae: 0.0250 - mse: 9.8873e-04 - val_loss: 0.0016 - val_mae: 0.0283 - val_mse: 0.0012 - lr: 0.0870
Epoch 24/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0251 - mse: 9.8732e-04 - val_loss: 0.0011 - val_mae: 0.0252 - val_mse: 9.8502e-04 - lr: 0.0870
Epoch 25/150
98/98 [==============================] - 0s 969us/step - loss: 0.0011 - mae: 0.0244 - mse: 9.3930e-04 - val_loss: 0.0013 - val_mae: 0.0242 - val_mse: 9.3310e-04 - lr: 0.0870
Epoch 26/150
98/98 [==============================] - 0s 887us/step - loss: 0.0011 - mae: 0.0244 - mse: 9.4588e-04 - val_loss: 0.0012 - val_mae: 0.0263 - val_mse: 0.0011 - lr: 0.0870
Epoch 27/150
98/98 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0240 - mse: 9.1626e-04
Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0434899628162384.
98/98 [==============================] - 0s 965us/step - loss: 0.0011 - mae: 0.0240 - mse: 9.1626e-04 - val_loss: 0.0020 - val_mae: 0.0340 - val_mse: 0.0018 - lr: 0.0870
Epoch 28/150
98/98 [==============================] - 0s 1ms/step - loss: 9.8545e-04 - mae: 0.0227 - mse: 8.4043e-04 - val_loss: 0.0011 - val_mae: 0.0255 - val_mse: 0.0010 - lr: 0.0435
Epoch 29/150
98/98 [==============================] - 0s 968us/step - loss: 9.8611e-04 - mae: 0.0228 - mse: 8.4461e-04 - val_loss: 0.0011 - val_mae: 0.0247 - val_mse: 9.4766e-04 - lr: 0.0435
Epoch 30/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0237 - mse: 8.9632e-04 - val_loss: 0.0011 - val_mae: 0.0250 - val_mse: 9.6426e-04 - lr: 0.0435
Epoch 31/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6600e-04 - mae: 0.0228 - mse: 8.4062e-04 - val_loss: 0.0010 - val_mae: 0.0244 - val_mse: 9.3623e-04 - lr: 0.0435
Epoch 32/150
98/98 [==============================] - 0s 1ms/step - loss: 9.5178e-04 - mae: 0.0226 - mse: 8.3529e-04 - val_loss: 9.2761e-04 - val_mae: 0.0213 - val_mse: 7.6223e-04 - lr: 0.0435
Epoch 33/150
98/98 [==============================] - 0s 2ms/step - loss: 9.3840e-04 - mae: 0.0225 - mse: 8.2209e-04 - val_loss: 8.7916e-04 - val_mae: 0.0211 - val_mse: 7.5612e-04 - lr: 0.0435
Epoch 34/150
98/98 [==============================] - 0s 1ms/step - loss: 9.1094e-04 - mae: 0.0221 - mse: 8.0109e-04 - val_loss: 0.0012 - val_mae: 0.0274 - val_mse: 0.0012 - lr: 0.0435
Epoch 35/150
98/98 [==============================] - 0s 1ms/step - loss: 9.3856e-04 - mae: 0.0225 - mse: 8.2202e-04 - val_loss: 8.7174e-04 - val_mae: 0.0220 - val_mse: 7.8702e-04 - lr: 0.0435
Epoch 36/150
98/98 [==============================] - 0s 1ms/step - loss: 9.0627e-04 - mae: 0.0221 - mse: 7.9575e-04 - val_loss: 9.3388e-04 - val_mae: 0.0223 - val_mse: 7.7868e-04 - lr: 0.0435
Epoch 37/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0267 - mse: 0.0011 - val_loss: 9.9452e-04 - val_mae: 0.0240 - val_mse: 8.9387e-04 - lr: 0.0435
Epoch 38/150
98/98 [==============================] - 0s 990us/step - loss: 9.1523e-04 - mae: 0.0220 - mse: 7.9533e-04 - val_loss: 9.1233e-04 - val_mae: 0.0227 - val_mse: 8.1167e-04 - lr: 0.0435
Epoch 39/150
98/98 [==============================] - 0s 981us/step - loss: 0.0010 - mae: 0.0232 - mse: 8.7048e-04 - val_loss: 0.0010 - val_mae: 0.0238 - val_mse: 9.0411e-04 - lr: 0.0435
Epoch 40/150
98/98 [==============================] - 0s 976us/step - loss: 9.1631e-04 - mae: 0.0219 - mse: 7.8948e-04 - val_loss: 0.0014 - val_mae: 0.0294 - val_mse: 0.0013 - lr: 0.0435
Epoch 41/150
98/98 [==============================] - 0s 1ms/step - loss: 9.9253e-04 - mae: 0.0230 - mse: 8.5111e-04 - val_loss: 0.0011 - val_mae: 0.0212 - val_mse: 7.5449e-04 - lr: 0.0435
Epoch 42/150
92/98 [===========================>..] - ETA: 0s - loss: 9.4486e-04 - mae: 0.0216 - mse: 7.6889e-04
Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0217449814081192.
98/98 [==============================] - 0s 986us/step - loss: 9.4081e-04 - mae: 0.0216 - mse: 7.6842e-04 - val_loss: 0.0013 - val_mae: 0.0283 - val_mse: 0.0012 - lr: 0.0435
Epoch 43/150
98/98 [==============================] - 0s 1ms/step - loss: 8.9619e-04 - mae: 0.0216 - mse: 7.7848e-04 - val_loss: 8.4746e-04 - val_mae: 0.0210 - val_mse: 7.3306e-04 - lr: 0.0217
Epoch 44/150
98/98 [==============================] - 0s 2ms/step - loss: 8.5730e-04 - mae: 0.0213 - mse: 7.4488e-04 - val_loss: 9.0578e-04 - val_mae: 0.0222 - val_mse: 8.1058e-04 - lr: 0.0217
Epoch 45/150
98/98 [==============================] - 0s 1ms/step - loss: 8.3262e-04 - mae: 0.0209 - mse: 7.2835e-04 - val_loss: 8.3562e-04 - val_mae: 0.0205 - val_mse: 7.2196e-04 - lr: 0.0217
Epoch 46/150
98/98 [==============================] - 0s 1ms/step - loss: 8.4115e-04 - mae: 0.0210 - mse: 7.3934e-04 - val_loss: 8.5425e-04 - val_mae: 0.0216 - val_mse: 7.4527e-04 - lr: 0.0217
Epoch 47/150
98/98 [==============================] - 0s 1ms/step - loss: 8.0660e-04 - mae: 0.0205 - mse: 7.0508e-04 - val_loss: 8.1092e-04 - val_mae: 0.0208 - val_mse: 6.9966e-04 - lr: 0.0217
Epoch 48/150
98/98 [==============================] - 0s 1ms/step - loss: 7.9157e-04 - mae: 0.0202 - mse: 6.8880e-04 - val_loss: 9.3433e-04 - val_mae: 0.0233 - val_mse: 8.3188e-04 - lr: 0.0217
Epoch 49/150
98/98 [==============================] - 0s 1ms/step - loss: 8.1277e-04 - mae: 0.0206 - mse: 7.1312e-04 - val_loss: 8.6440e-04 - val_mae: 0.0220 - val_mse: 7.6047e-04 - lr: 0.0217
Epoch 50/150
98/98 [==============================] - 0s 972us/step - loss: 8.2842e-04 - mae: 0.0210 - mse: 7.2407e-04 - val_loss: 0.0010 - val_mae: 0.0250 - val_mse: 9.5752e-04 - lr: 0.0217
Epoch 51/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2928e-04 - mae: 0.0210 - mse: 7.2712e-04 - val_loss: 7.7315e-04 - val_mae: 0.0200 - val_mse: 6.7501e-04 - lr: 0.0217
Epoch 52/150
82/98 [========================>.....] - ETA: 0s - loss: 8.3040e-04 - mae: 0.0210 - mse: 7.2909e-04
Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0108724907040596.
Epoch 37/150=========================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
Epoch 98/150=========================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
98/98 [==============================] - 0s 1ms/step - loss: 6.6323e-04 - mae: 0.0181 - mse: 5.7612e-04 - val_loss: 6.8366e-04 - val_mae: 0.0186 - val_mse: 5.9734e-04 - lr: 6.7953e-04
Epoch 99/150
98/98 [==============================] - 0s 972us/step - loss: 6.6450e-04 - mae: 0.0182 - mse: 5.7778e-04 - val_loss: 6.8034e-04 - val_mae: 0.0186 - val_mse: 5.9386e-04 - lr: 6.7953e-04
Epoch 100/150
98/98 [==============================] - 0s 1ms/step - loss: 6.6189e-04 - mae: 0.0182 - mse: 5.7639e-04 - val_loss: 6.8690e-04 - val_mae: 0.0190 - val_mse: 5.9799e-04 - lr: 6.7953e-04
Epoch 101/150
98/98 [==============================] - 0s 1ms/step - loss: 6.6946e-04 - mae: 0.0183 - mse: 5.7925e-04 - val_loss: 6.8863e-04 - val_mae: 0.0185 - val_mse: 5.9974e-04 - lr: 6.7953e-04
Epoch 102/150
98/98 [==============================] - 0s 983us/step - loss: 6.6188e-04 - mae: 0.0181 - mse: 5.7336e-04 - val_loss: 6.7563e-04 - val_mae: 0.0185 - val_mse: 5.8676e-04 - lr: 6.7953e-04
Epoch 103/150
98/98 [==============================] - 0s 946us/step - loss: 6.6016e-04 - mae: 0.0181 - mse: 5.7505e-04 - val_loss: 6.7945e-04 - val_mae: 0.0186 - val_mse: 5.9391e-04 - lr: 6.7953e-04
Epoch 104/150
98/98 [==============================] - 0s 1ms/step - loss: 6.6075e-04 - mae: 0.0181 - mse: 5.7421e-04 - val_loss: 6.8814e-04 - val_mae: 0.0186 - val_mse: 6.0231e-04 - lr: 6.7953e-04
Epoch 105/150
98/98 [==============================] - 0s 1ms/step - loss: 6.6166e-04 - mae: 0.0182 - mse: 5.7523e-04 - val_loss: 6.7843e-04 - val_mae: 0.0185 - val_mse: 5.9308e-04 - lr: 6.7953e-04
Epoch 106/150
98/98 [==============================] - 0s 1ms/step - loss: 6.6200e-04 - mae: 0.0182 - mse: 5.7711e-04 - val_loss: 6.7502e-04 - val_mae: 0.0185 - val_mse: 5.8686e-04 - lr: 6.7953e-04
Epoch 107/150
91/98 [==========================>...] - ETA: 0s - loss: 6.6758e-04 - mae: 0.0182 - mse: 5.8065e-04
Epoch 107: ReduceLROnPlateau reducing learning rate to 0.0003397653345018625.
98/98 [==============================] - 0s 959us/step - loss: 6.6196e-04 - mae: 0.0181 - mse: 5.7505e-04 - val_loss: 6.7661e-04 - val_mae: 0.0186 - val_mse: 5.8979e-04 - lr: 6.7953e-04
Epoch 108/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5862e-04 - mae: 0.0181 - mse: 5.7209e-04 - val_loss: 6.7590e-04 - val_mae: 0.0186 - val_mse: 5.8917e-04 - lr: 3.3977e-04
Epoch 109/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5790e-04 - mae: 0.0181 - mse: 5.7159e-04 - val_loss: 6.8238e-04 - val_mae: 0.0186 - val_mse: 5.9794e-04 - lr: 3.3977e-04
Epoch 110/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5659e-04 - mae: 0.0181 - mse: 5.7081e-04 - val_loss: 6.8919e-04 - val_mae: 0.0185 - val_mse: 6.0398e-04 - lr: 3.3977e-04
Epoch 111/150
98/98 [==============================] - 0s 1ms/step - loss: 6.6008e-04 - mae: 0.0181 - mse: 5.7431e-04 - val_loss: 6.8278e-04 - val_mae: 0.0185 - val_mse: 5.9744e-04 - lr: 3.3977e-04
Epoch 112/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5717e-04 - mae: 0.0180 - mse: 5.7120e-04 - val_loss: 6.7512e-04 - val_mae: 0.0186 - val_mse: 5.8880e-04 - lr: 3.3977e-04
Epoch 113/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5742e-04 - mae: 0.0181 - mse: 5.7185e-04 - val_loss: 6.7649e-04 - val_mae: 0.0185 - val_mse: 5.9083e-04 - lr: 3.3977e-04
Epoch 114/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5661e-04 - mae: 0.0181 - mse: 5.7105e-04 - val_loss: 6.7245e-04 - val_mae: 0.0184 - val_mse: 5.8397e-04 - lr: 3.3977e-04
Epoch 115/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5728e-04 - mae: 0.0180 - mse: 5.7139e-04 - val_loss: 6.7566e-04 - val_mae: 0.0186 - val_mse: 5.9003e-04 - lr: 3.3977e-04
Epoch 116/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5647e-04 - mae: 0.0180 - mse: 5.7033e-04 - val_loss: 6.7548e-04 - val_mae: 0.0185 - val_mse: 5.8971e-04 - lr: 3.3977e-04
Epoch 117/150
96/98 [============================>.] - ETA: 0s - loss: 6.5773e-04 - mae: 0.0181 - mse: 5.7084e-04
Epoch 117: ReduceLROnPlateau reducing learning rate to 0.00016988266725093126.
98/98 [==============================] - 0s 967us/step - loss: 6.5530e-04 - mae: 0.0180 - mse: 5.6843e-04 - val_loss: 6.8403e-04 - val_mae: 0.0186 - val_mse: 5.9933e-04 - lr: 3.3977e-04
Epoch 118/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5519e-04 - mae: 0.0180 - mse: 5.7001e-04 - val_loss: 6.7692e-04 - val_mae: 0.0185 - val_mse: 5.9158e-04 - lr: 1.6988e-04
Epoch 119/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5469e-04 - mae: 0.0180 - mse: 5.6850e-04 - val_loss: 6.8014e-04 - val_mae: 0.0185 - val_mse: 5.9507e-04 - lr: 1.6988e-04
Epoch 120/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5510e-04 - mae: 0.0180 - mse: 5.7011e-04 - val_loss: 6.7308e-04 - val_mae: 0.0186 - val_mse: 5.8697e-04 - lr: 1.6988e-04
Epoch 121/150
98/98 [==============================] - 0s 985us/step - loss: 6.5528e-04 - mae: 0.0180 - mse: 5.6939e-04 - val_loss: 6.7449e-04 - val_mae: 0.0185 - val_mse: 5.8879e-04 - lr: 1.6988e-04
Epoch 122/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5449e-04 - mae: 0.0180 - mse: 5.6935e-04 - val_loss: 6.7367e-04 - val_mae: 0.0185 - val_mse: 5.8787e-04 - lr: 1.6988e-04
Epoch 123/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5463e-04 - mae: 0.0180 - mse: 5.6907e-04 - val_loss: 6.7332e-04 - val_mae: 0.0185 - val_mse: 5.8727e-04 - lr: 1.6988e-04
Epoch 124/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5393e-04 - mae: 0.0180 - mse: 5.6779e-04 - val_loss: 6.7765e-04 - val_mae: 0.0185 - val_mse: 5.9229e-04 - lr: 1.6988e-04
Epoch 125/150
98/98 [==============================] - 0s 994us/step - loss: 6.5402e-04 - mae: 0.0180 - mse: 5.6785e-04 - val_loss: 6.8046e-04 - val_mae: 0.0185 - val_mse: 5.9559e-04 - lr: 1.6988e-04
Epoch 126/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5412e-04 - mae: 0.0180 - mse: 5.6899e-04 - val_loss: 6.7526e-04 - val_mae: 0.0184 - val_mse: 5.8952e-04 - lr: 1.6988e-04
Epoch 127/150
84/98 [========================>.....] - ETA: 0s - loss: 6.5709e-04 - mae: 0.0180 - mse: 5.7159e-04
Epoch 127: ReduceLROnPlateau reducing learning rate to 8.494133362546563e-05.
98/98 [==============================] - 0s 1ms/step - loss: 6.5403e-04 - mae: 0.0180 - mse: 5.6852e-04 - val_loss: 6.7710e-04 - val_mae: 0.0185 - val_mse: 5.9159e-04 - lr: 1.6988e-04
Epoch 128/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5315e-04 - mae: 0.0180 - mse: 5.6751e-04 - val_loss: 6.7336e-04 - val_mae: 0.0184 - val_mse: 5.8729e-04 - lr: 8.4941e-05
Epoch 129/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5379e-04 - mae: 0.0180 - mse: 5.6779e-04 - val_loss: 6.7658e-04 - val_mae: 0.0184 - val_mse: 5.9078e-04 - lr: 8.4941e-05
Epoch 130/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5385e-04 - mae: 0.0180 - mse: 5.6775e-04 - val_loss: 6.7621e-04 - val_mae: 0.0184 - val_mse: 5.9047e-04 - lr: 8.4941e-05
Epoch 131/150
98/98 [==============================] - 0s 971us/step - loss: 6.5317e-04 - mae: 0.0180 - mse: 5.6706e-04 - val_loss: 6.7622e-04 - val_mae: 0.0184 - val_mse: 5.9043e-04 - lr: 8.4941e-05
Epoch 132/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5312e-04 - mae: 0.0180 - mse: 5.6764e-04 - val_loss: 6.7393e-04 - val_mae: 0.0185 - val_mse: 5.8798e-04 - lr: 8.4941e-05
Epoch 133/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5325e-04 - mae: 0.0180 - mse: 5.6727e-04 - val_loss: 6.7407e-04 - val_mae: 0.0184 - val_mse: 5.8789e-04 - lr: 8.4941e-05
Epoch 134/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5307e-04 - mae: 0.0180 - mse: 5.6706e-04 - val_loss: 6.7414e-04 - val_mae: 0.0185 - val_mse: 5.8830e-04 - lr: 8.4941e-05
Epoch 135/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5377e-04 - mae: 0.0180 - mse: 5.6732e-04 - val_loss: 6.7373e-04 - val_mae: 0.0185 - val_mse: 5.8760e-04 - lr: 8.4941e-05
Epoch 136/150
98/98 [==============================] - 0s 976us/step - loss: 6.5299e-04 - mae: 0.0180 - mse: 5.6717e-04 - val_loss: 6.7357e-04 - val_mae: 0.0185 - val_mse: 5.8786e-04 - lr: 8.4941e-05
Epoch 137/150
85/98 [=========================>....] - ETA: 0s - loss: 6.4812e-04 - mae: 0.0180 - mse: 5.6225e-04
Epoch 137: ReduceLROnPlateau reducing learning rate to 4.2470666812732816e-05.
98/98 [==============================] - 0s 1ms/step - loss: 6.5327e-04 - mae: 0.0180 - mse: 5.6742e-04 - val_loss: 6.7378e-04 - val_mae: 0.0184 - val_mse: 5.8800e-04 - lr: 8.4941e-05
Epoch 138/150
98/98 [==============================] - 0s 969us/step - loss: 6.5245e-04 - mae: 0.0179 - mse: 5.6680e-04 - val_loss: 6.7340e-04 - val_mae: 0.0185 - val_mse: 5.8772e-04 - lr: 4.2471e-05
Epoch 139/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5240e-04 - mae: 0.0180 - mse: 5.6653e-04 - val_loss: 6.7457e-04 - val_mae: 0.0184 - val_mse: 5.8877e-04 - lr: 4.2471e-05
Epoch 140/150
98/98 [==============================] - 0s 983us/step - loss: 6.5249e-04 - mae: 0.0179 - mse: 5.6699e-04 - val_loss: 6.7423e-04 - val_mae: 0.0185 - val_mse: 5.8846e-04 - lr: 4.2471e-05
Epoch 141/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5250e-04 - mae: 0.0180 - mse: 5.6654e-04 - val_loss: 6.7451e-04 - val_mae: 0.0184 - val_mse: 5.8856e-04 - lr: 4.2471e-05
Epoch 142/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5244e-04 - mae: 0.0180 - mse: 5.6644e-04 - val_loss: 6.7408e-04 - val_mae: 0.0184 - val_mse: 5.8814e-04 - lr: 4.2471e-05
Epoch 143/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5236e-04 - mae: 0.0180 - mse: 5.6657e-04 - val_loss: 6.7333e-04 - val_mae: 0.0185 - val_mse: 5.8727e-04 - lr: 4.2471e-05
Epoch 144/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5230e-04 - mae: 0.0180 - mse: 5.6632e-04 - val_loss: 6.7320e-04 - val_mae: 0.0184 - val_mse: 5.8698e-04 - lr: 4.2471e-05
Epoch 145/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5253e-04 - mae: 0.0180 - mse: 5.6627e-04 - val_loss: 6.7375e-04 - val_mae: 0.0184 - val_mse: 5.8754e-04 - lr: 4.2471e-05
Epoch 146/150
98/98 [==============================] - 0s 980us/step - loss: 6.5277e-04 - mae: 0.0180 - mse: 5.6694e-04 - val_loss: 6.7456e-04 - val_mae: 0.0184 - val_mse: 5.8857e-04 - lr: 4.2471e-05
Epoch 147/150
78/98 [======================>.......] - ETA: 0s - loss: 6.5800e-04 - mae: 0.0181 - mse: 5.7207e-04
Epoch 147: ReduceLROnPlateau reducing learning rate to 2.1235333406366408e-05.
98/98 [==============================] - 0s 1ms/step - loss: 6.5224e-04 - mae: 0.0180 - mse: 5.6625e-04 - val_loss: 6.7285e-04 - val_mae: 0.0184 - val_mse: 5.8660e-04 - lr: 4.2471e-05
Epoch 148/150
98/98 [==============================] - 0s 902us/step - loss: 6.5205e-04 - mae: 0.0179 - mse: 5.6591e-04 - val_loss: 6.7322e-04 - val_mae: 0.0184 - val_mse: 5.8708e-04 - lr: 2.1235e-05
Epoch 149/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5204e-04 - mae: 0.0179 - mse: 5.6589e-04 - val_loss: 6.7320e-04 - val_mae: 0.0184 - val_mse: 5.8705e-04 - lr: 2.1235e-05
Epoch 150/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5210e-04 - mae: 0.0180 - mse: 5.6592e-04 - val_loss: 6.7371e-04 - val_mae: 0.0184 - val_mse: 5.8759e-04 - lr: 2.1235e-05
>Saved ../trained_models/models_segments_overlap_adam_0.08697992935283343LR_[70]HN_40BS_10P_val_mseM_150epochs/model_8.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0776 - mae: 0.0544 - mse: 0.0058 - val_loss: 0.0060 - val_mae: 0.0544 - val_mse: 0.0044 - lr: 0.0870
Epoch 2/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0041 - mae: 0.0430 - mse: 0.0027 - val_loss: 0.0048 - val_mae: 0.0567 - val_mse: 0.0045 - lr: 0.0870
Epoch 3/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0361 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0343 - val_mse: 0.0016 - lr: 0.0870
Epoch 4/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0337 - mse: 0.0017 - val_loss: 0.0017 - val_mae: 0.0317 - val_mse: 0.0015 - lr: 0.0870
Epoch 5/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0334 - mse: 0.0016 - val_loss: 0.0027 - val_mae: 0.0428 - val_mse: 0.0027 - lr: 0.0870
Epoch 6/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0333 - mse: 0.0016 - val_loss: 0.0023 - val_mae: 0.0389 - val_mse: 0.0022 - lr: 0.0870
Epoch 7/150
98/98 [==============================] - 0s 998us/step - loss: 0.0018 - mae: 0.0326 - mse: 0.0015 - val_loss: 0.0023 - val_mae: 0.0382 - val_mse: 0.0021 - lr: 0.0870
Epoch 8/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0318 - mse: 0.0015 - val_loss: 0.0021 - val_mae: 0.0315 - val_mse: 0.0016 - lr: 0.0870
Epoch 9/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0316 - mse: 0.0015 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 0.0870
Epoch 10/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0320 - mse: 0.0015 - val_loss: 0.0015 - val_mae: 0.0298 - val_mse: 0.0013 - lr: 0.0870
Epoch 11/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0308 - mse: 0.0014 - val_loss: 0.0022 - val_mae: 0.0334 - val_mse: 0.0019 - lr: 0.0870
Epoch 12/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0311 - mse: 0.0014 - val_loss: 0.0016 - val_mae: 0.0330 - val_mse: 0.0015 - lr: 0.0870
Epoch 13/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0305 - mse: 0.0014 - val_loss: 0.0038 - val_mae: 0.0499 - val_mse: 0.0037 - lr: 0.0870
Epoch 14/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0332 - mse: 0.0016 - val_loss: 0.0017 - val_mae: 0.0290 - val_mse: 0.0014 - lr: 0.0870
Epoch 15/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0306 - mse: 0.0014 - val_loss: 0.0022 - val_mae: 0.0324 - val_mse: 0.0017 - lr: 0.0870
Epoch 16/150
98/98 [==============================] - 0s 986us/step - loss: 0.0016 - mae: 0.0297 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0282 - val_mse: 0.0012 - lr: 0.0870
Epoch 17/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0297 - mse: 0.0013 - val_loss: 0.0024 - val_mae: 0.0399 - val_mse: 0.0023 - lr: 0.0870
Epoch 18/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0297 - mse: 0.0013 - val_loss: 0.0022 - val_mae: 0.0387 - val_mse: 0.0022 - lr: 0.0870
Epoch 19/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0299 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0306 - val_mse: 0.0013 - lr: 0.0870
Epoch 20/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0299 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0291 - val_mse: 0.0012 - lr: 0.0870
Epoch 21/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0295 - mse: 0.0013 - val_loss: 0.0013 - val_mae: 0.0280 - val_mse: 0.0011 - lr: 0.0870
Epoch 22/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0296 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0282 - val_mse: 0.0012 - lr: 0.0870
Epoch 23/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0286 - mse: 0.0012 - val_loss: 0.0041 - val_mae: 0.0513 - val_mse: 0.0039 - lr: 0.0870
Epoch 24/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0323 - mse: 0.0016 - val_loss: 0.0020 - val_mae: 0.0363 - val_mse: 0.0019 - lr: 0.0870
Epoch 25/150
98/98 [==============================] - 0s 989us/step - loss: 0.0016 - mae: 0.0292 - mse: 0.0013 - val_loss: 0.0022 - val_mae: 0.0374 - val_mse: 0.0020 - lr: 0.0870
Epoch 26/150
83/98 [========================>.....] - ETA: 0s - loss: 0.0015 - mae: 0.0288 - mse: 0.0013
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0434899628162384.
98/98 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0288 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0270 - val_mse: 0.0012 - lr: 0.0870
Epoch 27/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0280 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0279 - val_mse: 0.0012 - lr: 0.0435
Epoch 28/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0282 - mse: 0.0012 - val_loss: 0.0016 - val_mae: 0.0325 - val_mse: 0.0015 - lr: 0.0435
Epoch 29/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0280 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0264 - val_mse: 0.0010 - lr: 0.0435
Epoch 30/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0278 - mse: 0.0012 - val_loss: 0.0018 - val_mae: 0.0346 - val_mse: 0.0017 - lr: 0.0435
Epoch 31/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0276 - mse: 0.0012 - val_loss: 0.0017 - val_mae: 0.0338 - val_mse: 0.0016 - lr: 0.0435
Epoch 32/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0280 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0290 - val_mse: 0.0012 - lr: 0.0435
Epoch 33/150
98/98 [==============================] - 0s 957us/step - loss: 0.0013 - mae: 0.0272 - mse: 0.0011 - val_loss: 0.0019 - val_mae: 0.0328 - val_mse: 0.0017 - lr: 0.0435
Epoch 34/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0279 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0272 - val_mse: 0.0011 - lr: 0.0435
Epoch 35/150
98/98 [==============================] - 0s 993us/step - loss: 0.0013 - mae: 0.0272 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0257 - val_mse: 0.0010 - lr: 0.0435
Epoch 36/150
98/98 [==============================] - 0s 975us/step - loss: 0.0013 - mae: 0.0271 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0266 - val_mse: 0.0010 - lr: 0.0435
Epoch 37/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0267 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0262 - val_mse: 0.0010 - lr: 0.0435
Epoch 38/150
98/98 [==============================] - 0s 969us/step - loss: 0.0012 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0010 - lr: 0.0435
Epoch 39/150
59/98 [=================>............] - ETA: 0s - loss: 0.0012 - mae: 0.0266 - mse: 0.0011
Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0217449814081192.
98/98 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0268 - val_mse: 0.0011 - lr: 0.0435
Epoch 40/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0260 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0253 - val_mse: 9.8549e-04 - lr: 0.0217
Epoch 41/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0259 - val_mse: 0.0010 - lr: 0.0217
Epoch 42/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0259 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0255 - val_mse: 0.0011 - lr: 0.0217
Epoch 43/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0257 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0258 - val_mse: 9.9429e-04 - lr: 0.0217
Epoch 44/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0255 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0253 - val_mse: 9.6965e-04 - lr: 0.0217
Epoch 45/150
98/98 [==============================] - 0s 980us/step - loss: 0.0011 - mae: 0.0254 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0248 - val_mse: 9.7230e-04 - lr: 0.0217
Epoch 46/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0254 - mse: 0.0010 - val_loss: 0.0013 - val_mae: 0.0285 - val_mse: 0.0012 - lr: 0.0217
Epoch 47/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0257 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0251 - val_mse: 9.8175e-04 - lr: 0.0217
Epoch 48/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0252 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0248 - val_mse: 9.6686e-04 - lr: 0.0217
Epoch 49/150
47/98 [=============>................] - ETA: 0s - loss: 0.0011 - mae: 0.0248 - mse: 9.7281e-04
Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0108724907040596.
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0251 - mse: 9.9133e-04 - val_loss: 0.0012 - val_mae: 0.0270 - val_mse: 0.0011 - lr: 0.0217
Epoch 50/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0250 - mse: 9.8310e-04 - val_loss: 0.0010 - val_mae: 0.0249 - val_mse: 9.5341e-04 - lr: 0.0109
Epoch 51/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0251 - mse: 9.9961e-04 - val_loss: 0.0010 - val_mae: 0.0244 - val_mse: 9.2363e-04 - lr: 0.0109
Epoch 52/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0249 - mse: 9.8549e-04 - val_loss: 0.0012 - val_mae: 0.0273 - val_mse: 0.0011 - lr: 0.0109
Epoch 53/150
98/98 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0249 - mse: 9.8011e-04 - val_loss: 0.0010 - val_mae: 0.0245 - val_mse: 9.3798e-04 - lr: 0.0109
Epoch 54/150
98/98 [==============================] - 0s 970us/step - loss: 0.0011 - mae: 0.0247 - mse: 9.7438e-04 - val_loss: 0.0010 - val_mae: 0.0248 - val_mse: 9.4565e-04 - lr: 0.0109
Epoch 55/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0245 - mse: 9.5521e-04 - val_loss: 0.0010 - val_mae: 0.0244 - val_mse: 9.3701e-04 - lr: 0.0109
Epoch 56/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0245 - mse: 9.5627e-04 - val_loss: 0.0010 - val_mae: 0.0244 - val_mse: 9.2353e-04 - lr: 0.0109
Epoch 57/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0245 - mse: 9.5265e-04 - val_loss: 0.0010 - val_mae: 0.0245 - val_mse: 9.2792e-04 - lr: 0.0109
Epoch 58/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0246 - mse: 9.6298e-04 - val_loss: 0.0010 - val_mae: 0.0240 - val_mse: 8.9465e-04 - lr: 0.0109
Epoch 59/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0244 - mse: 9.4536e-04 - val_loss: 0.0010 - val_mae: 0.0247 - val_mse: 9.4045e-04 - lr: 0.0109
Epoch 60/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0246 - mse: 9.6440e-04 - val_loss: 9.9163e-04 - val_mae: 0.0240 - val_mse: 8.9629e-04 - lr: 0.0109
Epoch 61/150
76/98 [======================>.......] - ETA: 0s - loss: 0.0010 - mae: 0.0244 - mse: 9.5565e-04
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0054362453520298.
98/98 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0243 - mse: 9.4392e-04 - val_loss: 0.0010 - val_mae: 0.0245 - val_mse: 9.2655e-04 - lr: 0.0109
Epoch 62/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0243 - mse: 9.4248e-04 - val_loss: 9.9293e-04 - val_mae: 0.0238 - val_mse: 8.8808e-04 - lr: 0.0054
Epoch 63/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0243 - mse: 9.3716e-04 - val_loss: 9.8193e-04 - val_mae: 0.0240 - val_mse: 8.9722e-04 - lr: 0.0054
Epoch 64/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0241 - mse: 9.2683e-04 - val_loss: 9.8191e-04 - val_mae: 0.0239 - val_mse: 8.9513e-04 - lr: 0.0054
Epoch 65/150
98/98 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0241 - mse: 9.2364e-04 - val_loss: 0.0010 - val_mae: 0.0247 - val_mse: 9.4912e-04 - lr: 0.0054
Epoch 66/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0241 - mse: 9.2907e-04 - val_loss: 9.7571e-04 - val_mae: 0.0239 - val_mse: 8.9046e-04 - lr: 0.0054
Epoch 67/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0240 - mse: 9.2529e-04 - val_loss: 9.7571e-04 - val_mae: 0.0237 - val_mse: 8.8081e-04 - lr: 0.0054
Epoch 68/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0239 - mse: 9.1061e-04 - val_loss: 9.7175e-04 - val_mae: 0.0238 - val_mse: 8.8971e-04 - lr: 0.0054
Epoch 69/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0240 - mse: 9.2540e-04 - val_loss: 9.8150e-04 - val_mae: 0.0239 - val_mse: 8.9378e-04 - lr: 0.0054
Epoch 70/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0010 - mae: 0.0240 - mse: 9.2403e-04 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0010 - lr: 0.0054
Epoch 71/150
75/98 [=====================>........] - ETA: 0s - loss: 0.0011 - mae: 0.0246 - mse: 9.6258e-04
Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0027181226760149.
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0243 - mse: 9.3528e-04 - val_loss: 9.8440e-04 - val_mae: 0.0239 - val_mse: 8.9212e-04 - lr: 0.0054
Epoch 72/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0240 - mse: 9.1715e-04 - val_loss: 9.6826e-04 - val_mae: 0.0237 - val_mse: 8.8353e-04 - lr: 0.0027
Epoch 73/150
98/98 [==============================] - 0s 1ms/step - loss: 9.9687e-04 - mae: 0.0238 - mse: 9.0958e-04 - val_loss: 9.6510e-04 - val_mae: 0.0237 - val_mse: 8.8141e-04 - lr: 0.0027
Epoch 74/150
98/98 [==============================] - 0s 1ms/step - loss: 9.9952e-04 - mae: 0.0240 - mse: 9.1633e-04 - val_loss: 9.6720e-04 - val_mae: 0.0236 - val_mse: 8.7673e-04 - lr: 0.0027
Epoch 75/150
98/98 [==============================] - 0s 1ms/step - loss: 9.9194e-04 - mae: 0.0238 - mse: 9.0821e-04 - val_loss: 0.0010 - val_mae: 0.0245 - val_mse: 9.3524e-04 - lr: 0.0027
Epoch 76/150
98/98 [==============================] - 0s 1ms/step - loss: 9.8965e-04 - mae: 0.0238 - mse: 9.0607e-04 - val_loss: 9.7152e-04 - val_mae: 0.0236 - val_mse: 8.7721e-04 - lr: 0.0027
Epoch 77/150
98/98 [==============================] - 0s 1ms/step - loss: 9.9032e-04 - mae: 0.0238 - mse: 9.0444e-04 - val_loss: 9.7447e-04 - val_mae: 0.0239 - val_mse: 8.9445e-04 - lr: 0.0027
Epoch 78/150
98/98 [==============================] - 0s 1ms/step - loss: 9.9363e-04 - mae: 0.0238 - mse: 9.1143e-04 - val_loss: 0.0010 - val_mae: 0.0245 - val_mse: 9.3180e-04 - lr: 0.0027
Epoch 79/150
98/98 [==============================] - 0s 2ms/step - loss: 9.8732e-04 - mae: 0.0238 - mse: 9.0244e-04 - val_loss: 9.6148e-04 - val_mae: 0.0236 - val_mse: 8.7393e-04 - lr: 0.0027
Epoch 80/150
98/98 [==============================] - 0s 2ms/step - loss: 9.8858e-04 - mae: 0.0237 - mse: 9.0267e-04 - val_loss: 9.6795e-04 - val_mae: 0.0237 - val_mse: 8.7686e-04 - lr: 0.0027
Epoch 81/150
54/98 [===============>..............] - ETA: 0s - loss: 0.0010 - mae: 0.0242 - mse: 9.3280e-04
Epoch 81: ReduceLROnPlateau reducing learning rate to 0.00135906133800745.
98/98 [==============================] - 0s 2ms/step - loss: 9.9322e-04 - mae: 0.0238 - mse: 9.0662e-04 - val_loss: 9.5621e-04 - val_mae: 0.0236 - val_mse: 8.7468e-04 - lr: 0.0027
Epoch 82/150
98/98 [==============================] - 0s 1ms/step - loss: 9.8449e-04 - mae: 0.0237 - mse: 9.0242e-04 - val_loss: 9.7306e-04 - val_mae: 0.0239 - val_mse: 8.9577e-04 - lr: 0.0014
Epoch 83/150
98/98 [==============================] - 0s 1ms/step - loss: 9.8075e-04 - mae: 0.0237 - mse: 8.9690e-04 - val_loss: 9.5705e-04 - val_mae: 0.0236 - val_mse: 8.7248e-04 - lr: 0.0014
Epoch 84/150
98/98 [==============================] - 0s 1ms/step - loss: 9.8304e-04 - mae: 0.0237 - mse: 9.0061e-04 - val_loss: 9.5370e-04 - val_mae: 0.0234 - val_mse: 8.6396e-04 - lr: 0.0014
Epoch 85/150
98/98 [==============================] - 0s 1ms/step - loss: 9.8146e-04 - mae: 0.0237 - mse: 8.9799e-04 - val_loss: 9.6038e-04 - val_mae: 0.0235 - val_mse: 8.6807e-04 - lr: 0.0014
Epoch 86/150
98/98 [==============================] - 0s 1ms/step - loss: 9.7987e-04 - mae: 0.0236 - mse: 8.9711e-04 - val_loss: 9.5181e-04 - val_mae: 0.0235 - val_mse: 8.6687e-04 - lr: 0.0014
Epoch 87/150
98/98 [==============================] - 0s 1ms/step - loss: 9.7653e-04 - mae: 0.0236 - mse: 8.9500e-04 - val_loss: 9.5593e-04 - val_mae: 0.0234 - val_mse: 8.6448e-04 - lr: 0.0014
Epoch 88/150
98/98 [==============================] - 0s 2ms/step - loss: 9.7845e-04 - mae: 0.0236 - mse: 8.9403e-04 - val_loss: 9.5880e-04 - val_mae: 0.0237 - val_mse: 8.7928e-04 - lr: 0.0014
Epoch 89/150
98/98 [==============================] - 0s 1ms/step - loss: 9.7387e-04 - mae: 0.0235 - mse: 8.9032e-04 - val_loss: 9.6111e-04 - val_mae: 0.0237 - val_mse: 8.7993e-04 - lr: 0.0014
Epoch 90/150
98/98 [==============================] - 0s 1ms/step - loss: 9.7667e-04 - mae: 0.0236 - mse: 8.9209e-04 - val_loss: 9.4919e-04 - val_mae: 0.0234 - val_mse: 8.6320e-04 - lr: 0.0014
Epoch 91/150
75/98 [=====================>........] - ETA: 0s - loss: 9.8243e-04 - mae: 0.0237 - mse: 9.0095e-04
Epoch 91: ReduceLROnPlateau reducing learning rate to 0.000679530669003725.
98/98 [==============================] - 0s 1ms/step - loss: 9.7519e-04 - mae: 0.0235 - mse: 8.9245e-04 - val_loss: 9.4818e-04 - val_mae: 0.0234 - val_mse: 8.6439e-04 - lr: 0.0014
Epoch 92/150
98/98 [==============================] - 0s 1ms/step - loss: 9.7241e-04 - mae: 0.0236 - mse: 8.9162e-04 - val_loss: 9.4899e-04 - val_mae: 0.0235 - val_mse: 8.6693e-04 - lr: 6.7953e-04
Epoch 93/150
98/98 [==============================] - 0s 1ms/step - loss: 9.7217e-04 - mae: 0.0235 - mse: 8.8992e-04 - val_loss: 9.4737e-04 - val_mae: 0.0234 - val_mse: 8.6347e-04 - lr: 6.7953e-04
Epoch 94/150
98/98 [==============================] - 0s 2ms/step - loss: 9.7238e-04 - mae: 0.0236 - mse: 8.9110e-04 - val_loss: 9.5283e-04 - val_mae: 0.0236 - val_mse: 8.7207e-04 - lr: 6.7953e-04
Epoch 95/150
98/98 [==============================] - 0s 2ms/step - loss: 9.6898e-04 - mae: 0.0235 - mse: 8.8815e-04 - val_loss: 9.4741e-04 - val_mae: 0.0234 - val_mse: 8.6386e-04 - lr: 6.7953e-04
Epoch 96/150
98/98 [==============================] - 0s 2ms/step - loss: 9.7285e-04 - mae: 0.0235 - mse: 8.9061e-04 - val_loss: 9.4633e-04 - val_mae: 0.0234 - val_mse: 8.6198e-04 - lr: 6.7953e-04
Epoch 97/150
98/98 [==============================] - 0s 2ms/step - loss: 9.7017e-04 - mae: 0.0235 - mse: 8.8794e-04 - val_loss: 9.4641e-04 - val_mae: 0.0234 - val_mse: 8.6411e-04 - lr: 6.7953e-04
Epoch 98/150
98/98 [==============================] - 0s 1ms/step - loss: 9.7056e-04 - mae: 0.0235 - mse: 8.8988e-04 - val_loss: 9.4907e-04 - val_mae: 0.0234 - val_mse: 8.6295e-04 - lr: 6.7953e-04
Epoch 99/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6985e-04 - mae: 0.0235 - mse: 8.8759e-04 - val_loss: 9.5539e-04 - val_mae: 0.0236 - val_mse: 8.7533e-04 - lr: 6.7953e-04
Epoch 100/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6980e-04 - mae: 0.0235 - mse: 8.8663e-04 - val_loss: 9.6022e-04 - val_mae: 0.0237 - val_mse: 8.8219e-04 - lr: 6.7953e-04
Epoch 101/150
47/98 [=============>................] - ETA: 0s - loss: 9.5039e-04 - mae: 0.0230 - mse: 8.6684e-04
Epoch 101: ReduceLROnPlateau reducing learning rate to 0.0003397653345018625.
98/98 [==============================] - 0s 1ms/step - loss: 9.6940e-04 - mae: 0.0235 - mse: 8.8705e-04 - val_loss: 9.4442e-04 - val_mae: 0.0234 - val_mse: 8.5951e-04 - lr: 6.7953e-04
Epoch 102/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6858e-04 - mae: 0.0234 - mse: 8.8537e-04 - val_loss: 9.4462e-04 - val_mae: 0.0234 - val_mse: 8.6056e-04 - lr: 3.3977e-04
Epoch 103/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6627e-04 - mae: 0.0234 - mse: 8.8315e-04 - val_loss: 9.4387e-04 - val_mae: 0.0234 - val_mse: 8.5963e-04 - lr: 3.3977e-04
Epoch 104/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6695e-04 - mae: 0.0235 - mse: 8.8510e-04 - val_loss: 9.4399e-04 - val_mae: 0.0234 - val_mse: 8.6128e-04 - lr: 3.3977e-04
Epoch 105/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6749e-04 - mae: 0.0235 - mse: 8.8563e-04 - val_loss: 9.4859e-04 - val_mae: 0.0235 - val_mse: 8.6856e-04 - lr: 3.3977e-04
Epoch 106/150
98/98 [==============================] - 0s 974us/step - loss: 9.6610e-04 - mae: 0.0235 - mse: 8.8606e-04 - val_loss: 9.4363e-04 - val_mae: 0.0234 - val_mse: 8.5977e-04 - lr: 3.3977e-04
Epoch 107/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6837e-04 - mae: 0.0234 - mse: 8.8634e-04 - val_loss: 9.5173e-04 - val_mae: 0.0236 - val_mse: 8.7258e-04 - lr: 3.3977e-04
Epoch 108/150
98/98 [==============================] - 0s 974us/step - loss: 9.6688e-04 - mae: 0.0235 - mse: 8.8613e-04 - val_loss: 9.4360e-04 - val_mae: 0.0234 - val_mse: 8.6218e-04 - lr: 3.3977e-04
Epoch 109/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6581e-04 - mae: 0.0235 - mse: 8.8503e-04 - val_loss: 9.4346e-04 - val_mae: 0.0233 - val_mse: 8.5919e-04 - lr: 3.3977e-04
Epoch 110/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6768e-04 - mae: 0.0234 - mse: 8.8491e-04 - val_loss: 9.5340e-04 - val_mae: 0.0236 - val_mse: 8.7495e-04 - lr: 3.3977e-04
Epoch 111/150
90/98 [==========================>...] - ETA: 0s - loss: 9.6661e-04 - mae: 0.0235 - mse: 8.8571e-04
Epoch 111: ReduceLROnPlateau reducing learning rate to 0.00016988266725093126.
98/98 [==============================] - 0s 967us/step - loss: 9.6667e-04 - mae: 0.0235 - mse: 8.8576e-04 - val_loss: 9.4358e-04 - val_mae: 0.0234 - val_mse: 8.6291e-04 - lr: 3.3977e-04
Epoch 112/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6507e-04 - mae: 0.0234 - mse: 8.8440e-04 - val_loss: 9.4638e-04 - val_mae: 0.0235 - val_mse: 8.6695e-04 - lr: 1.6988e-04
Epoch 113/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6417e-04 - mae: 0.0234 - mse: 8.8425e-04 - val_loss: 9.4244e-04 - val_mae: 0.0234 - val_mse: 8.6160e-04 - lr: 1.6988e-04
Epoch 114/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6440e-04 - mae: 0.0234 - mse: 8.8494e-04 - val_loss: 9.4623e-04 - val_mae: 0.0235 - val_mse: 8.6764e-04 - lr: 1.6988e-04
Epoch 115/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6460e-04 - mae: 0.0234 - mse: 8.8400e-04 - val_loss: 9.4948e-04 - val_mae: 0.0235 - val_mse: 8.7149e-04 - lr: 1.6988e-04
Epoch 116/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6409e-04 - mae: 0.0235 - mse: 8.8438e-04 - val_loss: 9.4181e-04 - val_mae: 0.0234 - val_mse: 8.6041e-04 - lr: 1.6988e-04
Epoch 117/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6457e-04 - mae: 0.0234 - mse: 8.8367e-04 - val_loss: 9.4222e-04 - val_mae: 0.0234 - val_mse: 8.6097e-04 - lr: 1.6988e-04
Epoch 118/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6404e-04 - mae: 0.0234 - mse: 8.8364e-04 - val_loss: 9.4144e-04 - val_mae: 0.0234 - val_mse: 8.5969e-04 - lr: 1.6988e-04
Epoch 119/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6395e-04 - mae: 0.0234 - mse: 8.8416e-04 - val_loss: 9.4157e-04 - val_mae: 0.0233 - val_mse: 8.5806e-04 - lr: 1.6988e-04
Epoch 120/150
98/98 [==============================] - 0s 990us/step - loss: 9.6536e-04 - mae: 0.0234 - mse: 8.8396e-04 - val_loss: 9.4309e-04 - val_mae: 0.0234 - val_mse: 8.6273e-04 - lr: 1.6988e-04
Epoch 121/150
68/98 [===================>..........] - ETA: 0s - loss: 9.6056e-04 - mae: 0.0234 - mse: 8.8077e-04
Epoch 121: ReduceLROnPlateau reducing learning rate to 8.494133362546563e-05.
98/98 [==============================] - 0s 1ms/step - loss: 9.6382e-04 - mae: 0.0234 - mse: 8.8347e-04 - val_loss: 9.4116e-04 - val_mae: 0.0234 - val_mse: 8.5959e-04 - lr: 1.6988e-04
Epoch 122/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6326e-04 - mae: 0.0234 - mse: 8.8305e-04 - val_loss: 9.4268e-04 - val_mae: 0.0234 - val_mse: 8.6267e-04 - lr: 8.4941e-05
Epoch 123/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6298e-04 - mae: 0.0234 - mse: 8.8340e-04 - val_loss: 9.4402e-04 - val_mae: 0.0234 - val_mse: 8.6492e-04 - lr: 8.4941e-05
Epoch 124/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6281e-04 - mae: 0.0234 - mse: 8.8224e-04 - val_loss: 9.4465e-04 - val_mae: 0.0235 - val_mse: 8.6556e-04 - lr: 8.4941e-05
Epoch 125/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6352e-04 - mae: 0.0234 - mse: 8.8401e-04 - val_loss: 9.4374e-04 - val_mae: 0.0234 - val_mse: 8.6447e-04 - lr: 8.4941e-05
Epoch 126/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6335e-04 - mae: 0.0235 - mse: 8.8453e-04 - val_loss: 9.4244e-04 - val_mae: 0.0234 - val_mse: 8.6300e-04 - lr: 8.4941e-05
Epoch 127/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6320e-04 - mae: 0.0234 - mse: 8.8424e-04 - val_loss: 9.4284e-04 - val_mae: 0.0234 - val_mse: 8.6350e-04 - lr: 8.4941e-05
Epoch 128/150
98/98 [==============================] - 0s 988us/step - loss: 9.6255e-04 - mae: 0.0234 - mse: 8.8164e-04 - val_loss: 9.4393e-04 - val_mae: 0.0234 - val_mse: 8.6490e-04 - lr: 8.4941e-05
Epoch 129/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6340e-04 - mae: 0.0235 - mse: 8.8421e-04 - val_loss: 9.4271e-04 - val_mae: 0.0234 - val_mse: 8.6322e-04 - lr: 8.4941e-05
Epoch 130/150
98/98 [==============================] - 0s 967us/step - loss: 9.6260e-04 - mae: 0.0234 - mse: 8.8271e-04 - val_loss: 9.4135e-04 - val_mae: 0.0234 - val_mse: 8.6114e-04 - lr: 8.4941e-05
Epoch 131/150
81/98 [=======================>......] - ETA: 0s - loss: 9.6806e-04 - mae: 0.0235 - mse: 8.8829e-04
Epoch 131: ReduceLROnPlateau reducing learning rate to 4.2470666812732816e-05.
98/98 [==============================] - 0s 1ms/step - loss: 9.6279e-04 - mae: 0.0234 - mse: 8.8302e-04 - val_loss: 9.4116e-04 - val_mae: 0.0234 - val_mse: 8.6093e-04 - lr: 8.4941e-05
Epoch 132/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6253e-04 - mae: 0.0234 - mse: 8.8239e-04 - val_loss: 9.4186e-04 - val_mae: 0.0234 - val_mse: 8.6205e-04 - lr: 4.2471e-05
Epoch 133/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6225e-04 - mae: 0.0234 - mse: 8.8261e-04 - val_loss: 9.4199e-04 - val_mae: 0.0234 - val_mse: 8.6239e-04 - lr: 4.2471e-05
Epoch 134/150
98/98 [==============================] - 0s 970us/step - loss: 9.6219e-04 - mae: 0.0234 - mse: 8.8246e-04 - val_loss: 9.4194e-04 - val_mae: 0.0234 - val_mse: 8.6228e-04 - lr: 4.2471e-05
Epoch 135/150
98/98 [==============================] - 0s 959us/step - loss: 9.6214e-04 - mae: 0.0234 - mse: 8.8259e-04 - val_loss: 9.4236e-04 - val_mae: 0.0234 - val_mse: 8.6301e-04 - lr: 4.2471e-05
Epoch 136/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6223e-04 - mae: 0.0234 - mse: 8.8280e-04 - val_loss: 9.4145e-04 - val_mae: 0.0234 - val_mse: 8.6160e-04 - lr: 4.2471e-05
Epoch 137/150
77/98 [======================>.......] - ETA: 0s - loss: 9.6310e-04 - mae: 0.0233 - mse: 8.8290e-04
Epoch 98/150=========================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05
Epoch 98/150=========================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0618e-05