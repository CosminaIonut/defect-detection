Y [[0.096]
 [0.014]
 [0.026]
 ...
 [0.02 ]
 [0.074]
 [0.086]]
X [[0.00293123 0.00242012 0.00202833 ... 0.00123472 0.00110405 0.0010347 ]
 [0.01003065 0.00520174 0.00222913 ... 0.00047567 0.00160212 0.00299861]
 [0.0651209  0.0624661  0.06012098 ... 0.0531939  0.05098064 0.04881471]
 ...
 [0.0141577  0.00361839 0.00010273 ... 0.00797822 0.00888544 0.00702019]
 [0.01199593 0.00969102 0.00783776 ... 0.00348408 0.0024832  0.00170184]
 [0.02677437 0.00450759 0.00090166 ... 0.01828678 0.01288733 0.00463391]]
Epoch 1/10
60/86 [===================>..........] - ETA: 0s - loss: 14.3462 - mae: 0.0256 - mse: 9.2914e-04
wandb: WARNING Calling wandb.login() after wandb.init() has no effect.
wandb: WARNING The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
86/86 [==============================] - 3s 25ms/step - loss: 14.1401 - mae: 0.0252 - mse: 8.8956e-04 - val_loss: 13.4371 - val_mae: 0.0250 - val_mse: 8.7495e-04 - lr: 1.0000e-04
Epoch 2/10
83/86 [===========================>..] - ETA: 0s - loss: 12.8478 - mae: 0.0241 - mse: 7.9664e-04
86/86 [==============================] - 1s 17ms/step - loss: 12.8329 - mae: 0.0241 - mse: 7.9653e-04 - val_loss: 12.2318 - val_mae: 0.0247 - val_mse: 8.5498e-04 - lr: 1.0000e-04
Epoch 3/10
74/86 [========================>.....] - ETA: 0s - loss: 11.7751 - mae: 0.0243 - mse: 8.0444e-04
86/86 [==============================] - 2s 18ms/step - loss: 11.7085 - mae: 0.0241 - mse: 7.9693e-04 - val_loss: 11.1893 - val_mae: 0.0248 - val_mse: 8.3157e-04 - lr: 1.0000e-04
Epoch 4/10
84/86 [============================>.] - ETA: 0s - loss: 10.7457 - mae: 0.0240 - mse: 7.9502e-04
Epoch 4: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\wandb\run-20230406_134321-x6zy30e0\files\model-best)... Done. 0.0s
86/86 [==============================] - 2s 19ms/step - loss: 10.7398 - mae: 0.0240 - mse: 7.9512e-04 - val_loss: 10.2950 - val_mae: 0.0249 - val_mse: 8.3314e-04 - lr: 1.0000e-04
Epoch 5/10
85/86 [============================>.] - ETA: 0s - loss: 10.0977 - mae: 0.0241 - mse: 7.9022e-04
86/86 [==============================] - 2s 21ms/step - loss: 10.0973 - mae: 0.0240 - mse: 7.8996e-04 - val_loss: 9.8964 - val_mae: 0.0248 - val_mse: 8.3173e-04 - lr: 5.0000e-05
Epoch 6/10
56/86 [==================>...........] - ETA: 0s - loss: 9.7762 - mae: 0.0242 - mse: 8.0253e-04
86/86 [==============================] - 1s 17ms/step - loss: 9.7142 - mae: 0.0240 - mse: 7.9039e-04 - val_loss: 9.5296 - val_mae: 0.0247 - val_mse: 8.3744e-04 - lr: 5.0000e-05
Epoch 7/10
80/86 [==========================>...] - ETA: 0s - loss: 9.3725 - mae: 0.0240 - mse: 7.8900e-04
Epoch 7: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\wandb\run-20230406_134321-x6zy30e0\files\model-best)... Done. 0.0s
86/86 [==============================] - 1s 16ms/step - loss: 9.3625 - mae: 0.0240 - mse: 7.9071e-04 - val_loss: 9.1932 - val_mae: 0.0249 - val_mse: 8.3686e-04 - lr: 5.0000e-05
Epoch 8/10
74/86 [========================>.....] - ETA: 0s - loss: 9.1255 - mae: 0.0241 - mse: 7.9635e-04
86/86 [==============================] - 2s 18ms/step - loss: 9.1152 - mae: 0.0240 - mse: 7.9133e-04 - val_loss: 9.0352 - val_mae: 0.0249 - val_mse: 8.3370e-04 - lr: 2.5000e-05
Epoch 9/10
81/86 [===========================>..] - ETA: 0s - loss: 8.9642 - mae: 0.0240 - mse: 7.9112e-04
86/86 [==============================] - 1s 17ms/step - loss: 8.9606 - mae: 0.0241 - mse: 7.9244e-04 - val_loss: 8.8840 - val_mae: 0.0250 - val_mse: 8.3391e-04 - lr: 2.5000e-05
Epoch 10/10
78/86 [==========================>...] - ETA: 0s - loss: 8.8187 - mae: 0.0240 - mse: 7.9152e-04
Epoch 10: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\wandb\run-20230406_134321-x6zy30e0\files\model-best)... Done. 0.0s
86/86 [==============================] - 1s 15ms/step - loss: 8.8127 - mae: 0.0241 - mse: 7.9299e-04 - val_loss: 8.7396 - val_mae: 0.0251 - val_mse: 8.3588e-04 - lr: 2.5000e-05
>Saved models_no_overlap_30.0_10epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Y [[0.196]
 [0.114]
 [0.126]
 ...
 [0.12 ]
 [0.174]
 [0.186]]
X [[0.02748851 0.00039159 0.00726006 ... 0.0061901  0.00020034 0.01068299]
 [0.04808978 0.01491017 0.00209172 ... 0.02369569 0.02969262 0.02770941]
 [0.03573033 0.00888656 0.00066304 ... 0.02158401 0.02246699 0.01629257]
 ...
 [0.00124297 0.0006329  0.00042122 ... 0.00086485 0.00093282 0.0008421 ]
 [0.00653011 0.00134035 0.00166156 ... 0.00377469 0.00158575 0.00118001]
 [0.00629538 0.00118206 0.00202483 ... 0.00288299 0.00107985 0.00197787]]
Epoch 1/10
86/86 [==============================] - 1s 4ms/step - loss: 14.3903 - mae: 0.0591 - mse: 0.0055 - val_loss: 13.6796 - val_mae: 0.0231 - val_mse: 7.4890e-04 - lr: 1.0000e-04
Epoch 2/10
86/86 [==============================] - 0s 3ms/step - loss: 13.0726 - mae: 0.0189 - mse: 5.2841e-04 - val_loss: 12.4689 - val_mae: 0.0214 - val_mse: 6.2881e-04 - lr: 1.0000e-04
Epoch 3/10
86/86 [==============================] - 0s 4ms/step - loss: 11.9430 - mae: 0.0171 - mse: 4.5570e-04 - val_loss: 11.4213 - val_mae: 0.0183 - val_mse: 5.7207e-04 - lr: 1.0000e-04
Epoch 4/10
86/86 [==============================] - 0s 5ms/step - loss: 10.9693 - mae: 0.0168 - mse: 4.4460e-04 - val_loss: 10.5221 - val_mae: 0.0181 - val_mse: 4.8092e-04 - lr: 1.0000e-04
Epoch 5/10
86/86 [==============================] - 0s 3ms/step - loss: 10.1367 - mae: 0.0168 - mse: 4.4022e-04 - val_loss: 9.7564 - val_mae: 0.0176 - val_mse: 5.1687e-04 - lr: 1.0000e-04
Epoch 6/10
86/86 [==============================] - 0s 3ms/step - loss: 9.4303 - mae: 0.0171 - mse: 4.5886e-04 - val_loss: 9.1093 - val_mae: 0.0204 - val_mse: 5.7967e-04 - lr: 1.0000e-04
Epoch 7/10
74/86 [========================>.....] - ETA: 0s - loss: 8.8697 - mae: 0.0175 - mse: 4.7038e-04
Epoch 7: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.
wandb: WARNING Calling wandb.login() after wandb.init() has no effect.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0033s vs `on_train_batch_end` time: 0.0038s). Check your callbacks.
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\wandb\run-20230406_134321-x6zy30e0\files\model-best)... Done. 0.0s
86/86 [==============================] - 1s 16ms/step - loss: 8.8351 - mae: 0.0175 - mse: 4.7081e-04 - val_loss: 8.5658 - val_mae: 0.0203 - val_mse: 5.6714e-04 - lr: 1.0000e-04
Epoch 8/10
72/86 [========================>.....] - ETA: 0s - loss: 8.4650 - mae: 0.0177 - mse: 4.8208e-04
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\wandb\run-20230406_134321-x6zy30e0\files\model-best)... Done. 0.0s
86/86 [==============================] - 1s 17ms/step - loss: 8.4468 - mae: 0.0177 - mse: 4.7731e-04 - val_loss: 8.3265 - val_mae: 0.0186 - val_mse: 5.4371e-04 - lr: 5.0000e-05
Epoch 9/10
62/86 [====================>.........] - ETA: 0s - loss: 8.2471 - mae: 0.0179 - mse: 4.8735e-04
86/86 [==============================] - 1s 15ms/step - loss: 8.2179 - mae: 0.0178 - mse: 4.8615e-04 - val_loss: 8.1080 - val_mae: 0.0198 - val_mse: 5.5560e-04 - lr: 5.0000e-05
Epoch 10/10
69/86 [=======================>......] - ETA: 0s - loss: 8.0274 - mae: 0.0179 - mse: 4.9055e-04
Epoch 10: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.
86/86 [==============================] - 1s 16ms/step - loss: 8.0088 - mae: 0.0180 - mse: 4.9519e-04 - val_loss: 7.9085 - val_mae: 0.0200 - val_mse: 5.6753e-04 - lr: 5.0000e-05
>Saved models_no_overlap_30.0_10epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Y [[0.296]
 [0.214]
 [0.226]
 ...
 [0.22 ]
 [0.274]
 [0.286]]
X [[0.0182882  0.00473865 0.02211658 ... 0.0223316  0.01884855 0.00023106]
 [0.03406256 0.00102707 0.01487339 ... 0.00247679 0.00735794 0.02798943]
 [0.02507582 0.00064567 0.01368136 ... 0.00056875 0.01117072 0.02570779]
 ...
 [0.00099347 0.00041288 0.00068923 ... 0.00041979 0.00058872 0.00095584]
 [0.0047433  0.00150399 0.00482519 ... 0.00354627 0.00575795 0.00259891]
 [0.00455493 0.00170686 0.00501392 ... 0.00449312 0.00525996 0.00152137]]
Epoch 1/10
86/86 [==============================] - 1s 7ms/step - loss: 14.7871 - mae: 0.1079 - mse: 0.0166 - val_loss: 14.0628 - val_mae: 0.0218 - val_mse: 8.1275e-04 - lr: 1.0000e-04
Epoch 2/10
86/86 [==============================] - 0s 2ms/step - loss: 13.4527 - mae: 0.0173 - mse: 4.9406e-04 - val_loss: 12.8460 - val_mae: 0.0164 - val_mse: 4.4325e-04 - lr: 1.0000e-04
Epoch 3/10
86/86 [==============================] - 0s 3ms/step - loss: 12.3177 - mae: 0.0154 - mse: 3.9779e-04 - val_loss: 11.7934 - val_mae: 0.0164 - val_mse: 4.3573e-04 - lr: 1.0000e-04
Epoch 4/10
86/86 [==============================] - 0s 3ms/step - loss: 11.3391 - mae: 0.0156 - mse: 4.0448e-04 - val_loss: 10.8894 - val_mae: 0.0170 - val_mse: 4.5442e-04 - lr: 1.0000e-04
Epoch 5/10
73/86 [========================>.....] - ETA: 0s - loss: 10.5553 - mae: 0.0160 - mse: 4.2032e-04
Epoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.
86/86 [==============================] - 0s 3ms/step - loss: 10.5018 - mae: 0.0160 - mse: 4.2035e-04 - val_loss: 10.1192 - val_mae: 0.0204 - val_mse: 5.9100e-04 - lr: 1.0000e-04
Epoch 6/10
86/86 [==============================] - 0s 3ms/step - loss: 9.9492 - mae: 0.0161 - mse: 4.2733e-04 - val_loss: 9.7769 - val_mae: 0.0170 - val_mse: 4.6712e-04 - lr: 5.0000e-05
Epoch 7/10
86/86 [==============================] - 0s 3ms/step - loss: 9.6209 - mae: 0.0161 - mse: 4.3023e-04 - val_loss: 9.4629 - val_mae: 0.0177 - val_mse: 4.8050e-04 - lr: 5.0000e-05
Epoch 8/10
56/86 [==================>...........] - ETA: 0s - loss: 9.3686 - mae: 0.0163 - mse: 4.2855e-04
Epoch 8: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.
86/86 [==============================] - 0s 3ms/step - loss: 9.3200 - mae: 0.0164 - mse: 4.3441e-04 - val_loss: 9.1753 - val_mae: 0.0177 - val_mse: 5.0308e-04 - lr: 5.0000e-05
Epoch 9/10
86/86 [==============================] - 0s 3ms/step - loss: 9.1087 - mae: 0.0164 - mse: 4.4002e-04 - val_loss: 9.0402 - val_mae: 0.0174 - val_mse: 4.8915e-04 - lr: 2.5000e-05
Epoch 10/10
86/86 [==============================] - 0s 3ms/step - loss: 8.9765 - mae: 0.0164 - mse: 4.4162e-04 - val_loss: 8.9111 - val_mae: 0.0177 - val_mse: 4.8751e-04 - lr: 2.5000e-05
>Saved models_no_overlap_30.0_10epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Y [[0.396]
 [0.314]
 [0.326]
 ...
 [0.32 ]
 [0.374]
 [0.386]]
X [[0.01118243 0.01738499 0.01228667 ... 0.00130245 0.01862108 0.01527098]
 [0.02270906 0.0097482  0.02967412 ... 0.03415757 0.01340192 0.0044837 ]
 [0.01650482 0.00882636 0.0223758  ... 0.02595569 0.00470275 0.00906345]
 ...
 [0.00079213 0.00058654 0.0009241  ... 0.00101096 0.00056759 0.00053519]
 [0.00334416 0.00371257 0.0040112  ... 0.00257067 0.00239752 0.00563637]
 [0.00320211 0.00400127 0.00362818 ... 0.00174091 0.00353137 0.00485635]]
Epoch 1/10
86/86 [==============================] - 1s 4ms/step - loss: 14.6798 - mae: 0.1673 - mse: 0.0365 - val_loss: 13.9381 - val_mae: 0.0419 - val_mse: 0.0026 - lr: 1.0000e-04
Epoch 2/10
86/86 [==============================] - 0s 3ms/step - loss: 13.3255 - mae: 0.0227 - mse: 8.6259e-04 - val_loss: 12.7178 - val_mae: 0.0209 - val_mse: 6.2131e-04 - lr: 1.0000e-04
Epoch 3/10
86/86 [==============================] - 0s 3ms/step - loss: 12.1891 - mae: 0.0175 - mse: 4.7068e-04 - val_loss: 11.6646 - val_mae: 0.0202 - val_mse: 6.4466e-04 - lr: 1.0000e-04
Epoch 4/10
86/86 [==============================] - 0s 4ms/step - loss: 11.2101 - mae: 0.0172 - mse: 4.5799e-04 - val_loss: 10.7604 - val_mae: 0.0181 - val_mse: 4.9169e-04 - lr: 1.0000e-04
Epoch 5/10
86/86 [==============================] - 0s 5ms/step - loss: 10.3730 - mae: 0.0173 - mse: 4.6294e-04 - val_loss: 9.9906 - val_mae: 0.0192 - val_mse: 5.8844e-04 - lr: 1.0000e-04
Epoch 6/10
86/86 [==============================] - 0s 5ms/step - loss: 9.6626 - mae: 0.0178 - mse: 4.8568e-04 - val_loss: 9.3396 - val_mae: 0.0204 - val_mse: 5.8244e-04 - lr: 1.0000e-04
Epoch 7/10
82/86 [===========================>..] - ETA: 0s - loss: 9.0736 - mae: 0.0184 - mse: 5.1145e-04
Epoch 7: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.
86/86 [==============================] - 0s 3ms/step - loss: 9.0638 - mae: 0.0184 - mse: 5.0991e-04 - val_loss: 8.7926 - val_mae: 0.0195 - val_mse: 5.8323e-04 - lr: 1.0000e-04
Epoch 8/10
86/86 [==============================] - 0s 3ms/step - loss: 8.6730 - mae: 0.0186 - mse: 5.1446e-04 - val_loss: 8.5518 - val_mae: 0.0196 - val_mse: 5.6472e-04 - lr: 5.0000e-05
Epoch 9/10
86/86 [==============================] - 0s 2ms/step - loss: 8.4423 - mae: 0.0188 - mse: 5.2511e-04 - val_loss: 8.3317 - val_mae: 0.0197 - val_mse: 5.6498e-04 - lr: 5.0000e-05
Epoch 10/10
85/86 [============================>.] - ETA: 0s - loss: 8.2319 - mae: 0.0191 - mse: 5.3911e-04
Epoch 10: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.
86/86 [==============================] - 0s 3ms/step - loss: 8.2317 - mae: 0.0191 - mse: 5.3933e-04 - val_loss: 8.1307 - val_mae: 0.0224 - val_mse: 7.7421e-04 - lr: 5.0000e-05
>Saved models_no_overlap_30.0_10epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Y [[0.496]
 [0.414]
 [0.426]
 ...
 [0.42 ]
 [0.474]
 [0.486]]
X [[6.09523062e-03 2.60635719e-02 3.23428795e-07 ... 2.56026743e-02
  1.71041837e-04 2.54984670e-02]
 [1.40446918e-02 2.61646829e-02 1.25673051e-02 ... 1.25419787e-03
  3.29900489e-02 7.42571154e-03]
 [1.00183570e-02 2.14339205e-02 7.42171361e-03 ... 2.69533320e-03
  2.61955631e-02 1.32740317e-03]
 ...
 [6.39117437e-04 8.80646365e-04 5.95484829e-04 ... 4.33446885e-04
  1.00569413e-03 4.69498592e-04]
 [2.32347860e-03 5.63694251e-03 1.16408700e-03 ... 4.87953571e-03
  2.23918923e-03 4.20476051e-03]
 [2.22512691e-03 5.76013101e-03 1.05127168e-03 ... 5.50438660e-03
  1.39780310e-03 5.27877300e-03]]
Epoch 1/10
86/86 [==============================] - 1s 5ms/step - loss: 14.9146 - mae: 0.3194 - mse: 0.1087 - val_loss: 14.1339 - val_mae: 0.1712 - val_mse: 0.0299 - lr: 1.0000e-04
Epoch 2/10
86/86 [==============================] - 0s 3ms/step - loss: 13.4983 - mae: 0.0703 - mse: 0.0076 - val_loss: 12.8788 - val_mae: 0.0206 - val_mse: 6.6257e-04 - lr: 1.0000e-04
Epoch 3/10
86/86 [==============================] - 0s 4ms/step - loss: 12.3457 - mae: 0.0191 - mse: 5.5759e-04 - val_loss: 11.8167 - val_mae: 0.0198 - val_mse: 5.7129e-04 - lr: 1.0000e-04
Epoch 4/10
86/86 [==============================] - 0s 4ms/step - loss: 11.3587 - mae: 0.0191 - mse: 5.5224e-04 - val_loss: 10.9054 - val_mae: 0.0209 - val_mse: 6.1982e-04 - lr: 1.0000e-04
Epoch 5/10
75/86 [=========================>....] - ETA: 0s - loss: 10.5595 - mae: 0.0192 - mse: 5.6036e-04
Epoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.
86/86 [==============================] - 0s 4ms/step - loss: 10.5144 - mae: 0.0193 - mse: 5.6238e-04 - val_loss: 10.1286 - val_mae: 0.0203 - val_mse: 5.9262e-04 - lr: 1.0000e-04
Epoch 6/10
86/86 [==============================] - 0s 3ms/step - loss: 9.9573 - mae: 0.0191 - mse: 5.5121e-04 - val_loss: 9.7837 - val_mae: 0.0212 - val_mse: 6.4298e-04 - lr: 5.0000e-05
Epoch 7/10
86/86 [==============================] - 0s 3ms/step - loss: 9.6263 - mae: 0.0192 - mse: 5.5479e-04 - val_loss: 9.4670 - val_mae: 0.0202 - val_mse: 5.9480e-04 - lr: 5.0000e-05
Epoch 8/10
85/86 [============================>.] - ETA: 0s - loss: 9.3231 - mae: 0.0192 - mse: 5.5665e-04
Epoch 8: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.
86/86 [==============================] - 0s 4ms/step - loss: 9.3228 - mae: 0.0192 - mse: 5.5779e-04 - val_loss: 9.1770 - val_mae: 0.0210 - val_mse: 6.3441e-04 - lr: 5.0000e-05
Epoch 9/10
86/86 [==============================] - 0s 4ms/step - loss: 9.1098 - mae: 0.0192 - mse: 5.5377e-04 - val_loss: 9.0409 - val_mae: 0.0207 - val_mse: 6.3371e-04 - lr: 2.5000e-05
Epoch 10/10
86/86 [==============================] - 0s 5ms/step - loss: 8.9767 - mae: 0.0193 - mse: 5.5990e-04 - val_loss: 8.9108 - val_mae: 0.0202 - val_mse: 5.9539e-04 - lr: 2.5000e-05
>Saved models_no_overlap_30.0_10epochs/model_5.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Y [[0.596]
 [0.514]
 [0.526]
 ...
 [0.52 ]
 [0.574]
 [0.586]]
X [[0.00281704 0.02431304 0.01335414 ... 0.0001957  0.02202468 0.01045449]
 [0.00794252 0.03519745 0.00164735 ... 0.03222877 0.00365329 0.03065086]
 [0.0055022  0.02725266 0.00194181 ... 0.02144673 0.00716432 0.01778728]
 ...
 [0.00053196 0.00102944 0.00043293 ... 0.00093997 0.0005066  0.00088545]
 [0.00164814 0.00575309 0.00262877 ... 0.00141542 0.00576226 0.00116022]
 [0.00158778 0.00563416 0.00308913 ... 0.0010541  0.00561785 0.00194067]]
Epoch 1/10
wandb: WARNING Calling wandb.login() after wandb.init() has no effect.
wandb: WARNING Calling wandb.login() after wandb.init() has no effect.
wandb: WARNING Calling wandb.login() after wandb.init() has no effect.
wandb: WARNING Calling wandb.login() after wandb.init() has no effect.
86/86 [==============================] - 1s 7ms/step - loss: 14.8860 - mae: 0.3612 - mse: 0.1428 - val_loss: 14.0785 - val_mae: 0.1712 - val_mse: 0.0310 - lr: 1.0000e-04
Epoch 2/10
86/86 [==============================] - 0s 4ms/step - loss: 13.4411 - mae: 0.0693 - mse: 0.0077 - val_loss: 12.8216 - val_mae: 0.0275 - val_mse: 0.0012 - lr: 1.0000e-04
Epoch 3/10
86/86 [==============================] - 0s 3ms/step - loss: 12.2884 - mae: 0.0237 - mse: 8.8139e-04 - val_loss: 11.7596 - val_mae: 0.0248 - val_mse: 8.1913e-04 - lr: 1.0000e-04
Epoch 4/10
86/86 [==============================] - 0s 5ms/step - loss: 11.3016 - mae: 0.0196 - mse: 6.0526e-04 - val_loss: 10.8484 - val_mae: 0.0207 - val_mse: 5.8766e-04 - lr: 1.0000e-04
Epoch 5/10
86/86 [==============================] - 0s 5ms/step - loss: 10.4579 - mae: 0.0184 - mse: 5.2633e-04 - val_loss: 10.0724 - val_mae: 0.0182 - val_mse: 5.5394e-04 - lr: 1.0000e-04
Epoch 6/10
86/86 [==============================] - 0s 6ms/step - loss: 9.7418 - mae: 0.0183 - mse: 5.2329e-04 - val_loss: 9.4162 - val_mae: 0.0197 - val_mse: 6.9653e-04 - lr: 1.0000e-04
Epoch 7/10
73/86 [========================>.....] - ETA: 0s - loss: 9.1761 - mae: 0.0185 - mse: 5.2838e-04
Epoch 7: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.
86/86 [==============================] - 0s 4ms/step - loss: 9.1378 - mae: 0.0185 - mse: 5.3456e-04 - val_loss: 8.8641 - val_mae: 0.0190 - val_mse: 5.5084e-04 - lr: 1.0000e-04
Epoch 8/10
86/86 [==============================] - 1s 6ms/step - loss: 8.7432 - mae: 0.0180 - mse: 5.0287e-04 - val_loss: 8.6207 - val_mae: 0.0185 - val_mse: 5.5676e-04 - lr: 5.0000e-05
Epoch 9/10
86/86 [==============================] - 0s 3ms/step - loss: 8.5101 - mae: 0.0181 - mse: 5.0815e-04 - val_loss: 8.3981 - val_mae: 0.0192 - val_mse: 5.2741e-04 - lr: 5.0000e-05
Epoch 10/10
60/86 [===================>..........] - ETA: 0s - loss: 8.3266 - mae: 0.0181 - mse: 5.1527e-04
Epoch 10: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.
86/86 [==============================] - 0s 3ms/step - loss: 8.2970 - mae: 0.0181 - mse: 5.1180e-04 - val_loss: 8.1946 - val_mae: 0.0196 - val_mse: 5.3536e-04 - lr: 5.0000e-05
>Saved models_no_overlap_30.0_10epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Y [[0.696]
 [0.614]
 [0.626]
 ...
 [0.62 ]
 [0.674]
 [0.686]]
X [[0.00100632 0.01468389 0.02928995 ... 0.02402802 0.01473997 0.0002305 ]
 [0.00410087 0.03056912 0.02327682 ... 0.00599302 0.01852052 0.02772186]
 [0.00270548 0.02250158 0.02040663 ... 0.00888944 0.00803623 0.02553832]
 ...
 [0.00046505 0.00093261 0.00084285 ... 0.0005503  0.00065485 0.00095144]
 [0.00125998 0.00418219 0.00613691 ... 0.00566793 0.00177753 0.00259461]
 [0.00122914 0.00393944 0.00633418 ... 0.00572376 0.00278586 0.00152013]]
Epoch 1/10
86/86 [==============================] - 1s 5ms/step - loss: 14.8639 - mae: 0.4118 - mse: 0.1924 - val_loss: 14.0285 - val_mae: 0.1926 - val_mse: 0.0450 - lr: 1.0000e-04
Epoch 2/10
16/86 [====>.........................] - ETA: 0s - loss: 13.9040 - mae: 0.1619 - mse: 0.0327
86/86 [==============================] - 0s 3ms/step - loss: 13.3853 - mae: 0.1060 - mse: 0.0156 - val_loss: 12.7623 - val_mae: 0.0600 - val_mse: 0.0057 - lr: 1.0000e-04
Epoch 3/10
86/86 [==============================] - 0s 5ms/step - loss: 12.2268 - mae: 0.0510 - mse: 0.0039 - val_loss: 11.6955 - val_mae: 0.0389 - val_mse: 0.0025 - lr: 1.0000e-04
Epoch 4/10
86/86 [==============================] - 0s 6ms/step - loss: 11.2359 - mae: 0.0352 - mse: 0.0019 - val_loss: 10.7812 - val_mae: 0.0330 - val_mse: 0.0016 - lr: 1.0000e-04
Epoch 5/10
86/86 [==============================] - 0s 6ms/step - loss: 10.3893 - mae: 0.0285 - mse: 0.0012 - val_loss: 10.0034 - val_mae: 0.0343 - val_mse: 0.0019 - lr: 1.0000e-04
Epoch 6/10
86/86 [==============================] - 0s 4ms/step - loss: 9.6716 - mae: 0.0259 - mse: 9.8418e-04 - val_loss: 9.3457 - val_mae: 0.0270 - val_mse: 0.0012 - lr: 1.0000e-04
Epoch 7/10
86/86 [==============================] - 0s 3ms/step - loss: 9.0672 - mae: 0.0247 - mse: 8.8687e-04 - val_loss: 8.7936 - val_mae: 0.0237 - val_mse: 8.4154e-04 - lr: 1.0000e-04
Epoch 8/10
86/86 [==============================] - 0s 5ms/step - loss: 8.5605 - mae: 0.0241 - mse: 8.5279e-04 - val_loss: 8.3315 - val_mae: 0.0241 - val_mse: 8.0131e-04 - lr: 1.0000e-04
Epoch 9/10
86/86 [==============================] - 0s 4ms/step - loss: 8.1362 - mae: 0.0239 - mse: 8.3549e-04 - val_loss: 7.9444 - val_mae: 0.0269 - val_mse: 0.0012 - lr: 1.0000e-04
Epoch 10/10
64/86 [=====================>........] - ETA: 0s - loss: 7.8190 - mae: 0.0236 - mse: 8.3222e-04
Epoch 10: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\wandb\run-20230406_134321-x6zy30e0\files\model-best)... Done. 0.0s
86/86 [==============================] - 1s 16ms/step - loss: 7.7791 - mae: 0.0236 - mse: 8.3121e-04 - val_loss: 7.6160 - val_mae: 0.0261 - val_mse: 9.1158e-04 - lr: 1.0000e-04
>Saved models_no_overlap_30.0_10epochs/model_7.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Y [[0.796]
 [0.714]
 [0.726]
 ...
 [0.72 ]
 [0.774]
 [0.786]]
X [[0.00022629 0.00495616 0.01957348 ... 0.00437114 0.00130849 0.01504514]
 [0.00205337 0.01737347 0.03898619 ... 0.02461781 0.03026386 0.00447503]
 [0.00125259 0.01198549 0.0296546  ... 0.013766   0.02591585 0.00904026]
 ...
 [0.00042983 0.00069183 0.00109211 ... 0.00077923 0.00097717 0.00053487]
 [0.00108117 0.00226479 0.0053754  ... 0.00102576 0.00289618 0.00560514]
 [0.00106969 0.00207929 0.00498671 ... 0.0013048  0.00185761 0.00481809]]
Epoch 1/10
86/86 [==============================] - 1s 5ms/step - loss: 14.7787 - mae: 0.5000 - mse: 0.2753 - val_loss: 13.8852 - val_mae: 0.2294 - val_mse: 0.0576 - lr: 1.0000e-04
Epoch 2/10
86/86 [==============================] - 0s 2ms/step - loss: 13.2294 - mae: 0.1000 - mse: 0.0150 - val_loss: 12.6032 - val_mae: 0.0457 - val_mse: 0.0033 - lr: 1.0000e-04
Epoch 3/10
86/86 [==============================] - 0s 4ms/step - loss: 12.0675 - mae: 0.0373 - mse: 0.0023 - val_loss: 11.5365 - val_mae: 0.0317 - val_mse: 0.0017 - lr: 1.0000e-04
Epoch 4/10
86/86 [==============================] - 0s 3ms/step - loss: 11.0767 - mae: 0.0272 - mse: 0.0012 - val_loss: 10.6222 - val_mae: 0.0284 - val_mse: 0.0013 - lr: 1.0000e-04
Epoch 5/10
86/86 [==============================] - 0s 3ms/step - loss: 10.2306 - mae: 0.0230 - mse: 8.2280e-04 - val_loss: 9.8451 - val_mae: 0.0285 - val_mse: 0.0011 - lr: 1.0000e-04
Epoch 6/10
86/86 [==============================] - 0s 3ms/step - loss: 9.5140 - mae: 0.0214 - mse: 7.0523e-04 - val_loss: 9.1885 - val_mae: 0.0204 - val_mse: 6.4382e-04 - lr: 1.0000e-04
Epoch 7/10
86/86 [==============================] - 0s 2ms/step - loss: 8.9109 - mae: 0.0209 - mse: 6.7365e-04 - val_loss: 8.6382 - val_mae: 0.0229 - val_mse: 7.4214e-04 - lr: 1.0000e-04
Epoch 8/10
80/86 [==========================>...] - ETA: 0s - loss: 8.4196 - mae: 0.0211 - mse: 6.7259e-04
86/86 [==============================] - 0s 4ms/step - loss: 8.4061 - mae: 0.0212 - mse: 6.7719e-04 - val_loss: 8.1782 - val_mae: 0.0228 - val_mse: 7.1726e-04 - lr: 1.0000e-04
Epoch 9/10
64/86 [=====================>........] - ETA: 0s - loss: 8.0309 - mae: 0.0212 - mse: 6.8749e-04
Epoch 9: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.
86/86 [==============================] - 0s 2ms/step - loss: 7.9841 - mae: 0.0214 - mse: 6.9673e-04 - val_loss: 7.7932 - val_mae: 0.0213 - val_mse: 6.4055e-04 - lr: 1.0000e-04
Epoch 10/10
86/86 [==============================] - 0s 4ms/step - loss: 7.7086 - mae: 0.0200 - mse: 6.0746e-04 - val_loss: 7.6227 - val_mae: 0.0220 - val_mse: 6.6643e-04 - lr: 5.0000e-05
>Saved models_no_overlap_30.0_10epochs/model_8.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Y [[0.896]
 [0.814]
 [0.826]
 ...
 [0.82 ]
 [0.874]
 [0.886]]
X [[1.68700350e-05 5.08684465e-04 3.04420353e-03 ... 2.39526770e-02
  2.87784802e-02 2.87183658e-02]
 [1.22442942e-03 5.80032512e-03 2.16794600e-02 ... 1.64463190e-02
  1.70881136e-03 7.17214544e-03]
 [6.90631753e-04 3.56631514e-03 1.42720027e-02 ... 1.83272921e-02
  4.38938646e-03 1.22751731e-03]
 ...
 [4.15892437e-04 4.90099039e-04 7.56990916e-04 ... 7.57091876e-04
  4.54970753e-04 4.65827606e-04]
 [1.02609682e-03 1.20563218e-03 2.05233827e-03 ... 6.40833769e-03
  6.07325777e-03 4.49378265e-03]
 [1.02397732e-03 1.15023685e-03 1.77614442e-03 ... 6.01792407e-03
  6.45268516e-03 5.72367207e-03]]
Epoch 1/10
62/86 [====================>.........] - ETA: 0s - loss: 15.1785 - mae: 0.6817 - mse: 0.4770
86/86 [==============================] - 1s 6ms/step - loss: 14.9208 - mae: 0.6106 - mse: 0.3975 - val_loss: 13.9755 - val_mae: 0.3305 - val_mse: 0.1165 - lr: 1.0000e-04
Epoch 2/10
86/86 [==============================] - 0s 3ms/step - loss: 13.2847 - mae: 0.1484 - mse: 0.0319 - val_loss: 12.6461 - val_mae: 0.0656 - val_mse: 0.0073 - lr: 1.0000e-04
Epoch 3/10
86/86 [==============================] - 1s 6ms/step - loss: 12.1089 - mae: 0.0617 - mse: 0.0059 - val_loss: 11.5755 - val_mae: 0.0511 - val_mse: 0.0043 - lr: 1.0000e-04
Epoch 4/10
86/86 [==============================] - 0s 6ms/step - loss: 11.1146 - mae: 0.0493 - mse: 0.0038 - val_loss: 10.6594 - val_mae: 0.0565 - val_mse: 0.0043 - lr: 1.0000e-04
Epoch 5/10
86/86 [==============================] - 0s 3ms/step - loss: 10.2656 - mae: 0.0421 - mse: 0.0027 - val_loss: 9.8776 - val_mae: 0.0382 - val_mse: 0.0023 - lr: 1.0000e-04
Epoch 6/10
86/86 [==============================] - 0s 4ms/step - loss: 9.5452 - mae: 0.0375 - mse: 0.0021 - val_loss: 9.2183 - val_mae: 0.0357 - val_mse: 0.0019 - lr: 1.0000e-04
Epoch 7/10
86/86 [==============================] - 0s 4ms/step - loss: 8.9391 - mae: 0.0341 - mse: 0.0017 - val_loss: 8.6648 - val_mae: 0.0349 - val_mse: 0.0019 - lr: 1.0000e-04
Epoch 8/10
86/86 [==============================] - 0s 3ms/step - loss: 8.4313 - mae: 0.0328 - mse: 0.0016 - val_loss: 8.2024 - val_mae: 0.0356 - val_mse: 0.0020 - lr: 1.0000e-04
Epoch 9/10
80/86 [==========================>...] - ETA: 0s - loss: 8.0181 - mae: 0.0319 - mse: 0.0015
Epoch 9: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.
86/86 [==============================] - 0s 4ms/step - loss: 8.0067 - mae: 0.0319 - mse: 0.0015 - val_loss: 7.8152 - val_mae: 0.0390 - val_mse: 0.0023 - lr: 1.0000e-04
Epoch 10/10
86/86 [==============================] - 0s 4ms/step - loss: 7.7292 - mae: 0.0307 - mse: 0.0013 - val_loss: 7.6428 - val_mae: 0.0310 - val_mse: 0.0013 - lr: 5.0000e-05
>Saved models_no_overlap_30.0_10epochs/model_9.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Y [[0.972]
 [0.94 ]
 [0.948]
 ...
 [1.   ]
 [0.986]
 [0.944]]
X [[0.00041265 0.00041287 0.00041432 ... 0.00044489 0.00047125 0.00050919]
 [0.00056971 0.0006524  0.00114772 ... 0.00882494 0.01385096 0.01967764]
 [0.00056777 0.00058678 0.00070343 ... 0.00267332 0.00407844 0.00582863]
 ...
 [0.00041264 0.00041264 0.00041264 ... 0.00041264 0.00041264 0.00041264]
 [0.00056721 0.00056735 0.00056832 ... 0.00059086 0.00061189 0.00064387]
 [0.00101958 0.00102164 0.00103412 ... 0.00123619 0.00137453 0.00154112]]
Epoch 1/10
wandb: WARNING Calling wandb.login() after wandb.init() has no effect.
87/87 [==============================] - 1s 6ms/step - loss: 15.2728 - mae: 0.7607 - mse: 0.5958 - val_loss: 14.2665 - val_mae: 0.5028 - val_mse: 0.2538 - lr: 1.0000e-04
Epoch 2/10
87/87 [==============================] - 0s 3ms/step - loss: 13.4832 - mae: 0.2225 - mse: 0.0710 - val_loss: 12.8023 - val_mae: 0.0376 - val_mse: 0.0021 - lr: 1.0000e-04
Epoch 3/10
87/87 [==============================] - 0s 4ms/step - loss: 12.2503 - mae: 0.0266 - mse: 0.0010 - val_loss: 11.7132 - val_mae: 0.0246 - val_mse: 8.3727e-04 - lr: 1.0000e-04
Epoch 4/10
87/87 [==============================] - 0s 3ms/step - loss: 11.2419 - mae: 0.0231 - mse: 7.5547e-04 - val_loss: 10.7834 - val_mae: 0.0237 - val_mse: 8.1034e-04 - lr: 1.0000e-04
Epoch 5/10
87/87 [==============================] - 0s 5ms/step - loss: 10.3825 - mae: 0.0223 - mse: 7.1557e-04 - val_loss: 9.9936 - val_mae: 0.0241 - val_mse: 8.1112e-04 - lr: 1.0000e-04
Epoch 6/10
76/87 [=========================>....] - ETA: 0s - loss: 9.6962 - mae: 0.0224 - mse: 7.2170e-04
Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.
87/87 [==============================] - 0s 6ms/step - loss: 9.6555 - mae: 0.0221 - mse: 7.0777e-04 - val_loss: 9.3281 - val_mae: 0.0229 - val_mse: 7.6033e-04 - lr: 1.0000e-04
Epoch 7/10
87/87 [==============================] - 0s 5ms/step - loss: 9.1809 - mae: 0.0217 - mse: 6.7197e-04 - val_loss: 9.0344 - val_mae: 0.0232 - val_mse: 7.4969e-04 - lr: 5.0000e-05
Epoch 8/10
87/87 [==============================] - 0s 3ms/step - loss: 8.9001 - mae: 0.0218 - mse: 6.7975e-04 - val_loss: 8.7665 - val_mae: 0.0230 - val_mse: 7.3771e-04 - lr: 5.0000e-05
Epoch 9/10
87/87 [==============================] - 0s 4ms/step - loss: 8.6439 - mae: 0.0218 - mse: 6.8010e-04 - val_loss: 8.5221 - val_mae: 0.0227 - val_mse: 7.2811e-04 - lr: 5.0000e-05
Epoch 10/10
87/87 [==============================] - 0s 4ms/step - loss: 8.4103 - mae: 0.0217 - mse: 6.7671e-04 - val_loss: 8.2994 - val_mae: 0.0243 - val_mse: 8.6939e-04 - lr: 5.0000e-05
>Saved models_no_overlap_30.0_10epochs/model_10.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])