wandb: WARNING The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0003s vs `on_train_batch_end` time: 0.0041s). Check your callbacks.
Epoch 1/50
226/243 [==========================>...] - ETA: 0s - loss: 0.8574 - mae: 0.9249 - mse: 0.8574
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
243/243 [==============================] - 3s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0225
Epoch 2/50
243/243 [==============================] - 1s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0225
Epoch 3/50
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0225
Epoch 4/50
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0225
Epoch 5/50
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0225
Epoch 6/50
243/243 [==============================] - 1s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0225
Epoch 7/50
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0225
Epoch 8/50
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0225
Epoch 9/50
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0225
Epoch 10/50
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0225
Epoch 11/50
235/243 [============================>.] - ETA: 0s - loss: 0.8577 - mae: 0.9251 - mse: 0.8577
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.011236922815442085.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0225
Epoch 12/50
243/243 [==============================] - 1s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0112
Epoch 13/50
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0112
Epoch 14/50
243/243 [==============================] - 0s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0112
Epoch 15/50
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0112
Epoch 16/50
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0112
Epoch 17/50
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0112
Epoch 18/50
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0112
Epoch 19/50
243/243 [==============================] - 1s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0112
Epoch 20/50
243/243 [==============================] - 1s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0112
Epoch 21/50
218/243 [=========================>....] - ETA: 0s - loss: 0.8576 - mae: 0.9251 - mse: 0.8576
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.005618461407721043.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0112
Epoch 22/50
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0056
Epoch 23/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0056
Epoch 24/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0056
Epoch 25/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0056
Epoch 26/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0056
Epoch 27/50
243/243 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0056
Epoch 28/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0056
Epoch 29/50
243/243 [==============================] - 1s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0056
Epoch 30/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0056
Epoch 31/50
226/243 [==========================>...] - ETA: 0s - loss: 0.8569 - mae: 0.9246 - mse: 0.8569
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0028092307038605213.
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0056
Epoch 32/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0028
Epoch 33/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0028
Epoch 34/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0028
Epoch 35/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0028
Epoch 36/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0028
Epoch 37/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0028
Epoch 38/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0028
Epoch 39/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0028
Epoch 40/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0028
Epoch 41/50
239/243 [============================>.] - ETA: 0s - loss: 0.8580 - mae: 0.9252 - mse: 0.8580
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0014046153519302607.
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0028
Epoch 42/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
Epoch 43/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
Epoch 44/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
Epoch 45/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
Epoch 46/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
Epoch 47/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
Epoch 48/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
Epoch 49/50
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
Epoch 50/50
231/243 [===========================>..] - ETA: 0s - loss: 0.8576 - mae: 0.9250 - mse: 0.8576
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_end` time: 0.0071s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_end` time: 0.0071s). Check your callbacks.
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0014
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
238/323 [=====================>........] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.64316431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0225
323/323 [==============================] - 2s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0225
323/323 [==============================] - 2s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0225
194/323 [=================>............] - ETA: 0s - loss: 0.6414 - mae: 0.7988 - mse: 0.64146431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0225
323/323 [==============================] - 2s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0225
301/323 [==========================>...] - ETA: 0s - loss: 0.6430 - mae: 0.7997 - mse: 0.64306431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0225
323/323 [==============================] - 2s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0225
107/323 [========>.....................] - ETA: 0s - loss: 0.6423 - mae: 0.7992 - mse: 0.64236431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0225
323/323 [==============================] - 2s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0112
316/323 [============================>.] - ETA: 0s - loss: 0.6429 - mae: 0.7997 - mse: 0.64296431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0112
323/323 [==============================] - 2s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0112
323/323 [==============================] - 2s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0112
103/323 [========>.....................] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.64316431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0112
323/323 [==============================] - 2s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0112
315/323 [============================>.] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.64316431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0112
323/323 [==============================] - 2s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0056
 94/323 [=======>......................] - ETA: 0s - loss: 0.6433 - mae: 0.7999 - mse: 0.64336431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0056
323/323 [==============================] - 2s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0056
313/323 [============================>.] - ETA: 0s - loss: 0.6432 - mae: 0.7999 - mse: 0.64326431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0056
323/323 [==============================] - 2s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0056
323/323 [==============================] - 2s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0056
158/323 [=============>................] - ETA: 0s - loss: 0.6411 - mae: 0.7985 - mse: 0.64116431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0056
323/323 [==============================] - 2s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0056
323/323 [==============================] - 2s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0056
  1/323 [..............................] - ETA: 2s - loss: 0.6944 - mae: 0.8320 - mse: 0.69446431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0028
  1/323 [..............................] - ETA: 0s - loss: 0.6513 - mae: 0.8044 - mse: 0.65136431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0028
  1/323 [..............................] - ETA: 0s - loss: 0.5820 - mae: 0.7611 - mse: 0.58206431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0028
323/323 [==============================] - 1s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0028
314/323 [============================>.] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.64316431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0028
233/323 [====================>.........] - ETA: 0s - loss: 0.6435 - mae: 0.8001 - mse: 0.64356431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0014
 56/323 [====>.........................] - ETA: 1s - loss: 0.6469 - mae: 0.8022 - mse: 0.64696431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0014
323/323 [==============================] - 2s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0014
311/323 [===========================>..] - ETA: 0s - loss: 0.6432 - mae: 0.7999 - mse: 0.64326431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0014
  1/323 [..............................] - ETA: 5s - loss: 0.6300 - mae: 0.7916 - mse: 0.63006431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0014
319/323 [============================>.] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.64316431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0014
323/323 [==============================] - 2s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0014
213/243 [=========================>....] - ETA: 0s - loss: 0.4582 - mae: 0.6755 - mse: 0.4582  31 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0014
243/243 [==============================] - ETA: 0s - loss: 0.4578 - mae: 0.6752 - mse: 0.4578  31 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0014
243/243 [==============================] - ETA: 0s - loss: 0.4578 - mae: 0.6752 - mse: 0.4578  31 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0014
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
109/243 [============>.................] - ETA: 0s - loss: 0.4576 - mae: 0.6751 - mse: 0.45764578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.02255
243/243 [==============================] - 1s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.02255
243/243 [==============================] - 1s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.02255
243/243 [==============================] - 1s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.02255
200/243 [=======================>......] - ETA: 0s - loss: 0.4579 - mae: 0.6752 - mse: 0.45794578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.02255
243/243 [==============================] - 1s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.01125
233/243 [===========================>..] - ETA: 0s - loss: 0.4574 - mae: 0.6749 - mse: 0.45744578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.01125
133/243 [===============>..............] - ETA: 0s - loss: 0.4576 - mae: 0.6750 - mse: 0.45764578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.01125
243/243 [==============================] - 1s 6ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.01125
243/243 [==============================] - 1s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.01125
243/243 [==============================] - 1s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.01125
243/243 [==============================] - 1s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.01125
243/243 [==============================] - 1s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.00565
243/243 [==============================] - 1s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.00565
229/243 [===========================>..] - ETA: 0s - loss: 0.4579 - mae: 0.6753 - mse: 0.45794578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.00565
201/243 [=======================>......] - ETA: 0s - loss: 0.4579 - mae: 0.6752 - mse: 0.45794578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.00565
119/243 [=============>................] - ETA: 0s - loss: 0.4572 - mae: 0.6747 - mse: 0.45724578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.00565
243/243 [==============================] - 1s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.00285
242/243 [============================>.] - ETA: 0s - loss: 0.4578 - mae: 0.6752 - mse: 0.45784578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.00285
 35/243 [===>..........................] - ETA: 0s - loss: 0.4570 - mae: 0.6746 - mse: 0.45704578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.00285
243/243 [==============================] - 1s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.00285
243/243 [==============================] - 1s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.00285
243/243 [==============================] - 1s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.00285
 16/243 [>.............................] - ETA: 0s - loss: 0.4488 - mae: 0.6685 - mse: 0.44884578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.00285
243/243 [==============================] - 1s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.00145
243/243 [==============================] - 1s 5ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.00145
237/243 [============================>.] - ETA: 0s - loss: 0.4576 - mae: 0.6751 - mse: 0.45764578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.00145
154/243 [==================>...........] - ETA: 0s - loss: 0.4586 - mae: 0.6758 - mse: 0.45864578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.00145
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.00145
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.00145
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.00145
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.00145
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.

243/243 [==============================] - 1s 5ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.02255
184/243 [=====================>........] - ETA: 0s - loss: 0.3334 - mae: 0.5757 - mse: 0.33343328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.02255
243/243 [==============================] - 2s 7ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.02255
243/243 [==============================] - 1s 6ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.02255
243/243 [==============================] - 1s 5ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.02255
243/243 [==============================] - 2s 6ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.02255
231/243 [===========================>..] - ETA: 0s - loss: 0.3333 - mae: 0.5756 - mse: 0.33333328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.02255
124/243 [==============>...............] - ETA: 0s - loss: 0.3318 - mae: 0.5744 - mse: 0.33183328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.01125
243/243 [==============================] - 1s 5ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.01125
243/243 [==============================] - 1s 6ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.01125
237/243 [============================>.] - ETA: 0s - loss: 0.3328 - mae: 0.5752 - mse: 0.33283328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.01125
105/243 [===========>..................] - ETA: 0s - loss: 0.3337 - mae: 0.5761 - mse: 0.33373328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.01125
237/243 [============================>.] - ETA: 0s - loss: 0.3327 - mae: 0.5752 - mse: 0.33273328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.01125
 47/243 [====>.........................] - ETA: 1s - loss: 0.3331 - mae: 0.5755 - mse: 0.33313328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.00565
243/243 [==============================] - 2s 6ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.00565
243/243 [==============================] - 0s 2ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.00565
243/243 [==============================] - 1s 2ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.00565
243/243 [==============================] - 1s 2ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.00285
125/243 [==============>...............] - ETA: 0s - loss: 0.3331 - mae: 0.5755 - mse: 0.33313328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.00285
228/243 [===========================>..] - ETA: 0s - loss: 0.3330 - mae: 0.5754 - mse: 0.33303328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.00285
 47/243 [====>.........................] - ETA: 0s - loss: 0.3332 - mae: 0.5756 - mse: 0.33323328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.00145
 28/243 [==>...........................] - ETA: 0s - loss: 0.3357 - mae: 0.5777 - mse: 0.33573328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.00145
121/243 [=============>................] - ETA: 0s - loss: 0.2273 - mae: 0.4747 - mse: 0.2273  28 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.00145
121/243 [=============>................] - ETA: 0s - loss: 0.2273 - mae: 0.4747 - mse: 0.2273  28 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.00145
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0031s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0031s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
239/243 [============================>.] - ETA: 0s - loss: 0.2277 - mae: 0.4751 - mse: 0.2277  28 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.00145
243/243 [==============================] - 1s 2ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.02255
 66/243 [=======>......................] - ETA: 0s - loss: 0.2281 - mae: 0.4756 - mse: 0.22812277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.02255
113/243 [============>.................] - ETA: 0s - loss: 0.2276 - mae: 0.4751 - mse: 0.22762277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.01125
243/243 [==============================] - 1s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.01125
233/243 [===========================>..] - ETA: 0s - loss: 0.2279 - mae: 0.4754 - mse: 0.22792277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.01125
 87/243 [=========>....................] - ETA: 0s - loss: 0.2266 - mae: 0.4740 - mse: 0.22662277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.01125
207/243 [========================>.....] - ETA: 0s - loss: 0.2278 - mae: 0.4753 - mse: 0.22782277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.00565
243/243 [==============================] - 1s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.00565
 47/243 [====>.........................] - ETA: 0s - loss: 0.2269 - mae: 0.4744 - mse: 0.22692277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.00565
196/243 [=======================>......] - ETA: 0s - loss: 0.2278 - mae: 0.4753 - mse: 0.22782277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.00285
243/243 [==============================] - 1s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.00285
243/243 [==============================] - 1s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.00285
  1/243 [..............................] - ETA: 0s - loss: 0.2403 - mae: 0.4876 - mse: 0.24032277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.00285
243/243 [==============================] - 1s 2ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.00145
 84/243 [=========>....................] - ETA: 0s - loss: 0.2287 - mae: 0.4762 - mse: 0.22872277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.00145
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.00145
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 0.00145
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230423_153309-61d4rl6m\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.02255
243/243 [==============================] - 1s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.02255
243/243 [==============================] - 1s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.02255
Epoch 11/50
 46/243 [====>.........................] - ETA: 0s - loss: 0.1417 - mae: 0.3739 - mse: 0.1417
232/243 [===========================>..] - ETA: 0s - loss: 0.1425 - mae: 0.3749 - mse: 0.14251427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.02255
Epoch 12/50
243/243 [==============================] - 1s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0112
Epoch 13/50
243/243 [==============================] - 1s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.01125
Epoch 14/50
243/243 [==============================] - 0s 2ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0112
Epoch 15/50
243/243 [==============================] - 1s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.01125
Epoch 16/50
243/243 [==============================] - 1s 2ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0112
Epoch 17/50
243/243 [==============================] - 1s 2ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0112
Epoch 18/50
243/243 [==============================] - 1s 2ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0112
Epoch 19/50
243/243 [==============================] - 1s 2ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0112
Epoch 20/50
204/243 [========================>.....] - ETA: 0s - loss: 0.1426 - mae: 0.3751 - mse: 0.1426
210/243 [========================>.....] - ETA: 0s - loss: 0.1426 - mae: 0.3750 - mse: 0.14261427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0112
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.005618461407721043.
243/243 [==============================] - 1s 2ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0112
Epoch 22/50
243/243 [==============================] - 1s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0056
Epoch 23/50
106/243 [============>.................] - ETA: 0s - loss: 0.1423 - mae: 0.3747 - mse: 0.1423
243/243 [==============================] - 1s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0056
Epoch 25/50
243/243 [==============================] - 1s 2ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0056
Epoch 26/50
198/243 [=======================>......] - ETA: 0s - loss: 0.1425 - mae: 0.3749 - mse: 0.1425
243/243 [==============================] - 1s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0056
Epoch 29/50
176/243 [====================>.........] - ETA: 0s - loss: 0.1424 - mae: 0.3748 - mse: 0.1424
243/243 [==============================] - 0s 2ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0056
Epoch 32/50
229/243 [===========================>..] - ETA: 0s - loss: 0.1426 - mae: 0.3751 - mse: 0.1426
155/243 [==================>...........] - ETA: 0s - loss: 0.1414 - mae: 0.3734 - mse: 0.14141427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0056
243/243 [==============================] - 1s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0028
243/243 [==============================] - 1s 2ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0028
243/243 [==============================] - 0s 2ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0014
243/243 [==============================] - 1s 2ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0014
243/243 [==============================] - 1s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0014
243/243 [==============================] - 1s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0014
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
243/243 [==============================] - 1s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 0.0014
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
 98/243 [===========>..................] - ETA: 0s - loss: 0.0769 - mae: 0.2738 - mse: 0.07690776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0225
243/243 [==============================] - 1s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0225
219/243 [==========================>...] - ETA: 0s - loss: 0.0776 - mae: 0.2751 - mse: 0.07760776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0225
243/243 [==============================] - 1s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0112
192/243 [======================>.......] - ETA: 0s - loss: 0.0778 - mae: 0.2755 - mse: 0.07780776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0112
243/243 [==============================] - 1s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0112
243/243 [==============================] - 0s 2ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0112
243/243 [==============================] - 1s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0056
150/243 [=================>............] - ETA: 0s - loss: 0.0778 - mae: 0.2755 - mse: 0.07780776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0056
119/243 [=============>................] - ETA: 0s - loss: 0.0775 - mae: 0.2749 - mse: 0.07750776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0056
243/243 [==============================] - 1s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0028
243/243 [==============================] - 1s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0028
219/243 [==========================>...] - ETA: 0s - loss: 0.0775 - mae: 0.2749 - mse: 0.07750776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0028
241/243 [============================>.] - ETA: 0s - loss: 0.0776 - mae: 0.2752 - mse: 0.07760776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0028
243/243 [==============================] - 1s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0014
243/243 [==============================] - 1s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0014
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0014
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0014
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 0.0014
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
243/243 [==============================] - 1s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0225
243/243 [==============================] - 1s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0225
243/243 [==============================] - 1s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0225
243/243 [==============================] - 1s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0225
243/243 [==============================] - 1s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0225
243/243 [==============================] - 1s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0112
 83/243 [=========>....................] - ETA: 0s - loss: 0.0322 - mae: 0.1740 - mse: 0.03220326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0112
243/243 [==============================] - 1s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0112
243/243 [==============================] - 0s 2ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0056
243/243 [==============================] - 1s 3ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0056
227/243 [===========================>..] - ETA: 0s - loss: 0.0327 - mae: 0.1754 - mse: 0.03270326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0056
186/243 [=====================>........] - ETA: 0s - loss: 0.0326 - mae: 0.1752 - mse: 0.03260326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0056
243/243 [==============================] - 1s 3ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
178/243 [====================>.........] - ETA: 0s - loss: 0.0324 - mae: 0.1746 - mse: 0.03240326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
243/243 [==============================] - 1s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
243/243 [==============================] - 1s 5ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
231/243 [===========================>..] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 44/50=========================>..] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 44/50=========================>..] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 47/50=========================>..] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 47/50=========================>..] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 50/50=========================>..] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 50/50=========================>..] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 50/50=========================>..] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 50/50=========================>..] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 50/50=========================>..] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 3/500=========================>..] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 7/500=========================>..] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 9/500=========================>..] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 11/50=========================>..] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 12/50=========================>..] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 16/50=========================>..] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 18/50=========================>..] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 21/50=========================>..] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 22/50=========================>..] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 26/50=========================>..] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 30/50=========================>..] - ETA: 0s - loss: 0.0325 - mae: 0.1750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0028092307038605213.750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 35/50educeLROnPlateau reducing learning rate to 0.0028092307038605213.750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 39/50educeLROnPlateau reducing learning rate to 0.0028092307038605213.750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0014046153519302607.750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 45/50educeLROnPlateau reducing learning rate to 0.0014046153519302607.750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 48/50educeLROnPlateau reducing learning rate to 0.0014046153519302607.750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 50/50educeLROnPlateau reducing learning rate to 0.0014046153519302607.750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 50/50educeLROnPlateau reducing learning rate to 0.0014046153519302607.750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028
Epoch 50/50educeLROnPlateau reducing learning rate to 0.0014046153519302607.750 - mse: 0.03250326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 0.0028