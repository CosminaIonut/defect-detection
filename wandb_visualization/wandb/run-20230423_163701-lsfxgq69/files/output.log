Epoch 1/30
230/243 [===========================>..] - ETA: 0s - loss: 0.8573 - mae: 0.9249 - mse: 0.8573
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
243/243 [==============================] - 3s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0573
Epoch 2/30
238/243 [============================>.] - ETA: 0s - loss: 0.8581 - mae: 0.9253 - mse: 0.8581
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.02864476665854454.
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0573
Epoch 3/30
242/243 [============================>.] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.01432238332927227.
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0286
Epoch 4/30
241/243 [============================>.] - ETA: 0s - loss: 0.8580 - mae: 0.9253 - mse: 0.8580
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.007161191664636135.
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0143
Epoch 5/30
218/243 [=========================>....] - ETA: 0s - loss: 0.8572 - mae: 0.9248 - mse: 0.8572
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0035805958323180676.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0072
Epoch 6/30
217/243 [=========================>....] - ETA: 0s - loss: 0.8588 - mae: 0.9257 - mse: 0.8588
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0017902979161590338.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0036
Epoch 7/30
240/243 [============================>.] - ETA: 0s - loss: 0.8578 - mae: 0.9251 - mse: 0.8578
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0008951489580795169.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0018
Epoch 8/30
236/243 [============================>.] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00044757447903975844.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 8.9515e-04
Epoch 9/30
230/243 [===========================>..] - ETA: 0s - loss: 0.8578 - mae: 0.9252 - mse: 0.8578
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00022378723951987922.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 4.4757e-04
Epoch 10/30
210/243 [========================>.....] - ETA: 0s - loss: 0.8578 - mae: 0.9252 - mse: 0.8578
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00011189361975993961.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 2.2379e-04
Epoch 11/30
237/243 [============================>.] - ETA: 0s - loss: 0.8580 - mae: 0.9252 - mse: 0.8580
Epoch 11: ReduceLROnPlateau reducing learning rate to 5.5946809879969805e-05.
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.1189e-04
Epoch 12/30
235/243 [============================>.] - ETA: 0s - loss: 0.8580 - mae: 0.9252 - mse: 0.8580
Epoch 12: ReduceLROnPlateau reducing learning rate to 2.7973404939984903e-05.
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 5.5947e-05
Epoch 13/30
225/243 [==========================>...] - ETA: 0s - loss: 0.8580 - mae: 0.9252 - mse: 0.8580
Epoch 13: ReduceLROnPlateau reducing learning rate to 1.3986702469992451e-05.
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 2.7973e-05
Epoch 14/30
228/243 [===========================>..] - ETA: 0s - loss: 0.8581 - mae: 0.9253 - mse: 0.8581
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.3987e-05
Epoch 15/30
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 16/30
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 17/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 18/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 19/30
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 20/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 21/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 22/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 23/30
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 24/30
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 25/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 26/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 27/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 28/30
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 29/30
243/243 [==============================] - 1s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 30/30
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.057289535137883735LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30

316/323 [============================>.] - ETA: 0s - loss: 0.6430 - mae: 0.7997 - mse: 0.6430
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
323/323 [==============================] - 3s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0573
Epoch 2/30
310/323 [===========================>..] - ETA: 0s - loss: 0.6438 - mae: 0.8003 - mse: 0.6438
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.02864476665854454.
323/323 [==============================] - 1s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0573
Epoch 3/30
318/323 [============================>.] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.01432238332927227.
323/323 [==============================] - 1s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0286
Epoch 4/30
291/323 [==========================>...] - ETA: 0s - loss: 0.6429 - mae: 0.7997 - mse: 0.6429
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.007161191664636135.
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0143
Epoch 5/30
318/323 [============================>.] - ETA: 0s - loss: 0.6430 - mae: 0.7997 - mse: 0.6430
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0035805958323180676.
323/323 [==============================] - 1s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0072
Epoch 6/30
318/323 [============================>.] - ETA: 0s - loss: 0.6430 - mae: 0.7997 - mse: 0.6430
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0017902979161590338.
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0036
Epoch 7/30
 44/323 [===>..........................] - ETA: 0s - loss: 0.6401 - mae: 0.7980 - mse: 0.6401
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0008951489580795169.
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0018
Epoch 8/30
316/323 [============================>.] - ETA: 0s - loss: 0.6429 - mae: 0.7997 - mse: 0.6429
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00044757447903975844.
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 8.9515e-04
Epoch 9/30
316/323 [============================>.] - ETA: 0s - loss: 0.6430 - mae: 0.7997 - mse: 0.6430
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00022378723951987922.
323/323 [==============================] - 1s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 4.4757e-04
Epoch 10/30
175/323 [===============>..............] - ETA: 0s - loss: 0.6448 - mae: 0.8009 - mse: 0.6448
321/323 [============================>.] - ETA: 0s - loss: 0.6432 - mae: 0.7999 - mse: 0.6432
Epoch 11: ReduceLROnPlateau reducing learning rate to 5.5946809879969805e-05.
323/323 [==============================] - 1s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.1189e-04
Epoch 12/30
101/323 [========>.....................] - ETA: 0s - loss: 0.6422 - mae: 0.7993 - mse: 0.6422
311/323 [===========================>..] - ETA: 0s - loss: 0.6433 - mae: 0.7999 - mse: 0.6433
311/323 [===========================>..] - ETA: 0s - loss: 0.6430 - mae: 0.7997 - mse: 0.6430
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
317/323 [============================>.] - ETA: 0s - loss: 0.6430 - mae: 0.7997 - mse: 0.64306431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
 97/323 [========>.....................] - ETA: 0s - loss: 0.6443 - mae: 0.8005 - mse: 0.64436431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
235/243 [============================>.] - ETA: 0s - loss: 0.4579 - mae: 0.6753 - mse: 0.45796431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
229/243 [===========================>..] - ETA: 0s - loss: 0.4578 - mae: 0.6752 - mse: 0.45786431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
240/243 [============================>.] - ETA: 0s - loss: 0.4576 - mae: 0.6750 - mse: 0.45766431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
 37/243 [===>..........................] - ETA: 0s - loss: 0.4579 - mae: 0.6753 - mse: 0.45796431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
228/243 [===========================>..] - ETA: 0s - loss: 0.4580 - mae: 0.6754 - mse: 0.45806431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
235/243 [============================>.] - ETA: 0s - loss: 0.4579 - mae: 0.6753 - mse: 0.45794578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
243/243 [==============================] - 1s 4ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
120/243 [=============>................] - ETA: 0s - loss: 0.4580 - mae: 0.6754 - mse: 0.45804578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
243/243 [==============================] - 1s 4ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
 18/243 [=>............................] - ETA: 0s - loss: 0.3286 - mae: 0.5716 - mse: 0.32864578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
110/243 [============>.................] - ETA: 0s - loss: 0.3328 - mae: 0.5752 - mse: 0.33284578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
181/243 [=====================>........] - ETA: 0s - loss: 0.3329 - mae: 0.5753 - mse: 0.33294578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
234/243 [===========================>..] - ETA: 0s - loss: 0.3330 - mae: 0.5754 - mse: 0.33304578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
239/243 [============================>.] - ETA: 0s - loss: 0.3327 - mae: 0.5751 - mse: 0.33274578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
243/243 [==============================] - 1s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
 60/243 [======>.......................] - ETA: 0s - loss: 0.3303 - mae: 0.5731 - mse: 0.33033328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
235/243 [============================>.] - ETA: 0s - loss: 0.3326 - mae: 0.5751 - mse: 0.33263328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
243/243 [==============================] - 1s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
243/243 [==============================] - 1s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0025s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0025s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
165/243 [===================>..........] - ETA: 0s - loss: 0.2273 - mae: 0.4747 - mse: 0.22733328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
230/243 [===========================>..] - ETA: 0s - loss: 0.2275 - mae: 0.4750 - mse: 0.22753328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
238/243 [============================>.] - ETA: 0s - loss: 0.2277 - mae: 0.4752 - mse: 0.22773328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
238/243 [============================>.] - ETA: 0s - loss: 0.2276 - mae: 0.4751 - mse: 0.22763328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
235/243 [============================>.] - ETA: 0s - loss: 0.2279 - mae: 0.4754 - mse: 0.22793328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
 43/243 [====>.........................] - ETA: 0s - loss: 0.2255 - mae: 0.4729 - mse: 0.22552277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
243/243 [==============================] - 1s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
220/243 [==========================>...] - ETA: 0s - loss: 0.2281 - mae: 0.4756 - mse: 0.22812277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
243/243 [==============================] - 1s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 30/30============================] - 1s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 1/300============================] - 1s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 1/300============================] - 1s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 1/300============================] - 1s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.007161191664636135.e: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0017902979161590338.: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00044757447903975844. 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 12: ReduceLROnPlateau reducing learning rate to 2.7973404939984903e-05.0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.404939984903e-05.0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.404939984903e-05.0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 18/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 22/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 22/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 29/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.057289535137883735LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.057289535137883735LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.057289535137883735LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00011189361975993961.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 12: ReduceLROnPlateau reducing learning rate to 2.7973404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 18/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 18/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 22/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 30/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 30/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 30/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 30/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.007161191664636135.05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0017902979161590338.5.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00011189361975993961.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00011189361975993961.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 18/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 22/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 22/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 29/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_6.h56 - val_mse: 0.2272 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.057289535137883735LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.2272 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.057289535137883735LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.2272 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0016s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0016s). Check your callbacks.
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.057289535137883735LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.2272 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.02864476665854454.83735LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.007161191664636135.3735LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00044757447903975844.35LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00011189361975993961.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 12: ReduceLROnPlateau reducing learning rate to 2.7973404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 18/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 18/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 22/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 22/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 27/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 30/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 30/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 30/30educeLROnPlateau reducing learning rate to 1e-05.404939984903e-05.5LR_[64]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_8.h56 - val_mse: 0.2272 - lr: 1.0000e-05