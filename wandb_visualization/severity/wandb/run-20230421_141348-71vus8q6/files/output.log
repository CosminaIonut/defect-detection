Epoch 1/150
102/162 [=================>............] - ETA: 0s - loss: 0.1453 - mae: 0.1213 - mse: 0.0312
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0005s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
162/162 [==============================] - 1s 5ms/step - loss: 0.0946 - mae: 0.0921 - mse: 0.0205 - val_loss: 0.0058 - val_mae: 0.0416 - val_mse: 0.0022 - lr: 0.0093
Epoch 2/150
 70/162 [===========>..................] - ETA: 0s - loss: 0.0048 - mae: 0.0403 - mse: 0.0021
162/162 [==============================] - 1s 5ms/step - loss: 0.0040 - mae: 0.0394 - mse: 0.0020 - val_loss: 0.0032 - val_mae: 0.0366 - val_mse: 0.0020 - lr: 0.0093
Epoch 3/150
143/162 [=========================>....] - ETA: 0s - loss: 0.0027 - mae: 0.0382 - mse: 0.0020
162/162 [==============================] - 1s 5ms/step - loss: 0.0027 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0025 - val_mae: 0.0368 - val_mse: 0.0020 - lr: 0.0093
Epoch 4/150
 74/162 [============>.................] - ETA: 0s - loss: 0.0024 - mae: 0.0378 - mse: 0.0020
162/162 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0376 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0376 - val_mse: 0.0020 - lr: 0.0093
Epoch 5/150
 96/162 [================>.............] - ETA: 0s - loss: 0.0023 - mae: 0.0375 - mse: 0.0020
162/162 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0373 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0093
Epoch 6/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0374 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0361 - val_mse: 0.0020 - lr: 0.0093
Epoch 7/150
 91/162 [===============>..............] - ETA: 0s - loss: 0.0022 - mae: 0.0370 - mse: 0.0019
162/162 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0371 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0366 - val_mse: 0.0019 - lr: 0.0093
Epoch 8/150
162/162 [==============================] - 0s 949us/step - loss: 0.0021 - mae: 0.0368 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0392 - val_mse: 0.0020 - lr: 0.0093
Epoch 9/150
162/162 [==============================] - 0s 917us/step - loss: 0.0021 - mae: 0.0367 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0425 - val_mse: 0.0023 - lr: 0.0093
Epoch 10/150
 69/162 [===========>..................] - ETA: 0s - loss: 0.0020 - mae: 0.0361 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.004649415612220764.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
162/162 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0365 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0382 - val_mse: 0.0019 - lr: 0.0093
Epoch 11/150
 73/162 [============>.................] - ETA: 0s - loss: 0.0020 - mae: 0.0367 - mse: 0.0019
162/162 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0362 - mse: 0.0018 - val_loss: 0.0020 - val_mae: 0.0366 - val_mse: 0.0019 - lr: 0.0046
Epoch 12/150
158/162 [============================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0361 - mse: 0.0018
162/162 [==============================] - 1s 6ms/step - loss: 0.0020 - mae: 0.0362 - mse: 0.0018 - val_loss: 0.0020 - val_mae: 0.0363 - val_mse: 0.0019 - lr: 0.0046
Epoch 13/150
 67/162 [===========>..................] - ETA: 0s - loss: 0.0020 - mae: 0.0361 - mse: 0.0018
162/162 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0361 - mse: 0.0018 - val_loss: 0.0020 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 0.0046
Epoch 14/150
 71/162 [============>.................] - ETA: 0s - loss: 0.0019 - mae: 0.0355 - mse: 0.0018
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.002324707806110382.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0358 - mse: 0.0018 - val_loss: 0.0020 - val_mae: 0.0362 - val_mse: 0.0018 - lr: 0.0046
Epoch 15/150
162/162 [==============================] - 0s 953us/step - loss: 0.0019 - mae: 0.0358 - mse: 0.0018 - val_loss: 0.0020 - val_mae: 0.0375 - val_mse: 0.0019 - lr: 0.0023
Epoch 16/150
162/162 [==============================] - ETA: 0s - loss: 0.0019 - mae: 0.0357 - mse: 0.0018
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0357 - mse: 0.0018 - val_loss: 0.0020 - val_mae: 0.0363 - val_mse: 0.0018 - lr: 0.0023
Epoch 17/150
 65/162 [===========>..................] - ETA: 0s - loss: 0.0019 - mae: 0.0355 - mse: 0.0018
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.001162353903055191.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0357 - mse: 0.0018 - val_loss: 0.0019 - val_mae: 0.0359 - val_mse: 0.0018 - lr: 0.0023
Epoch 18/150
162/162 [==============================] - 0s 950us/step - loss: 0.0019 - mae: 0.0356 - mse: 0.0018 - val_loss: 0.0019 - val_mae: 0.0369 - val_mse: 0.0018 - lr: 0.0012
Epoch 19/150
105/162 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0353 - mse: 0.0018
162/162 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0356 - mse: 0.0018 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 0.0012
Epoch 20/150
 69/162 [===========>..................] - ETA: 0s - loss: 0.0019 - mae: 0.0354 - mse: 0.0017
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005811769515275955.
162/162 [==============================] - 0s 954us/step - loss: 0.0019 - mae: 0.0356 - mse: 0.0018 - val_loss: 0.0019 - val_mae: 0.0355 - val_mse: 0.0018 - lr: 0.0012
Epoch 21/150
 85/162 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0355 - mse: 0.0017
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0355 - mse: 0.0018 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 5.8118e-04
Epoch 22/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0356 - mse: 0.0018 - val_loss: 0.0020 - val_mae: 0.0353 - val_mse: 0.0018 - lr: 5.8118e-04
Epoch 23/150
 79/162 [=============>................] - ETA: 0s - loss: 0.0019 - mae: 0.0356 - mse: 0.0017
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00029058847576379776.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0355 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 5.8118e-04
Epoch 24/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0355 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0353 - val_mse: 0.0018 - lr: 2.9059e-04
Epoch 25/150
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0355 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0359 - val_mse: 0.0018 - lr: 2.9059e-04
Epoch 26/150
 65/162 [===========>..................] - ETA: 0s - loss: 0.0018 - mae: 0.0353 - mse: 0.0017
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00014529423788189888.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0355 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 2.9059e-04
Epoch 27/150
 66/162 [===========>..................] - ETA: 0s - loss: 0.0018 - mae: 0.0349 - mse: 0.0017
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.4529e-04
Epoch 28/150
155/162 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0355 - mse: 0.0017
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0355 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.4529e-04
Epoch 29/150
 72/162 [============>.................] - ETA: 0s - loss: 0.0019 - mae: 0.0354 - mse: 0.0017
Epoch 29: ReduceLROnPlateau reducing learning rate to 7.264711894094944e-05.
162/162 [==============================] - 0s 952us/step - loss: 0.0019 - mae: 0.0355 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0358 - val_mse: 0.0018 - lr: 1.4529e-04
Epoch 30/150
 83/162 [==============>...............] - ETA: 0s - loss: 0.0018 - mae: 0.0349 - mse: 0.0017
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 7.2647e-05
Epoch 31/150
 68/162 [===========>..................] - ETA: 0s - loss: 0.0019 - mae: 0.0355 - mse: 0.0017
162/162 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 7.2647e-05
Epoch 32/150
147/162 [==========================>...] - ETA: 0s - loss: 0.0018 - mae: 0.0354 - mse: 0.0017
Epoch 32: ReduceLROnPlateau reducing learning rate to 3.632355947047472e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0364 - val_mse: 0.0018 - lr: 7.2647e-05
Epoch 33/150
 83/162 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0355 - mse: 0.0017
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0355 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0362 - val_mse: 0.0018 - lr: 3.6324e-05
Epoch 34/150
 68/162 [===========>..................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.0017
162/162 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 3.6324e-05
Epoch 35/150
 69/162 [===========>..................] - ETA: 0s - loss: 0.0019 - mae: 0.0357 - mse: 0.0018
Epoch 35: ReduceLROnPlateau reducing learning rate to 1.816177973523736e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 3.6324e-05
Epoch 36/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0355 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.8162e-05
Epoch 37/150
 97/162 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0356 - mse: 0.0018
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.8162e-05
Epoch 38/150
161/162 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0354 - mse: 0.0017
Epoch 38: ReduceLROnPlateau reducing learning rate to 1e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0363 - val_mse: 0.0018 - lr: 1.8162e-05
Epoch 39/150
 98/162 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0361 - mse: 0.0018
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0355 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
Epoch 40/150
 77/162 [=============>................] - ETA: 0s - loss: 0.0019 - mae: 0.0357 - mse: 0.0017
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0362 - val_mse: 0.0018 - lr: 1.0000e-05
Epoch 41/150
157/162 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0354 - mse: 0.0017
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
162/162 [==============================] - 0s 948us/step - loss: 0.0019 - mae: 0.0355 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
Epoch 42/150
162/162 [==============================] - 0s 948us/step - loss: 0.0019 - mae: 0.0355 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
Epoch 43/150
 82/162 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0356 - mse: 0.0017
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
Epoch 44/150
 74/162 [============>.................] - ETA: 0s - loss: 0.0019 - mae: 0.0352 - mse: 0.0017
 70/162 [===========>..................] - ETA: 0s - loss: 0.0019 - mae: 0.0354 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
 70/162 [===========>..................] - ETA: 0s - loss: 0.0019 - mae: 0.0354 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
157/162 [============================>.] - ETA: 0s - loss: 0.0018 - mae: 0.0353 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
157/162 [============================>.] - ETA: 0s - loss: 0.0018 - mae: 0.0353 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
162/162 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0362 - val_mse: 0.0018 - lr: 1.0000e-05
 83/162 [==============>...............] - ETA: 0s - loss: 0.0018 - mae: 0.0352 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0362 - val_mse: 0.0018 - lr: 1.0000e-05
 83/162 [==============>...............] - ETA: 0s - loss: 0.0018 - mae: 0.0352 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0362 - val_mse: 0.0018 - lr: 1.0000e-05
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
 74/162 [============>.................] - ETA: 0s - loss: 0.0018 - mae: 0.0350 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
 74/162 [============>.................] - ETA: 0s - loss: 0.0018 - mae: 0.0350 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0362 - val_mse: 0.0018 - lr: 1.0000e-05
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0362 - val_mse: 0.0018 - lr: 1.0000e-05
160/162 [============================>.] - ETA: 0s - loss: 0.0018 - mae: 0.0354 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0362 - val_mse: 0.0018 - lr: 1.0000e-05
160/162 [============================>.] - ETA: 0s - loss: 0.0018 - mae: 0.0354 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0362 - val_mse: 0.0018 - lr: 1.0000e-05
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
 71/162 [============>.................] - ETA: 0s - loss: 0.0018 - mae: 0.0353 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
 71/162 [============>.................] - ETA: 0s - loss: 0.0018 - mae: 0.0353 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
142/162 [=========================>....] - ETA: 0s - loss: 0.0018 - mae: 0.0353 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
142/162 [=========================>....] - ETA: 0s - loss: 0.0018 - mae: 0.0353 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
162/162 [==============================] - 0s 973us/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-05
162/162 [==============================] - 0s 973us/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-05
 74/162 [============>.................] - ETA: 0s - loss: 0.0019 - mae: 0.0355 - mse: 0.00170.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-05
 74/162 [============>.................] - ETA: 0s - loss: 0.0019 - mae: 0.0355 - mse: 0.00170.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-05
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 0s 949us/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
162/162 [==============================] - 0s 949us/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
 59/162 [=========>....................] - ETA: 0s - loss: 0.0018 - mae: 0.0353 - mse: 0.00170.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
 59/162 [=========>....................] - ETA: 0s - loss: 0.0018 - mae: 0.0353 - mse: 0.00170.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-05
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 66/162 [===========>..................] - ETA: 0s - loss: 0.0019 - mae: 0.0357 - mse: 0.00180017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 66/162 [===========>..................] - ETA: 0s - loss: 0.0019 - mae: 0.0357 - mse: 0.00180017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 96/162 [================>.............] - ETA: 0s - loss: 0.0018 - mae: 0.0354 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 96/162 [================>.............] - ETA: 0s - loss: 0.0018 - mae: 0.0354 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0355 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0355 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 68/162 [===========>..................] - ETA: 0s - loss: 0.0019 - mae: 0.0358 - mse: 0.00180017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 68/162 [===========>..................] - ETA: 0s - loss: 0.0019 - mae: 0.0358 - mse: 0.00180017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 0s 922us/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0362 - val_mse: 0.0018 - lr: 1.0000e-05
162/162 [==============================] - 0s 922us/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0362 - val_mse: 0.0018 - lr: 1.0000e-05
150/162 [==========================>...] - ETA: 0s - loss: 0.0018 - mae: 0.0353 - mse: 0.00170.0017 - val_loss: 0.0019 - val_mae: 0.0362 - val_mse: 0.0018 - lr: 1.0000e-05
150/162 [==========================>...] - ETA: 0s - loss: 0.0018 - mae: 0.0353 - mse: 0.00170.0017 - val_loss: 0.0019 - val_mae: 0.0362 - val_mse: 0.0018 - lr: 1.0000e-05
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 74/162 [============>.................] - ETA: 0s - loss: 0.0018 - mae: 0.0350 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 74/162 [============>.................] - ETA: 0s - loss: 0.0018 - mae: 0.0350 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 81/162 [==============>...............] - ETA: 0s - loss: 0.0018 - mae: 0.0351 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 81/162 [==============>...............] - ETA: 0s - loss: 0.0018 - mae: 0.0351 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 92/162 [================>.............] - ETA: 0s - loss: 0.0018 - mae: 0.0351 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 92/162 [================>.............] - ETA: 0s - loss: 0.0018 - mae: 0.0351 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 71/162 [============>.................] - ETA: 0s - loss: 0.0018 - mae: 0.0350 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 71/162 [============>.................] - ETA: 0s - loss: 0.0018 - mae: 0.0350 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
160/162 [============================>.] - ETA: 0s - loss: 0.0018 - mae: 0.0354 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
160/162 [============================>.] - ETA: 0s - loss: 0.0018 - mae: 0.0354 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 83/162 [==============>...............] - ETA: 0s - loss: 0.0018 - mae: 0.0353 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 83/162 [==============>...............] - ETA: 0s - loss: 0.0018 - mae: 0.0353 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
148/162 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0355 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
148/162 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0355 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
157/162 [============================>.] - ETA: 0s - loss: 0.0018 - mae: 0.0354 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
157/162 [============================>.] - ETA: 0s - loss: 0.0018 - mae: 0.0354 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 70/162 [===========>..................] - ETA: 0s - loss: 0.0018 - mae: 0.0351 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 70/162 [===========>..................] - ETA: 0s - loss: 0.0018 - mae: 0.0351 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 63/162 [==========>...................] - ETA: 0s - loss: 0.0018 - mae: 0.0356 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 63/162 [==========>...................] - ETA: 0s - loss: 0.0018 - mae: 0.0356 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0355 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0355 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-0505
 84/162 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0356 - mse: 0.00180.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-05
 84/162 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0356 - mse: 0.00180.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-05
 98/162 [=================>............] - ETA: 0s - loss: 0.0018 - mae: 0.0349 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 98/162 [=================>............] - ETA: 0s - loss: 0.0018 - mae: 0.0349 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 93/162 [================>.............] - ETA: 0s - loss: 0.0018 - mae: 0.0354 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 93/162 [================>.............] - ETA: 0s - loss: 0.0018 - mae: 0.0354 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
149/162 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0355 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
149/162 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0355 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-0505
 78/162 [=============>................] - ETA: 0s - loss: 0.0018 - mae: 0.0353 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-0505
 78/162 [=============>................] - ETA: 0s - loss: 0.0018 - mae: 0.0353 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-0505
 96/162 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0354 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 96/162 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0354 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
 76/162 [=============>................] - ETA: 0s - loss: 0.0019 - mae: 0.0358 - mse: 0.00180017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-0505
 76/162 [=============>................] - ETA: 0s - loss: 0.0018 - mae: 0.0352 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-0505
 76/162 [=============>................] - ETA: 0s - loss: 0.0018 - mae: 0.0352 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 0s 940us/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-05
162/162 [==============================] - 0s 940us/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-05
 68/162 [===========>..................] - ETA: 0s - loss: 0.0019 - mae: 0.0355 - mse: 0.00170.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-05
 68/162 [===========>..................] - ETA: 0s - loss: 0.0019 - mae: 0.0355 - mse: 0.00170.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-05
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 0s 954us/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-05
162/162 [==============================] - 0s 954us/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
 67/162 [===========>..................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.00170.0017 - val_loss: 0.0019 - val_mae: 0.0360 - val_mse: 0.0018 - lr: 1.0000e-05
 78/162 [=============>................] - ETA: 0s - loss: 0.0018 - mae: 0.0351 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 78/162 [=============>................] - ETA: 0s - loss: 0.0018 - mae: 0.0351 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0353 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0362 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0353 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0362 - val_mse: 0.0018 - lr: 1.0000e-0505
 75/162 [============>.................] - ETA: 0s - loss: 0.0019 - mae: 0.0357 - mse: 0.00180017 - val_loss: 0.0019 - val_mae: 0.0362 - val_mse: 0.0018 - lr: 1.0000e-0505
 75/162 [============>.................] - ETA: 0s - loss: 0.0019 - mae: 0.0357 - mse: 0.00180017 - val_loss: 0.0019 - val_mae: 0.0362 - val_mse: 0.0018 - lr: 1.0000e-0505
 85/162 [==============>...............] - ETA: 0s - loss: 0.0018 - mae: 0.0350 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 85/162 [==============>...............] - ETA: 0s - loss: 0.0018 - mae: 0.0350 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0353 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0353 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 97/162 [================>.............] - ETA: 0s - loss: 0.0018 - mae: 0.0355 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
162/162 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0354 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 61/162 [==========>...................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
 61/162 [==========>...................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
 61/162 [==========>...................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
Epoch 136/150======>...................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
Epoch 136/150======>...................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
Epoch 136/150======>...................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
Epoch 139/150======>...................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
Epoch 139/150======>...................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
Epoch 139/150======>...................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
Epoch 139/150======>...................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
Epoch 143/150======>...................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
Epoch 143/150======>...................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
Epoch 143/150======>...................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
Epoch 143/150======>...................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
Epoch 143/150======>...................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
Epoch 143/150======>...................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
Epoch 143/150======>...................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
Epoch 143/150======>...................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_141348-71vus8q6\files\model-best)... Done. 0.0s
Epoch 143/150======>...................] - ETA: 0s - loss: 0.0018 - mae: 0.0348 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
Epoch 41/150duceLROnPlateau reducing learning rate to 0.002324707806110382.0348 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
172/216 [======================>.......] - ETA: 0s - loss: 0.0097 - mae: 0.0901 - mse: 0.0096
Epoch 40: ReduceLROnPlateau reducing learning rate to 1e-05.
216/216 [==============================] - 0s 933us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.8162e-05
Epoch 41/150duceLROnPlateau reducing learning rate to 0.002324707806110382.0348 - mse: 0.00170017 - val_loss: 0.0019 - val_mae: 0.0361 - val_mse: 0.0018 - lr: 1.0000e-0505
216/216 [==============================] - 0s 1ms/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 42/150
216/216 [==============================] - 0s 873us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 43/150
216/216 [==============================] - 0s 914us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 44/150
216/216 [==============================] - 0s 931us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 45/150
216/216 [==============================] - 0s 931us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 46/150
216/216 [==============================] - 0s 930us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 47/150
216/216 [==============================] - 0s 858us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 48/150
216/216 [==============================] - 0s 930us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 49/150
216/216 [==============================] - 0s 931us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 50/150
216/216 [==============================] - 0s 932us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 51/150
216/216 [==============================] - 0s 930us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 52/150
216/216 [==============================] - 0s 934us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 53/150
216/216 [==============================] - 0s 854us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 54/150
216/216 [==============================] - 0s 931us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 55/150
216/216 [==============================] - 0s 930us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 56/150
216/216 [==============================] - 0s 930us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 57/150
216/216 [==============================] - 0s 933us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 58/150
216/216 [==============================] - 0s 901us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 59/150
216/216 [==============================] - 0s 831us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 60/150
216/216 [==============================] - 0s 939us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 61/150
216/216 [==============================] - 0s 928us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 62/150
216/216 [==============================] - 0s 929us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 63/150
216/216 [==============================] - 0s 926us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 64/150
216/216 [==============================] - 0s 934us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 65/150
216/216 [==============================] - 0s 857us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 66/150
216/216 [==============================] - 0s 934us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 67/150
216/216 [==============================] - 0s 923us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 68/150
216/216 [==============================] - 0s 937us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 69/150
216/216 [==============================] - 0s 856us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 70/150
216/216 [==============================] - 0s 897us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 71/150
216/216 [==============================] - 0s 897us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 72/150
216/216 [==============================] - 0s 855us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 73/150
216/216 [==============================] - 0s 923us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 74/150
216/216 [==============================] - 0s 930us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 75/150
216/216 [==============================] - 0s 953us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 76/150
216/216 [==============================] - 0s 910us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 77/150
216/216 [==============================] - 0s 951us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 78/150
216/216 [==============================] - 0s 929us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 79/150
216/216 [==============================] - 0s 936us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 80/150
216/216 [==============================] - 0s 908us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 81/150
216/216 [==============================] - 0s 910us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 82/150
216/216 [==============================] - 0s 854us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 83/150
216/216 [==============================] - 0s 929us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 84/150
216/216 [==============================] - 0s 930us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 85/150
216/216 [==============================] - 0s 859us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 86/150
216/216 [==============================] - 0s 934us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 87/150
216/216 [==============================] - 0s 853us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 88/150
216/216 [==============================] - 0s 857us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 89/150
216/216 [==============================] - 0s 934us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 90/150
216/216 [==============================] - 0s 927us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 91/150
216/216 [==============================] - 0s 857us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 92/150
216/216 [==============================] - 0s 860us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 93/150
216/216 [==============================] - 0s 928us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 94/150
216/216 [==============================] - 0s 932us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 95/150
216/216 [==============================] - 0s 931us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 96/150
216/216 [==============================] - 0s 931us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 97/150
216/216 [==============================] - 0s 1ms/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 98/150
216/216 [==============================] - 0s 904us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 99/150
216/216 [==============================] - 0s 886us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 100/150
216/216 [==============================] - 0s 930us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 101/150
216/216 [==============================] - 0s 931us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 102/150
216/216 [==============================] - 0s 931us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 103/150
216/216 [==============================] - 0s 929us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 104/150
216/216 [==============================] - 0s 884us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 105/150
216/216 [==============================] - 0s 876us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 106/150
216/216 [==============================] - 0s 860us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 107/150
216/216 [==============================] - 0s 933us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 108/150
216/216 [==============================] - 0s 960us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 109/150
216/216 [==============================] - 0s 899us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 110/150
216/216 [==============================] - 0s 932us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 111/150
216/216 [==============================] - 0s 931us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 112/150
216/216 [==============================] - 0s 857us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 113/150
216/216 [==============================] - 0s 861us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 114/150
216/216 [==============================] - 0s 855us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 115/150
216/216 [==============================] - 0s 931us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 116/150
216/216 [==============================] - 0s 932us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 117/150
216/216 [==============================] - 0s 862us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 118/150
216/216 [==============================] - 0s 947us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 119/150
216/216 [==============================] - 0s 996us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 120/150
216/216 [==============================] - 0s 917us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 121/150
216/216 [==============================] - 0s 931us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 122/150
216/216 [==============================] - 0s 931us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 123/150
216/216 [==============================] - 0s 863us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 124/150
216/216 [==============================] - 0s 928us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 125/150
216/216 [==============================] - 0s 855us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 126/150
216/216 [==============================] - 0s 931us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 127/150
216/216 [==============================] - 0s 929us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 128/150
216/216 [==============================] - 0s 858us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 129/150
216/216 [==============================] - 0s 859us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 130/150
216/216 [==============================] - 0s 929us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 131/150
216/216 [==============================] - 0s 1ms/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 132/150
216/216 [==============================] - 0s 930us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 133/150
216/216 [==============================] - 0s 857us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 134/150
216/216 [==============================] - 0s 929us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 135/150
216/216 [==============================] - 0s 932us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 136/150
216/216 [==============================] - 0s 859us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 137/150
216/216 [==============================] - 0s 932us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 138/150
216/216 [==============================] - 0s 922us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 139/150
216/216 [==============================] - 0s 930us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 140/150
216/216 [==============================] - 0s 931us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 141/150
216/216 [==============================] - 0s 944us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 142/150
216/216 [==============================] - 0s 920us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 143/150
216/216 [==============================] - 0s 917us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 144/150
216/216 [==============================] - 0s 895us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 145/150
216/216 [==============================] - 0s 857us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 146/150
216/216 [==============================] - 0s 927us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 147/150
216/216 [==============================] - 0s 857us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 148/150
216/216 [==============================] - 0s 859us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 149/150
216/216 [==============================] - 0s 930us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
Epoch 150/150
216/216 [==============================] - 0s 932us/step - loss: 0.0097 - mae: 0.0903 - mse: 0.0096 - val_loss: 0.0097 - val_mae: 0.0902 - val_mse: 0.0096 - lr: 1.0000e-05
>Saved ../trained_models/severity/models__adam_0.009298830951384186LR_[22]HN_24BS_3P_val_lossM_150epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
162/162 [==============================] - 0s 2ms/step - loss: 0.1069 - mae: 0.1628 - mse: 0.0315 - val_loss: 0.0263 - val_mae: 0.1532 - val_mse: 0.0247 - lr: 0.0093
Epoch 2/150
162/162 [==============================] - 0s 909us/step - loss: 0.0254 - mae: 0.1525 - mse: 0.0245 - val_loss: 0.0253 - val_mae: 0.1532 - val_mse: 0.0247 - lr: 0.0093
Epoch 3/150
162/162 [==============================] - 0s 995us/step - loss: 0.0249 - mae: 0.1525 - mse: 0.0244 - val_loss: 0.0249 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 0.0093
Epoch 4/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0247 - mae: 0.1525 - mse: 0.0244 - val_loss: 0.0248 - val_mae: 0.1532 - val_mse: 0.0245 - lr: 0.0093
Epoch 5/150
162/162 [==============================] - 0s 917us/step - loss: 0.0245 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0248 - val_mae: 0.1532 - val_mse: 0.0246 - lr: 0.0093
Epoch 6/150
162/162 [==============================] - 0s 950us/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0248 - val_mae: 0.1532 - val_mse: 0.0246 - lr: 0.0093
Epoch 7/150
162/162 [==============================] - 0s 915us/step - loss: 0.0244 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0246 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 0.0093
Epoch 8/150
162/162 [==============================] - 0s 948us/step - loss: 0.0245 - mae: 0.1525 - mse: 0.0243 - val_loss: 0.0245 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 0.0093
Epoch 9/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0243 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0245 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 0.0093
Epoch 10/150
 77/162 [=============>................] - ETA: 0s - loss: 0.0243 - mae: 0.1526 - mse: 0.0242
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.004649415612220764.
162/162 [==============================] - 0s 951us/step - loss: 0.0243 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0245 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 0.0093
Epoch 11/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0243 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0245 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 0.0046
Epoch 12/150
162/162 [==============================] - 0s 926us/step - loss: 0.0243 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0245 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 0.0046
Epoch 13/150
158/162 [============================>.] - ETA: 0s - loss: 0.0243 - mae: 0.1525 - mse: 0.0242
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.002324707806110382.
162/162 [==============================] - 0s 1ms/step - loss: 0.0243 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0245 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 0.0046
Epoch 14/150
162/162 [==============================] - 0s 917us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0245 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 0.0023
Epoch 15/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0243 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0245 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 0.0023
Epoch 16/150
102/162 [=================>............] - ETA: 0s - loss: 0.0241 - mae: 0.1522 - mse: 0.0240
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.001162353903055191.
162/162 [==============================] - 0s 917us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0242 - val_loss: 0.0245 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 0.0023
Epoch 17/150
162/162 [==============================] - 0s 952us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0245 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 0.0012
Epoch 18/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0245 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 0.0012
Epoch 19/150
162/162 [==============================] - 0s 992us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0245 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 0.0012
Epoch 20/150
162/162 [==============================] - 0s 912us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0245 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 0.0012
Epoch 21/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0245 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 0.0012
Epoch 22/150
 80/162 [=============>................] - ETA: 0s - loss: 0.0244 - mae: 0.1531 - mse: 0.0243
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005811769515275955.
162/162 [==============================] - 0s 953us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 0.0012
Epoch 23/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 5.8118e-04
Epoch 24/150
162/162 [==============================] - 0s 942us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 5.8118e-04
Epoch 25/150
 91/162 [===============>..............] - ETA: 0s - loss: 0.0241 - mae: 0.1523 - mse: 0.0241
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00029058847576379776.
162/162 [==============================] - 0s 924us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 5.8118e-04
Epoch 26/150
162/162 [==============================] - 0s 942us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 2.9059e-04
Epoch 27/150
162/162 [==============================] - 0s 948us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 2.9059e-04
Epoch 28/150
 78/162 [=============>................] - ETA: 0s - loss: 0.0241 - mae: 0.1523 - mse: 0.0241
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00014529423788189888.
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 2.9059e-04
Epoch 29/150
162/162 [==============================] - 0s 946us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.4529e-04
Epoch 30/150
162/162 [==============================] - 0s 940us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.4529e-04
Epoch 31/150
 85/162 [==============>...............] - ETA: 0s - loss: 0.0242 - mae: 0.1527 - mse: 0.0242
Epoch 31: ReduceLROnPlateau reducing learning rate to 7.264711894094944e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.4529e-04
Epoch 32/150
162/162 [==============================] - 0s 944us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 7.2647e-05
Epoch 33/150
162/162 [==============================] - 0s 924us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 7.2647e-05
Epoch 34/150
 79/162 [=============>................] - ETA: 0s - loss: 0.0242 - mae: 0.1525 - mse: 0.0241
Epoch 34: ReduceLROnPlateau reducing learning rate to 3.632355947047472e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 7.2647e-05
Epoch 35/150
162/162 [==============================] - 0s 917us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 3.6324e-05
Epoch 36/150
162/162 [==============================] - 0s 946us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 3.6324e-05
Epoch 37/150
 80/162 [=============>................] - ETA: 0s - loss: 0.0240 - mae: 0.1518 - mse: 0.0239
Epoch 37: ReduceLROnPlateau reducing learning rate to 1.816177973523736e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 3.6324e-05
Epoch 38/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.8162e-05
Epoch 39/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.8162e-05
Epoch 40/150
 85/162 [==============>...............] - ETA: 0s - loss: 0.0240 - mae: 0.1519 - mse: 0.0239
Epoch 40: ReduceLROnPlateau reducing learning rate to 1e-05.
162/162 [==============================] - 0s 997us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.8162e-05
Epoch 41/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 42/150
162/162 [==============================] - 0s 979us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 43/150
162/162 [==============================] - 0s 917us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 44/150
162/162 [==============================] - 0s 950us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 45/150
162/162 [==============================] - 0s 911us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 46/150
162/162 [==============================] - 0s 952us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 47/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 48/150
162/162 [==============================] - 0s 950us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 49/150
162/162 [==============================] - 0s 998us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 50/150
162/162 [==============================] - 0s 912us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 51/150
162/162 [==============================] - 0s 953us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 52/150
162/162 [==============================] - 0s 914us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 53/150
162/162 [==============================] - 0s 950us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 54/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 55/150
162/162 [==============================] - 0s 946us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 56/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 57/150
162/162 [==============================] - 0s 960us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 58/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 59/150
162/162 [==============================] - 0s 915us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 60/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 61/150
162/162 [==============================] - 0s 920us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 62/150
162/162 [==============================] - 0s 945us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 63/150
162/162 [==============================] - 0s 922us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 64/150
162/162 [==============================] - 0s 956us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 65/150
162/162 [==============================] - 0s 995us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 66/150
162/162 [==============================] - 0s 931us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 67/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 68/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 69/150
162/162 [==============================] - 0s 915us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 70/150
162/162 [==============================] - 0s 947us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 71/150
162/162 [==============================] - 0s 917us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 72/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 73/150
162/162 [==============================] - 0s 913us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 74/150
162/162 [==============================] - 0s 955us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 75/150
162/162 [==============================] - 0s 973us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 76/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 77/150
162/162 [==============================] - 0s 938us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 78/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 79/150
162/162 [==============================] - 0s 957us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 80/150
162/162 [==============================] - 0s 913us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 81/150
162/162 [==============================] - 0s 952us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 82/150
162/162 [==============================] - 0s 984us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 83/150
162/162 [==============================] - 0s 977us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 84/150
162/162 [==============================] - 0s 951us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 85/150
162/162 [==============================] - 0s 920us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 86/150
162/162 [==============================] - 0s 964us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 87/150
162/162 [==============================] - 0s 993us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 88/150
162/162 [==============================] - 0s 972us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 89/150
162/162 [==============================] - 0s 947us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 90/150
162/162 [==============================] - 0s 909us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 91/150
162/162 [==============================] - 0s 951us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 92/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 93/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 94/150
162/162 [==============================] - 0s 975us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 95/150
162/162 [==============================] - 0s 964us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 96/150
162/162 [==============================] - 0s 890us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
162/162 [==============================] - 0s 948us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 104/150
162/162 [==============================] - 0s 915us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 105/150
162/162 [==============================] - 0s 949us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 106/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 107/150
162/162 [==============================] - 0s 951us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 108/150
162/162 [==============================] - 0s 980us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 109/150
162/162 [==============================] - 0s 988us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 110/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 111/150
162/162 [==============================] - 0s 954us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 112/150
162/162 [==============================] - 0s 946us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 113/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 114/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 115/150
162/162 [==============================] - 0s 909us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 116/150
162/162 [==============================] - 0s 954us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 117/150
162/162 [==============================] - 0s 947us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 118/150
162/162 [==============================] - 0s 917us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 119/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 120/150
162/162 [==============================] - 0s 913us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 121/150
162/162 [==============================] - 0s 951us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 122/150
162/162 [==============================] - 0s 974us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 123/150
162/162 [==============================] - 0s 989us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 124/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 125/150
162/162 [==============================] - 0s 956us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 126/150
162/162 [==============================] - 0s 948us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 127/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 128/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 129/150
162/162 [==============================] - 0s 918us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 130/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 131/150
162/162 [==============================] - 0s 946us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 132/150
162/162 [==============================] - 0s 915us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 133/150
162/162 [==============================] - 0s 958us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 134/150
162/162 [==============================] - 0s 896us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 135/150
162/162 [==============================] - 0s 952us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 136/150
162/162 [==============================] - 0s 1000us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 137/150
162/162 [==============================] - 0s 966us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 138/150
162/162 [==============================] - 0s 916us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 139/150
162/162 [==============================] - 0s 941us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 140/150
162/162 [==============================] - 0s 950us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 141/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 142/150
162/162 [==============================] - 0s 882us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 143/150
162/162 [==============================] - 0s 985us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 144/150
162/162 [==============================] - 0s 996us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 145/150
162/162 [==============================] - 0s 964us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 146/150
162/162 [==============================] - 0s 953us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 147/150
162/162 [==============================] - 0s 996us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 148/150
162/162 [==============================] - 0s 975us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 149/150
162/162 [==============================] - 0s 951us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
Epoch 150/150
162/162 [==============================] - 0s 917us/step - loss: 0.0242 - mae: 0.1525 - mse: 0.0241 - val_loss: 0.0244 - val_mae: 0.1532 - val_mse: 0.0244 - lr: 1.0000e-05
>Saved ../trained_models/severity/models__adam_0.009298830951384186LR_[22]HN_24BS_3P_val_lossM_150epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
162/162 [==============================] - 0s 2ms/step - loss: 0.1206 - mae: 0.2051 - mse: 0.0468 - val_loss: 0.0438 - val_mae: 0.2032 - val_mse: 0.0425 - lr: 0.0093
Epoch 2/150
162/162 [==============================] - 0s 913us/step - loss: 0.0429 - mae: 0.2025 - mse: 0.0422 - val_loss: 0.0429 - val_mae: 0.2032 - val_mse: 0.0425 - lr: 0.0093
Epoch 3/150
162/162 [==============================] - 0s 952us/step - loss: 0.0425 - mae: 0.2025 - mse: 0.0422 - val_loss: 0.0427 - val_mae: 0.2032 - val_mse: 0.0424 - lr: 0.0093
Epoch 4/150
162/162 [==============================] - 0s 948us/step - loss: 0.0424 - mae: 0.2025 - mse: 0.0422 - val_loss: 0.0426 - val_mae: 0.2032 - val_mse: 0.0425 - lr: 0.0093
Epoch 5/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0423 - mae: 0.2025 - mse: 0.0422 - val_loss: 0.0426 - val_mae: 0.2032 - val_mse: 0.0424 - lr: 0.0093
Epoch 6/150
162/162 [==============================] - 0s 993us/step - loss: 0.0423 - mae: 0.2025 - mse: 0.0422 - val_loss: 0.0425 - val_mae: 0.2032 - val_mse: 0.0424 - lr: 0.0093
Epoch 7/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0422 - mae: 0.2025 - mse: 0.0421 - val_loss: 0.0424 - val_mae: 0.2032 - val_mse: 0.0423 - lr: 0.0093
Epoch 8/150
162/162 [==============================] - 0s 912us/step - loss: 0.0421 - mae: 0.2025 - mse: 0.0420 - val_loss: 0.0424 - val_mae: 0.2032 - val_mse: 0.0423 - lr: 0.0093
Epoch 9/150
162/162 [==============================] - 0s 954us/step - loss: 0.0421 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0423 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0093
Epoch 10/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0420 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0423 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0093
Epoch 11/150
162/162 [==============================] - 0s 950us/step - loss: 0.0420 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0423 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0093
Epoch 12/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0420 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0423 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0093
Epoch 13/150
102/162 [=================>............] - ETA: 0s - loss: 0.0417 - mae: 0.2019 - mse: 0.0416
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.004649415612220764.
162/162 [==============================] - 0s 914us/step - loss: 0.0420 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0093
Epoch 14/150
162/162 [==============================] - 0s 952us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0423 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0046
Epoch 15/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0046
Epoch 16/150
 71/162 [============>.................] - ETA: 0s - loss: 0.0419 - mae: 0.2025 - mse: 0.0419
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.002324707806110382.
162/162 [==============================] - 0s 1ms/step - loss: 0.0420 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0046
Epoch 17/150
162/162 [==============================] - 0s 941us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 0.0023
Epoch 18/150
162/162 [==============================] - 0s 924us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0023
Epoch 19/150
 85/162 [==============>...............] - ETA: 0s - loss: 0.0418 - mae: 0.2024 - mse: 0.0418
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.001162353903055191.
162/162 [==============================] - 0s 952us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0419 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0023
Epoch 20/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 0.0012
Epoch 21/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 0.0012
Epoch 22/150
 90/162 [===============>..............] - ETA: 0s - loss: 0.0417 - mae: 0.2021 - mse: 0.0417
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005811769515275955.
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 0.0012
Epoch 23/150
162/162 [==============================] - 0s 914us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 5.8118e-04
Epoch 24/150
162/162 [==============================] - 0s 951us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 5.8118e-04
Epoch 25/150
101/162 [=================>............] - ETA: 0s - loss: 0.0419 - mae: 0.2025 - mse: 0.0418
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00029058847576379776.
162/162 [==============================] - 0s 915us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 5.8118e-04
Epoch 26/150
162/162 [==============================] - 0s 947us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 2.9059e-04
Epoch 27/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 2.9059e-04
Epoch 28/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 2.9059e-04
Epoch 29/150
162/162 [==============================] - 0s 963us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 2.9059e-04
Epoch 30/150
 65/162 [===========>..................] - ETA: 0s - loss: 0.0418 - mae: 0.2024 - mse: 0.0418
Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00014529423788189888.
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0422 - lr: 2.9059e-04
Epoch 31/150
162/162 [==============================] - 0s 951us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.4529e-04
Epoch 32/150
162/162 [==============================] - 0s 917us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.4529e-04
Epoch 33/150
 62/162 [==========>...................] - ETA: 0s - loss: 0.0421 - mae: 0.2030 - mse: 0.0420
Epoch 33: ReduceLROnPlateau reducing learning rate to 7.264711894094944e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.4529e-04
Epoch 34/150
162/162 [==============================] - 0s 953us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 7.2647e-05
Epoch 35/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 7.2647e-05
Epoch 36/150
 75/162 [============>.................] - ETA: 0s - loss: 0.0419 - mae: 0.2027 - mse: 0.0419
Epoch 36: ReduceLROnPlateau reducing learning rate to 3.632355947047472e-05.
162/162 [==============================] - 0s 949us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 7.2647e-05
Epoch 37/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 3.6324e-05
Epoch 38/150
162/162 [==============================] - 0s 927us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 3.6324e-05
Epoch 39/150
159/162 [============================>.] - ETA: 0s - loss: 0.0419 - mae: 0.2025 - mse: 0.0418
Epoch 39: ReduceLROnPlateau reducing learning rate to 1.816177973523736e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 3.6324e-05
Epoch 40/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.8162e-05
Epoch 41/150
162/162 [==============================] - 0s 954us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.8162e-05
Epoch 42/150
 89/162 [===============>..............] - ETA: 0s - loss: 0.0420 - mae: 0.2029 - mse: 0.0420
Epoch 42: ReduceLROnPlateau reducing learning rate to 1e-05.
162/162 [==============================] - 0s 970us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.8162e-05
Epoch 43/150
162/162 [==============================] - 0s 968us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 44/150
162/162 [==============================] - 0s 971us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 45/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 46/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 47/150
162/162 [==============================] - 0s 914us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 48/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 49/150
162/162 [==============================] - 0s 950us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 50/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 51/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 52/150
162/162 [==============================] - 0s 986us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 53/150
162/162 [==============================] - 0s 973us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 54/150
162/162 [==============================] - 0s 952us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 55/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 56/150
162/162 [==============================] - 0s 958us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 57/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 58/150
162/162 [==============================] - 0s 954us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 59/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 60/150
162/162 [==============================] - 0s 960us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 61/150
162/162 [==============================] - 0s 943us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 62/150
162/162 [==============================] - 0s 912us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 63/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 64/150
162/162 [==============================] - 0s 946us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 65/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 66/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 67/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 68/150
162/162 [==============================] - 0s 912us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 69/150
162/162 [==============================] - 0s 953us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 70/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 71/150
162/162 [==============================] - 0s 991us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 72/150
162/162 [==============================] - 0s 977us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 73/150
162/162 [==============================] - 0s 946us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 74/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 75/150
162/162 [==============================] - 0s 949us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 76/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 77/150
162/162 [==============================] - 0s 967us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 78/150
162/162 [==============================] - 0s 927us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 79/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 80/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 81/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 82/150
162/162 [==============================] - 0s 980us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 83/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 84/150
162/162 [==============================] - 0s 914us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 85/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 86/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 87/150
162/162 [==============================] - 0s 913us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 88/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 89/150
162/162 [==============================] - 0s 910us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 90/150
162/162 [==============================] - 0s 984us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 91/150
162/162 [==============================] - 0s 989us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 92/150
162/162 [==============================] - 0s 941us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 93/150
162/162 [==============================] - 0s 949us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 94/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 95/150
162/162 [==============================] - 0s 945us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 96/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 97/150
162/162 [==============================] - 0s 921us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 98/150
162/162 [==============================] - 0s 941us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 99/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 100/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 101/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 102/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 103/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 104/150
162/162 [==============================] - 0s 969us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 105/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 106/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 107/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 108/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 109/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 110/150
162/162 [==============================] - 0s 979us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 111/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 112/150
162/162 [==============================] - 0s 947us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 113/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 114/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 115/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 116/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 117/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 118/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 119/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 120/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 121/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 122/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 123/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 124/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 125/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 126/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 127/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 128/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 129/150
162/162 [==============================] - 0s 971us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 130/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 131/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 132/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 133/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 134/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 135/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 136/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 137/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 138/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 139/150
162/162 [==============================] - 0s 973us/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 140/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 141/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 142/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 143/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 144/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 145/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 146/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 147/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 148/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 149/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
Epoch 150/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0419 - mae: 0.2025 - mse: 0.0418 - val_loss: 0.0422 - val_mae: 0.2032 - val_mse: 0.0421 - lr: 1.0000e-05
>Saved ../trained_models/severity/models__adam_0.009298830951384186LR_[22]HN_24BS_3P_val_lossM_150epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
162/162 [==============================] - 1s 2ms/step - loss: 0.1435 - mae: 0.2527 - mse: 0.0676 - val_loss: 0.0661 - val_mae: 0.2532 - val_mse: 0.0655 - lr: 0.0093
Epoch 2/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0654 - mae: 0.2525 - mse: 0.0650 - val_loss: 0.0655 - val_mae: 0.2532 - val_mse: 0.0653 - lr: 0.0093
Epoch 3/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0652 - mae: 0.2525 - mse: 0.0650 - val_loss: 0.0654 - val_mae: 0.2532 - val_mse: 0.0653 - lr: 0.0093
Epoch 4/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0651 - mae: 0.2525 - mse: 0.0650 - val_loss: 0.0654 - val_mae: 0.2532 - val_mse: 0.0653 - lr: 0.0093
Epoch 5/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0650 - mae: 0.2525 - mse: 0.0649 - val_loss: 0.0653 - val_mae: 0.2532 - val_mse: 0.0652 - lr: 0.0093
Epoch 6/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0650 - mae: 0.2525 - mse: 0.0649 - val_loss: 0.0653 - val_mae: 0.2532 - val_mse: 0.0652 - lr: 0.0093
Epoch 7/150
162/162 [==============================] - ETA: 0s - loss: 0.0650 - mae: 0.2525 - mse: 0.0649
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.004649415612220764.
162/162 [==============================] - 0s 1ms/step - loss: 0.0650 - mae: 0.2525 - mse: 0.0649 - val_loss: 0.0653 - val_mae: 0.2532 - val_mse: 0.0652 - lr: 0.0093
Epoch 8/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0649 - mae: 0.2525 - mse: 0.0648 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0046
Epoch 9/150============>...............] - ETA: 0s - loss: 0.0240 - mae: 0.1519 - mse: 0.0239
162/162 [==============================] - 0s 1ms/step - loss: 0.0649 - mae: 0.2525 - mse: 0.0648 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0046
Epoch 10/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0649 - mae: 0.2525 - mse: 0.0648 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0652 - lr: 0.0046
Epoch 11/150
160/162 [============================>.] - ETA: 0s - loss: 0.0648 - mae: 0.2525 - mse: 0.0647
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.002324707806110382.
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0648 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0046
Epoch 12/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0648 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0023
Epoch 13/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0648 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0023
Epoch 14/150
154/162 [===========================>..] - ETA: 0s - loss: 0.0649 - mae: 0.2526 - mse: 0.0648
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.001162353903055191.
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0648 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0023
Epoch 15/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0012
Epoch 16/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0012
Epoch 17/150
 91/162 [===============>..............] - ETA: 0s - loss: 0.0647 - mae: 0.2523 - mse: 0.0646
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005811769515275955.
162/162 [==============================] - 0s 989us/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 0.0012
Epoch 18/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 5.8118e-04
Epoch 19/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 5.8118e-04
Epoch 20/150
 84/162 [==============>...............] - ETA: 0s - loss: 0.0647 - mae: 0.2524 - mse: 0.0647
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.00029058847576379776.
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 5.8118e-04
Epoch 21/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0652 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 2.9059e-04
Epoch 22/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 2.9059e-04
Epoch 23/150
161/162 [============================>.] - ETA: 0s - loss: 0.0648 - mae: 0.2525 - mse: 0.0647
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00014529423788189888.
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 2.9059e-04
Epoch 24/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.4529e-04
Epoch 25/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.4529e-04
Epoch 26/150
 82/162 [==============>...............] - ETA: 0s - loss: 0.0646 - mae: 0.2522 - mse: 0.0646
Epoch 26: ReduceLROnPlateau reducing learning rate to 7.264711894094944e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.4529e-04
Epoch 27/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 7.2647e-05
Epoch 28/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 7.2647e-05
Epoch 29/150
 90/162 [===============>..............] - ETA: 0s - loss: 0.0645 - mae: 0.2520 - mse: 0.0645
Epoch 29: ReduceLROnPlateau reducing learning rate to 3.632355947047472e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 7.2647e-05
Epoch 30/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 3.6324e-05
Epoch 31/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 3.6324e-05
Epoch 32/150
134/162 [=======================>......] - ETA: 0s - loss: 0.0647 - mae: 0.2523 - mse: 0.0646
Epoch 32: ReduceLROnPlateau reducing learning rate to 1.816177973523736e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 3.6324e-05
Epoch 33/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.8162e-05
Epoch 34/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.8162e-05
Epoch 35/150
117/162 [====================>.........] - ETA: 0s - loss: 0.0648 - mae: 0.2526 - mse: 0.0647
Epoch 35: ReduceLROnPlateau reducing learning rate to 1e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.8162e-05
Epoch 36/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 37/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 38/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 39/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 40/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 41/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 42/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 43/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 44/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 45/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 46/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 47/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 48/150
162/162 [==============================] - 0s 982us/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 49/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 50/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 51/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 52/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 53/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 54/150
162/162 [==============================] - 0s 937us/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 55/150
162/162 [==============================] - 0s 936us/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 56/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 57/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 58/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 59/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 60/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 61/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 62/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 63/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 64/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 65/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 66/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 67/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 68/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 69/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 70/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 71/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 72/150
162/162 [==============================] - 0s 939us/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 73/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 74/150
162/162 [==============================] - 0s 954us/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 75/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 76/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 77/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 78/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 79/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 80/150
162/162 [==============================] - 0s 996us/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 81/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 82/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 83/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 84/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 85/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 86/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 87/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 88/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 89/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 90/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 91/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 92/150
162/162 [==============================] - 0s 942us/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 93/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 94/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 95/150
162/162 [==============================] - 0s 976us/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 96/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 97/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 98/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 99/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 100/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 101/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 102/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 103/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 104/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 105/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 106/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 107/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 108/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 109/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 110/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 111/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 112/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 113/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 114/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 115/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 116/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 117/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 118/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 119/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 120/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 121/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 122/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 123/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 124/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 125/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 126/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 127/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 128/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 129/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 130/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 131/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 132/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 133/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 134/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 135/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 136/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 137/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 138/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 139/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 140/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 141/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 142/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 143/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 144/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 145/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 146/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 147/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 148/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 149/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
Epoch 150/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0648 - mae: 0.2525 - mse: 0.0647 - val_loss: 0.0651 - val_mae: 0.2532 - val_mse: 0.0651 - lr: 1.0000e-05
>Saved ../trained_models/severity/models__adam_0.009298830951384186LR_[22]HN_24BS_3P_val_lossM_150epochs/model_5.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
162/162 [==============================] - 1s 2ms/step - loss: 0.1749 - mae: 0.3025 - mse: 0.0938 - val_loss: 0.0937 - val_mae: 0.3032 - val_mse: 0.0932 - lr: 0.0093
Epoch 2/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0929 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0932 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0093
Epoch 3/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0928 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0932 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0093
Epoch 4/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0928 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0932 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0093
Epoch 5/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0093
Epoch 6/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0093
Epoch 7/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0093
Epoch 8/150
120/162 [=====================>........] - ETA: 0s - loss: 0.0927 - mae: 0.3025 - mse: 0.0927
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.004649415612220764.
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0093
Epoch 9/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0046
Epoch 10/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0046
Epoch 11/150
111/162 [===================>..........] - ETA: 0s - loss: 0.0926 - mae: 0.3025 - mse: 0.0926
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.002324707806110382.
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0046
Epoch 12/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0023
Epoch 13/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0023
Epoch 14/150
160/162 [============================>.] - ETA: 0s - loss: 0.0927 - mae: 0.3025 - mse: 0.0927
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.001162353903055191.
162/162 [==============================] - 0s 2ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0023
Epoch 15/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0012
Epoch 16/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0012
Epoch 17/150
122/162 [=====================>........] - ETA: 0s - loss: 0.0928 - mae: 0.3027 - mse: 0.0928
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005811769515275955.
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0012
Epoch 18/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 5.8118e-04
Epoch 19/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 5.8118e-04
Epoch 20/150
 72/162 [============>.................] - ETA: 0s - loss: 0.0926 - mae: 0.3023 - mse: 0.0926
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.00029058847576379776.
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 5.8118e-04
Epoch 21/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 2.9059e-04
Epoch 22/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 2.9059e-04
Epoch 23/150
 87/162 [===============>..............] - ETA: 0s - loss: 0.0930 - mae: 0.3031 - mse: 0.0930
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00014529423788189888.
162/162 [==============================] - 0s 983us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 2.9059e-04
Epoch 24/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.4529e-04
Epoch 25/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.4529e-04
Epoch 26/150
 85/162 [==============>...............] - ETA: 0s - loss: 0.0928 - mae: 0.3027 - mse: 0.0928
Epoch 26: ReduceLROnPlateau reducing learning rate to 7.264711894094944e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.4529e-04
Epoch 27/150
162/162 [==============================] - 0s 948us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 7.2647e-05
Epoch 28/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 7.2647e-05
Epoch 29/150
145/162 [=========================>....] - ETA: 0s - loss: 0.0929 - mae: 0.3028 - mse: 0.0929
Epoch 29: ReduceLROnPlateau reducing learning rate to 3.632355947047472e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 7.2647e-05
Epoch 30/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 3.6324e-05
Epoch 31/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 3.6324e-05
Epoch 32/150
137/162 [========================>.....] - ETA: 0s - loss: 0.0926 - mae: 0.3024 - mse: 0.0926
Epoch 32: ReduceLROnPlateau reducing learning rate to 1.816177973523736e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 3.6324e-05
Epoch 33/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.8162e-05
Epoch 34/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.8162e-05
Epoch 35/150
117/162 [====================>.........] - ETA: 0s - loss: 0.0927 - mae: 0.3026 - mse: 0.0927
Epoch 35: ReduceLROnPlateau reducing learning rate to 1e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.8162e-05
Epoch 36/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 37/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 38/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 39/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 40/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 41/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 42/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 43/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 44/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 45/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 46/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 47/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 48/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 49/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 50/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 51/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 52/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 53/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 54/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 55/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 56/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 57/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 58/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 59/150
162/162 [==============================] - 0s 954us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 60/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 61/150
162/162 [==============================] - 0s 918us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 62/150
162/162 [==============================] - 0s 972us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 63/150
162/162 [==============================] - 0s 995us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 64/150
162/162 [==============================] - 0s 989us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 65/150
162/162 [==============================] - 0s 950us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 66/150
162/162 [==============================] - 0s 914us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 67/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 68/150
162/162 [==============================] - 0s 950us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 69/150
162/162 [==============================] - 0s 963us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 70/150
162/162 [==============================] - 0s 876us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 71/150
162/162 [==============================] - 0s 969us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 72/150
162/162 [==============================] - 0s 931us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 73/150
162/162 [==============================] - 0s 902us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 74/150
162/162 [==============================] - 0s 951us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 75/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 76/150
162/162 [==============================] - 0s 936us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 77/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 78/150
162/162 [==============================] - 0s 1000us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 79/150
162/162 [==============================] - 0s 961us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 80/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 81/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 82/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 83/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 84/150
162/162 [==============================] - 0s 921us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 85/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 86/150
162/162 [==============================] - 0s 991us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 87/150
162/162 [==============================] - 0s 876us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 88/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 89/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 90/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 91/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 92/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 93/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 94/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 95/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 96/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 97/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 98/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 99/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 100/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 101/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 102/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 103/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 104/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 105/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 106/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 107/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 108/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 109/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 110/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 111/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 112/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 113/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 114/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 115/150
162/162 [==============================] - 0s 2ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 116/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 117/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 118/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 119/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 120/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 121/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 122/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 123/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 124/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 125/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 126/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 127/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 128/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 129/150
162/162 [==============================] - 0s 986us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 130/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 131/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 132/150
162/162 [==============================] - 0s 971us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 133/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 134/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 135/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 136/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 137/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 138/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 139/150
162/162 [==============================] - 0s 969us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 140/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 141/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 142/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 143/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 144/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 145/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 146/150
162/162 [==============================] - 0s 928us/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 147/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 148/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 149/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
Epoch 150/150
162/162 [==============================] - 0s 1ms/step - loss: 0.0927 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0931 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 1.0000e-05
>Saved ../trained_models/severity/models__adam_0.009298830951384186LR_[22]HN_24BS_3P_val_lossM_150epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
162/162 [==============================] - 1s 2ms/step - loss: 0.2121 - mae: 0.3525 - mse: 0.1259 - val_loss: 0.1262 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 0.0093
Epoch 2/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1255 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 0.0093
Epoch 3/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1255 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 0.0093
Epoch 4/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 0.0093
Epoch 5/150
147/162 [==========================>...] - ETA: 0s - loss: 0.1254 - mae: 0.3526 - mse: 0.1254
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.004649415612220764.
162/162 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1254 - val_loss: 0.1259 - val_mae: 0.3532 - val_mse: 0.1259 - lr: 0.0093
Epoch 6/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1254 - mae: 0.3525 - mse: 0.1253 - val_loss: 0.1258 - val_mae: 0.3532 - val_mse: 0.1258 - lr: 0.0046
Epoch 7/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1253 - mae: 0.3525 - mse: 0.1253 - val_loss: 0.1258 - val_mae: 0.3532 - val_mse: 0.1258 - lr: 0.0046
Epoch 8/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1253 - mae: 0.3525 - mse: 0.1253 - val_loss: 0.1258 - val_mae: 0.3532 - val_mse: 0.1258 - lr: 0.0046
Epoch 9/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1253 - mae: 0.3525 - mse: 0.1252 - val_loss: 0.1258 - val_mae: 0.3532 - val_mse: 0.1258 - lr: 0.0046
Epoch 10/150
161/162 [============================>.] - ETA: 0s - loss: 0.1253 - mae: 0.3525 - mse: 0.1252
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.002324707806110382.
162/162 [==============================] - 0s 973us/step - loss: 0.1253 - mae: 0.3525 - mse: 0.1252 - val_loss: 0.1258 - val_mae: 0.3532 - val_mse: 0.1257 - lr: 0.0046
Epoch 11/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1253 - mae: 0.3525 - mse: 0.1252 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1257 - lr: 0.0023
Epoch 12/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1253 - mae: 0.3525 - mse: 0.1252 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1257 - lr: 0.0023
Epoch 13/150
115/162 [====================>.........] - ETA: 0s - loss: 0.1251 - mae: 0.3523 - mse: 0.1250
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.001162353903055191.
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1252 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1257 - lr: 0.0023
Epoch 14/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1252 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1257 - lr: 0.0012
Epoch 15/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1252 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1257 - lr: 0.0012
Epoch 16/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1252 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1257 - lr: 0.0012
Epoch 17/150
129/162 [======================>.......] - ETA: 0s - loss: 0.1251 - mae: 0.3523 - mse: 0.1250
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005811769515275955.
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1252 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1257 - lr: 0.0012
Epoch 18/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1257 - lr: 5.8118e-04
Epoch 19/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 5.8118e-04
Epoch 20/150
132/162 [=======================>......] - ETA: 0s - loss: 0.1251 - mae: 0.3523 - mse: 0.1250
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.00029058847576379776.
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1257 - lr: 5.8118e-04
Epoch 21/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 2.9059e-04
Epoch 22/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 2.9059e-04
Epoch 23/150
153/162 [===========================>..] - ETA: 0s - loss: 0.1252 - mae: 0.3525 - mse: 0.1251
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00014529423788189888.
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 2.9059e-04
Epoch 24/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1257 - lr: 1.4529e-04
Epoch 25/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.4529e-04
Epoch 26/150
150/162 [==========================>...] - ETA: 0s - loss: 0.1253 - mae: 0.3527 - mse: 0.1252
Epoch 26: ReduceLROnPlateau reducing learning rate to 7.264711894094944e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.4529e-04
Epoch 27/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 7.2647e-05
Epoch 28/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 7.2647e-05
Epoch 29/150
150/162 [==========================>...] - ETA: 0s - loss: 0.1253 - mae: 0.3527 - mse: 0.1252
Epoch 29: ReduceLROnPlateau reducing learning rate to 3.632355947047472e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 7.2647e-05
Epoch 30/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 3.6324e-05
Epoch 31/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 3.6324e-05
Epoch 32/150
150/162 [==========================>...] - ETA: 0s - loss: 0.1251 - mae: 0.3524 - mse: 0.1250
Epoch 32: ReduceLROnPlateau reducing learning rate to 1.816177973523736e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 3.6324e-05
Epoch 33/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.8162e-05
Epoch 34/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.8162e-05
Epoch 35/150
155/162 [===========================>..] - ETA: 0s - loss: 0.1253 - mae: 0.3526 - mse: 0.1252
Epoch 35: ReduceLROnPlateau reducing learning rate to 1e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.8162e-05
Epoch 36/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 37/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 38/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 39/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 40/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 41/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 42/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 43/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 44/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 45/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 46/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 47/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 48/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 49/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 50/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 51/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 52/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 53/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 54/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 55/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 56/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 57/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 58/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 59/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 60/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 61/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 62/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 63/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 64/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 65/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 66/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 67/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 68/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 69/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 70/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 71/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 72/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 73/150
162/162 [==============================] - 0s 951us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 74/150
162/162 [==============================] - 0s 949us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 75/150
162/162 [==============================] - 0s 914us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 76/150
162/162 [==============================] - 0s 949us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 77/150
162/162 [==============================] - 0s 912us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 78/150
162/162 [==============================] - 0s 952us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 79/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 80/150
162/162 [==============================] - 0s 943us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 81/150
162/162 [==============================] - 0s 914us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 82/150
162/162 [==============================] - 0s 995us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 83/150
162/162 [==============================] - 0s 996us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 84/150
162/162 [==============================] - 0s 911us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 85/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 86/150
162/162 [==============================] - 0s 914us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 87/150
162/162 [==============================] - 0s 951us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 88/150
162/162 [==============================] - 0s 912us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 89/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 90/150
162/162 [==============================] - 0s 986us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 91/150
162/162 [==============================] - 0s 953us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 92/150
162/162 [==============================] - 0s 912us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 93/150
162/162 [==============================] - 0s 926us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 94/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 95/150
162/162 [==============================] - 0s 954us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 96/150
162/162 [==============================] - 0s 951us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 97/150
162/162 [==============================] - 0s 911us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 98/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 99/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 100/150
162/162 [==============================] - 0s 937us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 101/150
162/162 [==============================] - 0s 914us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 102/150
162/162 [==============================] - 0s 852us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 103/150
162/162 [==============================] - 0s 952us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 104/150
162/162 [==============================] - 0s 920us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 105/150
162/162 [==============================] - 0s 944us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 106/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 107/150
162/162 [==============================] - 0s 943us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 108/150
162/162 [==============================] - 0s 915us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 109/150
162/162 [==============================] - 0s 952us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 110/150
162/162 [==============================] - 0s 917us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 111/150
162/162 [==============================] - 0s 956us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 112/150
162/162 [==============================] - 0s 902us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 113/150
162/162 [==============================] - 0s 947us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 114/150
162/162 [==============================] - 0s 952us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 115/150
162/162 [==============================] - 0s 912us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 116/150
162/162 [==============================] - 0s 954us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 117/150
162/162 [==============================] - 0s 911us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 118/150
162/162 [==============================] - 0s 950us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 119/150
162/162 [==============================] - 0s 913us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 120/150
162/162 [==============================] - 0s 956us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 121/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 122/150
162/162 [==============================] - 0s 966us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 123/150
162/162 [==============================] - 0s 934us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 124/150
162/162 [==============================] - 0s 918us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 125/150
162/162 [==============================] - 0s 850us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 126/150
162/162 [==============================] - 0s 914us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 127/150
162/162 [==============================] - 0s 949us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 128/150
162/162 [==============================] - 0s 913us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 129/150
162/162 [==============================] - 0s 965us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 130/150
162/162 [==============================] - 0s 997us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 131/150
162/162 [==============================] - 0s 994us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 132/150
162/162 [==============================] - 0s 909us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 133/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 134/150
162/162 [==============================] - 0s 950us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 135/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 136/150
162/162 [==============================] - 0s 947us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 137/150
162/162 [==============================] - 0s 917us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 138/150
162/162 [==============================] - 0s 952us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 139/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 140/150
162/162 [==============================] - 0s 917us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 141/150
162/162 [==============================] - 0s 947us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 142/150
162/162 [==============================] - 0s 966us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 143/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 144/150
162/162 [==============================] - 0s 915us/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 145/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 146/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 147/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 148/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 149/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
Epoch 150/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1252 - mae: 0.3525 - mse: 0.1251 - val_loss: 0.1257 - val_mae: 0.3532 - val_mse: 0.1256 - lr: 1.0000e-05
>Saved ../trained_models/severity/models__adam_0.009298830951384186LR_[22]HN_24BS_3P_val_lossM_150epochs/model_7.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
162/162 [==============================] - 1s 2ms/step - loss: 0.2258 - mae: 0.4025 - mse: 0.1633 - val_loss: 0.1639 - val_mae: 0.4032 - val_mse: 0.1638 - lr: 0.0093
Epoch 2/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0093
Epoch 3/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0093
Epoch 4/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0093
Epoch 5/150
140/162 [========================>.....] - ETA: 0s - loss: 0.1630 - mae: 0.4023 - mse: 0.1630
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.004649415612220764.
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0093
Epoch 6/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0046
Epoch 7/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0046
Epoch 8/150
159/162 [============================>.] - ETA: 0s - loss: 0.1632 - mae: 0.4026 - mse: 0.1632
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.002324707806110382.
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0046
Epoch 9/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0023
Epoch 10/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0023
Epoch 11/150
158/162 [============================>.] - ETA: 0s - loss: 0.1632 - mae: 0.4025 - mse: 0.1632
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.001162353903055191.
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0023
Epoch 12/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0012
Epoch 13/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0012
Epoch 14/150
145/162 [=========================>....] - ETA: 0s - loss: 0.1630 - mae: 0.4023 - mse: 0.1630
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005811769515275955.
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 0.0012
Epoch 15/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 5.8118e-04
Epoch 16/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 5.8118e-04
Epoch 17/150
139/162 [========================>.....] - ETA: 0s - loss: 0.1631 - mae: 0.4025 - mse: 0.1631
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00029058847576379776.
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 5.8118e-04
Epoch 18/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 2.9059e-04
Epoch 19/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 2.9059e-04
Epoch 20/150
144/162 [=========================>....] - ETA: 0s - loss: 0.1632 - mae: 0.4025 - mse: 0.1632
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.00014529423788189888.
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 2.9059e-04
Epoch 21/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.4529e-04
Epoch 22/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.4529e-04
Epoch 23/150
156/162 [===========================>..] - ETA: 0s - loss: 0.1632 - mae: 0.4025 - mse: 0.1632
Epoch 23: ReduceLROnPlateau reducing learning rate to 7.264711894094944e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.4529e-04
Epoch 24/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 7.2647e-05
Epoch 25/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 7.2647e-05
Epoch 26/150
152/162 [===========================>..] - ETA: 0s - loss: 0.1631 - mae: 0.4025 - mse: 0.1631
Epoch 26: ReduceLROnPlateau reducing learning rate to 3.632355947047472e-05.
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 7.2647e-05
Epoch 27/150
162/162 [==============================] - 0s 939us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 3.6324e-05
Epoch 28/150
162/162 [==============================] - 0s 925us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 3.6324e-05
Epoch 29/150
 80/162 [=============>................] - ETA: 0s - loss: 0.1632 - mae: 0.4025 - mse: 0.1632
Epoch 29: ReduceLROnPlateau reducing learning rate to 1.816177973523736e-05.
162/162 [==============================] - 0s 938us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 3.6324e-05
Epoch 30/150
162/162 [==============================] - 0s 916us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.8162e-05
Epoch 31/150
162/162 [==============================] - 0s 952us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.8162e-05
Epoch 32/150
 87/162 [===============>..............] - ETA: 0s - loss: 0.1626 - mae: 0.4018 - mse: 0.1626
Epoch 32: ReduceLROnPlateau reducing learning rate to 1e-05.
162/162 [==============================] - 0s 954us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.8162e-05
Epoch 33/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 34/150
162/162 [==============================] - 0s 919us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 35/150
162/162 [==============================] - 0s 943us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 36/150
162/162 [==============================] - 0s 917us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 37/150
162/162 [==============================] - 0s 950us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 38/150
162/162 [==============================] - 0s 912us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 39/150
162/162 [==============================] - 0s 932us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 40/150
162/162 [==============================] - 0s 934us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 41/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 42/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 43/150
162/162 [==============================] - 0s 908us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 44/150
162/162 [==============================] - 0s 956us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 45/150
162/162 [==============================] - 0s 920us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 46/150
162/162 [==============================] - 0s 850us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 47/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 48/150
162/162 [==============================] - 0s 941us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 49/150
162/162 [==============================] - 0s 913us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 50/150
162/162 [==============================] - 0s 986us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 51/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 52/150
162/162 [==============================] - 0s 976us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 53/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 54/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 55/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 56/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 57/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 58/150
162/162 [==============================] - 0s 975us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 59/150
162/162 [==============================] - 0s 916us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 60/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 61/150
162/162 [==============================] - 0s 941us/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 62/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 63/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 64/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 65/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 66/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 67/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 68/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 69/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 70/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 71/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 72/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 73/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 74/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 75/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 76/150
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
Epoch 77/150
  1/162 [..............................] - ETA: 0s - loss: 0.1708 - mae: 0.4119 - mse: 0.1708
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05
162/162 [==============================] - 0s 1ms/step - loss: 0.1632 - mae: 0.4025 - mse: 0.1632 - val_loss: 0.1637 - val_mae: 0.4032 - val_mse: 0.1637 - lr: 1.0000e-05