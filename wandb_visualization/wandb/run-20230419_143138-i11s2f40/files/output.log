Epoch 1/30
206/243 [========================>.....] - ETA: 0s - loss: 0.1902 - mae: 0.0558 - mse: 0.0055
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_143138-i11s2f40\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 5ms/step - loss: 0.1797 - mae: 0.0541 - mse: 0.0051 - val_loss: 0.1181 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0327
Epoch 2/30
211/243 [=========================>....] - ETA: 0s - loss: 0.1194 - mae: 0.0405 - mse: 0.0023
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.016331231221556664.
243/243 [==============================] - 0s 1ms/step - loss: 0.1193 - mae: 0.0402 - mse: 0.0023 - val_loss: 0.1197 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0327
Epoch 3/30
203/243 [========================>.....] - ETA: 0s - loss: 0.0281 - mae: 0.0381 - mse: 0.0019
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.008165615610778332.
243/243 [==============================] - 1s 6ms/step - loss: 0.0286 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0309 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0163
Epoch 4/30
235/243 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0381 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.004082807805389166.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_143138-i11s2f40\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 5ms/step - loss: 0.0086 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0092 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0082
Epoch 5/30
200/243 [=======================>......] - ETA: 0s - loss: 0.0035 - mae: 0.0379 - mse: 0.0019
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.002041403902694583.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_143138-i11s2f40\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_143138-i11s2f40\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 5ms/step - loss: 0.0036 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0038 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0041
Epoch 6/30
200/243 [=======================>......] - ETA: 0s - loss: 0.0023 - mae: 0.0377 - mse: 0.0019
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0010207019513472915.
243/243 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0020
Epoch 7/30
197/243 [=======================>......] - ETA: 0s - loss: 0.0020 - mae: 0.0379 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005103509756736457.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_143138-i11s2f40\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0010
Epoch 8/30
240/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00025517548783682287.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_143138-i11s2f40\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_143138-i11s2f40\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 5.1035e-04
Epoch 9/30
203/243 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00012758774391841143.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_143138-i11s2f40\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.5518e-04
Epoch 10/30
185/243 [=====================>........] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 6.379387195920572e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_143138-i11s2f40\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.2759e-04
Epoch 11/30
205/243 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 3.189693597960286e-05.
243/243 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.3794e-05
Epoch 12/30
199/243 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.594846798980143e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_143138-i11s2f40\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_143138-i11s2f40\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.1897e-05
Epoch 13/30
201/243 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_143138-i11s2f40\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.5948e-05
Epoch 14/30
199/243 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
243/243 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 15/30
214/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
243/243 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 16/30
240/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
243/243 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 17/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 18/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 19/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 20/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 21/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 22/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 23/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 24/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 25/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 26/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 27/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 28/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 29/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 30/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.032662463797756815LR_[32, 64, 128, 256]HN_16BS_1P_val_mseM_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
323/323 [==============================] - 1s 1ms/step - loss: 0.1641 - mae: 0.0589 - mse: 0.0054 - val_loss: 0.1211 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0327
Epoch 2/30
306/323 [===========================>..] - ETA: 0s - loss: 0.1206 - mae: 0.0518 - mse: 0.0037
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.016331231221556664.
323/323 [==============================] - 0s 1ms/step - loss: 0.1205 - mae: 0.0517 - mse: 0.0036 - val_loss: 0.1260 - val_mae: 0.0522 - val_mse: 0.0037 - lr: 0.0327
Epoch 3/30
275/323 [========================>.....] - ETA: 0s - loss: 0.0304 - mae: 0.0508 - mse: 0.0034
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.008165615610778332.
323/323 [==============================] - 0s 1ms/step - loss: 0.0307 - mae: 0.0509 - mse: 0.0035 - val_loss: 0.0324 - val_mae: 0.0506 - val_mse: 0.0035 - lr: 0.0163
Epoch 4/30
266/323 [=======================>......] - ETA: 0s - loss: 0.0102 - mae: 0.0507 - mse: 0.0034
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.004082807805389166.
323/323 [==============================] - 0s 1ms/step - loss: 0.0102 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0107 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0082
Epoch 5/30
301/323 [==========================>...] - ETA: 0s - loss: 0.0051 - mae: 0.0505 - mse: 0.0034
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.002041403902694583.
323/323 [==============================] - 0s 1ms/step - loss: 0.0051 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0052 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0041
Epoch 6/30
293/323 [==========================>...] - ETA: 0s - loss: 0.0038 - mae: 0.0507 - mse: 0.0034
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0010207019513472915.
323/323 [==============================] - 0s 1ms/step - loss: 0.0038 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0039 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0020
Epoch 7/30
273/323 [========================>.....] - ETA: 0s - loss: 0.0035 - mae: 0.0506 - mse: 0.0034
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005103509756736457.
323/323 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0010
Epoch 8/30
297/323 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00025517548783682287.
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 5.1035e-04
Epoch 9/30
259/323 [=======================>......] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00012758774391841143.
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 2.5518e-04
Epoch 10/30
286/323 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 10: ReduceLROnPlateau reducing learning rate to 6.379387195920572e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.2759e-04
Epoch 11/30
303/323 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 11: ReduceLROnPlateau reducing learning rate to 3.189693597960286e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.3794e-05
Epoch 12/30
301/323 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.594846798980143e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.1897e-05
Epoch 13/30
321/323 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.5948e-05
Epoch 14/30
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 15/30
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 16/30
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 17/30
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 18/30
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 19/30
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 20/30
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 21/30
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 22/30
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 23/30
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 24/30
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 25/30
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 26/30
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 27/30
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 28/30
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 29/30
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 30/30
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.032662463797756815LR_[32, 64, 128, 256]HN_16BS_1P_val_mseM_30epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
243/243 [==============================] - 1s 2ms/step - loss: 0.1775 - mae: 0.0460 - mse: 0.0036 - val_loss: 0.1451 - val_mae: 0.0389 - val_mse: 0.0020 - lr: 0.0327
Epoch 2/30
200/243 [=======================>......] - ETA: 0s - loss: 0.1179 - mae: 0.0422 - mse: 0.0027
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.016331231221556664.
243/243 [==============================] - 0s 1ms/step - loss: 0.1180 - mae: 0.0419 - mse: 0.0026 - val_loss: 0.1231 - val_mae: 0.0411 - val_mse: 0.0024 - lr: 0.0327
Epoch 3/30
207/243 [========================>.....] - ETA: 0s - loss: 0.0284 - mae: 0.0384 - mse: 0.0020
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.008165615610778332.
243/243 [==============================] - 0s 1ms/step - loss: 0.0288 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0316 - val_mae: 0.0397 - val_mse: 0.0022 - lr: 0.0163
Epoch 4/30
192/243 [======================>.......] - ETA: 0s - loss: 0.0084 - mae: 0.0379 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.004082807805389166.
243/243 [==============================] - 0s 1ms/step - loss: 0.0086 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0093 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0082
Epoch 5/30
190/243 [======================>.......] - ETA: 0s - loss: 0.0035 - mae: 0.0379 - mse: 0.0019
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.002041403902694583.
243/243 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0038 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0041
Epoch 6/30
207/243 [========================>.....] - ETA: 0s - loss: 0.0023 - mae: 0.0380 - mse: 0.0019
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0010207019513472915.
243/243 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0020
Epoch 7/30
201/243 [=======================>......] - ETA: 0s - loss: 0.0020 - mae: 0.0379 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005103509756736457.
243/243 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0010
Epoch 8/30
194/243 [======================>.......] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00025517548783682287.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 5.1035e-04
Epoch 9/30
207/243 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00012758774391841143.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.5518e-04
Epoch 10/30
206/243 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 6.379387195920572e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.2759e-04
Epoch 11/30
209/243 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 3.189693597960286e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.3794e-05
Epoch 12/30
188/243 [======================>.......] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.594846798980143e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.1897e-05
Epoch 13/30
191/243 [======================>.......] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_143138-i11s2f40\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.5948e-05
Epoch 14/30
243/243 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 15/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 16/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 17/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 18/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 19/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 20/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 21/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 22/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 23/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 24/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 25/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 26/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 27/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 28/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 29/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 30/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.032662463797756815LR_[32, 64, 128, 256]HN_16BS_1P_val_mseM_30epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
243/243 [==============================] - 1s 2ms/step - loss: 0.1750 - mae: 0.0452 - mse: 0.0035 - val_loss: 0.1158 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0327
Epoch 2/30
223/243 [==========================>...] - ETA: 0s - loss: 0.1198 - mae: 0.0440 - mse: 0.0031
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.016331231221556664.
243/243 [==============================] - 0s 1ms/step - loss: 0.1197 - mae: 0.0437 - mse: 0.0030 - val_loss: 0.1171 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0327
Epoch 3/30
206/243 [========================>.....] - ETA: 0s - loss: 0.0281 - mae: 0.0386 - mse: 0.0020
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.008165615610778332.
243/243 [==============================] - 0s 1ms/step - loss: 0.0286 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0312 - val_mae: 0.0389 - val_mse: 0.0020 - lr: 0.0163
Epoch 4/30
216/243 [=========================>....] - ETA: 0s - loss: 0.0085 - mae: 0.0382 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.004082807805389166.
243/243 [==============================] - 0s 1ms/step - loss: 0.0086 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0092 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0082
Epoch 5/30
177/243 [====================>.........] - ETA: 0s - loss: 0.0035 - mae: 0.0377 - mse: 0.0019
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.002041403902694583.
243/243 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0038 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0041
Epoch 6/30
210/243 [========================>.....] - ETA: 0s - loss: 0.0023 - mae: 0.0381 - mse: 0.0019
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0010207019513472915.
243/243 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0020
Epoch 7/30
193/243 [======================>.......] - ETA: 0s - loss: 0.0020 - mae: 0.0382 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005103509756736457.
243/243 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0010
Epoch 8/30
205/243 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00025517548783682287.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 5.1035e-04
Epoch 9/30
209/243 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00012758774391841143.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.5518e-04
Epoch 10/30
209/243 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 6.379387195920572e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.2759e-04
Epoch 11/30
181/243 [=====================>........] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 3.189693597960286e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.3794e-05
Epoch 12/30
197/243 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.594846798980143e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.1897e-05
Epoch 13/30
213/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.5948e-05
Epoch 14/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 15/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 16/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 17/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 18/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 19/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 20/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 21/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 22/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 23/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 24/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 25/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 26/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 27/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 28/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 29/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 30/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.032662463797756815LR_[32, 64, 128, 256]HN_16BS_1P_val_mseM_30epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0004s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
Epoch 1/30
243/243 [==============================] - 1s 2ms/step - loss: 0.1782 - mae: 0.0488 - mse: 0.0047 - val_loss: 0.1179 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0327
Epoch 2/30
243/243 [==============================] - 0s 1ms/step - loss: 0.1198 - mae: 0.0443 - mse: 0.0031 - val_loss: 0.1134 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0327
Epoch 3/30
206/243 [========================>.....] - ETA: 0s - loss: 0.1210 - mae: 0.0442 - mse: 0.0030
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.016331231221556664.
243/243 [==============================] - 0s 1ms/step - loss: 0.1194 - mae: 0.0432 - mse: 0.0028 - val_loss: 0.1158 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0327
Epoch 4/30
232/243 [===========================>..] - ETA: 0s - loss: 0.0286 - mae: 0.0384 - mse: 0.0020
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.008165615610778332.
243/243 [==============================] - 0s 1ms/step - loss: 0.0287 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0307 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0163
Epoch 5/30
221/243 [==========================>...] - ETA: 0s - loss: 0.0085 - mae: 0.0380 - mse: 0.0019
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.004082807805389166.
243/243 [==============================] - 0s 1ms/step - loss: 0.0086 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0093 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0082
Epoch 6/30
218/243 [=========================>....] - ETA: 0s - loss: 0.0036 - mae: 0.0380 - mse: 0.0019
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.002041403902694583.
243/243 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0038 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0041
Epoch 7/30
197/243 [=======================>......] - ETA: 0s - loss: 0.0023 - mae: 0.0377 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0010207019513472915.
243/243 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0020
Epoch 8/30
195/243 [=======================>......] - ETA: 0s - loss: 0.0020 - mae: 0.0379 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005103509756736457.
243/243 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0010
Epoch 9/30
203/243 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00025517548783682287.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 5.1035e-04
Epoch 10/30
202/243 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00012758774391841143.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.5518e-04
Epoch 11/30
222/243 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 6.379387195920572e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.2759e-04
Epoch 12/30
199/243 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 3.189693597960286e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.3794e-05
Epoch 13/30
196/243 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 1.594846798980143e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.1897e-05
Epoch 14/30
210/243 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.5948e-05
Epoch 15/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 16/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 17/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 18/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 19/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 20/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 21/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 22/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 23/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 24/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 25/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 26/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 27/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 28/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 29/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 30/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.032662463797756815LR_[32, 64, 128, 256]HN_16BS_1P_val_mseM_30epochs/model_5.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
243/243 [==============================] - 1s 2ms/step - loss: 0.1747 - mae: 0.0456 - mse: 0.0034 - val_loss: 0.1484 - val_mae: 0.0771 - val_mse: 0.0079 - lr: 0.0327
Epoch 2/30
243/243 [==============================] - 0s 1ms/step - loss: 0.1195 - mae: 0.0430 - mse: 0.0028 - val_loss: 0.1176 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0327
Epoch 3/30
195/243 [=======================>......] - ETA: 0s - loss: 0.1198 - mae: 0.0433 - mse: 0.0029
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.016331231221556664.
243/243 [==============================] - 0s 1ms/step - loss: 0.1197 - mae: 0.0431 - mse: 0.0029 - val_loss: 0.1511 - val_mae: 0.0700 - val_mse: 0.0068 - lr: 0.0327
Epoch 4/30
232/243 [===========================>..] - ETA: 0s - loss: 0.0288 - mae: 0.0382 - mse: 0.0020
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.008165615610778332.
243/243 [==============================] - 0s 1ms/step - loss: 0.0289 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0309 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0163
Epoch 5/30
181/243 [=====================>........] - ETA: 0s - loss: 0.0084 - mae: 0.0380 - mse: 0.0019
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.004082807805389166.
243/243 [==============================] - 0s 1ms/step - loss: 0.0086 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0092 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0082
Epoch 6/30
216/243 [=========================>....] - ETA: 0s - loss: 0.0036 - mae: 0.0381 - mse: 0.0019
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.002041403902694583.
243/243 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0038 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0041
Epoch 7/30
198/243 [=======================>......] - ETA: 0s - loss: 0.0023 - mae: 0.0378 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0010207019513472915.
243/243 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0020
Epoch 8/30
226/243 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0380 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005103509756736457.
243/243 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0010
Epoch 9/30
211/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00025517548783682287.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 5.1035e-04
Epoch 10/30
227/243 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00012758774391841143.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.5518e-04
Epoch 11/30
189/243 [======================>.......] - ETA: 0s - loss: 0.0019 - mae: 0.0383 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 6.379387195920572e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.2759e-04
Epoch 12/30
203/243 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 3.189693597960286e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.3794e-05
Epoch 13/30
228/243 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 1.594846798980143e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.1897e-05
Epoch 14/30
224/243 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.5948e-05
Epoch 15/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 16/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 17/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 18/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 19/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 20/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 21/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 22/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 23/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 24/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 25/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 26/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 27/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 28/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 29/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 30/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.032662463797756815LR_[32, 64, 128, 256]HN_16BS_1P_val_mseM_30epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
243/243 [==============================] - 1s 2ms/step - loss: 0.1746 - mae: 0.0464 - mse: 0.0035 - val_loss: 0.1111 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0327
Epoch 2/30
224/243 [==========================>...] - ETA: 0s - loss: 0.1188 - mae: 0.0396 - mse: 0.0022
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.016331231221556664.
243/243 [==============================] - 0s 1ms/step - loss: 0.1188 - mae: 0.0398 - mse: 0.0022 - val_loss: 0.1135 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0327
Epoch 3/30
148/243 [=================>............] - ETA: 0s - loss: 0.0271 - mae: 0.0385 - mse: 0.0020
209/243 [========================>.....] - ETA: 0s - loss: 0.0282 - mae: 0.0383 - mse: 0.0020
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.008165615610778332.
243/243 [==============================] - 0s 1ms/step - loss: 0.0286 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0309 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0163
Epoch 4/30
185/243 [=====================>........] - ETA: 0s - loss: 0.0084 - mae: 0.0378 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.004082807805389166.
243/243 [==============================] - 0s 1ms/step - loss: 0.0086 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0092 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0082
Epoch 5/30
198/243 [=======================>......] - ETA: 0s - loss: 0.0035 - mae: 0.0379 - mse: 0.0019
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.002041403902694583.
243/243 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0037 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0041
Epoch 6/30
198/243 [=======================>......] - ETA: 0s - loss: 0.0023 - mae: 0.0378 - mse: 0.0019
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0010207019513472915.
243/243 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0020
Epoch 7/30
213/243 [=========================>....] - ETA: 0s - loss: 0.0020 - mae: 0.0380 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005103509756736457.
243/243 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0010
Epoch 8/30
208/243 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00025517548783682287.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 5.1035e-04
Epoch 9/30
215/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00012758774391841143.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.5518e-04
Epoch 10/30
226/243 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 6.379387195920572e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.2759e-04
Epoch 11/30
184/243 [=====================>........] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 3.189693597960286e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.3794e-05
Epoch 12/30
222/243 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.594846798980143e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.1897e-05
Epoch 13/30
205/243 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.5948e-05
Epoch 14/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 15/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 16/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 17/30
243/243 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 18/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 19/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 20/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 21/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 22/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 23/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 24/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 25/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 26/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 27/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 28/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 29/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 30/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.032662463797756815LR_[32, 64, 128, 256]HN_16BS_1P_val_mseM_30epochs/model_7.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
243/243 [==============================] - 1s 2ms/step - loss: 0.1775 - mae: 0.0503 - mse: 0.0044 - val_loss: 0.1182 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0327
Epoch 2/30
185/243 [=====================>........] - ETA: 0s - loss: 0.1189 - mae: 0.0397 - mse: 0.0022
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.016331231221556664.
243/243 [==============================] - 0s 1ms/step - loss: 0.1189 - mae: 0.0397 - mse: 0.0022 - val_loss: 0.1192 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0327
Epoch 3/30
198/243 [=======================>......] - ETA: 0s - loss: 0.0280 - mae: 0.0382 - mse: 0.0020
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.008165615610778332.
243/243 [==============================] - 0s 1ms/step - loss: 0.0285 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0309 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0163
Epoch 4/30
201/243 [=======================>......] - ETA: 0s - loss: 0.0085 - mae: 0.0379 - mse: 0.0019
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.004082807805389166.
243/243 [==============================] - 0s 1ms/step - loss: 0.0086 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0094 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0082
Epoch 5/30
204/243 [========================>.....] - ETA: 0s - loss: 0.0035 - mae: 0.0379 - mse: 0.0019
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.002041403902694583.
243/243 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0038 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0041
Epoch 6/30
195/243 [=======================>......] - ETA: 0s - loss: 0.0023 - mae: 0.0378 - mse: 0.0019
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0010207019513472915.
243/243 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0020
Epoch 7/30
183/243 [=====================>........] - ETA: 0s - loss: 0.0020 - mae: 0.0377 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005103509756736457.
243/243 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0010
Epoch 8/30
239/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00025517548783682287.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 5.1035e-04
Epoch 9/30
214/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00012758774391841143.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.5518e-04
Epoch 10/30
215/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 6.379387195920572e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.2759e-04
Epoch 11/30
215/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 3.189693597960286e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.3794e-05
Epoch 12/30
198/243 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 1.594846798980143e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.1897e-05
Epoch 13/30
186/243 [=====================>........] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0020
Epoch 13: ReduceLROnPlateau reducing learning rate to 1e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.5948e-05
Epoch 14/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 15/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 16/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 17/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 18/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 19/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 20/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 21/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 22/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 23/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 24/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 25/30
243/243 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 26/30
243/243 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 27/30
243/243 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 28/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 29/30
243/243 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 30/30
137/243 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
243/243 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.032662463797756815LR_[32, 64, 128, 256]HN_16BS_1P_val_mseM_30epochs/model_8.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
243/243 [==============================] - 1s 2ms/step - loss: 0.1787 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.1213 - val_mae: 0.0471 - val_mse: 0.0033 - lr: 0.0327
Epoch 2/30
243/243 [==============================] - 0s 2ms/step - loss: 0.1190 - mae: 0.0395 - mse: 0.0021 - val_loss: 0.1202 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0327
Epoch 3/30
217/243 [=========================>....] - ETA: 0s - loss: 0.1187 - mae: 0.0383 - mse: 0.0020
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.016331231221556664.
243/243 [==============================] - 1s 2ms/step - loss: 0.1187 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.1179 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0327
Epoch 4/30
231/243 [===========================>..] - ETA: 0s - loss: 0.0282 - mae: 0.0382 - mse: 0.0020
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.008165615610778332.
243/243 [==============================] - 0s 1ms/step - loss: 0.0283 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0310 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0163
Epoch 5/30
200/243 [=======================>......] - ETA: 0s - loss: 0.0084 - mae: 0.0378 - mse: 0.0019
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.004082807805389166.
243/243 [==============================] - 0s 1ms/step - loss: 0.0085 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0093 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0082
Epoch 6/30
199/243 [=======================>......] - ETA: 0s - loss: 0.0036 - mae: 0.0380 - mse: 0.0019
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.002041403902694583.
243/243 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0037 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0041
Epoch 7/30
199/243 [=======================>......] - ETA: 0s - loss: 0.0023 - mae: 0.0380 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0010207019513472915.
243/243 [==============================] - 0s 1ms/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0020
Epoch 8/30
193/243 [======================>.......] - ETA: 0s - loss: 0.0020 - mae: 0.0379 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005103509756736457.
243/243 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0010
Epoch 9/30
237/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00025517548783682287.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 5.1035e-04
Epoch 10/30
214/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00012758774391841143.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.5518e-04
Epoch 11/30
218/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 6.379387195920572e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.2759e-04
Epoch 12/30
219/243 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 3.189693597960286e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.3794e-05
Epoch 13/30
198/243 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 1.594846798980143e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.1897e-05
Epoch 14/30
200/243 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.5948e-05
Epoch 15/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 16/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 17/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 18/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 19/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 20/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 21/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 22/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 23/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 24/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 25/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 26/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 27/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 28/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 29/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 30/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.032662463797756815LR_[32, 64, 128, 256]HN_16BS_1P_val_mseM_30epochs/model_9.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])