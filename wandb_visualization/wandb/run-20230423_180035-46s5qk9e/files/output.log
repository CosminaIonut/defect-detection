Epoch 1/50
 1/22 [>.............................] - ETA: 6s - loss: 0.8624 - mae: 0.9277 - mse: 0.8624
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
22/22 [==============================] - 1s 42ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0514
Epoch 2/50
18/22 [=======================>......] - ETA: 0s - loss: 0.8575 - mae: 0.9250 - mse: 0.8575
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.025707373395562172.
22/22 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0514
Epoch 3/50
21/22 [===========================>..] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.012853686697781086.
22/22 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0257
Epoch 4/50
 1/22 [>.............................] - ETA: 0s - loss: 0.8721 - mae: 0.9328 - mse: 0.8721
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.006426843348890543.
22/22 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0129
Epoch 5/50
 1/22 [>.............................] - ETA: 0s - loss: 0.8536 - mae: 0.9229 - mse: 0.8536
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0032134216744452715.
22/22 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0064
Epoch 6/50
 1/22 [>.............................] - ETA: 0s - loss: 0.8589 - mae: 0.9258 - mse: 0.8589
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0016067108372226357.
22/22 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0032
Epoch 7/50
 1/22 [>.............................] - ETA: 0s - loss: 0.8569 - mae: 0.9245 - mse: 0.8569
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0008033554186113179.
22/22 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0016
Epoch 8/50
22/22 [==============================] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00040167770930565894.
22/22 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 8.0336e-04
Epoch 9/50
 1/22 [>.............................] - ETA: 0s - loss: 0.8600 - mae: 0.9263 - mse: 0.8600
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00020083885465282947.
22/22 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 4.0168e-04
Epoch 10/50
 1/22 [>.............................] - ETA: 0s - loss: 0.8656 - mae: 0.9294 - mse: 0.8656
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00010041942732641473.
22/22 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 2.0084e-04
Epoch 11/50
19/22 [========================>.....] - ETA: 0s - loss: 0.8581 - mae: 0.9253 - mse: 0.8581
Epoch 11: ReduceLROnPlateau reducing learning rate to 5.020971366320737e-05.
22/22 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0042e-04
Epoch 12/50
 1/22 [>.............................] - ETA: 0s - loss: 0.8529 - mae: 0.9224 - mse: 0.8529
Epoch 12: ReduceLROnPlateau reducing learning rate to 2.5104856831603684e-05.
22/22 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 5.0210e-05
Epoch 13/50
10/22 [============>.................] - ETA: 0s - loss: 0.8578 - mae: 0.9251 - mse: 0.8578
Epoch 13: ReduceLROnPlateau reducing learning rate to 1.2552428415801842e-05.
22/22 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 2.5105e-05
Epoch 14/50
17/22 [======================>.......] - ETA: 0s - loss: 0.8582 - mae: 0.9254 - mse: 0.8582
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.
22/22 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.2552e-05
Epoch 15/50
22/22 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 16/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 17/50
22/22 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 18/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 19/50
22/22 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 20/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 21/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 22/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 23/50
22/22 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 24/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 25/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 26/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 27/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 28/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 29/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 30/50
22/22 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 31/50
22/22 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 32/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 33/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 34/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 35/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 36/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 37/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 38/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 39/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 40/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 41/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 42/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 43/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 44/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 45/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 46/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 47/50
22/22 [==============================] - 0s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 48/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 49/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 50/50
22/22 [==============================] - 0s 3ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.05141474737559796LR_[64]CHN_100CNNI_184BS_1P_val_mseM_50epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/50
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230423_180035-46s5qk9e\files\model-best)...

29/29 [==============================] - 1s 31ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0514
Epoch 2/50
 1/29 [>.............................] - ETA: 0s - loss: 0.6408 - mae: 0.7982 - mse: 0.6408
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.025707373395562172.
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0514
Epoch 3/50
 1/29 [>.............................] - ETA: 0s - loss: 0.6547 - mae: 0.8071 - mse: 0.6547
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.012853686697781086.
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0257
Epoch 4/50
25/29 [========================>.....] - ETA: 0s - loss: 0.6429 - mae: 0.7997 - mse: 0.6429
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.006426843348890543.
29/29 [==============================] - 0s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0129
Epoch 5/50
23/29 [======================>.......] - ETA: 0s - loss: 0.6424 - mae: 0.7994 - mse: 0.6424
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0032134216744452715.
29/29 [==============================] - 0s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0064
Epoch 6/50
 1/29 [>.............................] - ETA: 0s - loss: 0.6533 - mae: 0.8060 - mse: 0.6533
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0016067108372226357.
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0032
Epoch 7/50
 1/29 [>.............................] - ETA: 0s - loss: 0.6473 - mae: 0.8022 - mse: 0.6473
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0008033554186113179.
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0016
Epoch 8/50
 1/29 [>.............................] - ETA: 0s - loss: 0.6602 - mae: 0.8104 - mse: 0.6602
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00040167770930565894.
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 8.0336e-04
Epoch 9/50
 1/29 [>.............................] - ETA: 0s - loss: 0.6410 - mae: 0.7985 - mse: 0.6410
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00020083885465282947.
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 4.0168e-04
Epoch 10/50
22/29 [=====================>........] - ETA: 0s - loss: 0.6433 - mae: 0.7999 - mse: 0.6433
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00010041942732641473.
29/29 [==============================] - 0s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 2.0084e-04
Epoch 11/50
 1/29 [>.............................] - ETA: 0s - loss: 0.6412 - mae: 0.7985 - mse: 0.6412
Epoch 11: ReduceLROnPlateau reducing learning rate to 5.020971366320737e-05.
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0042e-04
Epoch 12/50
 1/29 [>.............................] - ETA: 0s - loss: 0.6341 - mae: 0.7943 - mse: 0.6341
Epoch 12: ReduceLROnPlateau reducing learning rate to 2.5104856831603684e-05.
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 5.0210e-05
Epoch 13/50
 1/29 [>.............................] - ETA: 0s - loss: 0.6538 - mae: 0.8067 - mse: 0.6538
Epoch 13: ReduceLROnPlateau reducing learning rate to 1.2552428415801842e-05.
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 2.5105e-05
Epoch 14/50
26/29 [=========================>....] - ETA: 0s - loss: 0.6428 - mae: 0.7996 - mse: 0.6428
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.2552e-05
Epoch 15/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 16/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 17/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 18/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 19/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 20/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 21/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 22/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 23/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 24/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 25/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 26/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 27/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 28/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 29/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 30/50
29/29 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 31/50
29/29 [==============================] - 0s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 32/50
29/29 [==============================] - 0s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 33/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 34/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 35/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 36/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 37/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 38/50
29/29 [==============================] - 0s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 39/50
29/29 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 40/50
29/29 [==============================] - 0s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 41/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 42/50
29/29 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 43/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 44/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 45/50
29/29 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 46/50
29/29 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 47/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 48/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 49/50
29/29 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 50/50
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.05141474737559796LR_[64]CHN_100CNNI_184BS_1P_val_mseM_50epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/50
 1/22 [>.............................] - ETA: 6s - loss: 0.4534 - mae: 0.6719 - mse: 0.4534
29/29 [==============================] - 0s 3ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
22/22 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 21/50
22/22 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 22/50
22/22 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 23/50
22/22 [==============================] - 0s 4ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 24/50
22/22 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 25/50
22/22 [==============================] - 0s 4ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 26/50
22/22 [==============================] - 0s 4ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 27/50
22/22 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 28/50
22/22 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 29/50
22/22 [==============================] - 0s 4ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 30/50
22/22 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 31/50
22/22 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 32/50
22/22 [==============================] - 0s 4ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 33/50
22/22 [==============================] - 0s 4ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 34/50
22/22 [==============================] - 0s 4ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 35/50
22/22 [==============================] - 0s 4ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 36/50
22/22 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 37/50
22/22 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 38/50
22/22 [==============================] - 0s 4ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 39/50
22/22 [==============================] - 0s 4ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 40/50
22/22 [==============================] - 0s 4ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 41/50
22/22 [==============================] - 0s 4ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 42/50
22/22 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 43/50
22/22 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 44/50
22/22 [==============================] - 0s 4ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 45/50
 1/22 [>.............................] - ETA: 0s - loss: 0.4609 - mae: 0.6775 - mse: 0.4609
22/22 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
22/22 [==============================] - 0s 3ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 38/50duceLROnPlateau reducing learning rate to 0.025707373395562172. 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
22/22 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 39/50
22/22 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 40/50
22/22 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 41/50
22/22 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 42/50
22/22 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 43/50
22/22 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 44/50
22/22 [==============================] - 0s 4ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 45/50
22/22 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 46/50
22/22 [==============================] - 0s 5ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 47/50
 1/22 [>.............................] - ETA: 0s - loss: 0.3326 - mae: 0.5752 - mse: 0.3326
Epoch 38/50duceLROnPlateau reducing learning rate to 0.025707373395562172. 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 38/50duceLROnPlateau reducing learning rate to 0.025707373395562172. 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230423_180035-46s5qk9e\files\model-best)... Done. 0.0s
22/22 [==============================] - 0s 5ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 39/50
22/22 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 40/50
22/22 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 41/50
22/22 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 42/50
22/22 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 43/50
22/22 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 44/50
22/22 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 45/50
22/22 [==============================] - 0s 3ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 46/50
22/22 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 47/50
22/22 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 48/50
22/22 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 49/50
22/22 [==============================] - 0s 4ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 1.0000e-05
Epoch 50/50
 1/22 [>.............................] - ETA: 0s - loss: 0.2286 - mae: 0.4762 - mse: 0.2286
Epoch 38/50duceLROnPlateau reducing learning rate to 0.025707373395562172. 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 38/50duceLROnPlateau reducing learning rate to 0.025707373395562172. 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230423_180035-46s5qk9e\files\model-best)... Done. 0.0s
22/22 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 1.0000e-05
Epoch 39/50
22/22 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 1.0000e-05
Epoch 40/50
22/22 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 1.0000e-05
Epoch 41/50
22/22 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 1.0000e-05
Epoch 42/50
22/22 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 1.0000e-05
Epoch 43/50
22/22 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 1.0000e-05
Epoch 44/50
22/22 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 1.0000e-05
Epoch 45/50
22/22 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 1.0000e-05
Epoch 46/50
22/22 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 1.0000e-05
Epoch 47/50
22/22 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 1.0000e-05
Epoch 48/50
22/22 [==============================] - 0s 4ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 1.0000e-05
Epoch 49/50
22/22 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 1.0000e-05
Epoch 50/50
22/22 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.3752 - mse: 0.1427 - val_loss: 0.1423 - val_mae: 0.3746 - val_mse: 0.1423 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.05141474737559796LR_[64]CHN_100CNNI_184BS_1P_val_mseM_50epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/50
Epoch 38/50duceLROnPlateau reducing learning rate to 0.025707373395562172. 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 38/50duceLROnPlateau reducing learning rate to 0.025707373395562172. 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230423_180035-46s5qk9e\files\model-best)... Done. 0.0s
22/22 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 1.0000e-05
Epoch 39/50
22/22 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 1.0000e-05
Epoch 40/50
22/22 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 1.0000e-05
Epoch 41/50
22/22 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 1.0000e-05
Epoch 42/50
22/22 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 1.0000e-05
Epoch 43/50
22/22 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 1.0000e-05
Epoch 44/50
22/22 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 1.0000e-05
Epoch 45/50
22/22 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 1.0000e-05
Epoch 46/50
22/22 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 1.0000e-05
Epoch 47/50
22/22 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 1.0000e-05
Epoch 48/50
22/22 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 1.0000e-05
Epoch 49/50
22/22 [==============================] - 0s 4ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 1.0000e-05
Epoch 50/50
22/22 [==============================] - 0s 3ms/step - loss: 0.0776 - mae: 0.2752 - mse: 0.0776 - val_loss: 0.0773 - val_mae: 0.2746 - val_mse: 0.0773 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_rmsprop_0.05141474737559796LR_[64]CHN_100CNNI_184BS_1P_val_mseM_50epochs/model_7.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/50
Epoch 38/50duceLROnPlateau reducing learning rate to 0.025707373395562172. 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230423_180035-46s5qk9e\files\model-best)... Done. 0.0s
Epoch 38/50duceLROnPlateau reducing learning rate to 0.025707373395562172. 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
22/22 [==============================] - 0s 4ms/step - loss: 0.0326 - mae: 0.1752 - mse: 0.0326 - val_loss: 0.0324 - val_mae: 0.1746 - val_mse: 0.0324 - lr: 1.0000e-05
Epoch 39/50
 1/22 [>.............................] - ETA: 0s - loss: 0.0305 - mae: 0.1697 - mse: 0.0305
Epoch 38/50duceLROnPlateau reducing learning rate to 0.025707373395562172. 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 38/50duceLROnPlateau reducing learning rate to 0.025707373395562172. 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230423_180035-46s5qk9e\files\model-best)... Done. 0.0s
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.025707373395562172. 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 38/50duceLROnPlateau reducing learning rate to 0.025707373395562172. 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 38/50duceLROnPlateau reducing learning rate to 0.025707373395562172. 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05