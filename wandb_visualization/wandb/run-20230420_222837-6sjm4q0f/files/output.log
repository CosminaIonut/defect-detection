Epoch 1/30
141/162 [=========================>....] - ETA: 0s - loss: 0.0464 - mae: 0.0520 - mse: 0.0067
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0030s). Check your callbacks.
162/162 [==============================] - 2s 11ms/step - loss: 0.0408 - mae: 0.0501 - mse: 0.0061 - val_loss: 0.0024 - val_mae: 0.0368 - val_mse: 0.0018 - lr: 0.0297
Epoch 2/30
162/162 [==============================] - 0s 3ms/step - loss: 0.0027 - mae: 0.0386 - mse: 0.0021 - val_loss: 0.0028 - val_mae: 0.0386 - val_mse: 0.0022 - lr: 0.0297
Epoch 3/30
148/162 [==========================>...] - ETA: 0s - loss: 0.0025 - mae: 0.0371 - mse: 0.0020
162/162 [==============================] - 2s 11ms/step - loss: 0.0025 - mae: 0.0372 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0375 - val_mse: 0.0020 - lr: 0.0297
Epoch 4/30
147/162 [==========================>...] - ETA: 0s - loss: 0.0022 - mae: 0.0347 - mse: 0.0018
162/162 [==============================] - 2s 10ms/step - loss: 0.0022 - mae: 0.0345 - mse: 0.0018 - val_loss: 0.0020 - val_mae: 0.0332 - val_mse: 0.0016 - lr: 0.0297
Epoch 5/30
159/162 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0320 - mse: 0.0015
162/162 [==============================] - 2s 10ms/step - loss: 0.0019 - mae: 0.0319 - mse: 0.0015 - val_loss: 0.0016 - val_mae: 0.0280 - val_mse: 0.0012 - lr: 0.0297
Epoch 6/30
153/162 [===========================>..] - ETA: 0s - loss: 0.0020 - mae: 0.0317 - mse: 0.0016
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_222837-6sjm4q0f\files\model-best)... Done. 0.0s
162/162 [==============================] - 2s 10ms/step - loss: 0.0020 - mae: 0.0314 - mse: 0.0016 - val_loss: 0.0015 - val_mae: 0.0270 - val_mse: 0.0012 - lr: 0.0297
Epoch 7/30
162/162 [==============================] - 2s 11ms/step - loss: 0.0016 - mae: 0.0286 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0286 - val_mse: 0.0013 - lr: 0.0297
Epoch 8/30
149/162 [==========================>...] - ETA: 0s - loss: 0.0016 - mae: 0.0286 - mse: 0.0013
162/162 [==============================] - 1s 9ms/step - loss: 0.0015 - mae: 0.0284 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0274 - val_mse: 0.0012 - lr: 0.0297
Epoch 9/30
162/162 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0273 - mse: 0.0012 - val_loss: 0.0014 - val_mae: 0.0272 - val_mse: 0.0011 - lr: 0.0297
Epoch 10/30
162/162 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0014 - val_mae: 0.0278 - val_mse: 0.0012 - lr: 0.0297
Epoch 11/30
147/162 [==========================>...] - ETA: 0s - loss: 0.0013 - mae: 0.0255 - mse: 0.0011
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.014861345291137695.
162/162 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0255 - mse: 0.0011 - val_loss: 0.0019 - val_mae: 0.0330 - val_mse: 0.0016 - lr: 0.0297
Epoch 12/30
161/162 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0246 - mse: 9.9922e-04
162/162 [==============================] - 2s 10ms/step - loss: 0.0012 - mae: 0.0246 - mse: 9.9884e-04 - val_loss: 0.0012 - val_mae: 0.0245 - val_mse: 9.6464e-04 - lr: 0.0149
Epoch 13/30
153/162 [===========================>..] - ETA: 0s - loss: 0.0012 - mae: 0.0246 - mse: 9.9178e-04
162/162 [==============================] - 1s 9ms/step - loss: 0.0012 - mae: 0.0246 - mse: 9.8907e-04 - val_loss: 0.0011 - val_mae: 0.0240 - val_mse: 9.3462e-04 - lr: 0.0149
Epoch 14/30
159/162 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0249 - mse: 0.0010
162/162 [==============================] - 2s 10ms/step - loss: 0.0012 - mae: 0.0248 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0237 - val_mse: 9.2234e-04 - lr: 0.0149
Epoch 15/30
143/162 [=========================>....] - ETA: 0s - loss: 0.0011 - mae: 0.0240 - mse: 9.4344e-04
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.007430672645568848.
162/162 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0240 - mse: 9.4513e-04 - val_loss: 0.0012 - val_mae: 0.0249 - val_mse: 9.8458e-04 - lr: 0.0149
Epoch 16/30
162/162 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0236 - mse: 9.2024e-04 - val_loss: 0.0011 - val_mae: 0.0243 - val_mse: 9.4679e-04 - lr: 0.0074
Epoch 17/30
149/162 [==========================>...] - ETA: 0s - loss: 0.0011 - mae: 0.0235 - mse: 9.1067e-04
162/162 [==============================] - 2s 10ms/step - loss: 0.0011 - mae: 0.0234 - mse: 9.0907e-04 - val_loss: 0.0011 - val_mae: 0.0235 - val_mse: 9.0951e-04 - lr: 0.0074
Epoch 18/30
162/162 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0234 - mse: 9.0853e-04 - val_loss: 0.0011 - val_mae: 0.0237 - val_mse: 9.0699e-04 - lr: 0.0074
Epoch 19/30
162/162 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0236 - mse: 9.1151e-04 - val_loss: 0.0012 - val_mae: 0.0253 - val_mse: 0.0010 - lr: 0.0074
Epoch 20/30
143/162 [=========================>....] - ETA: 0s - loss: 0.0011 - mae: 0.0233 - mse: 9.0131e-04
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.003715336322784424.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_222837-6sjm4q0f\files\model-best)... Done. 0.0s
162/162 [==============================] - 2s 10ms/step - loss: 0.0010 - mae: 0.0233 - mse: 8.9738e-04 - val_loss: 0.0010 - val_mae: 0.0235 - val_mse: 8.9933e-04 - lr: 0.0074
Epoch 21/30
135/162 [========================>.....] - ETA: 0s - loss: 9.9613e-04 - mae: 0.0226 - mse: 8.5403e-04
162/162 [==============================] - 1s 9ms/step - loss: 9.9837e-04 - mae: 0.0226 - mse: 8.5582e-04 - val_loss: 0.0010 - val_mae: 0.0235 - val_mse: 9.0621e-04 - lr: 0.0037
Epoch 22/30
141/162 [=========================>....] - ETA: 0s - loss: 0.0010 - mae: 0.0227 - mse: 8.6477e-04
162/162 [==============================] - 2s 11ms/step - loss: 0.0010 - mae: 0.0228 - mse: 8.6925e-04 - val_loss: 0.0010 - val_mae: 0.0234 - val_mse: 8.8767e-04 - lr: 0.0037
Epoch 23/30
147/162 [==========================>...] - ETA: 0s - loss: 9.9964e-04 - mae: 0.0226 - mse: 8.6144e-04
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.001857668161392212.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_222837-6sjm4q0f\files\model-best)... Done. 0.0s
162/162 [==============================] - 1s 9ms/step - loss: 9.9991e-04 - mae: 0.0226 - mse: 8.6289e-04 - val_loss: 0.0010 - val_mae: 0.0234 - val_mse: 8.9280e-04 - lr: 0.0037
Epoch 24/30
125/162 [======================>.......] - ETA: 0s - loss: 9.9258e-04 - mae: 0.0227 - mse: 8.6171e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_222837-6sjm4q0f\files\model-best)... Done. 0.0s
162/162 [==============================] - 1s 9ms/step - loss: 9.7991e-04 - mae: 0.0225 - mse: 8.4871e-04 - val_loss: 0.0010 - val_mae: 0.0231 - val_mse: 8.7116e-04 - lr: 0.0019
Epoch 25/30
162/162 [==============================] - 0s 2ms/step - loss: 9.7429e-04 - mae: 0.0224 - mse: 8.4467e-04 - val_loss: 0.0010 - val_mae: 0.0235 - val_mse: 8.9125e-04 - lr: 0.0019
Epoch 26/30
130/162 [=======================>......] - ETA: 0s - loss: 9.6690e-04 - mae: 0.0223 - mse: 8.4117e-04
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.000928834080696106.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_222837-6sjm4q0f\files\model-best)... Done. 0.0s
162/162 [==============================] - 2s 11ms/step - loss: 9.8043e-04 - mae: 0.0225 - mse: 8.5228e-04 - val_loss: 9.9426e-04 - val_mae: 0.0229 - val_mse: 8.5415e-04 - lr: 0.0019
Epoch 27/30
162/162 [==============================] - 1s 9ms/step - loss: 9.6031e-04 - mae: 0.0221 - mse: 8.3196e-04 - val_loss: 9.9052e-04 - val_mae: 0.0230 - val_mse: 8.6298e-04 - lr: 9.2883e-04
Epoch 28/30
162/162 [==============================] - 0s 2ms/step - loss: 9.5621e-04 - mae: 0.0222 - mse: 8.2927e-04 - val_loss: 0.0010 - val_mae: 0.0238 - val_mse: 9.1434e-04 - lr: 9.2883e-04
Epoch 29/30
155/162 [===========================>..] - ETA: 0s - loss: 9.7201e-04 - mae: 0.0224 - mse: 8.4796e-04
Epoch 29: ReduceLROnPlateau reducing learning rate to 0.000464417040348053.
162/162 [==============================] - 0s 2ms/step - loss: 9.6388e-04 - mae: 0.0223 - mse: 8.3941e-04 - val_loss: 9.9141e-04 - val_mae: 0.0229 - val_mse: 8.5863e-04 - lr: 9.2883e-04
Epoch 30/30
162/162 [==============================] - 0s 3ms/step - loss: 9.5491e-04 - mae: 0.0222 - mse: 8.2808e-04 - val_loss: 9.9764e-04 - val_mae: 0.0231 - val_mse: 8.6883e-04 - lr: 4.6442e-04
>Saved ../trained_models/models_segments_overlap_adam_0.029722690445255273LR_[32]HN_24BS_3P_val_lossM_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
216/216 [==============================] - 1s 4ms/step - loss: 0.0305 - mae: 0.0577 - mse: 0.0054 - val_loss: 0.0047 - val_mae: 0.0538 - val_mse: 0.0041 - lr: 0.0297
Epoch 2/30
216/216 [==============================] - 1s 3ms/step - loss: 0.0039 - mae: 0.0521 - mse: 0.0037 - val_loss: 0.0035 - val_mae: 0.0506 - val_mse: 0.0035 - lr: 0.0297
Epoch 3/30
216/216 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0509 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0508 - val_mse: 0.0035 - lr: 0.0297
Epoch 4/30
216/216 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0297
Epoch 5/30
202/216 [===========================>..] - ETA: 0s - loss: 0.0035 - mae: 0.0507 - mse: 0.0034
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.014861345291137695.
216/216 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0297
Epoch 6/30
216/216 [==============================] - 1s 2ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0149
Epoch 7/30
216/216 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0510 - val_mse: 0.0035 - lr: 0.0149
Epoch 8/30
191/216 [=========================>....] - ETA: 0s - loss: 0.0035 - mae: 0.0509 - mse: 0.0034
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.007430672645568848.
216/216 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0149
Epoch 9/30
216/216 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0074
Epoch 10/30
216/216 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0074
Epoch 11/30
216/216 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0510 - val_mse: 0.0036 - lr: 0.0074
Epoch 12/30
216/216 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0074
Epoch 13/30
194/216 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0509 - mse: 0.0034
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.003715336322784424.
216/216 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0074
Epoch 14/30
216/216 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0037
Epoch 15/30
216/216 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0037
Epoch 16/30
144/216 [===================>..........] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034
194/216 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.001857668161392212.
216/216 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0037
Epoch 17/30
216/216 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0019
Epoch 18/30
216/216 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0019
Epoch 19/30
185/216 [========================>.....] - ETA: 0s - loss: 0.0034 - mae: 0.0504 - mse: 0.0034
216/216 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 9.2883e-04
Epoch 21/30
216/216 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 9.2883e-04
Epoch 22/30
  1/216 [..............................] - ETA: 0s - loss: 0.0032 - mae: 0.0473 - mse: 0.00320034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 9.2883e-04
214/216 [============================>.] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.00340034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 9.2883e-04
216/216 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.1610e-04
216/216 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.1610e-04
216/216 [==============================] - 1s 3ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.1610e-04
162/162 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04
162/162 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0273 - mse: 0.0012 - val_loss: 0.0017 - val_mae: 0.0306 - val_mse: 0.0014 - lr: 0.0149e-04
 48/162 [=======>......................] - ETA: 0s - loss: 0.0011 - mae: 0.0247 - mse: 9.8918e-04 - val_loss: 0.0017 - val_mae: 0.0306 - val_mse: 0.0014 - lr: 0.0149e-04
162/162 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0248 - mse: 9.8900e-04 - val_loss: 0.0011 - val_mae: 0.0249 - val_mse: 0.0010 - lr: 0.0149
162/162 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0241 - mse: 9.3009e-04 - val_loss: 0.0010 - val_mae: 0.0246 - val_mse: 9.6560e-04 - lr: 0.0074
162/162 [==============================] - 1s 3ms/step - loss: 9.8590e-04 - mae: 0.0237 - mse: 8.9994e-04 - val_loss: 0.0012 - val_mae: 0.0276 - val_mse: 0.0011 - lr: 0.0037
162/162 [==============================] - 0s 2ms/step - loss: 9.5780e-04 - mae: 0.0233 - mse: 8.7782e-04 - val_loss: 0.0010 - val_mae: 0.0240 - val_mse: 9.4143e-04 - lr: 9.2883e-04
162/162 [==============================] - 0s 2ms/step - loss: 9.5780e-04 - mae: 0.0233 - mse: 8.7782e-04 - val_loss: 0.0010 - val_mae: 0.0240 - val_mse: 9.4143e-04 - lr: 9.2883e-04
162/162 [==============================] - 0s 2ms/step - loss: 9.5780e-04 - mae: 0.0233 - mse: 8.7782e-04 - val_loss: 0.0010 - val_mae: 0.0240 - val_mse: 9.4143e-04 - lr: 9.2883e-04
162/162 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0297- lr: 9.2883e-04
162/162 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0149- lr: 9.2883e-04
162/162 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0037- lr: 9.2883e-04
162/162 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0019- lr: 9.2883e-04
162/162 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.6442e-04: 9.2883e-04
162/162 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.3221e-04: 9.2883e-04
162/162 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 5.8052e-05: 9.2883e-04
162/162 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 5.8052e-05: 9.2883e-04
162/162 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 5.8052e-05: 9.2883e-04
162/162 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0297e-05: 9.2883e-04
162/162 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0074e-05: 9.2883e-04
162/162 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0037e-05: 9.2883e-04
134/162 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0037e-05: 9.2883e-04
162/162 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 9.2883e-04: 9.2883e-04
162/162 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 4.6442e-04: 9.2883e-04
162/162 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.1610e-04: 9.2883e-04
162/162 [==============================] - ETA: 0s - loss: 0.0326 - mae: 0.0394 - mse: 0.0021  19 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.1610e-04: 9.2883e-04
162/162 [==============================] - ETA: 0s - loss: 0.0326 - mae: 0.0394 - mse: 0.0021  19 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.1610e-04: 9.2883e-04
162/162 [==============================] - 1s 4ms/step - loss: 0.0326 - mae: 0.0394 - mse: 0.0021 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0297e-04: 9.2883e-04
162/162 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0149e-04: 9.2883e-04
162/162 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0074e-04: 9.2883e-04
162/162 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0019e-04: 9.2883e-04
162/162 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.2883e-04: 9.2883e-04
162/162 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.3221e-04: 9.2883e-04
162/162 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.1610e-04: 9.2883e-04
162/162 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.1610e-04: 9.2883e-04
162/162 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.1610e-04: 9.2883e-04
162/162 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 8/30=============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.014861345291137695.: 0.0372 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 15/30educeLROnPlateau reducing learning rate to 0.014861345291137695.: 0.0372 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.003715336322784424.: 0.0372 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 22/30educeLROnPlateau reducing learning rate to 0.003715336322784424.: 0.0372 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 22/30educeLROnPlateau reducing learning rate to 0.003715336322784424.: 0.0372 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.000928834080696106.: 0.0372 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.000928834080696106.: 0.0372 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 26/30educeLROnPlateau reducing learning rate to 0.000928834080696106.: 0.0372 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 26/30educeLROnPlateau reducing learning rate to 0.000928834080696106.: 0.0372 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 27: ReduceLROnPlateau reducing learning rate to 0.000464417040348053.: 0.0372 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 27: ReduceLROnPlateau reducing learning rate to 0.000464417040348053.: 0.0372 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 3/300educeLROnPlateau reducing learning rate to 0.000464417040348053.: 0.0372 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 3/300educeLROnPlateau reducing learning rate to 0.000464417040348053.: 0.0372 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
Epoch 9/300educeLROnPlateau reducing learning rate to 0.000464417040348053.: 0.0372 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 13/30educeLROnPlateau reducing learning rate to 0.000464417040348053.: 0.0372 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 17/30educeLROnPlateau reducing learning rate to 0.000464417040348053.: 0.0372 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 21/30educeLROnPlateau reducing learning rate to 0.000464417040348053.: 0.0372 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 25/30educeLROnPlateau reducing learning rate to 0.000464417040348053.: 0.0372 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.000464417040348053.: 0.0372 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
159/162 [============================>.] - ETA: 0s - loss: 0.0025 - mae: 0.0369 - mse: 0.00200019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
159/162 [============================>.] - ETA: 0s - loss: 0.0025 - mae: 0.0369 - mse: 0.00200019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 4/30===========================>.] - ETA: 0s - loss: 0.0025 - mae: 0.0369 - mse: 0.00200019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 8/30===========================>.] - ETA: 0s - loss: 0.0025 - mae: 0.0369 - mse: 0.00200019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.014861345291137695.0369 - mse: 0.00200019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 16/30educeLROnPlateau reducing learning rate to 0.014861345291137695.0369 - mse: 0.00200019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 19/30educeLROnPlateau reducing learning rate to 0.014861345291137695.0369 - mse: 0.00200019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 23/30educeLROnPlateau reducing learning rate to 0.014861345291137695.0369 - mse: 0.00200019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
Epoch 28/30educeLROnPlateau reducing learning rate to 0.014861345291137695.0369 - mse: 0.00200019 - val_loss: 0.0020 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
>Saved ../trained_models/models_segments_overlap_adam_0.029722690445255273LR_[32]HN_24BS_3P_val_lossM_30epochs/model_9.h5l_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04
>Saved ../trained_models/models_segments_overlap_adam_0.029722690445255273LR_[32]HN_24BS_3P_val_lossM_30epochs/model_9.h5l_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0297e-04: 9.2883e-04