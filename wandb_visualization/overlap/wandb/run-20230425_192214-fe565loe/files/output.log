(3883, 8)
(1665, 8)
Epoch 1/20
168/486 [=========>....................] - ETA: 0s - loss: 0.0063 - mae: 0.0530 - mse: 0.0063 - root_mean_squared_error: 0.0796
wandb: WARNING The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.

486/486 [==============================] - ETA: 0s - loss: 0.0036 - mae: 0.0444 - mse: 0.0036 - root_mean_squared_error: 0.0604
486/486 [==============================] - 6s 10ms/step - loss: 0.0036 - mae: 0.0444 - mse: 0.0036 - root_mean_squared_error: 0.0604 - val_loss: 0.0025 - val_mae: 0.0420 - val_mse: 0.0025 - val_root_mean_squared_error: 0.0502 - lr: 0.0690
Epoch 2/20
484/486 [============================>.] - ETA: 0s - loss: 0.0022 - mae: 0.0401 - mse: 0.0022 - root_mean_squared_error: 0.0472
486/486 [==============================] - 5s 9ms/step - loss: 0.0022 - mae: 0.0401 - mse: 0.0022 - root_mean_squared_error: 0.0472 - val_loss: 0.0021 - val_mae: 0.0391 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0454 - lr: 0.0690
Epoch 3/20
477/486 [============================>.] - ETA: 0s - loss: 0.0022 - mae: 0.0397 - mse: 0.0022 - root_mean_squared_error: 0.0466
486/486 [==============================] - 3s 6ms/step - loss: 0.0022 - mae: 0.0397 - mse: 0.0022 - root_mean_squared_error: 0.0466 - val_loss: 0.0020 - val_mae: 0.0387 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0451 - lr: 0.0690
Epoch 4/20
479/486 [============================>.] - ETA: 0s - loss: 0.0023 - mae: 0.0407 - mse: 0.0023 - root_mean_squared_error: 0.0482
486/486 [==============================] - 5s 9ms/step - loss: 0.0023 - mae: 0.0407 - mse: 0.0023 - root_mean_squared_error: 0.0482 - val_loss: 0.0020 - val_mae: 0.0387 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0450 - lr: 0.0690
Epoch 5/20
486/486 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0411 - mse: 0.0024 - root_mean_squared_error: 0.0493 - val_loss: 0.0022 - val_mae: 0.0398 - val_mse: 0.0022 - val_root_mean_squared_error: 0.0467 - lr: 0.0690
Epoch 6/20
467/486 [===========================>..] - ETA: 0s - loss: 0.0022 - mae: 0.0400 - mse: 0.0022 - root_mean_squared_error: 0.0474
486/486 [==============================] - 4s 8ms/step - loss: 0.0022 - mae: 0.0401 - mse: 0.0022 - root_mean_squared_error: 0.0474 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0444 - lr: 0.0690
Epoch 7/20
479/486 [============================>.] - ETA: 0s - loss: 0.0022 - mae: 0.0398 - mse: 0.0022 - root_mean_squared_error: 0.0468
486/486 [==============================] - 3s 7ms/step - loss: 0.0022 - mae: 0.0399 - mse: 0.0022 - root_mean_squared_error: 0.0469 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0444 - lr: 0.0690
Epoch 8/20
486/486 [==============================] - 2s 4ms/step - loss: 0.0022 - mae: 0.0398 - mse: 0.0022 - root_mean_squared_error: 0.0471 - val_loss: 0.0027 - val_mae: 0.0434 - val_mse: 0.0027 - val_root_mean_squared_error: 0.0523 - lr: 0.0690
Epoch 9/20
486/486 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0402 - mse: 0.0023 - root_mean_squared_error: 0.0479 - val_loss: 0.0034 - val_mae: 0.0480 - val_mse: 0.0034 - val_root_mean_squared_error: 0.0586 - lr: 0.0690
Epoch 10/20
486/486 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0404 - mse: 0.0023 - root_mean_squared_error: 0.0478 - val_loss: 0.0039 - val_mae: 0.0512 - val_mse: 0.0039 - val_root_mean_squared_error: 0.0627 - lr: 0.0690
Epoch 11/20
486/486 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0406 - mse: 0.0024 - root_mean_squared_error: 0.0486 - val_loss: 0.0021 - val_mae: 0.0396 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0463 - lr: 0.0690
Epoch 12/20

485/486 [============================>.] - ETA: 0s - loss: 0.0022 - mae: 0.0398 - mse: 0.0022 - root_mean_squared_error: 0.0467
486/486 [==============================] - 5s 10ms/step - loss: 0.0022 - mae: 0.0398 - mse: 0.0022 - root_mean_squared_error: 0.0467 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0690
Epoch 13/20
486/486 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0407 - mse: 0.0023 - root_mean_squared_error: 0.0481 - val_loss: 0.0025 - val_mae: 0.0420 - val_mse: 0.0025 - val_root_mean_squared_error: 0.0503 - lr: 0.0690
Epoch 14/20
486/486 [==============================] - 2s 3ms/step - loss: 0.0024 - mae: 0.0405 - mse: 0.0024 - root_mean_squared_error: 0.0485 - val_loss: 0.0024 - val_mae: 0.0411 - val_mse: 0.0024 - val_root_mean_squared_error: 0.0491 - lr: 0.0690
Epoch 15/20
486/486 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0401 - mse: 0.0023 - root_mean_squared_error: 0.0477 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - lr: 0.0690
Epoch 16/20
486/486 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0399 - mse: 0.0022 - root_mean_squared_error: 0.0473 - val_loss: 0.0024 - val_mae: 0.0410 - val_mse: 0.0024 - val_root_mean_squared_error: 0.0485 - lr: 0.0690
Epoch 17/20
486/486 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0408 - mse: 0.0023 - root_mean_squared_error: 0.0481 - val_loss: 0.0022 - val_mae: 0.0399 - val_mse: 0.0022 - val_root_mean_squared_error: 0.0468 - lr: 0.0690
Epoch 18/20
486/486 [==============================] - 2s 3ms/step - loss: 0.0023 - mae: 0.0406 - mse: 0.0023 - root_mean_squared_error: 0.0483 - val_loss: 0.0021 - val_mae: 0.0394 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0460 - lr: 0.0690
Epoch 19/20
486/486 [==============================] - 2s 3ms/step - loss: 0.0022 - mae: 0.0398 - mse: 0.0022 - root_mean_squared_error: 0.0470 - val_loss: 0.0032 - val_mae: 0.0462 - val_mse: 0.0032 - val_root_mean_squared_error: 0.0563 - lr: 0.0690
Epoch 20/20
486/486 [==============================] - 2s 4ms/step - loss: 0.0023 - mae: 0.0402 - mse: 0.0023 - root_mean_squared_error: 0.0476 - val_loss: 0.0026 - val_mae: 0.0425 - val_mse: 0.0026 - val_root_mean_squared_error: 0.0509 - lr: 0.0690
>Saved ../trained_models/RNN/models_segments_overlap-rnn_adam_0.06896LR_[10]HL8DU_8BS_['sigmoid', 'tanh']_15P_val_mseM_20epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'root_mean_squared_error', 'val_loss', 'val_mae', 'val_mse', 'val_root_mean_squared_error', 'lr'])