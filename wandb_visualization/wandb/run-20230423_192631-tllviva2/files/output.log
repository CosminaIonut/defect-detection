Epoch 1/30
242/243 [============================>.] - ETA: 0s - loss: 0.8578 - mae: 0.9252 - mse: 0.8578
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
243/243 [==============================] - 1s 4ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0977
Epoch 2/30
235/243 [============================>.] - ETA: 0s - loss: 0.8577 - mae: 0.9251 - mse: 0.8577
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.04886384680867195.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0977
Epoch 3/30
210/243 [========================>.....] - ETA: 0s - loss: 0.8576 - mae: 0.9250 - mse: 0.8576
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.024431923404335976.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0489
Epoch 4/30
184/243 [=====================>........] - ETA: 0s - loss: 0.8565 - mae: 0.9245 - mse: 0.8565
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.012215961702167988.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0244
Epoch 5/30
188/243 [======================>.......] - ETA: 0s - loss: 0.8574 - mae: 0.9249 - mse: 0.8574
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.006107980851083994.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0122
Epoch 6/30
187/243 [======================>.......] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.003053990425541997.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0061
Epoch 7/30
188/243 [======================>.......] - ETA: 0s - loss: 0.8581 - mae: 0.9253 - mse: 0.8581
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0015269952127709985.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0031
Epoch 8/30
191/243 [======================>.......] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0007634976063854992.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0015
Epoch 9/30
184/243 [=====================>........] - ETA: 0s - loss: 0.8564 - mae: 0.9244 - mse: 0.8564
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003817488031927496.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 7.6350e-04
Epoch 10/30
235/243 [============================>.] - ETA: 0s - loss: 0.8578 - mae: 0.9252 - mse: 0.8578
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001908744015963748.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 3.8175e-04
Epoch 11/30
232/243 [===========================>..] - ETA: 0s - loss: 0.8581 - mae: 0.9253 - mse: 0.8581
Epoch 11: ReduceLROnPlateau reducing learning rate to 9.54372007981874e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.9087e-04
Epoch 12/30
234/243 [===========================>..] - ETA: 0s - loss: 0.8583 - mae: 0.9254 - mse: 0.8583
Epoch 12: ReduceLROnPlateau reducing learning rate to 4.77186003990937e-05.
243/243 [==============================] - 0s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 9.5437e-05
Epoch 13/30
235/243 [============================>.] - ETA: 0s - loss: 0.8580 - mae: 0.9253 - mse: 0.8580
Epoch 13: ReduceLROnPlateau reducing learning rate to 2.385930019954685e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 4.7719e-05
Epoch 14/30
225/243 [==========================>...] - ETA: 0s - loss: 0.8578 - mae: 0.9251 - mse: 0.8578
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.1929650099773426e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 2.3859e-05
Epoch 15/30
209/243 [========================>.....] - ETA: 0s - loss: 0.8576 - mae: 0.9250 - mse: 0.8576
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.1930e-05
Epoch 16/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 17/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 18/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 19/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 20/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 21/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 22/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 23/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 24/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 25/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 26/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 27/30
243/243 [==============================] - 0s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 28/30
243/243 [==============================] - 0s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 29/30
243/243 [==============================] - 0s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 30/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.0977276966646613LR_[124]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
229/323 [====================>.........] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.

323/323 [==============================] - 1s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0977
Epoch 2/30
287/323 [=========================>....] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.04886384680867195.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0977
Epoch 3/30
292/323 [==========================>...] - ETA: 0s - loss: 0.6433 - mae: 0.7999 - mse: 0.6433
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.024431923404335976.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0489
Epoch 4/30
268/323 [=======================>......] - ETA: 0s - loss: 0.6429 - mae: 0.7997 - mse: 0.6429
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.012215961702167988.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0244
Epoch 5/30
303/323 [===========================>..] - ETA: 0s - loss: 0.6426 - mae: 0.7995 - mse: 0.6426
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.006107980851083994.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0122
Epoch 6/30
305/323 [===========================>..] - ETA: 0s - loss: 0.6434 - mae: 0.8000 - mse: 0.6434
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.003053990425541997.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0061
Epoch 7/30
309/323 [===========================>..] - ETA: 0s - loss: 0.6432 - mae: 0.7999 - mse: 0.6432
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0015269952127709985.
323/323 [==============================] - 0s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0031
Epoch 8/30
309/323 [===========================>..] - ETA: 0s - loss: 0.6430 - mae: 0.7998 - mse: 0.6430
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0007634976063854992.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0015
Epoch 9/30
292/323 [==========================>...] - ETA: 0s - loss: 0.6421 - mae: 0.7992 - mse: 0.6421
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003817488031927496.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 7.6350e-04
Epoch 10/30
274/323 [========================>.....] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001908744015963748.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 3.8175e-04
Epoch 11/30
303/323 [===========================>..] - ETA: 0s - loss: 0.6428 - mae: 0.7996 - mse: 0.6428
Epoch 11: ReduceLROnPlateau reducing learning rate to 9.54372007981874e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.9087e-04
Epoch 12/30
285/323 [=========================>....] - ETA: 0s - loss: 0.6426 - mae: 0.7995 - mse: 0.6426
Epoch 12: ReduceLROnPlateau reducing learning rate to 4.77186003990937e-05.
323/323 [==============================] - 1s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 9.5437e-05
Epoch 13/30
280/323 [=========================>....] - ETA: 0s - loss: 0.6427 - mae: 0.7996 - mse: 0.6427
Epoch 13: ReduceLROnPlateau reducing learning rate to 2.385930019954685e-05.
323/323 [==============================] - 1s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 4.7719e-05
Epoch 14/30
  1/323 [..............................] - ETA: 0s - loss: 0.6604 - mae: 0.8105 - mse: 0.6604
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 2.3859e-05
Epoch 15/30
319/323 [============================>.] - ETA: 0s - loss: 0.6429 - mae: 0.7997 - mse: 0.6429
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.
323/323 [==============================] - 1s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.1930e-05
Epoch 16/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 17/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 18/30
271/323 [========================>.....] - ETA: 0s - loss: 0.6424 - mae: 0.7993 - mse: 0.6424
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 2.3859e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0025s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0025s). Check your callbacks.
323/323 [==============================] - 1s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
185/243 [=====================>........] - ETA: 0s - loss: 0.4578 - mae: 0.6752 - mse: 0.45784578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0015e-05
185/243 [=====================>........] - ETA: 0s - loss: 0.4578 - mae: 0.6752 - mse: 0.45784578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 0.0015e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
237/243 [============================>.] - ETA: 0s - loss: 0.3327 - mae: 0.5752 - mse: 0.33273328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0977e-05
243/243 [==============================] - 0s 2ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 4.7719e-05
243/243 [==============================] - 0s 2ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 4.7719e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 1/30=============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 1/30=============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230423_192631-tllviva2\files\model-best)... Done. 0.0s
Epoch 10/30duceLROnPlateau reducing learning rate to 0.012215961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 10/30duceLROnPlateau reducing learning rate to 0.012215961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0015s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0015s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 10/30duceLROnPlateau reducing learning rate to 0.012215961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0021s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0021s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 10/30duceLROnPlateau reducing learning rate to 0.012215961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.012215961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 10/30duceLROnPlateau reducing learning rate to 0.012215961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 26/30educeLROnPlateau reducing learning rate to 1e-05.5961702167988.e: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05