Epoch 1/200
65/81 [=======================>......] - ETA: 0s - loss: 0.0588 - mae: 0.0589 - mse: 0.0094
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.
81/81 [==============================] - 1s 10ms/step - loss: 0.0478 - mae: 0.0549 - mse: 0.0080 - val_loss: 0.0025 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0752
Epoch 2/200
77/81 [===========================>..] - ETA: 0s - loss: 0.0027 - mae: 0.0392 - mse: 0.0022
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 9ms/step - loss: 0.0027 - mae: 0.0392 - mse: 0.0022 - val_loss: 0.0023 - val_mae: 0.0372 - val_mse: 0.0019 - lr: 0.0752
Epoch 3/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0024 - mae: 0.0384 - mse: 0.0021 - val_loss: 0.0038 - val_mae: 0.0451 - val_mse: 0.0031 - lr: 0.0752
Epoch 4/200
81/81 [==============================] - 1s 9ms/step - loss: 0.0023 - mae: 0.0373 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0367 - val_mse: 0.0018 - lr: 0.0752
Epoch 5/200
79/81 [============================>.] - ETA: 0s - loss: 0.0021 - mae: 0.0364 - mse: 0.0019
81/81 [==============================] - 1s 9ms/step - loss: 0.0021 - mae: 0.0364 - mse: 0.0018 - val_loss: 0.0019 - val_mae: 0.0351 - val_mse: 0.0017 - lr: 0.0752
Epoch 6/200
74/81 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0359 - mse: 0.0018
81/81 [==============================] - 1s 9ms/step - loss: 0.0020 - mae: 0.0358 - mse: 0.0018 - val_loss: 0.0018 - val_mae: 0.0346 - val_mse: 0.0016 - lr: 0.0752
Epoch 7/200
75/81 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0351 - mse: 0.0018
81/81 [==============================] - 1s 9ms/step - loss: 0.0020 - mae: 0.0351 - mse: 0.0018 - val_loss: 0.0018 - val_mae: 0.0339 - val_mse: 0.0016 - lr: 0.0752
Epoch 8/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0346 - mse: 0.0017 - val_loss: 0.0018 - val_mae: 0.0342 - val_mse: 0.0017 - lr: 0.0752
Epoch 9/200
 1/81 [..............................] - ETA: 0s - loss: 0.0015 - mae: 0.0307 - mse: 0.0014
81/81 [==============================] - 1s 12ms/step - loss: 0.0018 - mae: 0.0328 - mse: 0.0016 - val_loss: 0.0017 - val_mae: 0.0323 - val_mse: 0.0015 - lr: 0.0752
Epoch 10/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0311 - mse: 0.0014 - val_loss: 0.0017 - val_mae: 0.0318 - val_mse: 0.0015 - lr: 0.0752
Epoch 11/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0311 - mse: 0.0015 - val_loss: 0.0018 - val_mae: 0.0325 - val_mse: 0.0016 - lr: 0.0752
Epoch 12/200
 1/81 [..............................] - ETA: 0s - loss: 0.0022 - mae: 0.0360 - mse: 0.0019
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 9ms/step - loss: 0.0015 - mae: 0.0280 - mse: 0.0012 - val_loss: 0.0014 - val_mae: 0.0273 - val_mse: 0.0012 - lr: 0.0752
Epoch 13/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0268 - mse: 0.0012 - val_loss: 0.0014 - val_mae: 0.0277 - val_mse: 0.0012 - lr: 0.0752
Epoch 14/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0015 - val_mae: 0.0284 - val_mse: 0.0013 - lr: 0.0752
Epoch 15/200
81/81 [==============================] - 1s 9ms/step - loss: 0.0012 - mae: 0.0252 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0244 - val_mse: 9.6907e-04 - lr: 0.0752
Epoch 16/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0255 - mse: 0.0011 - val_loss: 0.0015 - val_mae: 0.0279 - val_mse: 0.0012 - lr: 0.0752
Epoch 17/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0250 - mse: 0.0010 - val_loss: 0.0019 - val_mae: 0.0327 - val_mse: 0.0017 - lr: 0.0752
Epoch 18/200
80/81 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0246 - mse: 9.8628e-04
81/81 [==============================] - 1s 10ms/step - loss: 0.0012 - mae: 0.0246 - mse: 9.8936e-04 - val_loss: 0.0011 - val_mae: 0.0233 - val_mse: 8.9123e-04 - lr: 0.0752
Epoch 19/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0255 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0239 - val_mse: 9.2366e-04 - lr: 0.0752
Epoch 20/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0242 - mse: 9.5248e-04 - val_loss: 0.0011 - val_mae: 0.0248 - val_mse: 9.8617e-04 - lr: 0.0752
Epoch 21/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0244 - mse: 9.6473e-04 - val_loss: 0.0011 - val_mae: 0.0237 - val_mse: 9.1270e-04 - lr: 0.0752
Epoch 22/200
81/81 [==============================] - ETA: 0s - loss: 0.0011 - mae: 0.0236 - mse: 9.3241e-04
81/81 [==============================] - 1s 9ms/step - loss: 0.0011 - mae: 0.0236 - mse: 9.3241e-04 - val_loss: 0.0010 - val_mae: 0.0221 - val_mse: 7.9387e-04 - lr: 0.0752
Epoch 23/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0229 - mse: 8.7277e-04 - val_loss: 0.0011 - val_mae: 0.0243 - val_mse: 9.3900e-04 - lr: 0.0752
Epoch 24/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0248 - mse: 0.0010 - val_loss: 0.0013 - val_mae: 0.0245 - val_mse: 9.5147e-04 - lr: 0.0752
Epoch 25/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0243 - mse: 9.6930e-04 - val_loss: 0.0011 - val_mae: 0.0233 - val_mse: 8.8924e-04 - lr: 0.0752
Epoch 26/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0237 - mse: 9.3203e-04 - val_loss: 0.0010 - val_mae: 0.0222 - val_mse: 7.9584e-04 - lr: 0.0752
Epoch 27/200
77/81 [===========================>..] - ETA: 0s - loss: 0.0010 - mae: 0.0231 - mse: 8.7200e-04
81/81 [==============================] - 1s 10ms/step - loss: 0.0010 - mae: 0.0231 - mse: 8.7388e-04 - val_loss: 9.3937e-04 - val_mae: 0.0222 - val_mse: 7.9501e-04 - lr: 0.0752
Epoch 28/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0229 - mse: 8.5864e-04 - val_loss: 0.0014 - val_mae: 0.0287 - val_mse: 0.0013 - lr: 0.0752
Epoch 29/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0250 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0226 - val_mse: 8.3418e-04 - lr: 0.0752
Epoch 30/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0236 - mse: 9.0763e-04 - val_loss: 9.6471e-04 - val_mae: 0.0218 - val_mse: 7.7881e-04 - lr: 0.0752
Epoch 31/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0229 - mse: 8.5823e-04 - val_loss: 9.5523e-04 - val_mae: 0.0227 - val_mse: 8.4602e-04 - lr: 0.0752
Epoch 32/200
 1/81 [..............................] - ETA: 0s - loss: 8.3431e-04 - mae: 0.0220 - mse: 7.2510e-04
Epoch 32: ReduceLROnPlateau reducing learning rate to 0.03761362284421921.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 10ms/step - loss: 9.9248e-04 - mae: 0.0228 - mse: 8.5327e-04 - val_loss: 9.1434e-04 - val_mae: 0.0217 - val_mse: 7.6600e-04 - lr: 0.0752
Epoch 33/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0232 - mse: 8.7987e-04 - val_loss: 0.0010 - val_mae: 0.0234 - val_mse: 8.5894e-04 - lr: 0.0376
Epoch 34/200
81/81 [==============================] - 0s 1ms/step - loss: 9.5003e-04 - mae: 0.0221 - mse: 8.0987e-04 - val_loss: 9.3338e-04 - val_mae: 0.0219 - val_mse: 7.8560e-04 - lr: 0.0376
Epoch 35/200
81/81 [==============================] - 0s 1ms/step - loss: 9.5249e-04 - mae: 0.0222 - mse: 8.1690e-04 - val_loss: 9.6139e-04 - val_mae: 0.0219 - val_mse: 7.8529e-04 - lr: 0.0376
Epoch 36/200
 1/81 [..............................] - ETA: 0s - loss: 9.8834e-04 - mae: 0.0228 - mse: 8.1224e-04
81/81 [==============================] - 1s 10ms/step - loss: 9.4214e-04 - mae: 0.0220 - mse: 8.0614e-04 - val_loss: 9.0506e-04 - val_mae: 0.0223 - val_mse: 7.9524e-04 - lr: 0.0376
Epoch 37/200
81/81 [==============================] - 0s 1ms/step - loss: 9.7053e-04 - mae: 0.0224 - mse: 8.2155e-04 - val_loss: 9.8770e-04 - val_mae: 0.0224 - val_mse: 8.2194e-04 - lr: 0.0376
Epoch 38/200
81/81 [==============================] - 0s 1ms/step - loss: 9.1419e-04 - mae: 0.0219 - mse: 7.9216e-04 - val_loss: 9.2170e-04 - val_mae: 0.0218 - val_mse: 7.7664e-04 - lr: 0.0376
Epoch 39/200
81/81 [==============================] - 0s 1ms/step - loss: 9.4703e-04 - mae: 0.0220 - mse: 8.0031e-04 - val_loss: 9.7639e-04 - val_mae: 0.0225 - val_mse: 8.2600e-04 - lr: 0.0376
Epoch 40/200
81/81 [==============================] - 0s 2ms/step - loss: 9.3947e-04 - mae: 0.0222 - mse: 8.0430e-04 - val_loss: 9.2469e-04 - val_mae: 0.0224 - val_mse: 7.8386e-04 - lr: 0.0376
Epoch 41/200
74/81 [==========================>...] - ETA: 0s - loss: 8.9721e-04 - mae: 0.0216 - mse: 7.7453e-04
81/81 [==============================] - 1s 12ms/step - loss: 8.9707e-04 - mae: 0.0217 - mse: 7.7499e-04 - val_loss: 8.5219e-04 - val_mae: 0.0217 - val_mse: 7.5083e-04 - lr: 0.0376
Epoch 42/200
35/81 [===========>..................] - ETA: 0s - loss: 8.3976e-04 - mae: 0.0209 - mse: 7.2844e-04
Epoch 42: ReduceLROnPlateau reducing learning rate to 0.018806811422109604.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 13ms/step - loss: 9.2290e-04 - mae: 0.0221 - mse: 8.0648e-04 - val_loss: 8.5183e-04 - val_mae: 0.0212 - val_mse: 7.2289e-04 - lr: 0.0376
Epoch 43/200
81/81 [==============================] - 1s 12ms/step - loss: 8.4810e-04 - mae: 0.0212 - mse: 7.4269e-04 - val_loss: 8.4101e-04 - val_mae: 0.0212 - val_mse: 7.3443e-04 - lr: 0.0188
Epoch 44/200
81/81 [==============================] - 0s 2ms/step - loss: 8.2566e-04 - mae: 0.0208 - mse: 7.3054e-04 - val_loss: 8.6267e-04 - val_mae: 0.0216 - val_mse: 7.7567e-04 - lr: 0.0188
Epoch 45/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5726e-04 - mae: 0.0212 - mse: 7.5193e-04 - val_loss: 8.9755e-04 - val_mae: 0.0219 - val_mse: 7.9006e-04 - lr: 0.0188
Epoch 46/200
61/81 [=====================>........] - ETA: 0s - loss: 8.2576e-04 - mae: 0.0208 - mse: 7.2765e-04
81/81 [==============================] - 1s 15ms/step - loss: 8.4209e-04 - mae: 0.0211 - mse: 7.4047e-04 - val_loss: 8.3136e-04 - val_mae: 0.0217 - val_mse: 7.5581e-04 - lr: 0.0188
Epoch 47/200
81/81 [==============================] - 0s 1ms/step - loss: 8.7851e-04 - mae: 0.0215 - mse: 7.6485e-04 - val_loss: 8.4637e-04 - val_mae: 0.0212 - val_mse: 7.4713e-04 - lr: 0.0188
Epoch 48/200
69/81 [========================>.....] - ETA: 0s - loss: 8.1267e-04 - mae: 0.0207 - mse: 7.1365e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 10ms/step - loss: 8.1237e-04 - mae: 0.0206 - mse: 7.1228e-04 - val_loss: 8.0431e-04 - val_mae: 0.0209 - val_mse: 7.0513e-04 - lr: 0.0188
Epoch 49/200
81/81 [==============================] - 0s 1ms/step - loss: 8.0196e-04 - mae: 0.0203 - mse: 7.0568e-04 - val_loss: 8.0255e-04 - val_mae: 0.0206 - val_mse: 7.1789e-04 - lr: 0.01888
Epoch 50/200
81/81 [==============================] - 0s 1ms/step - loss: 8.0196e-04 - mae: 0.0203 - mse: 7.0568e-04 - val_loss: 8.0255e-04 - val_mae: 0.0206 - val_mse: 7.1789e-04 - lr: 0.01888
Epoch 51/200
49/81 [=================>............] - ETA: 0s - loss: 7.7513e-04 - mae: 0.0197 - mse: 6.7727e-04
81/81 [==============================] - 1s 12ms/step - loss: 7.9621e-04 - mae: 0.0202 - mse: 6.9808e-04 - val_loss: 7.9672e-04 - val_mae: 0.0204 - val_mse: 7.0602e-04 - lr: 0.0188
Epoch 52/200
56/81 [===================>..........] - ETA: 0s - loss: 7.6273e-04 - mae: 0.0198 - mse: 6.7227e-04
81/81 [==============================] - 1s 12ms/step - loss: 7.9621e-04 - mae: 0.0202 - mse: 6.9808e-04 - val_loss: 7.9672e-04 - val_mae: 0.0204 - val_mse: 7.0602e-04 - lr: 0.0188
81/81 [==============================] - 0s 2ms/step - loss: 8.2658e-04 - mae: 0.0203 - mse: 7.1001e-04 - val_loss: 7.9595e-04 - val_mae: 0.0200 - val_mse: 6.9571e-04 - lr: 0.01888
Epoch 54/200
81/81 [==============================] - 0s 3ms/step - loss: 7.7243e-04 - mae: 0.0197 - mse: 6.7361e-04 - val_loss: 8.8878e-04 - val_mae: 0.0214 - val_mse: 7.8282e-04 - lr: 0.0188
Epoch 55/200
81/81 [==============================] - 0s 2ms/step - loss: 8.2658e-04 - mae: 0.0203 - mse: 7.1001e-04 - val_loss: 7.9595e-04 - val_mae: 0.0200 - val_mse: 6.9571e-04 - lr: 0.01888
Epoch 56/200
54/81 [===================>..........] - ETA: 0s - loss: 7.5084e-04 - mae: 0.0194 - mse: 6.5462e-04
81/81 [==============================] - 1s 13ms/step - loss: 7.6292e-04 - mae: 0.0196 - mse: 6.6611e-04 - val_loss: 7.5116e-04 - val_mae: 0.0194 - val_mse: 6.4888e-04 - lr: 0.0188
Epoch 57/200
61/81 [=====================>........] - ETA: 0s - loss: 7.9539e-04 - mae: 0.0201 - mse: 6.9346e-04
81/81 [==============================] - 1s 13ms/step - loss: 7.6292e-04 - mae: 0.0196 - mse: 6.6611e-04 - val_loss: 7.5116e-04 - val_mae: 0.0194 - val_mse: 6.4888e-04 - lr: 0.0188
49/81 [=================>............] - ETA: 0s - loss: 7.2067e-04 - mae: 0.0187 - mse: 6.1594e-041e-04 - val_loss: 7.5116e-04 - val_mae: 0.0194 - val_mse: 6.4888e-04 - lr: 0.0188
49/81 [=================>............] - ETA: 0s - loss: 7.2067e-04 - mae: 0.0187 - mse: 6.1594e-041e-04 - val_loss: 7.5116e-04 - val_mae: 0.0194 - val_mse: 6.4888e-04 - lr: 0.0188
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
56/81 [===================>..........] - ETA: 0s - loss: 7.5756e-04 - mae: 0.0195 - mse: 6.6236e-046e-04 - val_loss: 7.2211e-04 - val_mae: 0.0190 - val_mse: 6.1525e-04 - lr: 0.0188
Epoch 62: ReduceLROnPlateau reducing learning rate to 0.009403405711054802.
81/81 [==============================] - 0s 2ms/step - loss: 7.8752e-04 - mae: 0.0196 - mse: 6.6969e-04 - val_loss: 7.3349e-04 - val_mae: 0.0188 - val_mse: 6.0011e-04 - lr: 0.0188
Epoch 63/200
44/81 [===============>..............] - ETA: 0s - loss: 7.3238e-04 - mae: 0.0187 - mse: 6.2662e-04
81/81 [==============================] - 0s 1ms/step - loss: 6.9469e-04 - mae: 0.0182 - mse: 6.0238e-04 - val_loss: 7.2633e-04 - val_mae: 0.0189 - val_mse: 6.4246e-04 - lr: 0.00948
Epoch 65/200
66/81 [=======================>......] - ETA: 0s - loss: 7.0582e-04 - mae: 0.0184 - mse: 6.1669e-04
81/81 [==============================] - 0s 1ms/step - loss: 6.9469e-04 - mae: 0.0182 - mse: 6.0238e-04 - val_loss: 7.2633e-04 - val_mae: 0.0189 - val_mse: 6.4246e-04 - lr: 0.00948
81/81 [==============================] - 0s 1ms/step - loss: 7.2024e-04 - mae: 0.0187 - mse: 6.2480e-04 - val_loss: 7.6245e-04 - val_mae: 0.0186 - val_mse: 6.3344e-04 - lr: 0.00948
Epoch 68/200
72/81 [=========================>....] - ETA: 0s - loss: 7.0575e-04 - mae: 0.0183 - mse: 6.0498e-04
81/81 [==============================] - 0s 1ms/step - loss: 7.2024e-04 - mae: 0.0187 - mse: 6.2480e-04 - val_loss: 7.6245e-04 - val_mae: 0.0186 - val_mse: 6.3344e-04 - lr: 0.00948
67/81 [=======================>......] - ETA: 0s - loss: 6.7978e-04 - mae: 0.0181 - mse: 5.8844e-04e-04 - val_loss: 7.6245e-04 - val_mae: 0.0186 - val_mse: 6.3344e-04 - lr: 0.00948
67/81 [=======================>......] - ETA: 0s - loss: 6.7978e-04 - mae: 0.0181 - mse: 5.8844e-04e-04 - val_loss: 7.6245e-04 - val_mae: 0.0186 - val_mse: 6.3344e-04 - lr: 0.00948
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
81/81 [==============================] - 0s 1ms/step - loss: 6.8930e-04 - mae: 0.0181 - mse: 5.9581e-04 - val_loss: 6.9821e-04 - val_mae: 0.0192 - val_mse: 6.1991e-04 - lr: 0.00944
Epoch 73/200
81/81 [==============================] - 0s 1ms/step - loss: 6.7249e-04 - mae: 0.0178 - mse: 5.8244e-04 - val_loss: 6.9846e-04 - val_mae: 0.0181 - val_mse: 6.0216e-04 - lr: 0.0047
Epoch 74/200
64/81 [======================>.......] - ETA: 0s - loss: 6.6625e-04 - mae: 0.0179 - mse: 5.7891e-04
81/81 [==============================] - 0s 1ms/step - loss: 6.7848e-04 - mae: 0.0179 - mse: 5.8884e-04 - val_loss: 7.1650e-04 - val_mae: 0.0184 - val_mse: 6.2514e-04 - lr: 0.00474
Epoch 76/200
70/81 [========================>.....] - ETA: 0s - loss: 6.5531e-04 - mae: 0.0176 - mse: 5.6834e-04
81/81 [==============================] - 0s 1ms/step - loss: 6.7848e-04 - mae: 0.0179 - mse: 5.8884e-04 - val_loss: 7.1650e-04 - val_mae: 0.0184 - val_mse: 6.2514e-04 - lr: 0.00474
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
81/81 [==============================] - 0s 1ms/step - loss: 6.7848e-04 - mae: 0.0179 - mse: 5.8884e-04 - val_loss: 7.1650e-04 - val_mae: 0.0184 - val_mse: 6.2514e-04 - lr: 0.00474
69/81 [========================>.....] - ETA: 0s - loss: 6.8363e-04 - mae: 0.0181 - mse: 5.9078e-04e-04 - val_loss: 7.1650e-04 - val_mae: 0.0184 - val_mse: 6.2514e-04 - lr: 0.00474
69/81 [========================>.....] - ETA: 0s - loss: 6.8363e-04 - mae: 0.0181 - mse: 5.9078e-04e-04 - val_loss: 7.1650e-04 - val_mae: 0.0184 - val_mse: 6.2514e-04 - lr: 0.00474
81/81 [==============================] - 0s 1ms/step - loss: 6.5629e-04 - mae: 0.0175 - mse: 5.7073e-04 - val_loss: 7.1900e-04 - val_mae: 0.0183 - val_mse: 6.2422e-04 - lr: 0.00477
81/81 [==============================] - 0s 1ms/step - loss: 6.5629e-04 - mae: 0.0175 - mse: 5.7073e-04 - val_loss: 7.1900e-04 - val_mae: 0.0183 - val_mse: 6.2422e-04 - lr: 0.00477
64/81 [======================>.......] - ETA: 0s - loss: 6.6207e-04 - mae: 0.0175 - mse: 5.7673e-04e-04 - val_loss: 7.1900e-04 - val_mae: 0.0183 - val_mse: 6.2422e-04 - lr: 0.00477
64/81 [======================>.......] - ETA: 0s - loss: 6.6207e-04 - mae: 0.0175 - mse: 5.7673e-04e-04 - val_loss: 7.1900e-04 - val_mae: 0.0183 - val_mse: 6.2422e-04 - lr: 0.00477
70/81 [========================>.....] - ETA: 0s - loss: 6.5091e-04 - mae: 0.0175 - mse: 5.6545e-049e-04 - val_loss: 6.6719e-04 - val_mae: 0.0181 - val_mse: 5.8382e-04 - lr: 0.0024
70/81 [========================>.....] - ETA: 0s - loss: 6.5091e-04 - mae: 0.0175 - mse: 5.6545e-049e-04 - val_loss: 6.6719e-04 - val_mae: 0.0181 - val_mse: 5.8382e-04 - lr: 0.0024
81/81 [==============================] - 1s 10ms/step - loss: 6.5175e-04 - mae: 0.0175 - mse: 5.6567e-04 - val_loss: 6.6510e-04 - val_mae: 0.0180 - val_mse: 5.7804e-04 - lr: 0.0024
81/81 [==============================] - 1s 10ms/step - loss: 6.5175e-04 - mae: 0.0175 - mse: 5.6567e-04 - val_loss: 6.6510e-04 - val_mae: 0.0180 - val_mse: 5.7804e-04 - lr: 0.0024
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
64/81 [======================>.......] - ETA: 0s - loss: 6.3913e-04 - mae: 0.0173 - mse: 5.5617e-04e-04 - val_loss: 6.9153e-04 - val_mae: 0.0180 - val_mse: 6.0081e-04 - lr: 0.00244
71/81 [=========================>....] - ETA: 0s - loss: 6.5306e-04 - mae: 0.0174 - mse: 5.6924e-04e-04 - val_loss: 6.7181e-04 - val_mae: 0.0179 - val_mse: 5.8991e-04 - lr: 0.00124
71/81 [=========================>....] - ETA: 0s - loss: 6.5306e-04 - mae: 0.0174 - mse: 5.6924e-04e-04 - val_loss: 6.7181e-04 - val_mae: 0.0179 - val_mse: 5.8991e-04 - lr: 0.00124
81/81 [==============================] - 0s 1ms/step - loss: 6.4049e-04 - mae: 0.0172 - mse: 5.5663e-04 - val_loss: 6.6781e-04 - val_mae: 0.0177 - val_mse: 5.8043e-04 - lr: 0.00122
Epoch 101/200
60/81 [=====================>........] - ETA: 0s - loss: 6.4122e-04 - mae: 0.0172 - mse: 5.5757e-04
81/81 [==============================] - 0s 1ms/step - loss: 6.4049e-04 - mae: 0.0172 - mse: 5.5663e-04 - val_loss: 6.6781e-04 - val_mae: 0.0177 - val_mse: 5.8043e-04 - lr: 0.00122
69/81 [========================>.....] - ETA: 0s - loss: 6.4255e-04 - mae: 0.0173 - mse: 5.5906e-04e-04 - val_loss: 6.6781e-04 - val_mae: 0.0177 - val_mse: 5.8043e-04 - lr: 0.00122
Epoch 103: ReduceLROnPlateau reducing learning rate to 0.0005877128569409251.
69/81 [========================>.....] - ETA: 0s - loss: 6.4255e-04 - mae: 0.0173 - mse: 5.5906e-04e-04 - val_loss: 6.6781e-04 - val_mae: 0.0177 - val_mse: 5.8043e-04 - lr: 0.00122
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
69/81 [========================>.....] - ETA: 0s - loss: 6.4255e-04 - mae: 0.0173 - mse: 5.5906e-04e-04 - val_loss: 6.6781e-04 - val_mae: 0.0177 - val_mse: 5.8043e-04 - lr: 0.00122
68/81 [========================>.....] - ETA: 0s - loss: 6.4118e-04 - mae: 0.0172 - mse: 5.5552e-04e-04 - val_loss: 6.6112e-04 - val_mae: 0.0177 - val_mse: 5.7710e-04 - lr: 5.8771e-04
68/81 [========================>.....] - ETA: 0s - loss: 6.4118e-04 - mae: 0.0172 - mse: 5.5552e-04e-04 - val_loss: 6.6112e-04 - val_mae: 0.0177 - val_mse: 5.7710e-04 - lr: 5.8771e-04
67/81 [=======================>......] - ETA: 0s - loss: 6.3842e-04 - mae: 0.0172 - mse: 5.5404e-046e-04 - val_loss: 6.5342e-04 - val_mae: 0.0178 - val_mse: 5.7191e-04 - lr: 5.8771e-04
67/81 [=======================>......] - ETA: 0s - loss: 6.3842e-04 - mae: 0.0172 - mse: 5.5404e-046e-04 - val_loss: 6.5342e-04 - val_mae: 0.0178 - val_mse: 5.7191e-04 - lr: 5.8771e-04
81/81 [==============================] - 1s 10ms/step - loss: 6.3384e-04 - mae: 0.0172 - mse: 5.5001e-04 - val_loss: 6.5186e-04 - val_mae: 0.0178 - val_mse: 5.7156e-04 - lr: 5.8771e-04
81/81 [==============================] - 1s 10ms/step - loss: 6.3384e-04 - mae: 0.0172 - mse: 5.5001e-04 - val_loss: 6.5186e-04 - val_mae: 0.0178 - val_mse: 5.7156e-04 - lr: 5.8771e-04
57/81 [====================>.........] - ETA: 0s - loss: 6.3455e-04 - mae: 0.0171 - mse: 5.5222e-04e-04 - val_loss: 6.5253e-04 - val_mae: 0.0180 - val_mse: 5.7215e-04 - lr: 2.9386e-044
Epoch 117/200
81/81 [==============================] - 0s 2ms/step - loss: 6.3310e-04 - mae: 0.0172 - mse: 5.5049e-04 - val_loss: 6.5250e-04 - val_mae: 0.0177 - val_mse: 5.7048e-04 - lr: 2.9386e-04
Epoch 118/200
81/81 [==============================] - 0s 2ms/step - loss: 6.3197e-04 - mae: 0.0171 - mse: 5.4985e-04 - val_loss: 6.5354e-04 - val_mae: 0.0177 - val_mse: 5.7171e-04 - lr: 2.9386e-04
Epoch 119/200
57/81 [====================>.........] - ETA: 0s - loss: 6.3455e-04 - mae: 0.0171 - mse: 5.5222e-04e-04 - val_loss: 6.5253e-04 - val_mae: 0.0180 - val_mse: 5.7215e-04 - lr: 2.9386e-044
81/81 [==============================] - 1s 12ms/step - loss: 6.3109e-04 - mae: 0.0171 - mse: 5.4878e-04 - val_loss: 6.5107e-04 - val_mae: 0.0178 - val_mse: 5.6962e-04 - lr: 2.9386e-04
Epoch 120/200
53/81 [==================>...........] - ETA: 0s - loss: 6.5639e-04 - mae: 0.0175 - mse: 5.7292e-04
81/81 [==============================] - 1s 12ms/step - loss: 6.3109e-04 - mae: 0.0171 - mse: 5.4878e-04 - val_loss: 6.5107e-04 - val_mae: 0.0178 - val_mse: 5.6962e-04 - lr: 2.9386e-04
81/81 [==============================] - 0s 2ms/step - loss: 6.3073e-04 - mae: 0.0171 - mse: 5.4934e-04 - val_loss: 6.5153e-04 - val_mae: 0.0177 - val_mse: 5.6989e-04 - lr: 1.4693e-044
Epoch 123/200
41/81 [==============>...............] - ETA: 0s - loss: 6.4325e-04 - mae: 0.0172 - mse: 5.5935e-04
Epoch 123: ReduceLROnPlateau reducing learning rate to 0.00014692821423523128.
81/81 [==============================] - 0s 2ms/step - loss: 6.3118e-04 - mae: 0.0171 - mse: 5.4785e-04 - val_loss: 6.5208e-04 - val_mae: 0.0177 - val_mse: 5.7009e-04 - lr: 2.9386e-04
Epoch 124/200
81/81 [==============================] - 0s 2ms/step - loss: 6.3073e-04 - mae: 0.0171 - mse: 5.4934e-04 - val_loss: 6.5153e-04 - val_mae: 0.0177 - val_mse: 5.6989e-04 - lr: 1.4693e-044
Epoch 125/200
81/81 [==============================] - 0s 2ms/step - loss: 6.3009e-04 - mae: 0.0171 - mse: 5.4857e-04 - val_loss: 6.5439e-04 - val_mae: 0.0177 - val_mse: 5.7196e-04 - lr: 1.4693e-04
Epoch 126/200
81/81 [==============================] - 0s 2ms/step - loss: 6.3059e-04 - mae: 0.0171 - mse: 5.4844e-04 - val_loss: 6.5295e-04 - val_mae: 0.0177 - val_mse: 5.7075e-04 - lr: 1.4693e-04
Epoch 127/200
53/81 [==================>...........] - ETA: 0s - loss: 6.2193e-04 - mae: 0.0170 - mse: 5.3952e-04
48/81 [================>.............] - ETA: 0s - loss: 6.0330e-04 - mae: 0.0167 - mse: 5.2108e-044e-04 - val_loss: 6.5062e-04 - val_mae: 0.0179 - val_mse: 5.6974e-04 - lr: 1.4693e-04
Epoch 128/200
81/81 [==============================] - 0s 2ms/step - loss: 6.3060e-04 - mae: 0.0171 - mse: 5.4907e-04 - val_loss: 6.5392e-04 - val_mae: 0.0176 - val_mse: 5.7120e-04 - lr: 1.4693e-04
Epoch 129/200
81/81 [==============================] - 0s 1ms/step - loss: 6.3021e-04 - mae: 0.0171 - mse: 5.4817e-04 - val_loss: 6.5209e-04 - val_mae: 0.0177 - val_mse: 5.6977e-04 - lr: 1.4693e-04
Epoch 130/200
81/81 [==============================] - 0s 2ms/step - loss: 6.3023e-04 - mae: 0.0171 - mse: 5.4790e-04 - val_loss: 6.5067e-04 - val_mae: 0.0177 - val_mse: 5.6876e-04 - lr: 1.4693e-04
Epoch 131/200
81/81 [==============================] - 0s 2ms/step - loss: 6.3015e-04 - mae: 0.0171 - mse: 5.4819e-04 - val_loss: 6.5182e-04 - val_mae: 0.0177 - val_mse: 5.6965e-04 - lr: 1.4693e-04
Epoch 132/200
81/81 [==============================] - 0s 2ms/step - loss: 6.2980e-04 - mae: 0.0171 - mse: 5.4806e-04 - val_loss: 6.5134e-04 - val_mae: 0.0177 - val_mse: 5.6943e-04 - lr: 1.4693e-04
Epoch 133/200
48/81 [================>.............] - ETA: 0s - loss: 6.0330e-04 - mae: 0.0167 - mse: 5.2108e-044e-04 - val_loss: 6.5062e-04 - val_mae: 0.0179 - val_mse: 5.6974e-04 - lr: 1.4693e-04
Epoch 133: ReduceLROnPlateau reducing learning rate to 7.346410711761564e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 13ms/step - loss: 6.2974e-04 - mae: 0.0171 - mse: 5.4735e-04 - val_loss: 6.5042e-04 - val_mae: 0.0177 - val_mse: 5.6859e-04 - lr: 1.4693e-04
Epoch 134/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2966e-04 - mae: 0.0171 - mse: 5.4778e-04 - val_loss: 6.5247e-04 - val_mae: 0.0176 - val_mse: 5.6999e-04 - lr: 7.3464e-05
Epoch 135/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2927e-04 - mae: 0.0171 - mse: 5.4731e-04 - val_loss: 6.5158e-04 - val_mae: 0.0177 - val_mse: 5.6934e-04 - lr: 7.3464e-05
Epoch 136/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2941e-04 - mae: 0.0171 - mse: 5.4735e-04 - val_loss: 6.5209e-04 - val_mae: 0.0176 - val_mse: 5.6979e-04 - lr: 7.3464e-05
Epoch 137/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2956e-04 - mae: 0.0171 - mse: 5.4775e-04 - val_loss: 6.5138e-04 - val_mae: 0.0177 - val_mse: 5.6941e-04 - lr: 7.3464e-05
Epoch 138/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2935e-04 - mae: 0.0171 - mse: 5.4715e-04 - val_loss: 6.5148e-04 - val_mae: 0.0177 - val_mse: 5.6947e-04 - lr: 7.3464e-05
Epoch 139/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2905e-04 - mae: 0.0171 - mse: 5.4773e-04 - val_loss: 6.5389e-04 - val_mae: 0.0176 - val_mse: 5.7137e-04 - lr: 7.3464e-05
Epoch 140/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2943e-04 - mae: 0.0171 - mse: 5.4754e-04 - val_loss: 6.5187e-04 - val_mae: 0.0176 - val_mse: 5.6979e-04 - lr: 7.3464e-05
Epoch 141/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2934e-04 - mae: 0.0171 - mse: 5.4772e-04 - val_loss: 6.5522e-04 - val_mae: 0.0176 - val_mse: 5.7228e-04 - lr: 7.3464e-05
Epoch 142/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2971e-04 - mae: 0.0171 - mse: 5.4784e-04 - val_loss: 6.5210e-04 - val_mae: 0.0176 - val_mse: 5.6993e-04 - lr: 7.3464e-05
Epoch 143/200
59/81 [====================>.........] - ETA: 0s - loss: 6.2811e-04 - mae: 0.0171 - mse: 5.4585e-04
Epoch 143: ReduceLROnPlateau reducing learning rate to 3.673205355880782e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 14ms/step - loss: 6.2895e-04 - mae: 0.0170 - mse: 5.4680e-04 - val_loss: 6.4975e-04 - val_mae: 0.0177 - val_mse: 5.6850e-04 - lr: 7.3464e-05
Epoch 144/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2902e-04 - mae: 0.0171 - mse: 5.4741e-04 - val_loss: 6.5067e-04 - val_mae: 0.0177 - val_mse: 5.6894e-04 - lr: 3.6732e-05
Epoch 145/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2893e-04 - mae: 0.0171 - mse: 5.4705e-04 - val_loss: 6.5026e-04 - val_mae: 0.0177 - val_mse: 5.6866e-04 - lr: 3.6732e-05
Epoch 146/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2880e-04 - mae: 0.0171 - mse: 5.4701e-04 - val_loss: 6.5078e-04 - val_mae: 0.0177 - val_mse: 5.6902e-04 - lr: 3.6732e-05
Epoch 147/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2889e-04 - mae: 0.0171 - mse: 5.4702e-04 - val_loss: 6.5018e-04 - val_mae: 0.0177 - val_mse: 5.6876e-04 - lr: 3.6732e-05
Epoch 148/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2901e-04 - mae: 0.0171 - mse: 5.4745e-04 - val_loss: 6.5072e-04 - val_mae: 0.0177 - val_mse: 5.6908e-04 - lr: 3.6732e-05
Epoch 149/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2875e-04 - mae: 0.0171 - mse: 5.4703e-04 - val_loss: 6.5078e-04 - val_mae: 0.0177 - val_mse: 5.6910e-04 - lr: 3.6732e-05
Epoch 150/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2882e-04 - mae: 0.0171 - mse: 5.4715e-04 - val_loss: 6.5093e-04 - val_mae: 0.0177 - val_mse: 5.6928e-04 - lr: 3.6732e-05
Epoch 151/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2875e-04 - mae: 0.0171 - mse: 5.4708e-04 - val_loss: 6.5087e-04 - val_mae: 0.0177 - val_mse: 5.6906e-04 - lr: 3.6732e-05
Epoch 152/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2879e-04 - mae: 0.0171 - mse: 5.4720e-04 - val_loss: 6.5184e-04 - val_mae: 0.0176 - val_mse: 5.6975e-04 - lr: 3.6732e-05
Epoch 153/200
72/81 [=========================>....] - ETA: 0s - loss: 6.3259e-04 - mae: 0.0171 - mse: 5.5058e-04
Epoch 153: ReduceLROnPlateau reducing learning rate to 1.836602677940391e-05.
81/81 [==============================] - 0s 1ms/step - loss: 6.2881e-04 - mae: 0.0171 - mse: 5.4683e-04 - val_loss: 6.5076e-04 - val_mae: 0.0177 - val_mse: 5.6904e-04 - lr: 3.6732e-05
Epoch 154/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2864e-04 - mae: 0.0171 - mse: 5.4691e-04 - val_loss: 6.5076e-04 - val_mae: 0.0177 - val_mse: 5.6905e-04 - lr: 1.8366e-05
Epoch 155/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2877e-04 - mae: 0.0171 - mse: 5.4724e-04 - val_loss: 6.5039e-04 - val_mae: 0.0177 - val_mse: 5.6887e-04 - lr: 1.8366e-05
Epoch 156/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2864e-04 - mae: 0.0171 - mse: 5.4691e-04 - val_loss: 6.5080e-04 - val_mae: 0.0177 - val_mse: 5.6909e-04 - lr: 1.8366e-05
Epoch 157/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2863e-04 - mae: 0.0171 - mse: 5.4686e-04 - val_loss: 6.5054e-04 - val_mae: 0.0177 - val_mse: 5.6892e-04 - lr: 1.8366e-05
Epoch 158/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2864e-04 - mae: 0.0171 - mse: 5.4708e-04 - val_loss: 6.5050e-04 - val_mae: 0.0177 - val_mse: 5.6891e-04 - lr: 1.8366e-05
Epoch 159/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2859e-04 - mae: 0.0171 - mse: 5.4693e-04 - val_loss: 6.5067e-04 - val_mae: 0.0177 - val_mse: 5.6897e-04 - lr: 1.8366e-05
Epoch 160/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2863e-04 - mae: 0.0171 - mse: 5.4700e-04 - val_loss: 6.5066e-04 - val_mae: 0.0177 - val_mse: 5.6898e-04 - lr: 1.8366e-05
Epoch 161/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2867e-04 - mae: 0.0171 - mse: 5.4695e-04 - val_loss: 6.5062e-04 - val_mae: 0.0177 - val_mse: 5.6897e-04 - lr: 1.8366e-05
Epoch 162/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2864e-04 - mae: 0.0171 - mse: 5.4704e-04 - val_loss: 6.5086e-04 - val_mae: 0.0177 - val_mse: 5.6913e-04 - lr: 1.8366e-05
Epoch 163/200
68/81 [========================>.....] - ETA: 0s - loss: 6.2250e-04 - mae: 0.0169 - mse: 5.4076e-04
Epoch 163: ReduceLROnPlateau reducing learning rate to 1e-05.
81/81 [==============================] - 0s 1ms/step - loss: 6.2862e-04 - mae: 0.0171 - mse: 5.4692e-04 - val_loss: 6.5048e-04 - val_mae: 0.0177 - val_mse: 5.6891e-04 - lr: 1.8366e-05
Epoch 164/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2853e-04 - mae: 0.0171 - mse: 5.4686e-04 - val_loss: 6.5067e-04 - val_mae: 0.0177 - val_mse: 5.6900e-04 - lr: 1.0000e-05
Epoch 165/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2854e-04 - mae: 0.0171 - mse: 5.4691e-04 - val_loss: 6.5060e-04 - val_mae: 0.0177 - val_mse: 5.6898e-04 - lr: 1.0000e-05
Epoch 166/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2851e-04 - mae: 0.0171 - mse: 5.4693e-04 - val_loss: 6.5051e-04 - val_mae: 0.0177 - val_mse: 5.6890e-04 - lr: 1.0000e-05
Epoch 167/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2856e-04 - mae: 0.0171 - mse: 5.4688e-04 - val_loss: 6.5069e-04 - val_mae: 0.0177 - val_mse: 5.6903e-04 - lr: 1.0000e-05
Epoch 168/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2853e-04 - mae: 0.0171 - mse: 5.4694e-04 - val_loss: 6.5055e-04 - val_mae: 0.0177 - val_mse: 5.6894e-04 - lr: 1.0000e-05
Epoch 169/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2851e-04 - mae: 0.0171 - mse: 5.4683e-04 - val_loss: 6.5056e-04 - val_mae: 0.0177 - val_mse: 5.6893e-04 - lr: 1.0000e-05
Epoch 170/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2852e-04 - mae: 0.0171 - mse: 5.4697e-04 - val_loss: 6.5047e-04 - val_mae: 0.0177 - val_mse: 5.6890e-04 - lr: 1.0000e-05
Epoch 171/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2857e-04 - mae: 0.0171 - mse: 5.4686e-04 - val_loss: 6.5046e-04 - val_mae: 0.0177 - val_mse: 5.6886e-04 - lr: 1.0000e-05
Epoch 172/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2852e-04 - mae: 0.0171 - mse: 5.4684e-04 - val_loss: 6.5055e-04 - val_mae: 0.0177 - val_mse: 5.6891e-04 - lr: 1.0000e-05
Epoch 173/200
81/81 [==============================] - 0s 2ms/step - loss: 6.2850e-04 - mae: 0.0171 - mse: 5.4684e-04 - val_loss: 6.5047e-04 - val_mae: 0.0177 - val_mse: 5.6884e-04 - lr: 1.0000e-05
Epoch 174/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2849e-04 - mae: 0.0171 - mse: 5.4688e-04 - val_loss: 6.5055e-04 - val_mae: 0.0177 - val_mse: 5.6892e-04 - lr: 1.0000e-05
Epoch 175/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2849e-04 - mae: 0.0171 - mse: 5.4683e-04 - val_loss: 6.5050e-04 - val_mae: 0.0177 - val_mse: 5.6890e-04 - lr: 1.0000e-05
Epoch 176/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2848e-04 - mae: 0.0171 - mse: 5.4684e-04 - val_loss: 6.5041e-04 - val_mae: 0.0177 - val_mse: 5.6884e-04 - lr: 1.0000e-05
Epoch 177/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2846e-04 - mae: 0.0171 - mse: 5.4680e-04 - val_loss: 6.5043e-04 - val_mae: 0.0177 - val_mse: 5.6882e-04 - lr: 1.0000e-05
Epoch 178/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2845e-04 - mae: 0.0171 - mse: 5.4685e-04 - val_loss: 6.5042e-04 - val_mae: 0.0177 - val_mse: 5.6882e-04 - lr: 1.0000e-05
Epoch 179/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2846e-04 - mae: 0.0171 - mse: 5.4681e-04 - val_loss: 6.5056e-04 - val_mae: 0.0177 - val_mse: 5.6891e-04 - lr: 1.0000e-05
Epoch 180/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2845e-04 - mae: 0.0171 - mse: 5.4674e-04 - val_loss: 6.5045e-04 - val_mae: 0.0177 - val_mse: 5.6882e-04 - lr: 1.0000e-05
Epoch 181/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2844e-04 - mae: 0.0171 - mse: 5.4685e-04 - val_loss: 6.5041e-04 - val_mae: 0.0177 - val_mse: 5.6883e-04 - lr: 1.0000e-05
Epoch 182/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2847e-04 - mae: 0.0171 - mse: 5.4683e-04 - val_loss: 6.5028e-04 - val_mae: 0.0177 - val_mse: 5.6873e-04 - lr: 1.0000e-05
Epoch 183/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2846e-04 - mae: 0.0171 - mse: 5.4697e-04 - val_loss: 6.5047e-04 - val_mae: 0.0177 - val_mse: 5.6887e-04 - lr: 1.0000e-05
Epoch 184/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2842e-04 - mae: 0.0171 - mse: 5.4674e-04 - val_loss: 6.5052e-04 - val_mae: 0.0177 - val_mse: 5.6887e-04 - lr: 1.0000e-05
Epoch 185/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2843e-04 - mae: 0.0171 - mse: 5.4679e-04 - val_loss: 6.5044e-04 - val_mae: 0.0177 - val_mse: 5.6882e-04 - lr: 1.0000e-05
Epoch 186/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2841e-04 - mae: 0.0171 - mse: 5.4677e-04 - val_loss: 6.5047e-04 - val_mae: 0.0177 - val_mse: 5.6885e-04 - lr: 1.0000e-05
Epoch 187/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2842e-04 - mae: 0.0171 - mse: 5.4681e-04 - val_loss: 6.5064e-04 - val_mae: 0.0177 - val_mse: 5.6894e-04 - lr: 1.0000e-05
Epoch 188/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2841e-04 - mae: 0.0171 - mse: 5.4675e-04 - val_loss: 6.5048e-04 - val_mae: 0.0177 - val_mse: 5.6885e-04 - lr: 1.0000e-05
Epoch 189/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2843e-04 - mae: 0.0171 - mse: 5.4679e-04 - val_loss: 6.5047e-04 - val_mae: 0.0177 - val_mse: 5.6885e-04 - lr: 1.0000e-05
Epoch 190/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2841e-04 - mae: 0.0171 - mse: 5.4670e-04 - val_loss: 6.5055e-04 - val_mae: 0.0177 - val_mse: 5.6887e-04 - lr: 1.0000e-05
Epoch 191/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2847e-04 - mae: 0.0171 - mse: 5.4684e-04 - val_loss: 6.5045e-04 - val_mae: 0.0177 - val_mse: 5.6882e-04 - lr: 1.0000e-05
Epoch 192/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2840e-04 - mae: 0.0171 - mse: 5.4677e-04 - val_loss: 6.5050e-04 - val_mae: 0.0177 - val_mse: 5.6886e-04 - lr: 1.0000e-05
Epoch 193/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2841e-04 - mae: 0.0171 - mse: 5.4678e-04 - val_loss: 6.5052e-04 - val_mae: 0.0177 - val_mse: 5.6887e-04 - lr: 1.0000e-05
Epoch 194/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2843e-04 - mae: 0.0171 - mse: 5.4687e-04 - val_loss: 6.5044e-04 - val_mae: 0.0177 - val_mse: 5.6881e-04 - lr: 1.0000e-05
Epoch 195/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2837e-04 - mae: 0.0171 - mse: 5.4677e-04 - val_loss: 6.5058e-04 - val_mae: 0.0177 - val_mse: 5.6891e-04 - lr: 1.0000e-05
Epoch 196/200
81/81 [==============================] - 0s 2ms/step - loss: 6.2846e-04 - mae: 0.0171 - mse: 5.4674e-04 - val_loss: 6.5073e-04 - val_mae: 0.0177 - val_mse: 5.6898e-04 - lr: 1.0000e-05
Epoch 197/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2840e-04 - mae: 0.0171 - mse: 5.4685e-04 - val_loss: 6.5029e-04 - val_mae: 0.0177 - val_mse: 5.6875e-04 - lr: 1.0000e-05
Epoch 198/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2839e-04 - mae: 0.0171 - mse: 5.4676e-04 - val_loss: 6.5067e-04 - val_mae: 0.0177 - val_mse: 5.6895e-04 - lr: 1.0000e-05
Epoch 199/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2836e-04 - mae: 0.0171 - mse: 5.4664e-04 - val_loss: 6.5049e-04 - val_mae: 0.0177 - val_mse: 5.6882e-04 - lr: 1.0000e-05
Epoch 200/200
81/81 [==============================] - 0s 1ms/step - loss: 6.2837e-04 - mae: 0.0171 - mse: 5.4677e-04 - val_loss: 6.5027e-04 - val_mae: 0.0177 - val_mse: 5.6870e-04 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_adam_0.07522724722750693LR_[30]HN_48BS_10P_val_mseM_200epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/200
108/108 [==============================] - 1s 3ms/step - loss: 0.0320 - mae: 0.0585 - mse: 0.0056 - val_loss: 0.0042 - val_mae: 0.0516 - val_mse: 0.0037 - lr: 0.0752
Epoch 2/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0509 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0502 - val_mse: 0.0034 - lr: 0.0752
Epoch 3/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0505 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0752
Epoch 4/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0505 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0752
Epoch 5/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0036 - val_mae: 0.0502 - val_mse: 0.0034 - lr: 0.0752
Epoch 6/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0505 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0502 - val_mse: 0.0034 - lr: 0.0752
Epoch 7/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0501 - val_mse: 0.0034 - lr: 0.0752
Epoch 8/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0035 - val_mae: 0.0507 - val_mse: 0.0035 - lr: 0.0752
Epoch 9/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0505 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0502 - val_mse: 0.0034 - lr: 0.0752
Epoch 10/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0504 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0500 - val_mse: 0.0034 - lr: 0.0752
Epoch 11/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0505 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0752
Epoch 12/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0502 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0490 - val_mse: 0.0033 - lr: 0.0752
Epoch 13/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0501 - mse: 0.0033 - val_loss: 0.0034 - val_mae: 0.0472 - val_mse: 0.0031 - lr: 0.0752
Epoch 14/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0461 - mse: 0.0030 - val_loss: 0.0029 - val_mae: 0.0412 - val_mse: 0.0025 - lr: 0.0752
Epoch 15/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0413 - mse: 0.0026 - val_loss: 0.0035 - val_mae: 0.0434 - val_mse: 0.0027 - lr: 0.0752
Epoch 16/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0357 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0315 - val_mse: 0.0017 - lr: 0.0752
Epoch 17/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0359 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0332 - val_mse: 0.0018 - lr: 0.0752
Epoch 18/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0331 - mse: 0.0018 - val_loss: 0.0018 - val_mae: 0.0304 - val_mse: 0.0016 - lr: 0.0752
Epoch 19/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0330 - mse: 0.0017 - val_loss: 0.0021 - val_mae: 0.0343 - val_mse: 0.0019 - lr: 0.0752
Epoch 20/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0325 - mse: 0.0017 - val_loss: 0.0017 - val_mae: 0.0297 - val_mse: 0.0015 - lr: 0.0752
Epoch 21/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0318 - mse: 0.0016 - val_loss: 0.0016 - val_mae: 0.0289 - val_mse: 0.0014 - lr: 0.0752
Epoch 22/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0308 - mse: 0.0015 - val_loss: 0.0016 - val_mae: 0.0288 - val_mse: 0.0014 - lr: 0.0752
Epoch 23/200
108/108 [==============================] - 0s 3ms/step - loss: 0.0019 - mae: 0.0321 - mse: 0.0017 - val_loss: 0.0016 - val_mae: 0.0283 - val_mse: 0.0014 - lr: 0.0752
Epoch 24/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0300 - mse: 0.0015 - val_loss: 0.0015 - val_mae: 0.0277 - val_mse: 0.0013 - lr: 0.0752
Epoch 25/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0017 - mae: 0.0304 - mse: 0.0015 - val_loss: 0.0015 - val_mae: 0.0281 - val_mse: 0.0013 - lr: 0.0752
Epoch 26/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0301 - mse: 0.0015 - val_loss: 0.0028 - val_mae: 0.0420 - val_mse: 0.0025 - lr: 0.0752
Epoch 27/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0318 - mse: 0.0016 - val_loss: 0.0027 - val_mae: 0.0387 - val_mse: 0.0022 - lr: 0.0752
Epoch 28/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0297 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0272 - val_mse: 0.0012 - lr: 0.0752
Epoch 29/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0294 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0278 - val_mse: 0.0013 - lr: 0.0752
Epoch 30/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0294 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0287 - val_mse: 0.0013 - lr: 0.0752
Epoch 31/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0298 - mse: 0.0014 - val_loss: 0.0017 - val_mae: 0.0308 - val_mse: 0.0015 - lr: 0.0752
Epoch 32/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0300 - mse: 0.0015 - val_loss: 0.0015 - val_mae: 0.0267 - val_mse: 0.0012 - lr: 0.0752
Epoch 33/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0292 - mse: 0.0014 - val_loss: 0.0014 - val_mae: 0.0264 - val_mse: 0.0012 - lr: 0.0752
Epoch 34/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0017 - mae: 0.0303 - mse: 0.0015 - val_loss: 0.0022 - val_mae: 0.0313 - val_mse: 0.0016 - lr: 0.0752
Epoch 35/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0285 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0264 - val_mse: 0.0012 - lr: 0.0752
Epoch 36/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0296 - mse: 0.0014 - val_loss: 0.0018 - val_mae: 0.0306 - val_mse: 0.0015 - lr: 0.0752
Epoch 37/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0291 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0275 - val_mse: 0.0012 - lr: 0.0752
Epoch 38/200
 69/108 [==================>...........] - ETA: 0s - loss: 0.0016 - mae: 0.0287 - mse: 0.0013
Epoch 38: ReduceLROnPlateau reducing learning rate to 0.03761362284421921.
108/108 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0289 - mse: 0.0014 - val_loss: 0.0016 - val_mae: 0.0290 - val_mse: 0.0014 - lr: 0.0752
Epoch 39/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0276 - mse: 0.0013 - val_loss: 0.0016 - val_mae: 0.0299 - val_mse: 0.0014 - lr: 0.0376
Epoch 40/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0276 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0261 - val_mse: 0.0012 - lr: 0.0376
Epoch 41/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0278 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0272 - val_mse: 0.0012 - lr: 0.0376
Epoch 42/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0283 - mse: 0.0013 - val_loss: 0.0020 - val_mae: 0.0350 - val_mse: 0.0019 - lr: 0.0376
Epoch 43/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0274 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.0376
Epoch 44/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0280 - mse: 0.0013 - val_loss: 0.0013 - val_mae: 0.0264 - val_mse: 0.0012 - lr: 0.0376
Epoch 45/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0285 - mse: 0.0013 - val_loss: 0.0013 - val_mae: 0.0268 - val_mse: 0.0012 - lr: 0.0376
Epoch 46/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0291 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0277 - val_mse: 0.0013 - lr: 0.0376
Epoch 47/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0278 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0275 - val_mse: 0.0013 - lr: 0.0376
Epoch 48/200
 67/108 [=================>............] - ETA: 0s - loss: 0.0015 - mae: 0.0285 - mse: 0.0013
Epoch 48: ReduceLROnPlateau reducing learning rate to 0.018806811422109604.
108/108 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0278 - mse: 0.0013 - val_loss: 0.0016 - val_mae: 0.0301 - val_mse: 0.0015 - lr: 0.0376
Epoch 49/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0272 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0265 - val_mse: 0.0012 - lr: 0.0188
Epoch 50/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0272 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0263 - val_mse: 0.0012 - lr: 0.0188
Epoch 51/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0272 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0260 - val_mse: 0.0011 - lr: 0.0188
Epoch 52/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0271 - mse: 0.0012 - val_loss: 0.0014 - val_mae: 0.0279 - val_mse: 0.0013 - lr: 0.0188
Epoch 53/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0272 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0266 - val_mse: 0.0012 - lr: 0.0188
Epoch 54/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0270 - mse: 0.0012 - val_loss: 0.0015 - val_mae: 0.0289 - val_mse: 0.0013 - lr: 0.0188
Epoch 55/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0273 - mse: 0.0012 - val_loss: 0.0014 - val_mae: 0.0280 - val_mse: 0.0013 - lr: 0.0188
Epoch 56/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0271 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0261 - val_mse: 0.0011 - lr: 0.0188
Epoch 57/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0277 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0268 - val_mse: 0.0012 - lr: 0.0188
Epoch 58/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0274 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0273 - val_mse: 0.0013 - lr: 0.0188
Epoch 59/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0270 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0188
Epoch 60/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0278 - mse: 0.0012 - val_loss: 0.0015 - val_mae: 0.0272 - val_mse: 0.0012 - lr: 0.0188
Epoch 61/200
 63/108 [================>.............] - ETA: 0s - loss: 0.0014 - mae: 0.0279 - mse: 0.0013
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.009403405711054802.
108/108 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0279 - mse: 0.0013 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0188
Epoch 62/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0265 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0094
Epoch 63/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0266 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0261 - val_mse: 0.0011 - lr: 0.0094
Epoch 64/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0268 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.0094
Epoch 65/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0265 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0260 - val_mse: 0.0011 - lr: 0.0094
Epoch 66/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0267 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0094
Epoch 67/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0273 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0266 - val_mse: 0.0012 - lr: 0.0094
Epoch 68/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0267 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0260 - val_mse: 0.0011 - lr: 0.0094
Epoch 69/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0269 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 0.0094
Epoch 70/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0267 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0262 - val_mse: 0.0012 - lr: 0.0094
Epoch 71/200
 68/108 [=================>............] - ETA: 0s - loss: 0.0013 - mae: 0.0266 - mse: 0.0012
Epoch 71: ReduceLROnPlateau reducing learning rate to 0.004701702855527401.
108/108 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0267 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0265 - val_mse: 0.0012 - lr: 0.0094
Epoch 72/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0260 - val_mse: 0.0011 - lr: 0.0047
Epoch 73/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0265 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0261 - val_mse: 0.0012 - lr: 0.0047
Epoch 74/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0262 - val_mse: 0.0011 - lr: 0.0047
Epoch 75/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0265 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0260 - val_mse: 0.0011 - lr: 0.0047
Epoch 76/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0265 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0047
Epoch 77/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0263 - val_mse: 0.0012 - lr: 0.0047
Epoch 78/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0047
Epoch 79/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0265 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0260 - val_mse: 0.0011 - lr: 0.0047
Epoch 80/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0264 - val_mse: 0.0011 - lr: 0.0047
Epoch 81/200
104/108 [===========================>..] - ETA: 0s - loss: 0.0012 - mae: 0.0264 - mse: 0.0011
Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0023508514277637005.
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0260 - val_mse: 0.0011 - lr: 0.0047
Epoch 82/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0024
Epoch 83/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0024
Epoch 84/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0024
Epoch 85/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0024
Epoch 86/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0024
Epoch 87/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0024
Epoch 88/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0024
Epoch 89/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 0.0024
Epoch 90/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 0.0024
Epoch 91/200
 53/108 [=============>................] - ETA: 0s - loss: 0.0012 - mae: 0.0266 - mse: 0.0012
Epoch 91: ReduceLROnPlateau reducing learning rate to 0.0011754257138818502.
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 0.0024
Epoch 92/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0012
Epoch 93/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.0012
Epoch 94/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0012
Epoch 95/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 0.0012
Epoch 96/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0261 - val_mse: 0.0011 - lr: 0.0012
Epoch 97/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 0.0012
Epoch 98/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0012
Epoch 99/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0012
Epoch 100/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0012
Epoch 101/200
 85/108 [======================>.......] - ETA: 0s - loss: 0.0012 - mae: 0.0261 - mse: 0.0011
Epoch 101: ReduceLROnPlateau reducing learning rate to 0.0005877128569409251.
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 0.0012
Epoch 102/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 5.8771e-04
Epoch 103/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 5.8771e-04
Epoch 104/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 5.8771e-04
Epoch 105/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 5.8771e-04
Epoch 106/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 5.8771e-04
Epoch 107/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 5.8771e-04
Epoch 108/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 5.8771e-04
Epoch 109/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 5.8771e-04
Epoch 110/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 5.8771e-04
Epoch 111/200
108/108 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0261 - mse: 0.0011
Epoch 111: ReduceLROnPlateau reducing learning rate to 0.00029385642847046256.
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 5.8771e-04
Epoch 112/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 2.9386e-04
Epoch 113/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 2.9386e-04
Epoch 114/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 2.9386e-04
Epoch 115/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 2.9386e-04
Epoch 116/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 2.9386e-04
Epoch 117/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 2.9386e-04
Epoch 118/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 2.9386e-04
Epoch 119/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 2.9386e-04
Epoch 120/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 2.9386e-04
Epoch 121/200
 67/108 [=================>............] - ETA: 0s - loss: 0.0012 - mae: 0.0256 - mse: 0.0011
Epoch 121: ReduceLROnPlateau reducing learning rate to 0.00014692821423523128.
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 2.9386e-04
Epoch 122/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.4693e-04
Epoch 123/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.4693e-04
Epoch 124/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.4693e-04
Epoch 125/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.4693e-04
Epoch 126/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.4693e-04
Epoch 127/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.4693e-04
Epoch 128/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.4693e-04
Epoch 129/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.4693e-04
Epoch 130/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.4693e-04
Epoch 131/200
 69/108 [==================>...........] - ETA: 0s - loss: 0.0012 - mae: 0.0260 - mse: 0.0011
Epoch 131: ReduceLROnPlateau reducing learning rate to 7.346410711761564e-05.
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.4693e-04
Epoch 132/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 7.3464e-05
Epoch 133/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 7.3464e-05
Epoch 134/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 7.3464e-05
Epoch 135/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 7.3464e-05
Epoch 136/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 7.3464e-05
Epoch 137/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 7.3464e-05
Epoch 138/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 7.3464e-05
Epoch 139/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 7.3464e-05
Epoch 140/200
 67/108 [=================>............] - ETA: 0s - loss: 0.0012 - mae: 0.0263 - mse: 0.0011
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
Epoch 135/200==========================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 7.3464e-05
Epoch 141/200
 62/108 [================>.............] - ETA: 0s - loss: 0.0012 - mae: 0.0261 - mse: 0.0011
Epoch 141: ReduceLROnPlateau reducing learning rate to 3.673205355880782e-05.
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 7.3464e-05
Epoch 142/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 3.6732e-05
Epoch 143/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 3.6732e-05
Epoch 144/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 3.6732e-05
Epoch 145/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 3.6732e-05
Epoch 146/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 3.6732e-05
Epoch 147/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 3.6732e-05
Epoch 148/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 3.6732e-05
Epoch 149/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 3.6732e-05
Epoch 150/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 3.6732e-05
Epoch 151/200
 90/108 [========================>.....] - ETA: 0s - loss: 0.0012 - mae: 0.0259 - mse: 0.0011
Epoch 151: ReduceLROnPlateau reducing learning rate to 1.836602677940391e-05.
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 3.6732e-05
Epoch 152/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.8366e-05
Epoch 153/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.8366e-05
Epoch 154/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.8366e-05
Epoch 155/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.8366e-05
Epoch 156/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.8366e-05
Epoch 157/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.8366e-05
Epoch 158/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.8366e-05
Epoch 159/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.8366e-05
Epoch 160/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.8366e-05
Epoch 161/200
 88/108 [=======================>......] - ETA: 0s - loss: 0.0012 - mae: 0.0261 - mse: 0.0011
Epoch 161: ReduceLROnPlateau reducing learning rate to 1e-05.
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.8366e-05
Epoch 162/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 163/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 164/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 165/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 166/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 167/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 168/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 169/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 170/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 171/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 172/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 173/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 174/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 175/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 176/200
108/108 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 177/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 178/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 179/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 180/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 181/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 182/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 183/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 184/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 185/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 186/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 187/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 188/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 189/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 190/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 191/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 192/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 193/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 194/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 195/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 196/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 197/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 198/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 199/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 200/200
108/108 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_adam_0.07522724722750693LR_[30]HN_48BS_10P_val_mseM_200epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/200
81/81 [==============================] - 0s 3ms/step - loss: 0.0341 - mae: 0.0415 - mse: 0.0026 - val_loss: 0.0022 - val_mae: 0.0393 - val_mse: 0.0021 - lr: 0.0752
Epoch 2/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0752
Epoch 3/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0382 - val_mse: 0.0019 - lr: 0.0752
Epoch 4/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0752
Epoch 5/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0752
Epoch 6/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0752
Epoch 7/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0752
Epoch 8/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 0.0752
Epoch 9/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0752
Epoch 10/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0752
Epoch 11/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0752
Epoch 12/200
71/81 [=========================>....] - ETA: 0s - loss: 0.0020 - mae: 0.0374 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.03761362284421921.
81/81 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.0027 - val_mae: 0.0390 - val_mse: 0.0022 - lr: 0.0752
Epoch 13/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0363 - mse: 0.0018 - val_loss: 0.0021 - val_mae: 0.0359 - val_mse: 0.0019 - lr: 0.0376
Epoch 14/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0301 - mse: 0.0014 - val_loss: 0.0013 - val_mae: 0.0270 - val_mse: 0.0012 - lr: 0.0376
Epoch 15/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0277 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0270 - val_mse: 0.0012 - lr: 0.0376
Epoch 16/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0017 - val_mae: 0.0321 - val_mse: 0.0015 - lr: 0.0376
Epoch 17/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0014 - val_mae: 0.0293 - val_mse: 0.0013 - lr: 0.0376
Epoch 18/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0252 - mse: 0.0010 - val_loss: 0.0013 - val_mae: 0.0264 - val_mse: 0.0011 - lr: 0.0376
Epoch 19/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0254 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0248 - val_mse: 9.8599e-04 - lr: 0.0376
Epoch 20/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0246 - mse: 9.6985e-04 - val_loss: 0.0011 - val_mae: 0.0249 - val_mse: 9.9263e-04 - lr: 0.0376
Epoch 21/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0251 - mse: 0.0010 - val_loss: 0.0014 - val_mae: 0.0279 - val_mse: 0.0013 - lr: 0.0376
Epoch 22/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0256 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0254 - val_mse: 0.0011 - lr: 0.0376
Epoch 23/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0245 - mse: 9.5639e-04 - val_loss: 0.0011 - val_mae: 0.0253 - val_mse: 9.7874e-04 - lr: 0.0376
Epoch 24/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0245 - mse: 9.5733e-04 - val_loss: 0.0011 - val_mae: 0.0257 - val_mse: 9.7314e-04 - lr: 0.0376
Epoch 25/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0247 - mse: 9.6540e-04 - val_loss: 0.0011 - val_mae: 0.0249 - val_mse: 0.0010 - lr: 0.0376
Epoch 26/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0247 - mse: 9.7176e-04 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0012 - lr: 0.0376
Epoch 27/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0243 - mse: 9.3958e-04 - val_loss: 0.0010 - val_mae: 0.0243 - val_mse: 9.3264e-04 - lr: 0.0376
Epoch 28/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0010 - val_mae: 0.0247 - val_mse: 9.3496e-04 - lr: 0.0376
Epoch 29/200
71/81 [=========================>....] - ETA: 0s - loss: 0.0010 - mae: 0.0243 - mse: 9.4053e-04
Epoch 29: ReduceLROnPlateau reducing learning rate to 0.018806811422109604.
81/81 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0241 - mse: 9.3007e-04 - val_loss: 0.0011 - val_mae: 0.0269 - val_mse: 0.0011 - lr: 0.0376
Epoch 30/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0239 - mse: 9.1291e-04 - val_loss: 0.0011 - val_mae: 0.0242 - val_mse: 9.8607e-04 - lr: 0.0188
Epoch 31/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0243 - mse: 9.3630e-04 - val_loss: 9.9020e-04 - val_mae: 0.0239 - val_mse: 9.0217e-04 - lr: 0.0188
Epoch 32/200
81/81 [==============================] - 0s 1ms/step - loss: 9.8023e-04 - mae: 0.0237 - mse: 8.9271e-04 - val_loss: 0.0010 - val_mae: 0.0246 - val_mse: 9.2940e-04 - lr: 0.0188
Epoch 33/200
81/81 [==============================] - 0s 1ms/step - loss: 9.8150e-04 - mae: 0.0236 - mse: 8.9721e-04 - val_loss: 0.0012 - val_mae: 0.0253 - val_mse: 0.0011 - lr: 0.0188
Epoch 34/200
81/81 [==============================] - 0s 1ms/step - loss: 9.4429e-04 - mae: 0.0231 - mse: 8.6298e-04 - val_loss: 9.7515e-04 - val_mae: 0.0240 - val_mse: 9.0005e-04 - lr: 0.0188
Epoch 35/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0241 - mse: 9.2806e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.5366e-04 - lr: 0.0188
Epoch 36/200
81/81 [==============================] - 0s 1ms/step - loss: 9.8720e-04 - mae: 0.0238 - mse: 9.0437e-04 - val_loss: 9.6647e-04 - val_mae: 0.0238 - val_mse: 8.8861e-04 - lr: 0.0188
Epoch 37/200
81/81 [==============================] - 0s 1ms/step - loss: 9.3702e-04 - mae: 0.0231 - mse: 8.5912e-04 - val_loss: 9.6175e-04 - val_mae: 0.0239 - val_mse: 8.8754e-04 - lr: 0.0188
Epoch 38/200
81/81 [==============================] - 0s 1ms/step - loss: 9.3231e-04 - mae: 0.0230 - mse: 8.5661e-04 - val_loss: 9.6162e-04 - val_mae: 0.0240 - val_mse: 8.9668e-04 - lr: 0.0188
Epoch 39/200
68/81 [========================>.....] - ETA: 0s - loss: 9.5332e-04 - mae: 0.0234 - mse: 8.7909e-04
Epoch 39: ReduceLROnPlateau reducing learning rate to 0.009403405711054802.
81/81 [==============================] - 0s 1ms/step - loss: 9.4829e-04 - mae: 0.0234 - mse: 8.7449e-04 - val_loss: 9.6301e-04 - val_mae: 0.0240 - val_mse: 9.0992e-04 - lr: 0.0188
Epoch 40/200
81/81 [==============================] - 0s 1ms/step - loss: 9.0940e-04 - mae: 0.0228 - mse: 8.4125e-04 - val_loss: 9.6174e-04 - val_mae: 0.0232 - val_mse: 8.8535e-04 - lr: 0.0094
Epoch 41/200
81/81 [==============================] - 0s 1ms/step - loss: 9.1770e-04 - mae: 0.0230 - mse: 8.4784e-04 - val_loss: 9.6433e-04 - val_mae: 0.0243 - val_mse: 8.9864e-04 - lr: 0.0094
Epoch 42/200
81/81 [==============================] - 0s 1ms/step - loss: 8.9903e-04 - mae: 0.0227 - mse: 8.3067e-04 - val_loss: 0.0010 - val_mae: 0.0235 - val_mse: 9.2769e-04 - lr: 0.0094
Epoch 43/200
81/81 [==============================] - 0s 1ms/step - loss: 9.3501e-04 - mae: 0.0231 - mse: 8.6567e-04 - val_loss: 9.4862e-04 - val_mae: 0.0239 - val_mse: 8.8686e-04 - lr: 0.0094
Epoch 44/200
81/81 [==============================] - 0s 1ms/step - loss: 9.1621e-04 - mae: 0.0229 - mse: 8.4816e-04 - val_loss: 0.0011 - val_mae: 0.0262 - val_mse: 0.0010 - lr: 0.0094
Epoch 45/200
81/81 [==============================] - 0s 1ms/step - loss: 9.2164e-04 - mae: 0.0230 - mse: 8.5108e-04 - val_loss: 9.8110e-04 - val_mae: 0.0233 - val_mse: 9.1342e-04 - lr: 0.0094
Epoch 46/200
81/81 [==============================] - 0s 1ms/step - loss: 9.1658e-04 - mae: 0.0230 - mse: 8.4793e-04 - val_loss: 9.3888e-04 - val_mae: 0.0238 - val_mse: 8.8259e-04 - lr: 0.0094
Epoch 47/200
81/81 [==============================] - 0s 1ms/step - loss: 9.2761e-04 - mae: 0.0232 - mse: 8.6120e-04 - val_loss: 9.8954e-04 - val_mae: 0.0233 - val_mse: 9.1128e-04 - lr: 0.0094
Epoch 48/200
81/81 [==============================] - 0s 1ms/step - loss: 9.0569e-04 - mae: 0.0229 - mse: 8.3971e-04 - val_loss: 9.4482e-04 - val_mae: 0.0240 - val_mse: 8.7954e-04 - lr: 0.0094
Epoch 49/200
81/81 [==============================] - 0s 1ms/step - loss: 9.0760e-04 - mae: 0.0229 - mse: 8.4074e-04 - val_loss: 9.2621e-04 - val_mae: 0.0235 - val_mse: 8.6589e-04 - lr: 0.0094
Epoch 50/200
70/81 [========================>.....] - ETA: 0s - loss: 8.9677e-04 - mae: 0.0227 - mse: 8.3213e-04
Epoch 50: ReduceLROnPlateau reducing learning rate to 0.004701702855527401.
81/81 [==============================] - 0s 1ms/step - loss: 8.8450e-04 - mae: 0.0225 - mse: 8.1955e-04 - val_loss: 9.2206e-04 - val_mae: 0.0233 - val_mse: 8.6360e-04 - lr: 0.0094
Epoch 51/200
81/81 [==============================] - 0s 2ms/step - loss: 8.8100e-04 - mae: 0.0225 - mse: 8.1831e-04 - val_loss: 9.4192e-04 - val_mae: 0.0230 - val_mse: 8.7691e-04 - lr: 0.0047
Epoch 52/200
81/81 [==============================] - 0s 2ms/step - loss: 8.7597e-04 - mae: 0.0223 - mse: 8.1318e-04 - val_loss: 9.7426e-04 - val_mae: 0.0247 - val_mse: 9.1113e-04 - lr: 0.0047
Epoch 53/200
81/81 [==============================] - 0s 2ms/step - loss: 8.9299e-04 - mae: 0.0227 - mse: 8.2826e-04 - val_loss: 9.2388e-04 - val_mae: 0.0230 - val_mse: 8.6279e-04 - lr: 0.0047
Epoch 54/200
81/81 [==============================] - 0s 2ms/step - loss: 8.7551e-04 - mae: 0.0224 - mse: 8.1312e-04 - val_loss: 9.1526e-04 - val_mae: 0.0231 - val_mse: 8.5505e-04 - lr: 0.0047
Epoch 55/200
81/81 [==============================] - 0s 2ms/step - loss: 8.7130e-04 - mae: 0.0224 - mse: 8.1120e-04 - val_loss: 9.1815e-04 - val_mae: 0.0230 - val_mse: 8.5478e-04 - lr: 0.0047
Epoch 56/200
81/81 [==============================] - 0s 2ms/step - loss: 8.7606e-04 - mae: 0.0224 - mse: 8.1429e-04 - val_loss: 9.1292e-04 - val_mae: 0.0234 - val_mse: 8.5371e-04 - lr: 0.0047
Epoch 57/200
81/81 [==============================] - 0s 2ms/step - loss: 8.7612e-04 - mae: 0.0224 - mse: 8.1500e-04 - val_loss: 9.1030e-04 - val_mae: 0.0231 - val_mse: 8.4392e-04 - lr: 0.0047
Epoch 58/200
81/81 [==============================] - 0s 2ms/step - loss: 8.7501e-04 - mae: 0.0224 - mse: 8.1353e-04 - val_loss: 9.5060e-04 - val_mae: 0.0243 - val_mse: 8.9575e-04 - lr: 0.0047
Epoch 59/200
81/81 [==============================] - 0s 2ms/step - loss: 8.6494e-04 - mae: 0.0223 - mse: 8.0470e-04 - val_loss: 9.7040e-04 - val_mae: 0.0231 - val_mse: 9.0768e-04 - lr: 0.0047
Epoch 60/200
54/81 [===================>..........] - ETA: 0s - loss: 8.8591e-04 - mae: 0.0226 - mse: 8.2592e-04
Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0023508514277637005.
81/81 [==============================] - 0s 2ms/step - loss: 8.7171e-04 - mae: 0.0223 - mse: 8.1187e-04 - val_loss: 9.1329e-04 - val_mae: 0.0229 - val_mse: 8.5553e-04 - lr: 0.0047
Epoch 61/200
81/81 [==============================] - 0s 2ms/step - loss: 8.6029e-04 - mae: 0.0222 - mse: 8.0146e-04 - val_loss: 9.3558e-04 - val_mae: 0.0228 - val_mse: 8.7321e-04 - lr: 0.0024
Epoch 62/200
81/81 [==============================] - 0s 2ms/step - loss: 8.6134e-04 - mae: 0.0221 - mse: 8.0213e-04 - val_loss: 9.1456e-04 - val_mae: 0.0228 - val_mse: 8.5320e-04 - lr: 0.0024
Epoch 63/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5546e-04 - mae: 0.0221 - mse: 7.9710e-04 - val_loss: 9.0427e-04 - val_mae: 0.0232 - val_mse: 8.4832e-04 - lr: 0.0024
Epoch 64/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5519e-04 - mae: 0.0221 - mse: 7.9821e-04 - val_loss: 9.0213e-04 - val_mae: 0.0229 - val_mse: 8.4007e-04 - lr: 0.0024
Epoch 65/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5363e-04 - mae: 0.0221 - mse: 7.9403e-04 - val_loss: 9.0200e-04 - val_mae: 0.0229 - val_mse: 8.4477e-04 - lr: 0.0024
Epoch 66/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5387e-04 - mae: 0.0221 - mse: 7.9622e-04 - val_loss: 9.0463e-04 - val_mae: 0.0228 - val_mse: 8.4963e-04 - lr: 0.0024
Epoch 67/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5370e-04 - mae: 0.0221 - mse: 7.9603e-04 - val_loss: 9.0723e-04 - val_mae: 0.0234 - val_mse: 8.4901e-04 - lr: 0.0024
Epoch 68/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5044e-04 - mae: 0.0220 - mse: 7.9296e-04 - val_loss: 8.9843e-04 - val_mae: 0.0230 - val_mse: 8.4368e-04 - lr: 0.0024
Epoch 69/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5005e-04 - mae: 0.0221 - mse: 7.9250e-04 - val_loss: 8.9908e-04 - val_mae: 0.0228 - val_mse: 8.4310e-04 - lr: 0.0024
Epoch 70/200
54/81 [===================>..........] - ETA: 0s - loss: 8.8814e-04 - mae: 0.0227 - mse: 8.3252e-04
Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0011754257138818502.
81/81 [==============================] - 0s 2ms/step - loss: 8.5649e-04 - mae: 0.0221 - mse: 7.9944e-04 - val_loss: 9.1168e-04 - val_mae: 0.0227 - val_mse: 8.5352e-04 - lr: 0.0024
Epoch 71/200
81/81 [==============================] - 0s 2ms/step - loss: 8.4835e-04 - mae: 0.0220 - mse: 7.9205e-04 - val_loss: 9.2387e-04 - val_mae: 0.0227 - val_mse: 8.6410e-04 - lr: 0.0012
Epoch 72/200
81/81 [==============================] - 0s 2ms/step - loss: 8.4680e-04 - mae: 0.0220 - mse: 7.8878e-04 - val_loss: 8.9838e-04 - val_mae: 0.0228 - val_mse: 8.4066e-04 - lr: 0.0012
Epoch 73/200
81/81 [==============================] - 0s 2ms/step - loss: 8.4817e-04 - mae: 0.0220 - mse: 7.9154e-04 - val_loss: 9.1465e-04 - val_mae: 0.0227 - val_mse: 8.5715e-04 - lr: 0.0012
Epoch 74/200
81/81 [==============================] - 0s 2ms/step - loss: 8.4688e-04 - mae: 0.0220 - mse: 7.9124e-04 - val_loss: 9.0808e-04 - val_mae: 0.0226 - val_mse: 8.4998e-04 - lr: 0.0012
Epoch 75/200
81/81 [==============================] - 0s 2ms/step - loss: 8.4521e-04 - mae: 0.0219 - mse: 7.8730e-04 - val_loss: 8.9869e-04 - val_mae: 0.0227 - val_mse: 8.4151e-04 - lr: 0.0012
Epoch 76/200
81/81 [==============================] - 0s 2ms/step - loss: 8.4862e-04 - mae: 0.0220 - mse: 7.9311e-04 - val_loss: 9.1445e-04 - val_mae: 0.0226 - val_mse: 8.5529e-04 - lr: 0.0012
Epoch 77/200
81/81 [==============================] - 0s 2ms/step - loss: 8.4380e-04 - mae: 0.0219 - mse: 7.8765e-04 - val_loss: 8.9738e-04 - val_mae: 0.0227 - val_mse: 8.4109e-04 - lr: 0.0012
Epoch 78/200
81/81 [==============================] - 0s 2ms/step - loss: 8.4369e-04 - mae: 0.0220 - mse: 7.8730e-04 - val_loss: 8.9528e-04 - val_mae: 0.0227 - val_mse: 8.3864e-04 - lr: 0.0012
Epoch 79/200
81/81 [==============================] - 0s 2ms/step - loss: 8.4442e-04 - mae: 0.0219 - mse: 7.8984e-04 - val_loss: 8.9618e-04 - val_mae: 0.0227 - val_mse: 8.4047e-04 - lr: 0.0012
Epoch 80/200
54/81 [===================>..........] - ETA: 0s - loss: 8.4716e-04 - mae: 0.0220 - mse: 7.8882e-04
Epoch 80: ReduceLROnPlateau reducing learning rate to 0.0005877128569409251.
81/81 [==============================] - 0s 2ms/step - loss: 8.4296e-04 - mae: 0.0219 - mse: 7.8599e-04 - val_loss: 8.9212e-04 - val_mae: 0.0229 - val_mse: 8.3914e-04 - lr: 0.0012
Epoch 81/200
81/81 [==============================] - 0s 2ms/step - loss: 8.4388e-04 - mae: 0.0220 - mse: 7.8950e-04 - val_loss: 8.9220e-04 - val_mae: 0.0228 - val_mse: 8.3732e-04 - lr: 5.8771e-04
Epoch 82/200
81/81 [==============================] - 0s 2ms/step - loss: 8.4044e-04 - mae: 0.0219 - mse: 7.8491e-04 - val_loss: 8.9666e-04 - val_mae: 0.0227 - val_mse: 8.4114e-04 - lr: 5.8771e-04
Epoch 83/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3982e-04 - mae: 0.0219 - mse: 7.8376e-04 - val_loss: 8.9142e-04 - val_mae: 0.0229 - val_mse: 8.3698e-04 - lr: 5.8771e-04
Epoch 84/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3964e-04 - mae: 0.0219 - mse: 7.8425e-04 - val_loss: 9.0103e-04 - val_mae: 0.0226 - val_mse: 8.4508e-04 - lr: 5.8771e-04
Epoch 85/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3942e-04 - mae: 0.0219 - mse: 7.8495e-04 - val_loss: 8.9744e-04 - val_mae: 0.0226 - val_mse: 8.4172e-04 - lr: 5.8771e-04
Epoch 86/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3956e-04 - mae: 0.0219 - mse: 7.8422e-04 - val_loss: 8.8987e-04 - val_mae: 0.0228 - val_mse: 8.3427e-04 - lr: 5.8771e-04
Epoch 87/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3838e-04 - mae: 0.0218 - mse: 7.8222e-04 - val_loss: 8.9375e-04 - val_mae: 0.0227 - val_mse: 8.3862e-04 - lr: 5.8771e-04
Epoch 88/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3970e-04 - mae: 0.0219 - mse: 7.8485e-04 - val_loss: 9.0079e-04 - val_mae: 0.0226 - val_mse: 8.4391e-04 - lr: 5.8771e-04
Epoch 89/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3713e-04 - mae: 0.0219 - mse: 7.8140e-04 - val_loss: 8.8978e-04 - val_mae: 0.0229 - val_mse: 8.3598e-04 - lr: 5.8771e-04
Epoch 90/200
72/81 [=========================>....] - ETA: 0s - loss: 8.2972e-04 - mae: 0.0217 - mse: 7.7378e-04
Epoch 90: ReduceLROnPlateau reducing learning rate to 0.00029385642847046256.
81/81 [==============================] - 0s 1ms/step - loss: 8.3778e-04 - mae: 0.0218 - mse: 7.8196e-04 - val_loss: 8.8947e-04 - val_mae: 0.0229 - val_mse: 8.3603e-04 - lr: 5.8771e-04
Epoch 91/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3730e-04 - mae: 0.0219 - mse: 7.8260e-04 - val_loss: 8.8913e-04 - val_mae: 0.0228 - val_mse: 8.3454e-04 - lr: 2.9386e-04
Epoch 92/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3550e-04 - mae: 0.0218 - mse: 7.8063e-04 - val_loss: 8.9619e-04 - val_mae: 0.0226 - val_mse: 8.4044e-04 - lr: 2.9386e-04
Epoch 93/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3573e-04 - mae: 0.0218 - mse: 7.8061e-04 - val_loss: 8.8915e-04 - val_mae: 0.0228 - val_mse: 8.3545e-04 - lr: 2.9386e-04
Epoch 94/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3598e-04 - mae: 0.0218 - mse: 7.8132e-04 - val_loss: 8.9719e-04 - val_mae: 0.0226 - val_mse: 8.4176e-04 - lr: 2.9386e-04
Epoch 95/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3520e-04 - mae: 0.0219 - mse: 7.8049e-04 - val_loss: 9.0235e-04 - val_mae: 0.0226 - val_mse: 8.4602e-04 - lr: 2.9386e-04
Epoch 96/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3625e-04 - mae: 0.0218 - mse: 7.8097e-04 - val_loss: 8.9265e-04 - val_mae: 0.0226 - val_mse: 8.3794e-04 - lr: 2.9386e-04
Epoch 97/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3605e-04 - mae: 0.0218 - mse: 7.8128e-04 - val_loss: 8.8980e-04 - val_mae: 0.0227 - val_mse: 8.3574e-04 - lr: 2.9386e-04
Epoch 98/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3562e-04 - mae: 0.0218 - mse: 7.8093e-04 - val_loss: 8.8955e-04 - val_mae: 0.0227 - val_mse: 8.3498e-04 - lr: 2.9386e-04
Epoch 99/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3581e-04 - mae: 0.0218 - mse: 7.8116e-04 - val_loss: 8.9277e-04 - val_mae: 0.0226 - val_mse: 8.3776e-04 - lr: 2.9386e-04
Epoch 100/200
67/81 [=======================>......] - ETA: 0s - loss: 8.3549e-04 - mae: 0.0218 - mse: 7.8019e-04
Epoch 100: ReduceLROnPlateau reducing learning rate to 0.00014692821423523128.
81/81 [==============================] - 0s 1ms/step - loss: 8.3546e-04 - mae: 0.0218 - mse: 7.8022e-04 - val_loss: 8.8859e-04 - val_mae: 0.0227 - val_mse: 8.3420e-04 - lr: 2.9386e-04
Epoch 101/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3457e-04 - mae: 0.0218 - mse: 7.7992e-04 - val_loss: 8.9102e-04 - val_mae: 0.0226 - val_mse: 8.3586e-04 - lr: 1.4693e-04
Epoch 102/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3382e-04 - mae: 0.0218 - mse: 7.7903e-04 - val_loss: 8.8783e-04 - val_mae: 0.0228 - val_mse: 8.3362e-04 - lr: 1.4693e-04
Epoch 103/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3408e-04 - mae: 0.0218 - mse: 7.7925e-04 - val_loss: 8.8764e-04 - val_mae: 0.0228 - val_mse: 8.3411e-04 - lr: 1.4693e-04
Epoch 104/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3362e-04 - mae: 0.0218 - mse: 7.7932e-04 - val_loss: 8.9059e-04 - val_mae: 0.0227 - val_mse: 8.3600e-04 - lr: 1.4693e-04
Epoch 105/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3377e-04 - mae: 0.0218 - mse: 7.7933e-04 - val_loss: 8.9109e-04 - val_mae: 0.0226 - val_mse: 8.3644e-04 - lr: 1.4693e-04
Epoch 106/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3390e-04 - mae: 0.0218 - mse: 7.7915e-04 - val_loss: 8.9621e-04 - val_mae: 0.0226 - val_mse: 8.4053e-04 - lr: 1.4693e-04
Epoch 107/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3431e-04 - mae: 0.0217 - mse: 7.7938e-04 - val_loss: 8.8743e-04 - val_mae: 0.0228 - val_mse: 8.3330e-04 - lr: 1.4693e-04
Epoch 108/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3447e-04 - mae: 0.0218 - mse: 7.8031e-04 - val_loss: 8.9079e-04 - val_mae: 0.0226 - val_mse: 8.3592e-04 - lr: 1.4693e-04
Epoch 109/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3344e-04 - mae: 0.0218 - mse: 7.7895e-04 - val_loss: 8.9015e-04 - val_mae: 0.0226 - val_mse: 8.3537e-04 - lr: 1.4693e-04
Epoch 110/200
71/81 [=========================>....] - ETA: 0s - loss: 8.3644e-04 - mae: 0.0218 - mse: 7.8183e-04
Epoch 110: ReduceLROnPlateau reducing learning rate to 7.346410711761564e-05.
81/81 [==============================] - 0s 1ms/step - loss: 8.3356e-04 - mae: 0.0218 - mse: 7.7892e-04 - val_loss: 8.9144e-04 - val_mae: 0.0226 - val_mse: 8.3652e-04 - lr: 1.4693e-04
Epoch 111/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3336e-04 - mae: 0.0218 - mse: 7.7846e-04 - val_loss: 8.9062e-04 - val_mae: 0.0226 - val_mse: 8.3571e-04 - lr: 7.3464e-05
Epoch 112/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3295e-04 - mae: 0.0218 - mse: 7.7836e-04 - val_loss: 8.8987e-04 - val_mae: 0.0226 - val_mse: 8.3523e-04 - lr: 7.3464e-05
Epoch 113/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3312e-04 - mae: 0.0218 - mse: 7.7843e-04 - val_loss: 8.8728e-04 - val_mae: 0.0227 - val_mse: 8.3319e-04 - lr: 7.3464e-05
Epoch 114/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3303e-04 - mae: 0.0218 - mse: 7.7860e-04 - val_loss: 8.9063e-04 - val_mae: 0.0226 - val_mse: 8.3585e-04 - lr: 7.3464e-05
Epoch 115/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3313e-04 - mae: 0.0218 - mse: 7.7848e-04 - val_loss: 8.8952e-04 - val_mae: 0.0227 - val_mse: 8.3489e-04 - lr: 7.3464e-05
Epoch 116/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3282e-04 - mae: 0.0218 - mse: 7.7806e-04 - val_loss: 8.8759e-04 - val_mae: 0.0227 - val_mse: 8.3343e-04 - lr: 7.3464e-05
Epoch 117/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3244e-04 - mae: 0.0218 - mse: 7.7802e-04 - val_loss: 8.9119e-04 - val_mae: 0.0226 - val_mse: 8.3635e-04 - lr: 7.3464e-05
Epoch 118/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3299e-04 - mae: 0.0218 - mse: 7.7838e-04 - val_loss: 8.8877e-04 - val_mae: 0.0227 - val_mse: 8.3450e-04 - lr: 7.3464e-05
Epoch 119/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3337e-04 - mae: 0.0218 - mse: 7.7887e-04 - val_loss: 8.8795e-04 - val_mae: 0.0227 - val_mse: 8.3375e-04 - lr: 7.3464e-05
Epoch 120/200
63/81 [======================>.......] - ETA: 0s - loss: 8.4274e-04 - mae: 0.0220 - mse: 7.8862e-04
Epoch 120: ReduceLROnPlateau reducing learning rate to 3.673205355880782e-05.
81/81 [==============================] - 0s 1ms/step - loss: 8.3223e-04 - mae: 0.0218 - mse: 7.7799e-04 - val_loss: 8.9307e-04 - val_mae: 0.0226 - val_mse: 8.3805e-04 - lr: 7.3464e-05
Epoch 121/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3286e-04 - mae: 0.0217 - mse: 7.7822e-04 - val_loss: 8.9002e-04 - val_mae: 0.0226 - val_mse: 8.3550e-04 - lr: 3.6732e-05
Epoch 122/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3263e-04 - mae: 0.0218 - mse: 7.7821e-04 - val_loss: 8.8932e-04 - val_mae: 0.0227 - val_mse: 8.3484e-04 - lr: 3.6732e-05
Epoch 123/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3244e-04 - mae: 0.0217 - mse: 7.7784e-04 - val_loss: 8.8846e-04 - val_mae: 0.0227 - val_mse: 8.3412e-04 - lr: 3.6732e-05
Epoch 124/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3243e-04 - mae: 0.0218 - mse: 7.7787e-04 - val_loss: 8.8854e-04 - val_mae: 0.0227 - val_mse: 8.3418e-04 - lr: 3.6732e-05
Epoch 125/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3236e-04 - mae: 0.0218 - mse: 7.7791e-04 - val_loss: 8.8954e-04 - val_mae: 0.0226 - val_mse: 8.3492e-04 - lr: 3.6732e-05
Epoch 126/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3238e-04 - mae: 0.0218 - mse: 7.7813e-04 - val_loss: 8.9007e-04 - val_mae: 0.0226 - val_mse: 8.3540e-04 - lr: 3.6732e-05
Epoch 127/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3233e-04 - mae: 0.0217 - mse: 7.7765e-04 - val_loss: 8.8880e-04 - val_mae: 0.0227 - val_mse: 8.3443e-04 - lr: 3.6732e-05
Epoch 128/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3283e-04 - mae: 0.0218 - mse: 7.7834e-04 - val_loss: 8.8849e-04 - val_mae: 0.0227 - val_mse: 8.3421e-04 - lr: 3.6732e-05
Epoch 129/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3279e-04 - mae: 0.0218 - mse: 7.7843e-04 - val_loss: 8.8789e-04 - val_mae: 0.0227 - val_mse: 8.3368e-04 - lr: 3.6732e-05
Epoch 130/200
71/81 [=========================>....] - ETA: 0s - loss: 8.3635e-04 - mae: 0.0219 - mse: 7.8208e-04
Epoch 130: ReduceLROnPlateau reducing learning rate to 1.836602677940391e-05.
81/81 [==============================] - 0s 1ms/step - loss: 8.3234e-04 - mae: 0.0218 - mse: 7.7808e-04 - val_loss: 8.8866e-04 - val_mae: 0.0227 - val_mse: 8.3429e-04 - lr: 3.6732e-05
Epoch 131/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3210e-04 - mae: 0.0218 - mse: 7.7757e-04 - val_loss: 8.8929e-04 - val_mae: 0.0226 - val_mse: 8.3476e-04 - lr: 1.8366e-05
Epoch 132/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3209e-04 - mae: 0.0218 - mse: 7.7763e-04 - val_loss: 8.8937e-04 - val_mae: 0.0226 - val_mse: 8.3486e-04 - lr: 1.8366e-05
Epoch 133/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3205e-04 - mae: 0.0218 - mse: 7.7760e-04 - val_loss: 8.8912e-04 - val_mae: 0.0226 - val_mse: 8.3463e-04 - lr: 1.8366e-05
Epoch 134/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3206e-04 - mae: 0.0217 - mse: 7.7753e-04 - val_loss: 8.8868e-04 - val_mae: 0.0227 - val_mse: 8.3428e-04 - lr: 1.8366e-05
Epoch 135/200==========================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0256 - val_mse: 0.0011 - lr: 7.3464e-05
81/81 [==============================] - 0s 1ms/step - loss: 8.3210e-04 - mae: 0.0218 - mse: 7.7767e-04 - val_loss: 8.8883e-04 - val_mae: 0.0227 - val_mse: 8.3442e-04 - lr: 1.8366e-05
Epoch 136/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3202e-04 - mae: 0.0218 - mse: 7.7752e-04 - val_loss: 8.8906e-04 - val_mae: 0.0226 - val_mse: 8.3457e-04 - lr: 1.8366e-05
Epoch 137/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3195e-04 - mae: 0.0218 - mse: 7.7758e-04 - val_loss: 8.8876e-04 - val_mae: 0.0227 - val_mse: 8.3437e-04 - lr: 1.8366e-05
Epoch 138/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3219e-04 - mae: 0.0218 - mse: 7.7770e-04 - val_loss: 8.8943e-04 - val_mae: 0.0226 - val_mse: 8.3488e-04 - lr: 1.8366e-05
Epoch 139/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3207e-04 - mae: 0.0218 - mse: 7.7772e-04 - val_loss: 8.8909e-04 - val_mae: 0.0226 - val_mse: 8.3459e-04 - lr: 1.8366e-05
Epoch 140/200
68/81 [========================>.....] - ETA: 0s - loss: 8.3302e-04 - mae: 0.0218 - mse: 7.7860e-04
Epoch 140: ReduceLROnPlateau reducing learning rate to 1e-05.
81/81 [==============================] - 0s 1ms/step - loss: 8.3197e-04 - mae: 0.0218 - mse: 7.7755e-04 - val_loss: 8.8899e-04 - val_mae: 0.0226 - val_mse: 8.3453e-04 - lr: 1.8366e-05
Epoch 141/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3193e-04 - mae: 0.0217 - mse: 7.7743e-04 - val_loss: 8.8908e-04 - val_mae: 0.0226 - val_mse: 8.3460e-04 - lr: 1.0000e-05
Epoch 142/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3199e-04 - mae: 0.0218 - mse: 7.7760e-04 - val_loss: 8.8903e-04 - val_mae: 0.0226 - val_mse: 8.3456e-04 - lr: 1.0000e-05
Epoch 143/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3189e-04 - mae: 0.0217 - mse: 7.7740e-04 - val_loss: 8.8904e-04 - val_mae: 0.0226 - val_mse: 8.3456e-04 - lr: 1.0000e-05
Epoch 144/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3186e-04 - mae: 0.0218 - mse: 7.7742e-04 - val_loss: 8.8888e-04 - val_mae: 0.0227 - val_mse: 8.3445e-04 - lr: 1.0000e-05
Epoch 145/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3193e-04 - mae: 0.0218 - mse: 7.7755e-04 - val_loss: 8.8891e-04 - val_mae: 0.0226 - val_mse: 8.3448e-04 - lr: 1.0000e-05
Epoch 146/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3192e-04 - mae: 0.0218 - mse: 7.7744e-04 - val_loss: 8.8877e-04 - val_mae: 0.0227 - val_mse: 8.3434e-04 - lr: 1.0000e-05
Epoch 147/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3192e-04 - mae: 0.0218 - mse: 7.7747e-04 - val_loss: 8.8909e-04 - val_mae: 0.0226 - val_mse: 8.3462e-04 - lr: 1.0000e-05
Epoch 148/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3191e-04 - mae: 0.0218 - mse: 7.7744e-04 - val_loss: 8.8896e-04 - val_mae: 0.0226 - val_mse: 8.3451e-04 - lr: 1.0000e-05
Epoch 149/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3187e-04 - mae: 0.0218 - mse: 7.7742e-04 - val_loss: 8.8873e-04 - val_mae: 0.0227 - val_mse: 8.3432e-04 - lr: 1.0000e-05
Epoch 150/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3188e-04 - mae: 0.0218 - mse: 7.7750e-04 - val_loss: 8.8873e-04 - val_mae: 0.0227 - val_mse: 8.3432e-04 - lr: 1.0000e-05
Epoch 151/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3186e-04 - mae: 0.0218 - mse: 7.7740e-04 - val_loss: 8.8873e-04 - val_mae: 0.0227 - val_mse: 8.3433e-04 - lr: 1.0000e-05
Epoch 152/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3182e-04 - mae: 0.0218 - mse: 7.7742e-04 - val_loss: 8.8885e-04 - val_mae: 0.0226 - val_mse: 8.3441e-04 - lr: 1.0000e-05
Epoch 153/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3192e-04 - mae: 0.0218 - mse: 7.7754e-04 - val_loss: 8.8863e-04 - val_mae: 0.0227 - val_mse: 8.3423e-04 - lr: 1.0000e-05
Epoch 154/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3187e-04 - mae: 0.0218 - mse: 7.7742e-04 - val_loss: 8.8868e-04 - val_mae: 0.0227 - val_mse: 8.3428e-04 - lr: 1.0000e-05
Epoch 155/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3188e-04 - mae: 0.0218 - mse: 7.7747e-04 - val_loss: 8.8895e-04 - val_mae: 0.0226 - val_mse: 8.3450e-04 - lr: 1.0000e-05
Epoch 156/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3194e-04 - mae: 0.0217 - mse: 7.7740e-04 - val_loss: 8.8888e-04 - val_mae: 0.0226 - val_mse: 8.3445e-04 - lr: 1.0000e-05
Epoch 157/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3192e-04 - mae: 0.0218 - mse: 7.7753e-04 - val_loss: 8.8898e-04 - val_mae: 0.0226 - val_mse: 8.3450e-04 - lr: 1.0000e-05
Epoch 158/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3182e-04 - mae: 0.0218 - mse: 7.7741e-04 - val_loss: 8.8876e-04 - val_mae: 0.0227 - val_mse: 8.3436e-04 - lr: 1.0000e-05
Epoch 159/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3183e-04 - mae: 0.0218 - mse: 7.7736e-04 - val_loss: 8.8872e-04 - val_mae: 0.0227 - val_mse: 8.3432e-04 - lr: 1.0000e-05
Epoch 160/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3181e-04 - mae: 0.0218 - mse: 7.7735e-04 - val_loss: 8.8901e-04 - val_mae: 0.0226 - val_mse: 8.3455e-04 - lr: 1.0000e-05
Epoch 161/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3179e-04 - mae: 0.0218 - mse: 7.7733e-04 - val_loss: 8.8876e-04 - val_mae: 0.0226 - val_mse: 8.3433e-04 - lr: 1.0000e-05
Epoch 162/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3181e-04 - mae: 0.0218 - mse: 7.7739e-04 - val_loss: 8.8864e-04 - val_mae: 0.0227 - val_mse: 8.3426e-04 - lr: 1.0000e-05
Epoch 163/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3180e-04 - mae: 0.0218 - mse: 7.7735e-04 - val_loss: 8.8865e-04 - val_mae: 0.0227 - val_mse: 8.3423e-04 - lr: 1.0000e-05
Epoch 164/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3179e-04 - mae: 0.0218 - mse: 7.7734e-04 - val_loss: 8.8884e-04 - val_mae: 0.0226 - val_mse: 8.3440e-04 - lr: 1.0000e-05
Epoch 165/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3176e-04 - mae: 0.0218 - mse: 7.7734e-04 - val_loss: 8.8855e-04 - val_mae: 0.0227 - val_mse: 8.3418e-04 - lr: 1.0000e-05
Epoch 166/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3188e-04 - mae: 0.0218 - mse: 7.7750e-04 - val_loss: 8.8854e-04 - val_mae: 0.0227 - val_mse: 8.3416e-04 - lr: 1.0000e-05
Epoch 167/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3179e-04 - mae: 0.0218 - mse: 7.7739e-04 - val_loss: 8.8868e-04 - val_mae: 0.0227 - val_mse: 8.3427e-04 - lr: 1.0000e-05
Epoch 168/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3184e-04 - mae: 0.0217 - mse: 7.7740e-04 - val_loss: 8.8892e-04 - val_mae: 0.0226 - val_mse: 8.3449e-04 - lr: 1.0000e-05
Epoch 169/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3177e-04 - mae: 0.0218 - mse: 7.7742e-04 - val_loss: 8.8856e-04 - val_mae: 0.0227 - val_mse: 8.3417e-04 - lr: 1.0000e-05
Epoch 170/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3175e-04 - mae: 0.0218 - mse: 7.7733e-04 - val_loss: 8.8870e-04 - val_mae: 0.0226 - val_mse: 8.3429e-04 - lr: 1.0000e-05
Epoch 171/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3176e-04 - mae: 0.0218 - mse: 7.7733e-04 - val_loss: 8.8898e-04 - val_mae: 0.0226 - val_mse: 8.3452e-04 - lr: 1.0000e-05
Epoch 172/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3179e-04 - mae: 0.0218 - mse: 7.7737e-04 - val_loss: 8.8847e-04 - val_mae: 0.0227 - val_mse: 8.3412e-04 - lr: 1.0000e-05
Epoch 173/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3178e-04 - mae: 0.0218 - mse: 7.7734e-04 - val_loss: 8.8881e-04 - val_mae: 0.0226 - val_mse: 8.3438e-04 - lr: 1.0000e-05
Epoch 174/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3176e-04 - mae: 0.0218 - mse: 7.7741e-04 - val_loss: 8.8858e-04 - val_mae: 0.0227 - val_mse: 8.3419e-04 - lr: 1.0000e-05
Epoch 175/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3174e-04 - mae: 0.0217 - mse: 7.7725e-04 - val_loss: 8.8885e-04 - val_mae: 0.0226 - val_mse: 8.3439e-04 - lr: 1.0000e-05
Epoch 176/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3177e-04 - mae: 0.0218 - mse: 7.7738e-04 - val_loss: 8.8845e-04 - val_mae: 0.0227 - val_mse: 8.3408e-04 - lr: 1.0000e-05
Epoch 177/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3170e-04 - mae: 0.0218 - mse: 7.7726e-04 - val_loss: 8.8870e-04 - val_mae: 0.0226 - val_mse: 8.3427e-04 - lr: 1.0000e-05
Epoch 178/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3174e-04 - mae: 0.0218 - mse: 7.7737e-04 - val_loss: 8.8866e-04 - val_mae: 0.0226 - val_mse: 8.3426e-04 - lr: 1.0000e-05
Epoch 179/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3173e-04 - mae: 0.0217 - mse: 7.7726e-04 - val_loss: 8.8897e-04 - val_mae: 0.0226 - val_mse: 8.3450e-04 - lr: 1.0000e-05
Epoch 180/200
81/81 [==============================] - 0s 1ms/step - loss: 8.3169e-04 - mae: 0.0218 - mse: 7.7729e-04 - val_loss: 8.8865e-04 - val_mae: 0.0226 - val_mse: 8.3425e-04 - lr: 1.0000e-05
Epoch 181/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3168e-04 - mae: 0.0218 - mse: 7.7730e-04 - val_loss: 8.8865e-04 - val_mae: 0.0226 - val_mse: 8.3425e-04 - lr: 1.0000e-05
Epoch 182/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3168e-04 - mae: 0.0218 - mse: 7.7725e-04 - val_loss: 8.8859e-04 - val_mae: 0.0226 - val_mse: 8.3419e-04 - lr: 1.0000e-05
Epoch 183/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3171e-04 - mae: 0.0218 - mse: 7.7733e-04 - val_loss: 8.8855e-04 - val_mae: 0.0227 - val_mse: 8.3417e-04 - lr: 1.0000e-05
Epoch 184/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3167e-04 - mae: 0.0218 - mse: 7.7723e-04 - val_loss: 8.8890e-04 - val_mae: 0.0226 - val_mse: 8.3445e-04 - lr: 1.0000e-05
Epoch 185/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3171e-04 - mae: 0.0218 - mse: 7.7729e-04 - val_loss: 8.8856e-04 - val_mae: 0.0226 - val_mse: 8.3418e-04 - lr: 1.0000e-05
Epoch 186/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3168e-04 - mae: 0.0218 - mse: 7.7731e-04 - val_loss: 8.8867e-04 - val_mae: 0.0226 - val_mse: 8.3427e-04 - lr: 1.0000e-05
Epoch 187/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3165e-04 - mae: 0.0218 - mse: 7.7724e-04 - val_loss: 8.8873e-04 - val_mae: 0.0226 - val_mse: 8.3430e-04 - lr: 1.0000e-05
Epoch 188/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3166e-04 - mae: 0.0217 - mse: 7.7721e-04 - val_loss: 8.8871e-04 - val_mae: 0.0226 - val_mse: 8.3428e-04 - lr: 1.0000e-05
Epoch 189/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3165e-04 - mae: 0.0218 - mse: 7.7723e-04 - val_loss: 8.8875e-04 - val_mae: 0.0226 - val_mse: 8.3431e-04 - lr: 1.0000e-05
Epoch 190/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3165e-04 - mae: 0.0217 - mse: 7.7717e-04 - val_loss: 8.8861e-04 - val_mae: 0.0226 - val_mse: 8.3421e-04 - lr: 1.0000e-05
Epoch 191/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3169e-04 - mae: 0.0218 - mse: 7.7736e-04 - val_loss: 8.8848e-04 - val_mae: 0.0227 - val_mse: 8.3412e-04 - lr: 1.0000e-05
Epoch 192/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3170e-04 - mae: 0.0217 - mse: 7.7722e-04 - val_loss: 8.8875e-04 - val_mae: 0.0226 - val_mse: 8.3431e-04 - lr: 1.0000e-05
Epoch 193/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3170e-04 - mae: 0.0218 - mse: 7.7726e-04 - val_loss: 8.8839e-04 - val_mae: 0.0227 - val_mse: 8.3402e-04 - lr: 1.0000e-05
Epoch 194/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3163e-04 - mae: 0.0218 - mse: 7.7726e-04 - val_loss: 8.8840e-04 - val_mae: 0.0227 - val_mse: 8.3405e-04 - lr: 1.0000e-05
Epoch 195/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3166e-04 - mae: 0.0218 - mse: 7.7725e-04 - val_loss: 8.8837e-04 - val_mae: 0.0227 - val_mse: 8.3400e-04 - lr: 1.0000e-05
Epoch 196/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3164e-04 - mae: 0.0218 - mse: 7.7725e-04 - val_loss: 8.8854e-04 - val_mae: 0.0226 - val_mse: 8.3415e-04 - lr: 1.0000e-05
Epoch 197/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3164e-04 - mae: 0.0217 - mse: 7.7716e-04 - val_loss: 8.8858e-04 - val_mae: 0.0226 - val_mse: 8.3419e-04 - lr: 1.0000e-05
Epoch 198/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3170e-04 - mae: 0.0218 - mse: 7.7733e-04 - val_loss: 8.8859e-04 - val_mae: 0.0226 - val_mse: 8.3418e-04 - lr: 1.0000e-05
Epoch 199/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3174e-04 - mae: 0.0218 - mse: 7.7743e-04 - val_loss: 8.8856e-04 - val_mae: 0.0226 - val_mse: 8.3416e-04 - lr: 1.0000e-05
Epoch 200/200
81/81 [==============================] - 0s 2ms/step - loss: 8.3162e-04 - mae: 0.0217 - mse: 7.7716e-04 - val_loss: 8.8845e-04 - val_mae: 0.0226 - val_mse: 8.3407e-04 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_adam_0.07522724722750693LR_[30]HN_48BS_10P_val_mseM_200epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/200
81/81 [==============================] - 1s 3ms/step - loss: 0.0372 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0752
Epoch 2/200
81/81 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0752
Epoch 3/200
81/81 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0752
Epoch 4/200
81/81 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0752
Epoch 5/200
81/81 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0752
Epoch 6/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0752
Epoch 7/200
81/81 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0752
Epoch 8/200
81/81 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0025 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0752
Epoch 9/200
81/81 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0402 - mse: 0.0023 - val_loss: 0.0023 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 0.0752
Epoch 10/200
81/81 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0373 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 0.0752
Epoch 11/200
54/81 [===================>..........] - ETA: 0s - loss: 0.0020 - mae: 0.0346 - mse: 0.0017
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.03761362284421921.
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0330 - mse: 0.0016 - val_loss: 0.0024 - val_mae: 0.0365 - val_mse: 0.0020 - lr: 0.0752
Epoch 12/200
81/81 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0275 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0252 - val_mse: 0.0010 - lr: 0.0376
Epoch 13/200
81/81 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0237 - mse: 9.1017e-04 - val_loss: 0.0011 - val_mae: 0.0226 - val_mse: 8.3457e-04 - lr: 0.0376
Epoch 14/200
81/81 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0245 - mse: 9.6731e-04 - val_loss: 0.0010 - val_mae: 0.0219 - val_mse: 7.9373e-04 - lr: 0.0376
Epoch 15/200
81/81 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0234 - mse: 8.8151e-04 - val_loss: 0.0011 - val_mae: 0.0230 - val_mse: 8.3921e-04 - lr: 0.0376
Epoch 16/200
81/81 [==============================] - 0s 2ms/step - loss: 9.9977e-04 - mae: 0.0223 - mse: 8.0868e-04 - val_loss: 9.1599e-04 - val_mae: 0.0213 - val_mse: 7.4535e-04 - lr: 0.0376
Epoch 17/200
81/81 [==============================] - 0s 2ms/step - loss: 9.6056e-04 - mae: 0.0219 - mse: 7.9398e-04 - val_loss: 0.0011 - val_mae: 0.0246 - val_mse: 9.4711e-04 - lr: 0.0376
Epoch 18/200
81/81 [==============================] - 0s 2ms/step - loss: 9.6872e-04 - mae: 0.0221 - mse: 7.9860e-04 - val_loss: 0.0013 - val_mae: 0.0272 - val_mse: 0.0012 - lr: 0.0376
Epoch 19/200
81/81 [==============================] - 0s 1ms/step - loss: 9.0995e-04 - mae: 0.0216 - mse: 7.5476e-04 - val_loss: 9.7764e-04 - val_mae: 0.0226 - val_mse: 8.1528e-04 - lr: 0.0376
Epoch 20/200
81/81 [==============================] - 0s 1ms/step - loss: 9.0716e-04 - mae: 0.0215 - mse: 7.5678e-04 - val_loss: 8.3270e-04 - val_mae: 0.0200 - val_mse: 6.4711e-04 - lr: 0.0376
Epoch 21/200
81/81 [==============================] - 0s 1ms/step - loss: 9.1977e-04 - mae: 0.0219 - mse: 7.6625e-04 - val_loss: 8.0880e-04 - val_mae: 0.0206 - val_mse: 6.9622e-04 - lr: 0.0376
Epoch 22/200
81/81 [==============================] - 0s 1ms/step - loss: 8.7369e-04 - mae: 0.0214 - mse: 7.3516e-04 - val_loss: 0.0010 - val_mae: 0.0240 - val_mse: 8.9145e-04 - lr: 0.0376
Epoch 23/200
81/81 [==============================] - 0s 1ms/step - loss: 8.8764e-04 - mae: 0.0215 - mse: 7.4607e-04 - val_loss: 8.7279e-04 - val_mae: 0.0216 - val_mse: 7.5015e-04 - lr: 0.0376
Epoch 24/200
81/81 [==============================] - 0s 1ms/step - loss: 8.5677e-04 - mae: 0.0213 - mse: 7.2766e-04 - val_loss: 8.7433e-04 - val_mae: 0.0214 - val_mse: 7.1353e-04 - lr: 0.0376
Epoch 25/200
81/81 [==============================] - 0s 1ms/step - loss: 8.4348e-04 - mae: 0.0211 - mse: 7.0857e-04 - val_loss: 8.9659e-04 - val_mae: 0.0223 - val_mse: 7.9752e-04 - lr: 0.0376
Epoch 26/200
81/81 [==============================] - 0s 1ms/step - loss: 9.0562e-04 - mae: 0.0218 - mse: 7.6768e-04 - val_loss: 8.0241e-04 - val_mae: 0.0208 - val_mse: 6.9515e-04 - lr: 0.0376
Epoch 27/200
81/81 [==============================] - 0s 1ms/step - loss: 8.2712e-04 - mae: 0.0208 - mse: 6.9398e-04 - val_loss: 9.9328e-04 - val_mae: 0.0236 - val_mse: 8.6158e-04 - lr: 0.0376
Epoch 28/200
81/81 [==============================] - 0s 1ms/step - loss: 8.1998e-04 - mae: 0.0208 - mse: 6.9067e-04 - val_loss: 7.5058e-04 - val_mae: 0.0197 - val_mse: 6.2298e-04 - lr: 0.0376
Epoch 29/200
81/81 [==============================] - 0s 1ms/step - loss: 7.6536e-04 - mae: 0.0201 - mse: 6.4816e-04 - val_loss: 7.1957e-04 - val_mae: 0.0195 - val_mse: 6.1290e-04 - lr: 0.0376
Epoch 30/200
70/81 [========================>.....] - ETA: 0s - loss: 7.7877e-04 - mae: 0.0203 - mse: 6.6682e-04
Epoch 30: ReduceLROnPlateau reducing learning rate to 0.018806811422109604.
81/81 [==============================] - 0s 1ms/step - loss: 8.0682e-04 - mae: 0.0207 - mse: 6.9171e-04 - val_loss: 9.4745e-04 - val_mae: 0.0232 - val_mse: 8.2754e-04 - lr: 0.0376
Epoch 31/200
81/81 [==============================] - 0s 1ms/step - loss: 7.4444e-04 - mae: 0.0198 - mse: 6.3395e-04 - val_loss: 7.0997e-04 - val_mae: 0.0194 - val_mse: 6.0034e-04 - lr: 0.0188
Epoch 32/200
81/81 [==============================] - 0s 2ms/step - loss: 7.6089e-04 - mae: 0.0202 - mse: 6.5087e-04 - val_loss: 7.0988e-04 - val_mae: 0.0193 - val_mse: 5.9150e-04 - lr: 0.0188
Epoch 33/200
81/81 [==============================] - 0s 2ms/step - loss: 7.3537e-04 - mae: 0.0199 - mse: 6.3312e-04 - val_loss: 7.0454e-04 - val_mae: 0.0195 - val_mse: 6.0718e-04 - lr: 0.0188
Epoch 34/200
81/81 [==============================] - 0s 1ms/step - loss: 7.4130e-04 - mae: 0.0199 - mse: 6.3488e-04 - val_loss: 7.4246e-04 - val_mae: 0.0204 - val_mse: 6.5812e-04 - lr: 0.0188
Epoch 35/200
81/81 [==============================] - 0s 1ms/step - loss: 7.2255e-04 - mae: 0.0197 - mse: 6.1948e-04 - val_loss: 7.0492e-04 - val_mae: 0.0195 - val_mse: 6.0185e-04 - lr: 0.0188
Epoch 36/200
81/81 [==============================] - 0s 1ms/step - loss: 7.3012e-04 - mae: 0.0198 - mse: 6.2662e-04 - val_loss: 7.1404e-04 - val_mae: 0.0196 - val_mse: 6.0414e-04 - lr: 0.0188
Epoch 37/200
81/81 [==============================] - 0s 1ms/step - loss: 6.9930e-04 - mae: 0.0193 - mse: 6.0032e-04 - val_loss: 7.0023e-04 - val_mae: 0.0194 - val_mse: 5.8740e-04 - lr: 0.0188
Epoch 38/200
81/81 [==============================] - 0s 1ms/step - loss: 6.8567e-04 - mae: 0.0192 - mse: 5.8779e-04 - val_loss: 7.1182e-04 - val_mae: 0.0197 - val_mse: 6.1206e-04 - lr: 0.0188
Epoch 39/200
81/81 [==============================] - 0s 1ms/step - loss: 7.5451e-04 - mae: 0.0204 - mse: 6.5473e-04 - val_loss: 6.8881e-04 - val_mae: 0.0191 - val_mse: 5.7342e-04 - lr: 0.0188
Epoch 40/200
67/81 [=======================>......] - ETA: 0s - loss: 7.6698e-04 - mae: 0.0206 - mse: 6.6179e-04
Epoch 40: ReduceLROnPlateau reducing learning rate to 0.009403405711054802.
81/81 [==============================] - 0s 1ms/step - loss: 7.7041e-04 - mae: 0.0207 - mse: 6.6590e-04 - val_loss: 6.9907e-04 - val_mae: 0.0196 - val_mse: 6.0049e-04 - lr: 0.0188
Epoch 41/200
81/81 [==============================] - 0s 2ms/step - loss: 6.8153e-04 - mae: 0.0191 - mse: 5.7750e-04 - val_loss: 6.7602e-04 - val_mae: 0.0191 - val_mse: 5.7451e-04 - lr: 0.0094
Epoch 42/200
81/81 [==============================] - 0s 1ms/step - loss: 7.0116e-04 - mae: 0.0195 - mse: 6.0744e-04 - val_loss: 6.7308e-04 - val_mae: 0.0192 - val_mse: 5.8049e-04 - lr: 0.0094
Epoch 43/200
81/81 [==============================] - 0s 1ms/step - loss: 6.7768e-04 - mae: 0.0192 - mse: 5.8623e-04 - val_loss: 6.9355e-04 - val_mae: 0.0194 - val_mse: 5.8129e-04 - lr: 0.0094
Epoch 44/200
81/81 [==============================] - 0s 2ms/step - loss: 6.8142e-04 - mae: 0.0193 - mse: 5.8656e-04 - val_loss: 7.0123e-04 - val_mae: 0.0199 - val_mse: 6.1152e-04 - lr: 0.0094
Epoch 45/200
81/81 [==============================] - 0s 1ms/step - loss: 6.9511e-04 - mae: 0.0194 - mse: 6.0093e-04 - val_loss: 7.1453e-04 - val_mae: 0.0200 - val_mse: 6.2905e-04 - lr: 0.0094
Epoch 46/200
81/81 [==============================] - 0s 1ms/step - loss: 6.8129e-04 - mae: 0.0192 - mse: 5.8894e-04 - val_loss: 6.8111e-04 - val_mae: 0.0196 - val_mse: 5.9404e-04 - lr: 0.0094
Epoch 47/200
81/81 [==============================] - 0s 2ms/step - loss: 6.6244e-04 - mae: 0.0189 - mse: 5.6914e-04 - val_loss: 6.6549e-04 - val_mae: 0.0193 - val_mse: 5.8505e-04 - lr: 0.0094
Epoch 48/200
81/81 [==============================] - 0s 1ms/step - loss: 6.7130e-04 - mae: 0.0192 - mse: 5.8267e-04 - val_loss: 6.6649e-04 - val_mae: 0.0190 - val_mse: 5.6636e-04 - lr: 0.0094
Epoch 49/200
81/81 [==============================] - 0s 1ms/step - loss: 6.7743e-04 - mae: 0.0193 - mse: 5.8573e-04 - val_loss: 6.7897e-04 - val_mae: 0.0195 - val_mse: 5.8950e-04 - lr: 0.0094
Epoch 50/200
72/81 [=========================>....] - ETA: 0s - loss: 6.5229e-04 - mae: 0.0189 - mse: 5.6360e-04
Epoch 50: ReduceLROnPlateau reducing learning rate to 0.004701702855527401.
81/81 [==============================] - 0s 1ms/step - loss: 6.6252e-04 - mae: 0.0191 - mse: 5.7348e-04 - val_loss: 7.5051e-04 - val_mae: 0.0203 - val_mse: 6.4558e-04 - lr: 0.0094
Epoch 51/200
81/81 [==============================] - 0s 1ms/step - loss: 6.6295e-04 - mae: 0.0190 - mse: 5.7382e-04 - val_loss: 6.5977e-04 - val_mae: 0.0191 - val_mse: 5.6753e-04 - lr: 0.0047
Epoch 52/200
81/81 [==============================] - 0s 1ms/step - loss: 6.5529e-04 - mae: 0.0190 - mse: 5.6762e-04 - val_loss: 7.1400e-04 - val_mae: 0.0203 - val_mse: 6.2765e-04 - lr: 0.0047
Epoch 53/200
81/81 [==============================] - 0s 1ms/step - loss: 6.5867e-04 - mae: 0.0191 - mse: 5.6898e-04 - val_loss: 6.5824e-04 - val_mae: 0.0191 - val_mse: 5.7197e-04 - lr: 0.0047
Epoch 54/200
81/81 [==============================] - 0s 2ms/step - loss: 6.5579e-04 - mae: 0.0190 - mse: 5.7005e-04 - val_loss: 6.5382e-04 - val_mae: 0.0190 - val_mse: 5.5997e-04 - lr: 0.0047
Epoch 55/200
81/81 [==============================] - 0s 2ms/step - loss: 6.5283e-04 - mae: 0.0189 - mse: 5.6548e-04 - val_loss: 6.6284e-04 - val_mae: 0.0194 - val_mse: 5.8133e-04 - lr: 0.0047
Epoch 56/200
81/81 [==============================] - 0s 2ms/step - loss: 6.5670e-04 - mae: 0.0189 - mse: 5.7092e-04 - val_loss: 6.7651e-04 - val_mae: 0.0196 - val_mse: 5.9555e-04 - lr: 0.0047
Epoch 57/200
79/81 [============================>.] - ETA: 0s - loss: 6.4706e-04 - mae: 0.0189 - mse: 5.6003e-04
81/81 [==============================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 58/200
81/81 [==============================] - 0s 2ms/step - loss: 6.6970e-04 - mae: 0.0193 - mse: 5.8499e-04 - val_loss: 7.0822e-04 - val_mae: 0.0201 - val_mse: 6.1420e-04 - lr: 0.0047
Epoch 59/200
81/81 [==============================] - 0s 2ms/step - loss: 6.4234e-04 - mae: 0.0188 - mse: 5.5591e-04 - val_loss: 6.5645e-04 - val_mae: 0.0192 - val_mse: 5.6883e-04 - lr: 0.0047
Epoch 60/200
50/81 [=================>............] - ETA: 0s - loss: 6.5497e-04 - mae: 0.0188 - mse: 5.6733e-04
Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0023508514277637005.
81/81 [==============================] - 0s 2ms/step - loss: 6.4813e-04 - mae: 0.0189 - mse: 5.6236e-04 - val_loss: 7.0114e-04 - val_mae: 0.0201 - val_mse: 6.1743e-04 - lr: 0.0047
Epoch 61/200
54/81 [===================>..........] - ETA: 0s - loss: 6.4302e-04 - mae: 0.0187 - mse: 5.5817e-04
81/81 [==============================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
81/81 [==============================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
81/81 [==============================] - 0s 1ms/step - loss: 6.1379e-04 - mae: 0.0185 - mse: 5.3787e-04 - val_loss: 6.3188e-04 - val_mae: 0.0190 - val_mse: 5.5596e-04 - lr: 1.0000e-05
Epoch 143/200
81/81 [==============================] - 0s 1ms/step - loss: 6.1371e-04 - mae: 0.0185 - mse: 5.3780e-04 - val_loss: 6.3211e-04 - val_mae: 0.0190 - val_mse: 5.5617e-04 - lr: 1.0000e-05
Epoch 144/200
81/81 [==============================] - 0s 1ms/step - loss: 6.1373e-04 - mae: 0.0185 - mse: 5.3784e-04 - val_loss: 6.3206e-04 - val_mae: 0.0190 - val_mse: 5.5617e-04 - lr: 1.0000e-05
Epoch 145/200
81/81 [==============================] - 0s 1ms/step - loss: 6.1370e-04 - mae: 0.0185 - mse: 5.3781e-04 - val_loss: 6.3195e-04 - val_mae: 0.0190 - val_mse: 5.5606e-04 - lr: 1.0000e-05
Epoch 146/200
81/81 [==============================] - 0s 1ms/step - loss: 6.1374e-04 - mae: 0.0185 - mse: 5.3780e-04 - val_loss: 6.3198e-04 - val_mae: 0.0190 - val_mse: 5.5607e-04 - lr: 1.0000e-05
Epoch 147/200
81/81 [==============================] - 0s 1ms/step - loss: 6.1377e-04 - mae: 0.0184 - mse: 5.3789e-04 - val_loss: 6.3186e-04 - val_mae: 0.0190 - val_mse: 5.5596e-04 - lr: 1.0000e-05
Epoch 148/200
81/81 [==============================] - 0s 1ms/step - loss: 6.1376e-04 - mae: 0.0185 - mse: 5.3785e-04 - val_loss: 6.3229e-04 - val_mae: 0.0190 - val_mse: 5.5640e-04 - lr: 1.0000e-05
Epoch 149/200
81/81 [==============================] - 0s 1ms/step - loss: 6.1373e-04 - mae: 0.0185 - mse: 5.3781e-04 - val_loss: 6.3183e-04 - val_mae: 0.0190 - val_mse: 5.5593e-04 - lr: 1.0000e-05
Epoch 150/200
81/81 [==============================] - 0s 1ms/step - loss: 6.1379e-04 - mae: 0.0184 - mse: 5.3792e-04 - val_loss: 6.3197e-04 - val_mae: 0.0190 - val_mse: 5.5607e-04 - lr: 1.0000e-05
Epoch 151/200
81/81 [==============================] - 0s 1ms/step - loss: 6.1379e-04 - mae: 0.0185 - mse: 5.3789e-04 - val_loss: 6.3247e-04 - val_mae: 0.0190 - val_mse: 5.5658e-04 - lr: 1.0000e-05
Epoch 152/200
81/81 [==============================] - 0s 1ms/step - loss: 6.1384e-04 - mae: 0.0185 - mse: 5.3799e-04 - val_loss: 6.3216e-04 - val_mae: 0.0190 - val_mse: 5.5626e-04 - lr: 1.0000e-05
Epoch 153/200
81/81 [==============================] - 0s 1ms/step - loss: 6.1374e-04 - mae: 0.0185 - mse: 5.3781e-04 - val_loss: 6.3209e-04 - val_mae: 0.0190 - val_mse: 5.5619e-04 - lr: 1.0000e-05
Epoch 154/200
81/81 [==============================] - 0s 1ms/step - loss: 6.1366e-04 - mae: 0.0185 - mse: 5.3779e-04 - val_loss: 6.3199e-04 - val_mae: 0.0190 - val_mse: 5.5612e-04 - lr: 1.0000e-05
Epoch 155/200
81/81 [==============================] - 0s 1ms/step - loss: 6.1370e-04 - mae: 0.0185 - mse: 5.3782e-04 - val_loss: 6.3187e-04 - val_mae: 0.0190 - val_mse: 5.5600e-04 - lr: 1.0000e-05
Epoch 156/200
81/81 [==============================] - 0s 1ms/step - loss: 6.1371e-04 - mae: 0.0185 - mse: 5.3787e-04 - val_loss: 6.3201e-04 - val_mae: 0.0190 - val_mse: 5.5612e-04 - lr: 1.0000e-05
Epoch 157/200
81/81 [==============================] - 0s 1ms/step - loss: 6.1379e-04 - mae: 0.0185 - mse: 5.3796e-04 - val_loss: 6.3218e-04 - val_mae: 0.0190 - val_mse: 5.5631e-04 - lr: 1.0000e-05
Epoch 158/200
81/81 [==============================] - 0s 1ms/step - loss: 6.1374e-04 - mae: 0.0185 - mse: 5.3787e-04 - val_loss: 6.3206e-04 - val_mae: 0.0190 - val_mse: 5.5620e-04 - lr: 1.0000e-05
Epoch 159/200
81/81 [==============================] - 0s 2ms/step - loss: 6.1372e-04 - mae: 0.0185 - mse: 5.3786e-04 - val_loss: 6.3179e-04 - val_mae: 0.0190 - val_mse: 5.5595e-04 - lr: 1.0000e-05
Epoch 160/200
81/81 [==============================] - 0s 2ms/step - loss: 6.1366e-04 - mae: 0.0185 - mse: 5.3782e-04 - val_loss: 6.3194e-04 - val_mae: 0.0190 - val_mse: 5.5611e-04 - lr: 1.0000e-05
Epoch 161/200
81/81 [==============================] - 0s 2ms/step - loss: 6.1368e-04 - mae: 0.0185 - mse: 5.3784e-04 - val_loss: 6.3216e-04 - val_mae: 0.0190 - val_mse: 5.5632e-04 - lr: 1.0000e-05
Epoch 162/200
81/81 [==============================] - 0s 2ms/step - loss: 6.1370e-04 - mae: 0.0185 - mse: 5.3785e-04 - val_loss: 6.3223e-04 - val_mae: 0.0190 - val_mse: 5.5634e-04 - lr: 1.0000e-05
Epoch 163/200
81/81 [==============================] - 0s 2ms/step - loss: 6.1368e-04 - mae: 0.0185 - mse: 5.3778e-04 - val_loss: 6.3224e-04 - val_mae: 0.0190 - val_mse: 5.5639e-04 - lr: 1.0000e-05
Epoch 164/200
81/81 [==============================] - 0s 2ms/step - loss: 6.1369e-04 - mae: 0.0185 - mse: 5.3790e-04 - val_loss: 6.3192e-04 - val_mae: 0.0190 - val_mse: 5.5611e-04 - lr: 1.0000e-05
Epoch 165/200
81/81 [==============================] - 0s 2ms/step - loss: 6.1368e-04 - mae: 0.0185 - mse: 5.3785e-04 - val_loss: 6.3160e-04 - val_mae: 0.0190 - val_mse: 5.5579e-04 - lr: 1.0000e-05
Epoch 166/200
81/81 [==============================] - 0s 2ms/step - loss: 6.1370e-04 - mae: 0.0185 - mse: 5.3787e-04 - val_loss: 6.3165e-04 - val_mae: 0.0190 - val_mse: 5.5584e-04 - lr: 1.0000e-05
Epoch 167/200
81/81 [==============================] - 0s 2ms/step - loss: 6.1361e-04 - mae: 0.0184 - mse: 5.3780e-04 - val_loss: 6.3169e-04 - val_mae: 0.0190 - val_mse: 5.5587e-04 - lr: 1.0000e-05
Epoch 168/200
81/81 [==============================] - 0s 2ms/step - loss: 6.1364e-04 - mae: 0.0185 - mse: 5.3780e-04 - val_loss: 6.3182e-04 - val_mae: 0.0190 - val_mse: 5.5601e-04 - lr: 1.0000e-05
Epoch 169/200
81/81 [==============================] - 0s 2ms/step - loss: 6.1365e-04 - mae: 0.0184 - mse: 5.3787e-04 - val_loss: 6.3168e-04 - val_mae: 0.0190 - val_mse: 5.5591e-04 - lr: 1.0000e-05
Epoch 170/200
81/81 [==============================] - 0s 2ms/step - loss: 6.1361e-04 - mae: 0.0185 - mse: 5.3783e-04 - val_loss: 6.3197e-04 - val_mae: 0.0190 - val_mse: 5.5616e-04 - lr: 1.0000e-05
Epoch 171/200
81/81 [==============================] - 0s 2ms/step - loss: 6.1359e-04 - mae: 0.0185 - mse: 5.3777e-04 - val_loss: 6.3193e-04 - val_mae: 0.0190 - val_mse: 5.5613e-04 - lr: 1.0000e-05
Epoch 172/200
81/81 [==============================] - 0s 2ms/step - loss: 6.1370e-04 - mae: 0.0185 - mse: 5.3794e-04 - val_loss: 6.3209e-04 - val_mae: 0.0190 - val_mse: 5.5629e-04 - lr: 1.0000e-05
Epoch 173/200
81/81 [==============================] - 0s 2ms/step - loss: 6.1363e-04 - mae: 0.0185 - mse: 5.3782e-04 - val_loss: 6.3198e-04 - val_mae: 0.0190 - val_mse: 5.5618e-04 - lr: 1.0000e-05
Epoch 174/200
81/81 [==============================] - 0s 2ms/step - loss: 6.1367e-04 - mae: 0.0185 - mse: 5.3790e-04 - val_loss: 6.3185e-04 - val_mae: 0.0190 - val_mse: 5.5607e-04 - lr: 1.0000e-05
Epoch 175/200
49/81 [=================>............] - ETA: 0s - loss: 6.1767e-04 - mae: 0.0184 - mse: 5.4183e-04
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
Epoch 142/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_190824-ank22yas\files\model-best)... Done. 0.0s
Epoch 172/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
81/81 [==============================] - 0s 1ms/step - loss: 5.8645e-04 - mae: 0.0152 - mse: 4.8418e-04 - val_loss: 6.0169e-04 - val_mae: 0.0157 - val_mse: 4.9931e-04 - lr: 1.0000e-05
Epoch 173/200
81/81 [==============================] - 0s 1ms/step - loss: 5.8648e-04 - mae: 0.0152 - mse: 4.8403e-04 - val_loss: 6.0164e-04 - val_mae: 0.0157 - val_mse: 4.9924e-04 - lr: 1.0000e-05
Epoch 174/200
81/81 [==============================] - 0s 1ms/step - loss: 5.8643e-04 - mae: 0.0152 - mse: 4.8390e-04 - val_loss: 6.0164e-04 - val_mae: 0.0157 - val_mse: 4.9922e-04 - lr: 1.0000e-05
Epoch 175/200
81/81 [==============================] - 0s 1ms/step - loss: 5.8640e-04 - mae: 0.0152 - mse: 4.8400e-04 - val_loss: 6.0168e-04 - val_mae: 0.0157 - val_mse: 4.9927e-04 - lr: 1.0000e-05
Epoch 176/200
81/81 [==============================] - 0s 1ms/step - loss: 5.8639e-04 - mae: 0.0152 - mse: 4.8398e-04 - val_loss: 6.0159e-04 - val_mae: 0.0157 - val_mse: 4.9919e-04 - lr: 1.0000e-05
Epoch 177/200
81/81 [==============================] - 0s 1ms/step - loss: 5.8633e-04 - mae: 0.0152 - mse: 4.8396e-04 - val_loss: 6.0166e-04 - val_mae: 0.0157 - val_mse: 4.9929e-04 - lr: 1.0000e-05
Epoch 178/200
81/81 [==============================] - 0s 1ms/step - loss: 5.8634e-04 - mae: 0.0152 - mse: 4.8394e-04 - val_loss: 6.0167e-04 - val_mae: 0.0157 - val_mse: 4.9930e-04 - lr: 1.0000e-05
Epoch 179/200
81/81 [==============================] - 0s 1ms/step - loss: 5.8639e-04 - mae: 0.0152 - mse: 4.8406e-04 - val_loss: 6.0165e-04 - val_mae: 0.0157 - val_mse: 4.9929e-04 - lr: 1.0000e-05
Epoch 180/200
81/81 [==============================] - 0s 1ms/step - loss: 5.8631e-04 - mae: 0.0152 - mse: 4.8389e-04 - val_loss: 6.0130e-04 - val_mae: 0.0157 - val_mse: 4.9886e-04 - lr: 1.0000e-05
Epoch 181/200
81/81 [==============================] - 0s 1ms/step - loss: 5.8629e-04 - mae: 0.0152 - mse: 4.8388e-04 - val_loss: 6.0145e-04 - val_mae: 0.0157 - val_mse: 4.9904e-04 - lr: 1.0000e-05
Epoch 182/200
81/81 [==============================] - 0s 1ms/step - loss: 5.8630e-04 - mae: 0.0152 - mse: 4.8391e-04 - val_loss: 6.0134e-04 - val_mae: 0.0157 - val_mse: 4.9891e-04 - lr: 1.0000e-05
Epoch 183/200
81/81 [==============================] - 0s 1ms/step - loss: 5.8632e-04 - mae: 0.0152 - mse: 4.8385e-04 - val_loss: 6.0166e-04 - val_mae: 0.0157 - val_mse: 4.9927e-04 - lr: 1.0000e-05
Epoch 184/200
81/81 [==============================] - 0s 1ms/step - loss: 5.8630e-04 - mae: 0.0152 - mse: 4.8386e-04 - val_loss: 6.0150e-04 - val_mae: 0.0157 - val_mse: 4.9910e-04 - lr: 1.0000e-05
Epoch 185/200
81/81 [==============================] - 0s 1ms/step - loss: 5.8632e-04 - mae: 0.0152 - mse: 4.8389e-04 - val_loss: 6.0140e-04 - val_mae: 0.0157 - val_mse: 4.9897e-04 - lr: 1.0000e-05
Epoch 186/200
81/81 [==============================] - 0s 1ms/step - loss: 5.8628e-04 - mae: 0.0152 - mse: 4.8392e-04 - val_loss: 6.0157e-04 - val_mae: 0.0157 - val_mse: 4.9919e-04 - lr: 1.0000e-05
Epoch 187/200
81/81 [==============================] - 0s 1ms/step - loss: 5.8625e-04 - mae: 0.0152 - mse: 4.8385e-04 - val_loss: 6.0146e-04 - val_mae: 0.0157 - val_mse: 4.9907e-04 - lr: 1.0000e-05
Epoch 188/200
81/81 [==============================] - 0s 2ms/step - loss: 5.8625e-04 - mae: 0.0152 - mse: 4.8387e-04 - val_loss: 6.0122e-04 - val_mae: 0.0157 - val_mse: 4.9879e-04 - lr: 1.0000e-05
Epoch 189/200
81/81 [==============================] - 0s 2ms/step - loss: 5.8625e-04 - mae: 0.0152 - mse: 4.8388e-04 - val_loss: 6.0143e-04 - val_mae: 0.0157 - val_mse: 4.9905e-04 - lr: 1.0000e-05
Epoch 190/200
81/81 [==============================] - 0s 2ms/step - loss: 5.8625e-04 - mae: 0.0152 - mse: 4.8378e-04 - val_loss: 6.0124e-04 - val_mae: 0.0157 - val_mse: 4.9881e-04 - lr: 1.0000e-05
Epoch 191/200
81/81 [==============================] - 0s 2ms/step - loss: 5.8626e-04 - mae: 0.0152 - mse: 4.8387e-04 - val_loss: 6.0171e-04 - val_mae: 0.0157 - val_mse: 4.9935e-04 - lr: 1.0000e-05
Epoch 192/200
81/81 [==============================] - 0s 2ms/step - loss: 5.8631e-04 - mae: 0.0152 - mse: 4.8390e-04 - val_loss: 6.0166e-04 - val_mae: 0.0157 - val_mse: 4.9932e-04 - lr: 1.0000e-05
Epoch 193/200
81/81 [==============================] - 0s 2ms/step - loss: 5.8620e-04 - mae: 0.0152 - mse: 4.8385e-04 - val_loss: 6.0121e-04 - val_mae: 0.0157 - val_mse: 4.9880e-04 - lr: 1.0000e-05
Epoch 194/200
81/81 [==============================] - 0s 2ms/step - loss: 5.8625e-04 - mae: 0.0152 - mse: 4.8384e-04 - val_loss: 6.0153e-04 - val_mae: 0.0157 - val_mse: 4.9919e-04 - lr: 1.0000e-05
Epoch 195/200
81/81 [==============================] - 0s 2ms/step - loss: 5.8621e-04 - mae: 0.0152 - mse: 4.8385e-04 - val_loss: 6.0143e-04 - val_mae: 0.0157 - val_mse: 4.9906e-04 - lr: 1.0000e-05
Epoch 196/200
81/81 [==============================] - 0s 2ms/step - loss: 5.8622e-04 - mae: 0.0152 - mse: 4.8383e-04 - val_loss: 6.0121e-04 - val_mae: 0.0157 - val_mse: 4.9880e-04 - lr: 1.0000e-05
Epoch 197/200
81/81 [==============================] - 0s 2ms/step - loss: 5.8619e-04 - mae: 0.0152 - mse: 4.8387e-04 - val_loss: 6.0132e-04 - val_mae: 0.0157 - val_mse: 4.9897e-04 - lr: 1.0000e-05
Epoch 198/200
81/81 [==============================] - 0s 2ms/step - loss: 5.8619e-04 - mae: 0.0152 - mse: 4.8387e-04 - val_loss: 6.0117e-04 - val_mae: 0.0157 - val_mse: 4.9877e-04 - lr: 1.0000e-05
Epoch 199/200
81/81 [==============================] - 0s 2ms/step - loss: 5.8618e-04 - mae: 0.0152 - mse: 4.8369e-04 - val_loss: 6.0136e-04 - val_mae: 0.0157 - val_mse: 4.9899e-04 - lr: 1.0000e-05
Epoch 200/200
81/81 [==============================] - 0s 2ms/step - loss: 5.8630e-04 - mae: 0.0152 - mse: 4.8394e-04 - val_loss: 6.0091e-04 - val_mae: 0.0157 - val_mse: 4.9844e-04 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_adam_0.07522724722750693LR_[30]HN_48BS_10P_val_mseM_200epochs/model_7.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/200
81/81 [==============================] - 1s 7ms/step - loss: 0.0393 - mae: 0.0489 - mse: 0.0045 - val_loss: 0.0028 - val_mae: 0.0403 - val_mse: 0.0023 - lr: 0.0752
Epoch 2/200
81/81 [==============================] - 0s 2ms/step - loss: 0.0024 - mae: 0.0393 - mse: 0.0021 - val_loss: 0.0024 - val_mae: 0.0408 - val_mse: 0.0024 - lr: 0.0752
Epoch 3/200
81/81 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0752
Epoch 4/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0381 - val_mse: 0.0020 - lr: 0.0752
Epoch 5/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0381 - val_mse: 0.0020 - lr: 0.0752
Epoch 6/200
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0370 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0370 - val_mse: 0.0018 - lr: 0.0752
Epoch 7/200
81/81 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0365 - mse: 0.0018 - val_loss: 0.0020 - val_mae: 0.0364 - val_mse: 0.0018 - lr: 0.0752
Epoch 8/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0352 - mse: 0.0017 - val_loss: 0.0018 - val_mae: 0.0333 - val_mse: 0.0016 - lr: 0.0752
Epoch 9/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0341 - mse: 0.0017 - val_loss: 0.0018 - val_mae: 0.0339 - val_mse: 0.0016 - lr: 0.0752
Epoch 10/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0298 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0273 - val_mse: 0.0012 - lr: 0.0752
Epoch 11/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0291 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0279 - val_mse: 0.0012 - lr: 0.0752
Epoch 12/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0279 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0752
Epoch 13/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0270 - val_mse: 0.0012 - lr: 0.0752
Epoch 14/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0267 - mse: 0.0011 - val_loss: 0.0017 - val_mae: 0.0319 - val_mse: 0.0016 - lr: 0.0752
Epoch 15/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0016 - val_mae: 0.0296 - val_mse: 0.0013 - lr: 0.0752
Epoch 16/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0271 - mse: 0.0012 - val_loss: 0.0019 - val_mae: 0.0321 - val_mse: 0.0015 - lr: 0.0752
Epoch 17/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0252 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0243 - val_mse: 9.3515e-04 - lr: 0.0752
Epoch 18/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0269 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0280 - val_mse: 0.0012 - lr: 0.0752
Epoch 19/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0253 - mse: 0.0010 - val_loss: 0.0014 - val_mae: 0.0288 - val_mse: 0.0013 - lr: 0.0752
Epoch 20/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0254 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0240 - val_mse: 9.0887e-04 - lr: 0.0752
Epoch 21/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0267 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0246 - val_mse: 9.6126e-04 - lr: 0.0752
Epoch 22/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0244 - mse: 9.4703e-04 - val_loss: 0.0010 - val_mae: 0.0238 - val_mse: 9.0861e-04 - lr: 0.0752
Epoch 23/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0247 - mse: 9.7852e-04 - val_loss: 0.0011 - val_mae: 0.0251 - val_mse: 9.6774e-04 - lr: 0.0752
Epoch 24/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0285 - mse: 0.0013 - val_loss: 0.0012 - val_mae: 0.0249 - val_mse: 9.8804e-04 - lr: 0.0752
Epoch 25/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0243 - mse: 9.4504e-04 - val_loss: 0.0011 - val_mae: 0.0244 - val_mse: 9.3882e-04 - lr: 0.0752
Epoch 26/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0263 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0271 - val_mse: 0.0011 - lr: 0.0752
Epoch 27/200
65/81 [=======================>......] - ETA: 0s - loss: 0.0011 - mae: 0.0248 - mse: 9.8235e-04
Epoch 27: ReduceLROnPlateau reducing learning rate to 0.03761362284421921.
81/81 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0248 - mse: 9.8255e-04 - val_loss: 0.0011 - val_mae: 0.0246 - val_mse: 9.4885e-04 - lr: 0.0752
Epoch 28/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0236 - mse: 8.9590e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.1236e-04 - lr: 0.0376
Epoch 29/200
81/81 [==============================] - 0s 2ms/step - loss: 9.9764e-04 - mae: 0.0237 - mse: 8.9825e-04 - val_loss: 0.0012 - val_mae: 0.0263 - val_mse: 0.0011 - lr: 0.0376
Epoch 30/200
81/81 [==============================] - 0s 1ms/step - loss: 9.8454e-04 - mae: 0.0236 - mse: 8.9080e-04 - val_loss: 0.0014 - val_mae: 0.0296 - val_mse: 0.0013 - lr: 0.0376
Epoch 31/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0244 - mse: 9.4835e-04 - val_loss: 0.0011 - val_mae: 0.0259 - val_mse: 0.0010 - lr: 0.0376
Epoch 32/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0241 - mse: 9.2185e-04 - val_loss: 0.0010 - val_mae: 0.0241 - val_mse: 9.2203e-04 - lr: 0.0376
Epoch 33/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0238 - mse: 9.1367e-04 - val_loss: 9.6242e-04 - val_mae: 0.0235 - val_mse: 8.8012e-04 - lr: 0.0376
Epoch 34/200
81/81 [==============================] - 0s 1ms/step - loss: 9.7287e-04 - mae: 0.0236 - mse: 8.8588e-04 - val_loss: 0.0014 - val_mae: 0.0287 - val_mse: 0.0013 - lr: 0.0376
Epoch 35/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0241 - mse: 9.2357e-04 - val_loss: 9.5418e-04 - val_mae: 0.0233 - val_mse: 8.6107e-04 - lr: 0.0376
Epoch 36/200
81/81 [==============================] - 0s 1ms/step - loss: 9.6999e-04 - mae: 0.0235 - mse: 8.8746e-04 - val_loss: 0.0011 - val_mae: 0.0249 - val_mse: 9.6254e-04 - lr: 0.0376
Epoch 37/200
66/81 [=======================>......] - ETA: 0s - loss: 9.9803e-04 - mae: 0.0240 - mse: 9.1070e-04
Epoch 37: ReduceLROnPlateau reducing learning rate to 0.018806811422109604.
81/81 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0242 - mse: 9.3029e-04 - val_loss: 0.0012 - val_mae: 0.0262 - val_mse: 0.0011 - lr: 0.0376
Epoch 38/200
81/81 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0239 - mse: 9.1199e-04 - val_loss: 9.4577e-04 - val_mae: 0.0232 - val_mse: 8.5524e-04 - lr: 0.0188
Epoch 39/200
81/81 [==============================] - 0s 1ms/step - loss: 9.3782e-04 - mae: 0.0232 - mse: 8.5756e-04 - val_loss: 0.0011 - val_mae: 0.0255 - val_mse: 9.9700e-04 - lr: 0.0188
Epoch 40/200
81/81 [==============================] - 0s 1ms/step - loss: 9.7361e-04 - mae: 0.0238 - mse: 8.9382e-04 - val_loss: 9.4313e-04 - val_mae: 0.0232 - val_mse: 8.5808e-04 - lr: 0.0188
Epoch 41/200
81/81 [==============================] - 0s 2ms/step - loss: 9.3259e-04 - mae: 0.0232 - mse: 8.5634e-04 - val_loss: 9.6800e-04 - val_mae: 0.0239 - val_mse: 8.9561e-04 - lr: 0.0188
Epoch 42/200
81/81 [==============================] - 0s 2ms/step - loss: 9.3433e-04 - mae: 0.0233 - mse: 8.6132e-04 - val_loss: 9.8050e-04 - val_mae: 0.0237 - val_mse: 8.8521e-04 - lr: 0.0188
Epoch 43/200
81/81 [==============================] - 0s 1ms/step - loss: 9.3525e-04 - mae: 0.0233 - mse: 8.6432e-04 - val_loss: 9.7703e-04 - val_mae: 0.0237 - val_mse: 8.8906e-04 - lr: 0.0188
Epoch 44/200
81/81 [==============================] - 0s 1ms/step - loss: 9.1907e-04 - mae: 0.0230 - mse: 8.4853e-04 - val_loss: 9.6927e-04 - val_mae: 0.0238 - val_mse: 8.9734e-04 - lr: 0.0188
Epoch 45/200
81/81 [==============================] - 0s 1ms/step - loss: 9.3296e-04 - mae: 0.0232 - mse: 8.6286e-04 - val_loss: 9.2619e-04 - val_mae: 0.0232 - val_mse: 8.5746e-04 - lr: 0.0188
Epoch 46/200
81/81 [==============================] - 0s 1ms/step - loss: 9.4027e-04 - mae: 0.0233 - mse: 8.6848e-04 - val_loss: 0.0011 - val_mae: 0.0259 - val_mse: 0.0010 - lr: 0.0188
Epoch 47/200
69/81 [========================>.....] - ETA: 0s - loss: 9.3106e-04 - mae: 0.0232 - mse: 8.6121e-04
Epoch 47: ReduceLROnPlateau reducing learning rate to 0.009403405711054802.
81/81 [==============================] - 0s 1ms/step - loss: 9.2135e-04 - mae: 0.0231 - mse: 8.5314e-04 - val_loss: 9.2311e-04 - val_mae: 0.0233 - val_mse: 8.6042e-04 - lr: 0.0188
Epoch 48/200
81/81 [==============================] - 0s 1ms/step - loss: 9.1265e-04 - mae: 0.0229 - mse: 8.4838e-04 - val_loss: 9.3688e-04 - val_mae: 0.0236 - val_mse: 8.7392e-04 - lr: 0.0094
Epoch 49/200
81/81 [==============================] - 0s 1ms/step - loss: 8.9848e-04 - mae: 0.0228 - mse: 8.3343e-04 - val_loss: 9.5713e-04 - val_mae: 0.0240 - val_mse: 9.0056e-04 - lr: 0.0094
Epoch 50/200
81/81 [==============================] - 0s 1ms/step - loss: 9.1290e-04 - mae: 0.0231 - mse: 8.4852e-04 - val_loss: 9.6439e-04 - val_mae: 0.0241 - val_mse: 9.0507e-04 - lr: 0.0094
Epoch 51/200
81/81 [==============================] - 0s 1ms/step - loss: 9.0995e-04 - mae: 0.0229 - mse: 8.4704e-04 - val_loss: 9.5558e-04 - val_mae: 0.0239 - val_mse: 8.8674e-04 - lr: 0.0094
Epoch 52/200
81/81 [==============================] - 0s 2ms/step - loss: 9.0760e-04 - mae: 0.0230 - mse: 8.4453e-04 - val_loss: 0.0010 - val_mae: 0.0248 - val_mse: 9.5042e-04 - lr: 0.0094
Epoch 53/200
81/81 [==============================] - 0s 1ms/step - loss: 9.0154e-04 - mae: 0.0229 - mse: 8.3993e-04 - val_loss: 0.0011 - val_mae: 0.0261 - val_mse: 0.0010 - lr: 0.0094
Epoch 54/200
81/81 [==============================] - 0s 1ms/step - loss: 9.1245e-04 - mae: 0.0230 - mse: 8.4730e-04 - val_loss: 9.1810e-04 - val_mae: 0.0232 - val_mse: 8.5808e-04 - lr: 0.0094
Epoch 55/200
81/81 [==============================] - 0s 1ms/step - loss: 9.0828e-04 - mae: 0.0230 - mse: 8.4686e-04 - val_loss: 9.1047e-04 - val_mae: 0.0230 - val_mse: 8.3777e-04 - lr: 0.0094
Epoch 56/200
81/81 [==============================] - 0s 1ms/step - loss: 9.2897e-04 - mae: 0.0234 - mse: 8.6433e-04 - val_loss: 9.0260e-04 - val_mae: 0.0230 - val_mse: 8.4142e-04 - lr: 0.0094
Epoch 57/200
68/81 [========================>.....] - ETA: 0s - loss: 8.8549e-04 - mae: 0.0226 - mse: 8.2361e-04
Epoch 57: ReduceLROnPlateau reducing learning rate to 0.004701702855527401.
81/81 [==============================] - 0s 1ms/step - loss: 8.9702e-04 - mae: 0.0228 - mse: 8.3477e-04 - val_loss: 9.1004e-04 - val_mae: 0.0232 - val_mse: 8.4580e-04 - lr: 0.0094
Epoch 58/200
81/81 [==============================] - 0s 1ms/step - loss: 8.9244e-04 - mae: 0.0228 - mse: 8.3215e-04 - val_loss: 9.0344e-04 - val_mae: 0.0230 - val_mse: 8.4906e-04 - lr: 0.0047
Epoch 59/200
81/81 [==============================] - 0s 1ms/step - loss: 8.7996e-04 - mae: 0.0226 - mse: 8.2438e-04 - val_loss: 9.0431e-04 - val_mae: 0.0229 - val_mse: 8.3965e-04 - lr: 0.0047
Epoch 60/200
81/81 [==============================] - 0s 2ms/step - loss: 8.8736e-04 - mae: 0.0227 - mse: 8.2887e-04 - val_loss: 8.9822e-04 - val_mae: 0.0230 - val_mse: 8.4127e-04 - lr: 0.0047
Epoch 61/200
81/81 [==============================] - 0s 1ms/step - loss: 8.8502e-04 - mae: 0.0228 - mse: 8.2812e-04 - val_loss: 9.3774e-04 - val_mae: 0.0238 - val_mse: 8.7783e-04 - lr: 0.0047
Epoch 62/200
81/81 [==============================] - 0s 1ms/step - loss: 8.8604e-04 - mae: 0.0227 - mse: 8.3004e-04 - val_loss: 9.0675e-04 - val_mae: 0.0232 - val_mse: 8.4612e-04 - lr: 0.0047
Epoch 63/200
81/81 [==============================] - 0s 1ms/step - loss: 8.9563e-04 - mae: 0.0229 - mse: 8.3552e-04 - val_loss: 8.9654e-04 - val_mae: 0.0229 - val_mse: 8.3393e-04 - lr: 0.0047
Epoch 64/200
81/81 [==============================] - 0s 1ms/step - loss: 8.8249e-04 - mae: 0.0227 - mse: 8.2720e-04 - val_loss: 8.9584e-04 - val_mae: 0.0230 - val_mse: 8.4227e-04 - lr: 0.0047
Epoch 65/200
81/81 [==============================] - 0s 1ms/step - loss: 8.7763e-04 - mae: 0.0226 - mse: 8.2292e-04 - val_loss: 9.1119e-04 - val_mae: 0.0234 - val_mse: 8.5543e-04 - lr: 0.0047
Epoch 66/200
81/81 [==============================] - 0s 2ms/step - loss: 8.8836e-04 - mae: 0.0228 - mse: 8.3158e-04 - val_loss: 9.1775e-04 - val_mae: 0.0233 - val_mse: 8.5999e-04 - lr: 0.0047
Epoch 67/200
81/81 [==============================] - 0s 1ms/step - loss: 8.8142e-04 - mae: 0.0227 - mse: 8.2639e-04 - val_loss: 9.2013e-04 - val_mae: 0.0233 - val_mse: 8.6362e-04 - lr: 0.0047
Epoch 68/200
81/81 [==============================] - 0s 1ms/step - loss: 8.7906e-04 - mae: 0.0226 - mse: 8.2384e-04 - val_loss: 8.9365e-04 - val_mae: 0.0229 - val_mse: 8.3751e-04 - lr: 0.0047
Epoch 69/200
81/81 [==============================] - 0s 1ms/step - loss: 8.8691e-04 - mae: 0.0227 - mse: 8.3225e-04 - val_loss: 8.9117e-04 - val_mae: 0.0229 - val_mse: 8.3843e-04 - lr: 0.0047
Epoch 70/200
81/81 [==============================] - 0s 1ms/step - loss: 8.7718e-04 - mae: 0.0226 - mse: 8.2558e-04 - val_loss: 8.9159e-04 - val_mae: 0.0230 - val_mse: 8.3422e-04 - lr: 0.0047
Epoch 71/200
81/81 [==============================] - 0s 1ms/step - loss: 8.7527e-04 - mae: 0.0226 - mse: 8.2132e-04 - val_loss: 9.0610e-04 - val_mae: 0.0233 - val_mse: 8.5879e-04 - lr: 0.0047
Epoch 72/200
81/81 [==============================] - 0s 1ms/step - loss: 9.0372e-04 - mae: 0.0230 - mse: 8.4879e-04 - val_loss: 9.5290e-04 - val_mae: 0.0238 - val_mse: 8.9349e-04 - lr: 0.0047
Epoch 73/200
55/81 [===================>..........] - ETA: 0s - loss: 9.0463e-04 - mae: 0.0230 - mse: 8.4854e-04
Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0023508514277637005.
81/81 [==============================] - 0s 2ms/step - loss: 9.1759e-04 - mae: 0.0232 - mse: 8.6225e-04 - val_loss: 8.9364e-04 - val_mae: 0.0231 - val_mse: 8.3945e-04 - lr: 0.0047
Epoch 74/200
81/81 [==============================] - 0s 2ms/step - loss: 8.7820e-04 - mae: 0.0227 - mse: 8.2421e-04 - val_loss: 8.9917e-04 - val_mae: 0.0230 - val_mse: 8.4159e-04 - lr: 0.0024
Epoch 75/200
81/81 [==============================] - 0s 2ms/step - loss: 8.6961e-04 - mae: 0.0226 - mse: 8.1756e-04 - val_loss: 8.8668e-04 - val_mae: 0.0229 - val_mse: 8.3291e-04 - lr: 0.0024
Epoch 76/200
81/81 [==============================] - 0s 2ms/step - loss: 8.7452e-04 - mae: 0.0226 - mse: 8.2113e-04 - val_loss: 8.8677e-04 - val_mae: 0.0229 - val_mse: 8.3534e-04 - lr: 0.0024
Epoch 77/200
81/81 [==============================] - 0s 2ms/step - loss: 8.7214e-04 - mae: 0.0226 - mse: 8.2123e-04 - val_loss: 9.0849e-04 - val_mae: 0.0234 - val_mse: 8.6194e-04 - lr: 0.0024
Epoch 78/200
81/81 [==============================] - 0s 2ms/step - loss: 8.7528e-04 - mae: 0.0226 - mse: 8.2369e-04 - val_loss: 8.9280e-04 - val_mae: 0.0231 - val_mse: 8.4423e-04 - lr: 0.0024
Epoch 79/200
81/81 [==============================] - 0s 2ms/step - loss: 8.6997e-04 - mae: 0.0226 - mse: 8.1970e-04 - val_loss: 8.8520e-04 - val_mae: 0.0229 - val_mse: 8.3257e-04 - lr: 0.0024
Epoch 80/200
81/81 [==============================] - 0s 2ms/step - loss: 8.6765e-04 - mae: 0.0225 - mse: 8.1640e-04 - val_loss: 8.8937e-04 - val_mae: 0.0230 - val_mse: 8.3834e-04 - lr: 0.0024
Epoch 81/200
81/81 [==============================] - 0s 2ms/step - loss: 8.6902e-04 - mae: 0.0225 - mse: 8.1750e-04 - val_loss: 8.9032e-04 - val_mae: 0.0231 - val_mse: 8.3921e-04 - lr: 0.0024
Epoch 82/200
81/81 [==============================] - 0s 2ms/step - loss: 8.6596e-04 - mae: 0.0225 - mse: 8.1477e-04 - val_loss: 8.8474e-04 - val_mae: 0.0229 - val_mse: 8.3470e-04 - lr: 0.0024
Epoch 83/200
51/81 [=================>............] - ETA: 0s - loss: 8.7199e-04 - mae: 0.0226 - mse: 8.2365e-04
Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0011754257138818502.
81/81 [==============================] - 0s 2ms/step - loss: 8.6683e-04 - mae: 0.0225 - mse: 8.1749e-04 - val_loss: 8.9090e-04 - val_mae: 0.0229 - val_mse: 8.3707e-04 - lr: 0.0024
Epoch 84/200
81/81 [==============================] - 0s 2ms/step - loss: 8.7218e-04 - mae: 0.0226 - mse: 8.2061e-04 - val_loss: 8.9570e-04 - val_mae: 0.0232 - val_mse: 8.4780e-04 - lr: 0.0012
Epoch 85/200
81/81 [==============================] - 0s 2ms/step - loss: 8.6230e-04 - mae: 0.0224 - mse: 8.1305e-04 - val_loss: 8.8599e-04 - val_mae: 0.0230 - val_mse: 8.3756e-04 - lr: 0.0012
Epoch 86/200
81/81 [==============================] - 0s 2ms/step - loss: 8.6925e-04 - mae: 0.0226 - mse: 8.2119e-04 - val_loss: 8.9361e-04 - val_mae: 0.0231 - val_mse: 8.4428e-04 - lr: 0.0012
Epoch 87/200
81/81 [==============================] - 0s 2ms/step - loss: 8.6493e-04 - mae: 0.0225 - mse: 8.1455e-04 - val_loss: 8.9689e-04 - val_mae: 0.0232 - val_mse: 8.4745e-04 - lr: 0.0012
Epoch 88/200
81/81 [==============================] - 0s 2ms/step - loss: 8.6359e-04 - mae: 0.0225 - mse: 8.1160e-04 - val_loss: 8.9487e-04 - val_mae: 0.0232 - val_mse: 8.4767e-04 - lr: 0.0012
Epoch 89/200
81/81 [==============================] - 0s 2ms/step - loss: 8.6175e-04 - mae: 0.0225 - mse: 8.1412e-04 - val_loss: 8.8271e-04 - val_mae: 0.0229 - val_mse: 8.3282e-04 - lr: 0.0012
Epoch 90/200
81/81 [==============================] - 0s 2ms/step - loss: 8.6123e-04 - mae: 0.0224 - mse: 8.1170e-04 - val_loss: 8.8197e-04 - val_mae: 0.0228 - val_mse: 8.3221e-04 - lr: 0.0012
Epoch 91/200
81/81 [==============================] - 0s 2ms/step - loss: 8.6269e-04 - mae: 0.0225 - mse: 8.1364e-04 - val_loss: 8.8538e-04 - val_mae: 0.0230 - val_mse: 8.3607e-04 - lr: 0.0012
Epoch 92/200
81/81 [==============================] - 0s 2ms/step - loss: 8.6379e-04 - mae: 0.0225 - mse: 8.1538e-04 - val_loss: 8.8704e-04 - val_mae: 0.0230 - val_mse: 8.3823e-04 - lr: 0.0012
Epoch 93/200
52/81 [==================>...........] - ETA: 0s - loss: 8.7711e-04 - mae: 0.0228 - mse: 8.2869e-04
Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0005877128569409251.
81/81 [==============================] - 0s 2ms/step - loss: 8.6054e-04 - mae: 0.0224 - mse: 8.1162e-04 - val_loss: 8.8743e-04 - val_mae: 0.0230 - val_mse: 8.3926e-04 - lr: 0.0012
Epoch 94/200
81/81 [==============================] - 0s 2ms/step - loss: 8.6085e-04 - mae: 0.0225 - mse: 8.1237e-04 - val_loss: 8.8169e-04 - val_mae: 0.0228 - val_mse: 8.3160e-04 - lr: 5.8771e-04
Epoch 95/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5914e-04 - mae: 0.0224 - mse: 8.1003e-04 - val_loss: 8.8239e-04 - val_mae: 0.0229 - val_mse: 8.3332e-04 - lr: 5.8771e-04
Epoch 96/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5913e-04 - mae: 0.0224 - mse: 8.1063e-04 - val_loss: 8.8151e-04 - val_mae: 0.0229 - val_mse: 8.3259e-04 - lr: 5.8771e-04
Epoch 97/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5855e-04 - mae: 0.0224 - mse: 8.1064e-04 - val_loss: 8.8465e-04 - val_mae: 0.0230 - val_mse: 8.3693e-04 - lr: 5.8771e-04
Epoch 98/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5935e-04 - mae: 0.0224 - mse: 8.1091e-04 - val_loss: 8.8327e-04 - val_mae: 0.0229 - val_mse: 8.3555e-04 - lr: 5.8771e-04
Epoch 99/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5962e-04 - mae: 0.0224 - mse: 8.1108e-04 - val_loss: 9.0251e-04 - val_mae: 0.0234 - val_mse: 8.5672e-04 - lr: 5.8771e-04
Epoch 100/200
81/81 [==============================] - 0s 2ms/step - loss: 8.6289e-04 - mae: 0.0225 - mse: 8.1469e-04 - val_loss: 8.8070e-04 - val_mae: 0.0228 - val_mse: 8.3179e-04 - lr: 5.8771e-04
Epoch 101/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5790e-04 - mae: 0.0224 - mse: 8.1037e-04 - val_loss: 8.8135e-04 - val_mae: 0.0229 - val_mse: 8.3348e-04 - lr: 5.8771e-04
Epoch 102/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5923e-04 - mae: 0.0224 - mse: 8.1208e-04 - val_loss: 8.8610e-04 - val_mae: 0.0230 - val_mse: 8.3897e-04 - lr: 5.8771e-04
Epoch 103/200
52/81 [==================>...........] - ETA: 0s - loss: 8.4167e-04 - mae: 0.0221 - mse: 7.9333e-04
Epoch 103: ReduceLROnPlateau reducing learning rate to 0.00029385642847046256.
81/81 [==============================] - 0s 2ms/step - loss: 8.5828e-04 - mae: 0.0224 - mse: 8.1003e-04 - val_loss: 8.8091e-04 - val_mae: 0.0229 - val_mse: 8.3245e-04 - lr: 5.8771e-04
Epoch 104/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5812e-04 - mae: 0.0224 - mse: 8.1006e-04 - val_loss: 8.8071e-04 - val_mae: 0.0229 - val_mse: 8.3236e-04 - lr: 2.9386e-04
Epoch 105/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5755e-04 - mae: 0.0224 - mse: 8.0975e-04 - val_loss: 8.8504e-04 - val_mae: 0.0230 - val_mse: 8.3807e-04 - lr: 2.9386e-04
Epoch 106/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5765e-04 - mae: 0.0224 - mse: 8.0979e-04 - val_loss: 8.8074e-04 - val_mae: 0.0229 - val_mse: 8.3291e-04 - lr: 2.9386e-04
Epoch 107/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5731e-04 - mae: 0.0224 - mse: 8.0960e-04 - val_loss: 8.8149e-04 - val_mae: 0.0229 - val_mse: 8.3405e-04 - lr: 2.9386e-04
Epoch 108/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5842e-04 - mae: 0.0224 - mse: 8.1059e-04 - val_loss: 8.8538e-04 - val_mae: 0.0230 - val_mse: 8.3852e-04 - lr: 2.9386e-04
Epoch 109/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5868e-04 - mae: 0.0224 - mse: 8.1140e-04 - val_loss: 8.8050e-04 - val_mae: 0.0229 - val_mse: 8.3268e-04 - lr: 2.9386e-04
Epoch 110/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5725e-04 - mae: 0.0224 - mse: 8.1012e-04 - val_loss: 8.9031e-04 - val_mae: 0.0231 - val_mse: 8.4424e-04 - lr: 2.9386e-04
Epoch 111/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5857e-04 - mae: 0.0224 - mse: 8.1146e-04 - val_loss: 8.8002e-04 - val_mae: 0.0229 - val_mse: 8.3190e-04 - lr: 2.9386e-04
Epoch 112/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5684e-04 - mae: 0.0224 - mse: 8.0943e-04 - val_loss: 8.7904e-04 - val_mae: 0.0228 - val_mse: 8.3011e-04 - lr: 2.9386e-04
Epoch 113/200
54/81 [===================>..........] - ETA: 0s - loss: 8.6214e-04 - mae: 0.0225 - mse: 8.1405e-04
Epoch 113: ReduceLROnPlateau reducing learning rate to 0.00014692821423523128.
81/81 [==============================] - 0s 2ms/step - loss: 8.5808e-04 - mae: 0.0224 - mse: 8.1048e-04 - val_loss: 8.8262e-04 - val_mae: 0.0230 - val_mse: 8.3487e-04 - lr: 2.9386e-04
Epoch 114/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5694e-04 - mae: 0.0224 - mse: 8.0880e-04 - val_loss: 8.7928e-04 - val_mae: 0.0229 - val_mse: 8.3076e-04 - lr: 1.4693e-04
Epoch 115/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5677e-04 - mae: 0.0224 - mse: 8.0872e-04 - val_loss: 8.8709e-04 - val_mae: 0.0231 - val_mse: 8.4011e-04 - lr: 1.4693e-04
Epoch 116/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5682e-04 - mae: 0.0224 - mse: 8.0913e-04 - val_loss: 8.8109e-04 - val_mae: 0.0229 - val_mse: 8.3340e-04 - lr: 1.4693e-04
Epoch 117/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5756e-04 - mae: 0.0224 - mse: 8.0984e-04 - val_loss: 8.8069e-04 - val_mae: 0.0229 - val_mse: 8.3301e-04 - lr: 1.4693e-04
Epoch 118/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5649e-04 - mae: 0.0224 - mse: 8.0862e-04 - val_loss: 8.8065e-04 - val_mae: 0.0229 - val_mse: 8.3287e-04 - lr: 1.4693e-04
Epoch 119/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5675e-04 - mae: 0.0224 - mse: 8.0953e-04 - val_loss: 8.8034e-04 - val_mae: 0.0229 - val_mse: 8.3273e-04 - lr: 1.4693e-04
Epoch 120/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5686e-04 - mae: 0.0224 - mse: 8.0935e-04 - val_loss: 8.8175e-04 - val_mae: 0.0229 - val_mse: 8.3432e-04 - lr: 1.4693e-04
Epoch 121/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5580e-04 - mae: 0.0224 - mse: 8.0811e-04 - val_loss: 8.8809e-04 - val_mae: 0.0231 - val_mse: 8.4175e-04 - lr: 1.4693e-04
Epoch 122/200
81/81 [==============================] - 0s 2ms/step - loss: 8.5694e-04 - mae: 0.0225 - mse: 8.1001e-04 - val_loss: 8.7938e-04 - val_mae: 0.0229 - val_mse: 8.3151e-04 - lr: 1.4693e-04
Epoch 123/200
46/81 [================>.............] - ETA: 0s - loss: 8.5618e-04 - mae: 0.0224 - mse: 8.0870e-04
Epoch 123: ReduceLROnPlateau reducing learning rate to 7.346410711761564e-05.
81/81 [==============================] - 0s 2ms/step - loss: 8.5653e-04 - mae: 0.0224 - mse: 8.0932e-04 - val_loss: 8.7957e-04 - val_mae: 0.0229 - val_mse: 8.3195e-04 - lr: 1.4693e-04
Epoch 124/200
81/81 [==============================] - 0s 1ms/step - loss: 8.5673e-04 - mae: 0.0224 - mse: 8.0937e-04 - val_loss: 8.8106e-04 - val_mae: 0.0229 - val_mse: 8.3382e-04 - lr: 7.3464e-05
Epoch 125/200
81/81 [==============================] - 0s 1ms/step - loss: 8.5630e-04 - mae: 0.0224 - mse: 8.0891e-04 - val_loss: 8.8328e-04 - val_mae: 0.0230 - val_mse: 8.3634e-04 - lr: 7.3464e-05
Epoch 126/200
69/81 [========================>.....] - ETA: 0s - loss: 8.4590e-04 - mae: 0.0222 - mse: 7.9861e-04
Epoch 172/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 172/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 172/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 172/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 172/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 172/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 172/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 172/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 172/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 172/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 172/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 172/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 172/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 172/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 172/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 172/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 172/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047
Epoch 172/200========================] - 1s 11ms/step - loss: 6.4638e-04 - mae: 0.0189 - mse: 5.5948e-04 - val_loss: 6.4684e-04 - val_mae: 0.0190 - val_mse: 5.6800e-04 - lr: 0.0047