
Epoch 1/50

82/86 [===========================>..] - ETA: 0s - loss: 2.4764 - mae: 0.0878 - mse: 0.0174
86/86 [==============================] - 9s 72ms/step - loss: 2.3866 - mae: 0.0863 - mse: 0.0169 - val_loss: 0.0631 - val_mae: 0.0908 - val_mse: 0.0091 - lr: 0.0100
Epoch 2/50
86/86 [==============================] - ETA: 0s - loss: 0.0411 - mae: 0.0499 - mse: 0.0046
86/86 [==============================] - 5s 56ms/step - loss: 0.0411 - mae: 0.0499 - mse: 0.0046 - val_loss: 0.0419 - val_mae: 0.0673 - val_mse: 0.0054 - lr: 0.0100
Epoch 3/50
83/86 [===========================>..] - ETA: 0s - loss: 0.0349 - mae: 0.0328 - mse: 0.0016
86/86 [==============================] - 5s 55ms/step - loss: 0.0349 - mae: 0.0326 - mse: 0.0016 - val_loss: 0.0351 - val_mae: 0.0297 - val_mse: 0.0013 - lr: 0.0100
Epoch 4/50
86/86 [==============================] - ETA: 0s - loss: 0.0351 - mae: 0.0275 - mse: 0.0011
86/86 [==============================] - 5s 64ms/step - loss: 0.0351 - mae: 0.0275 - mse: 0.0011 - val_loss: 0.0351 - val_mae: 0.0273 - val_mse: 0.0010 - lr: 0.0100
Epoch 5/50
85/86 [============================>.] - ETA: 0s - loss: 0.0350 - mae: 0.0269 - mse: 0.0010
86/86 [==============================] - 5s 54ms/step - loss: 0.0350 - mae: 0.0269 - mse: 0.0010 - val_loss: 0.0346 - val_mae: 0.0260 - val_mse: 9.1417e-04 - lr: 0.0100
Epoch 6/50
86/86 [==============================] - 1s 15ms/step - loss: 0.0349 - mae: 0.0260 - mse: 9.3270e-04 - val_loss: 0.0348 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 0.0100
Epoch 7/50
86/86 [==============================] - 1s 14ms/step - loss: 0.0351 - mae: 0.0270 - mse: 0.0011 - val_loss: 0.0348 - val_mae: 0.0303 - val_mse: 0.0013 - lr: 0.0100
Epoch 8/50
84/86 [============================>.] - ETA: 0s - loss: 0.0348 - mae: 0.0258 - mse: 9.2364e-04
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.
86/86 [==============================] - 1s 15ms/step - loss: 0.0348 - mae: 0.0258 - mse: 9.2795e-04 - val_loss: 0.0368 - val_mae: 0.0371 - val_mse: 0.0021 - lr: 0.0100
Epoch 9/50
84/86 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0251 - mse: 8.5637e-04
86/86 [==============================] - 5s 62ms/step - loss: 0.0069 - mae: 0.0252 - mse: 8.5753e-04 - val_loss: 0.0096 - val_mae: 0.0258 - val_mse: 8.7521e-04 - lr: 0.0050
Epoch 10/50
85/86 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0249 - mse: 8.4509e-04
86/86 [==============================] - 5s 55ms/step - loss: 0.0091 - mae: 0.0249 - mse: 8.4430e-04 - val_loss: 0.0091 - val_mae: 0.0261 - val_mse: 8.9949e-04 - lr: 0.0050
Epoch 11/50
83/86 [===========================>..] - ETA: 0s - loss: 0.0091 - mae: 0.0251 - mse: 8.4813e-04
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.
86/86 [==============================] - 1s 16ms/step - loss: 0.0091 - mae: 0.0250 - mse: 8.4724e-04 - val_loss: 0.0092 - val_mae: 0.0258 - val_mse: 8.8519e-04 - lr: 0.0050
Epoch 12/50
86/86 [==============================] - ETA: 0s - loss: 0.0023 - mae: 0.0247 - mse: 8.2465e-04
86/86 [==============================] - 6s 70ms/step - loss: 0.0023 - mae: 0.0247 - mse: 8.2465e-04 - val_loss: 0.0035 - val_mae: 0.0257 - val_mse: 8.7258e-04 - lr: 0.0025
Epoch 13/50
83/86 [===========================>..] - ETA: 0s - loss: 0.0029 - mae: 0.0248 - mse: 8.2645e-04
86/86 [==============================] - 5s 60ms/step - loss: 0.0029 - mae: 0.0249 - mse: 8.3105e-04 - val_loss: 0.0029 - val_mae: 0.0257 - val_mse: 8.6556e-04 - lr: 0.0025
Epoch 14/50
84/86 [============================>.] - ETA: 0s - loss: 0.0029 - mae: 0.0249 - mse: 8.2912e-04
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.
86/86 [==============================] - 1s 16ms/step - loss: 0.0029 - mae: 0.0249 - mse: 8.2913e-04 - val_loss: 0.0030 - val_mae: 0.0259 - val_mse: 8.8656e-04 - lr: 0.0025
Epoch 15/50
86/86 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0247 - mse: 8.2228e-04
86/86 [==============================] - 5s 57ms/step - loss: 0.0012 - mae: 0.0247 - mse: 8.2228e-04 - val_loss: 0.0014 - val_mae: 0.0257 - val_mse: 8.6664e-04 - lr: 0.0012
Epoch 16/50
86/86 [==============================] - 1s 17ms/step - loss: 0.0013 - mae: 0.0248 - mse: 8.2479e-04 - val_loss: 0.0014 - val_mae: 0.0260 - val_mse: 8.9125e-04 - lr: 0.0012
Epoch 17/50
85/86 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0247 - mse: 8.2201e-04
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\no_overlap\wandb\run-20230408_183340-oyy3vt5j\files\model-best)... Done. 0.3s
86/86 [==============================] - 5s 58ms/step - loss: 0.0013 - mae: 0.0247 - mse: 8.2295e-04 - val_loss: 0.0014 - val_mae: 0.0257 - val_mse: 8.8157e-04 - lr: 0.0012
Epoch 18/50
86/86 [==============================] - ETA: 0s - loss: 9.1303e-04 - mae: 0.0247 - mse: 8.2342e-04
86/86 [==============================] - 5s 58ms/step - loss: 9.1303e-04 - mae: 0.0247 - mse: 8.2342e-04 - val_loss: 9.9483e-04 - val_mae: 0.0256 - val_mse: 8.6548e-04 - lr: 6.2500e-04
Epoch 19/50
86/86 [==============================] - 1s 13ms/step - loss: 9.5018e-04 - mae: 0.0247 - mse: 8.2144e-04 - val_loss: 9.9542e-04 - val_mae: 0.0256 - val_mse: 8.6581e-04 - lr: 6.2500e-04
Epoch 20/50
86/86 [==============================] - ETA: 0s - loss: 9.5110e-04 - mae: 0.0248 - mse: 8.2216e-04
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.
86/86 [==============================] - 1s 13ms/step - loss: 9.5110e-04 - mae: 0.0248 - mse: 8.2216e-04 - val_loss: 9.9536e-04 - val_mae: 0.0257 - val_mse: 8.6638e-04 - lr: 6.2500e-04
Epoch 21/50
85/86 [============================>.] - ETA: 0s - loss: 8.3976e-04 - mae: 0.0247 - mse: 8.1910e-04
86/86 [==============================] - 4s 51ms/step - loss: 8.4067e-04 - mae: 0.0247 - mse: 8.1998e-04 - val_loss: 9.0352e-04 - val_mae: 0.0256 - val_mse: 8.6545e-04 - lr: 3.1250e-04
Epoch 22/50
85/86 [============================>.] - ETA: 0s - loss: 8.5369e-04 - mae: 0.0247 - mse: 8.2141e-04
86/86 [==============================] - 5s 55ms/step - loss: 8.5325e-04 - mae: 0.0247 - mse: 8.2096e-04 - val_loss: 8.9751e-04 - val_mae: 0.0257 - val_mse: 8.6530e-04 - lr: 3.1250e-04
Epoch 23/50
84/86 [============================>.] - ETA: 0s - loss: 8.5293e-04 - mae: 0.0247 - mse: 8.2070e-04
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.
86/86 [==============================] - 1s 15ms/step - loss: 8.5276e-04 - mae: 0.0247 - mse: 8.2053e-04 - val_loss: 8.9759e-04 - val_mae: 0.0257 - val_mse: 8.6534e-04 - lr: 3.1250e-04
Epoch 24/50
83/86 [===========================>..] - ETA: 0s - loss: 8.2518e-04 - mae: 0.0247 - mse: 8.2037e-04
86/86 [==============================] - 5s 62ms/step - loss: 8.2477e-04 - mae: 0.0247 - mse: 8.1990e-04 - val_loss: 8.7427e-04 - val_mae: 0.0257 - val_mse: 8.6574e-04 - lr: 1.5625e-04
Epoch 25/50
84/86 [============================>.] - ETA: 0s - loss: 8.3007e-04 - mae: 0.0247 - mse: 8.2206e-04
86/86 [==============================] - 5s 54ms/step - loss: 8.2748e-04 - mae: 0.0247 - mse: 8.1947e-04 - val_loss: 8.7353e-04 - val_mae: 0.0256 - val_mse: 8.6546e-04 - lr: 1.5625e-04
Epoch 26/50
85/86 [============================>.] - ETA: 0s - loss: 8.2797e-04 - mae: 0.0247 - mse: 8.1988e-04
Epoch 26: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\no_overlap\wandb\run-20230408_183340-oyy3vt5j\files\model-best)... Done. 0.1s
86/86 [==============================] - 5s 59ms/step - loss: 8.2817e-04 - mae: 0.0247 - mse: 8.2007e-04 - val_loss: 8.7334e-04 - val_mae: 0.0257 - val_mse: 8.6527e-04 - lr: 1.5625e-04
Epoch 27/50
82/86 [===========================>..] - ETA: 0s - loss: 8.1957e-04 - mae: 0.0247 - mse: 8.1845e-04
86/86 [==============================] - 5s 61ms/step - loss: 8.2050e-04 - mae: 0.0247 - mse: 8.1936e-04 - val_loss: 8.6753e-04 - val_mae: 0.0257 - val_mse: 8.6537e-04 - lr: 7.8125e-05
Epoch 28/50
86/86 [==============================] - ETA: 0s - loss: 8.2141e-04 - mae: 0.0247 - mse: 8.1943e-04
86/86 [==============================] - 5s 57ms/step - loss: 8.2141e-04 - mae: 0.0247 - mse: 8.1943e-04 - val_loss: 8.6727e-04 - val_mae: 0.0257 - val_mse: 8.6528e-04 - lr: 7.8125e-05
Epoch 29/50
86/86 [==============================] - ETA: 0s - loss: 8.2159e-04 - mae: 0.0247 - mse: 8.1959e-04
Epoch 29: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.
86/86 [==============================] - 1s 16ms/step - loss: 8.2159e-04 - mae: 0.0247 - mse: 8.1959e-04 - val_loss: 8.6728e-04 - val_mae: 0.0257 - val_mse: 8.6527e-04 - lr: 7.8125e-05
Epoch 30/50
82/86 [===========================>..] - ETA: 0s - loss: 8.1840e-04 - mae: 0.0247 - mse: 8.1813e-04
86/86 [==============================] - 5s 62ms/step - loss: 8.1966e-04 - mae: 0.0247 - mse: 8.1938e-04 - val_loss: 8.6569e-04 - val_mae: 0.0257 - val_mse: 8.6523e-04 - lr: 3.9062e-05
Epoch 31/50
86/86 [==============================] - 1s 17ms/step - loss: 8.1990e-04 - mae: 0.0247 - mse: 8.1941e-04 - val_loss: 8.6576e-04 - val_mae: 0.0257 - val_mse: 8.6527e-04 - lr: 3.9062e-05
Epoch 32/50
83/86 [===========================>..] - ETA: 0s - loss: 8.1903e-04 - mae: 0.0247 - mse: 8.1854e-04
Epoch 32: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.
86/86 [==============================] - 1s 14ms/step - loss: 8.1990e-04 - mae: 0.0247 - mse: 8.1941e-04 - val_loss: 8.6576e-04 - val_mae: 0.0257 - val_mse: 8.6526e-04 - lr: 3.9062e-05
Epoch 33/50

85/86 [============================>.] - ETA: 0s - loss: 8.1920e-04 - mae: 0.0247 - mse: 8.1913e-04
86/86 [==============================] - 6s 66ms/step - loss: 8.1934e-04 - mae: 0.0247 - mse: 8.1928e-04 - val_loss: 8.6536e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 1.9531e-05
Epoch 34/50
86/86 [==============================] - 1s 16ms/step - loss: 8.1942e-04 - mae: 0.0247 - mse: 8.1930e-04 - val_loss: 8.6539e-04 - val_mae: 0.0257 - val_mse: 8.6526e-04 - lr: 1.9531e-05
Epoch 35/50
82/86 [===========================>..] - ETA: 0s - loss: 8.2047e-04 - mae: 0.0247 - mse: 8.2034e-04
Epoch 35: ReduceLROnPlateau reducing learning rate to 1e-05.
86/86 [==============================] - 1s 15ms/step - loss: 8.1942e-04 - mae: 0.0247 - mse: 8.1930e-04 - val_loss: 8.6538e-04 - val_mae: 0.0257 - val_mse: 8.6525e-04 - lr: 1.9531e-05
Epoch 36/50

83/86 [===========================>..] - ETA: 0s - loss: 8.1777e-04 - mae: 0.0247 - mse: 8.1774e-04
86/86 [==============================] - 5s 59ms/step - loss: 8.1926e-04 - mae: 0.0247 - mse: 8.1923e-04 - val_loss: 8.6528e-04 - val_mae: 0.0257 - val_mse: 8.6526e-04 - lr: 1.0000e-05
Epoch 37/50
85/86 [============================>.] - ETA: 0s - loss: 8.1968e-04 - mae: 0.0247 - mse: 8.1965e-04
86/86 [==============================] - 5s 57ms/step - loss: 8.1928e-04 - mae: 0.0247 - mse: 8.1925e-04 - val_loss: 8.6528e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 1.0000e-05
Epoch 38/50
85/86 [============================>.] - ETA: 0s - loss: 8.1842e-04 - mae: 0.0247 - mse: 8.1838e-04
86/86 [==============================] - 5s 58ms/step - loss: 8.1928e-04 - mae: 0.0247 - mse: 8.1925e-04 - val_loss: 8.6527e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 1.0000e-05
Epoch 39/50
82/86 [===========================>..] - ETA: 0s - loss: 8.1889e-04 - mae: 0.0247 - mse: 8.1886e-04
86/86 [==============================] - 5s 60ms/step - loss: 8.1928e-04 - mae: 0.0247 - mse: 8.1925e-04 - val_loss: 8.6527e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 1.0000e-05
Epoch 40/50
86/86 [==============================] - 1s 15ms/step - loss: 8.1928e-04 - mae: 0.0247 - mse: 8.1925e-04 - val_loss: 8.6527e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 1.0000e-05
Epoch 41/50
86/86 [==============================] - 1s 15ms/step - loss: 8.1930e-04 - mae: 0.0247 - mse: 8.1927e-04 - val_loss: 8.6527e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 1.0000e-05
Epoch 42/50
86/86 [==============================] - 1s 15ms/step - loss: 8.1927e-04 - mae: 0.0247 - mse: 8.1923e-04 - val_loss: 8.6527e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 1.0000e-05
Epoch 43/50
84/86 [============================>.] - ETA: 0s - loss: 8.2003e-04 - mae: 0.0247 - mse: 8.2000e-04
86/86 [==============================] - 1s 15ms/step - loss: 8.1927e-04 - mae: 0.0247 - mse: 8.1924e-04 - val_loss: 8.6527e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 1.0000e-05
Epoch 45/50
20/86 [=====>........................] - ETA: 0s - loss: 7.8405e-04 - mae: 0.0241 - mse: 7.8401e-04
85/86 [============================>.] - ETA: 0s - loss: 8.1958e-04 - mae: 0.0247 - mse: 8.1955e-044e-04 - val_loss: 8.6527e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 1.0000e-05
43/86 [==============>...............] - ETA: 0s - loss: 8.1744e-04 - mae: 0.0248 - mse: 8.1741e-045e-04 - val_loss: 8.6528e-04 - val_mae: 0.0257 - val_mse: 8.6525e-04 - lr: 1.0000e-05
10/86 [==>...........................] - ETA: 0s - loss: 8.3575e-04 - mae: 0.0252 - mse: 8.3572e-043e-04 - val_loss: 8.6527e-04 - val_mae: 0.0257 - val_mse: 8.6524e-04 - lr: 1.0000e-05
86/86 [==============================] - 1s 15ms/step - loss: 8.1927e-04 - mae: 0.0247 - mse: 8.1924e-04 - val_loss: 8.6528e-04 - val_mae: 0.0257 - val_mse: 8.6525e-04 - lr: 1.0000e-05
86/86 [==============================] - 1s 15ms/step - loss: 8.1927e-04 - mae: 0.0247 - mse: 8.1924e-04 - val_loss: 8.6528e-04 - val_mae: 0.0257 - val_mse: 8.6525e-04 - lr: 1.0000e-05