Epoch 1/200
229/243 [===========================>..] - ETA: 0s - loss: 0.0287 - mae: 0.0466 - mse: 0.0049
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0028s). Check your callbacks.
243/243 [==============================] - 2s 8ms/step - loss: 0.0272 - mae: 0.0461 - mse: 0.0047 - val_loss: 0.0028 - val_mae: 0.0421 - val_mse: 0.0025 - lr: 0.0384
Epoch 2/200
243/243 [==============================] - 1s 2ms/step - loss: 0.0026 - mae: 0.0393 - mse: 0.0022 - val_loss: 0.0035 - val_mae: 0.0469 - val_mse: 0.0032 - lr: 0.0384
Epoch 3/200
241/243 [============================>.] - ETA: 0s - loss: 0.0024 - mae: 0.0378 - mse: 0.0020
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 7ms/step - loss: 0.0024 - mae: 0.0379 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0357 - val_mse: 0.0017 - lr: 0.0384
Epoch 4/200
243/243 [==============================] - 1s 2ms/step - loss: 0.0021 - mae: 0.0360 - mse: 0.0018 - val_loss: 0.0024 - val_mae: 0.0375 - val_mse: 0.0021 - lr: 0.0384
Epoch 5/200
225/243 [==========================>...] - ETA: 0s - loss: 0.0021 - mae: 0.0353 - mse: 0.0018
243/243 [==============================] - 2s 7ms/step - loss: 0.0021 - mae: 0.0350 - mse: 0.0018 - val_loss: 0.0019 - val_mae: 0.0343 - val_mse: 0.0017 - lr: 0.0384
Epoch 6/200
243/243 [==============================] - 2s 8ms/step - loss: 0.0018 - mae: 0.0322 - mse: 0.0016 - val_loss: 0.0015 - val_mae: 0.0293 - val_mse: 0.0013 - lr: 0.0384
Epoch 7/200
243/243 [==============================] - 1s 2ms/step - loss: 0.0016 - mae: 0.0299 - mse: 0.0014 - val_loss: 0.0022 - val_mae: 0.0351 - val_mse: 0.0018 - lr: 0.0384
Epoch 8/200
243/243 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0277 - mse: 0.0012 - val_loss: 0.0021 - val_mae: 0.0344 - val_mse: 0.0019 - lr: 0.0384
Epoch 9/200
240/243 [============================>.] - ETA: 0s - loss: 0.0015 - mae: 0.0284 - mse: 0.0013
243/243 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0284 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0281 - val_mse: 0.0012 - lr: 0.0384
Epoch 10/200
243/243 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0278 - mse: 0.0013 - val_loss: 0.0021 - val_mae: 0.0326 - val_mse: 0.0017 - lr: 0.0384
Epoch 11/200
243/243 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0273 - mse: 0.0012 - val_loss: 0.0017 - val_mae: 0.0281 - val_mse: 0.0012 - lr: 0.0384
Epoch 12/200
226/243 [==========================>...] - ETA: 0s - loss: 0.0014 - mae: 0.0261 - mse: 0.0011
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 9ms/step - loss: 0.0014 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0384
Epoch 13/200
243/243 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0255 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0236 - val_mse: 9.0052e-04 - lr: 0.0384
Epoch 14/200
243/243 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0255 - mse: 0.0011 - val_loss: 0.0019 - val_mae: 0.0326 - val_mse: 0.0016 - lr: 0.0384
Epoch 15/200
204/243 [========================>.....] - ETA: 0s - loss: 0.0012 - mae: 0.0242 - mse: 9.5980e-04
243/243 [==============================] - 2s 8ms/step - loss: 0.0012 - mae: 0.0243 - mse: 9.6706e-04 - val_loss: 0.0011 - val_mae: 0.0237 - val_mse: 9.1496e-04 - lr: 0.0384
Epoch 16/200
243/243 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0246 - mse: 9.7611e-04 - val_loss: 0.0013 - val_mae: 0.0268 - val_mse: 0.0011 - lr: 0.0384
Epoch 17/200
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0241 - mse: 9.4501e-04 - val_loss: 0.0017 - val_mae: 0.0303 - val_mse: 0.0014 - lr: 0.0384
Epoch 18/200
237/243 [============================>.] - ETA: 0s - loss: 0.0010 - mae: 0.0232 - mse: 8.9107e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0232 - mse: 8.8967e-04 - val_loss: 9.7205e-04 - val_mae: 0.0223 - val_mse: 8.1627e-04 - lr: 0.0384
Epoch 19/200
243/243 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0230 - mse: 8.6835e-04 - val_loss: 0.0011 - val_mae: 0.0244 - val_mse: 9.4175e-04 - lr: 0.0384
Epoch 20/200
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0234 - mse: 8.9411e-04 - val_loss: 0.0011 - val_mae: 0.0241 - val_mse: 9.2876e-04 - lr: 0.0384
Epoch 21/200
243/243 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0243 - mse: 9.5891e-04 - val_loss: 0.0013 - val_mae: 0.0269 - val_mse: 0.0011 - lr: 0.0384
Epoch 22/200
243/243 [==============================] - 2s 7ms/step - loss: 9.4317e-04 - mae: 0.0223 - mse: 8.1477e-04 - val_loss: 9.3288e-04 - val_mae: 0.0220 - val_mse: 7.9684e-04 - lr: 0.0384
Epoch 23/200
243/243 [==============================] - 1s 3ms/step - loss: 9.8801e-04 - mae: 0.0226 - mse: 8.4776e-04 - val_loss: 9.9948e-04 - val_mae: 0.0219 - val_mse: 7.8045e-04 - lr: 0.0384
Epoch 24/200
243/243 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0228 - mse: 8.5714e-04 - val_loss: 0.0012 - val_mae: 0.0264 - val_mse: 0.0011 - lr: 0.0384
Epoch 25/200
243/243 [==============================] - 1s 2ms/step - loss: 9.8779e-04 - mae: 0.0227 - mse: 8.5249e-04 - val_loss: 0.0017 - val_mae: 0.0302 - val_mse: 0.0014 - lr: 0.0384
Epoch 26/200
243/243 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0228 - mse: 8.5739e-04 - val_loss: 0.0016 - val_mae: 0.0291 - val_mse: 0.0013 - lr: 0.0384
Epoch 27/200
228/243 [===========================>..] - ETA: 0s - loss: 9.5142e-04 - mae: 0.0225 - mse: 8.2176e-04
243/243 [==============================] - 2s 7ms/step - loss: 9.4877e-04 - mae: 0.0224 - mse: 8.1470e-04 - val_loss: 8.2837e-04 - val_mae: 0.0210 - val_mse: 7.0487e-04 - lr: 0.0384
Epoch 28/200
243/243 [==============================] - 1s 3ms/step - loss: 9.5528e-04 - mae: 0.0224 - mse: 8.2338e-04 - val_loss: 9.4703e-04 - val_mae: 0.0232 - val_mse: 8.3950e-04 - lr: 0.0384
Epoch 29/200
243/243 [==============================] - 1s 3ms/step - loss: 9.4351e-04 - mae: 0.0219 - mse: 7.9507e-04 - val_loss: 0.0016 - val_mae: 0.0313 - val_mse: 0.0015 - lr: 0.0384
Epoch 30/200
243/243 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0227 - mse: 8.4514e-04 - val_loss: 9.5357e-04 - val_mae: 0.0218 - val_mse: 7.7615e-04 - lr: 0.0384
Epoch 31/200
243/243 [==============================] - 1s 3ms/step - loss: 9.0494e-04 - mae: 0.0219 - mse: 7.8143e-04 - val_loss: 8.8614e-04 - val_mae: 0.0216 - val_mse: 7.6333e-04 - lr: 0.0384
Epoch 32/200
231/243 [===========================>..] - ETA: 0s - loss: 9.1853e-04 - mae: 0.0221 - mse: 7.9050e-04
243/243 [==============================] - 2s 7ms/step - loss: 9.1863e-04 - mae: 0.0221 - mse: 7.9097e-04 - val_loss: 8.0306e-04 - val_mae: 0.0206 - val_mse: 6.8998e-04 - lr: 0.0384
Epoch 33/200
243/243 [==============================] - 1s 3ms/step - loss: 9.1721e-04 - mae: 0.0219 - mse: 7.8219e-04 - val_loss: 9.7114e-04 - val_mae: 0.0206 - val_mse: 6.8762e-04 - lr: 0.0384
Epoch 34/200
243/243 [==============================] - 1s 2ms/step - loss: 9.2392e-04 - mae: 0.0219 - mse: 7.8098e-04 - val_loss: 8.8365e-04 - val_mae: 0.0229 - val_mse: 8.0824e-04 - lr: 0.0384
Epoch 35/200
243/243 [==============================] - 1s 3ms/step - loss: 9.0018e-04 - mae: 0.0220 - mse: 7.8084e-04 - val_loss: 8.2464e-04 - val_mae: 0.0211 - val_mse: 7.0238e-04 - lr: 0.0384
Epoch 36/200
243/243 [==============================] - 1s 3ms/step - loss: 8.8253e-04 - mae: 0.0214 - mse: 7.5556e-04 - val_loss: 8.1385e-04 - val_mae: 0.0207 - val_mse: 7.1062e-04 - lr: 0.0384
Epoch 37/200
243/243 [==============================] - 1s 3ms/step - loss: 9.1962e-04 - mae: 0.0217 - mse: 7.5921e-04 - val_loss: 9.4768e-04 - val_mae: 0.0217 - val_mse: 7.7665e-04 - lr: 0.0384
Epoch 38/200
243/243 [==============================] - 1s 3ms/step - loss: 9.2102e-04 - mae: 0.0217 - mse: 7.6484e-04 - val_loss: 8.0671e-04 - val_mae: 0.0206 - val_mse: 6.8543e-04 - lr: 0.0384
Epoch 39/200
233/243 [===========================>..] - ETA: 0s - loss: 9.4562e-04 - mae: 0.0218 - mse: 7.8446e-04
243/243 [==============================] - 2s 7ms/step - loss: 9.4426e-04 - mae: 0.0217 - mse: 7.7909e-04 - val_loss: 7.8828e-04 - val_mae: 0.0207 - val_mse: 6.9330e-04 - lr: 0.0384
Epoch 40/200
243/243 [==============================] - 1s 3ms/step - loss: 8.6019e-04 - mae: 0.0211 - mse: 7.2663e-04 - val_loss: 8.3649e-04 - val_mae: 0.0215 - val_mse: 7.6507e-04 - lr: 0.0384
Epoch 41/200
243/243 [==============================] - 1s 3ms/step - loss: 8.7638e-04 - mae: 0.0211 - mse: 7.3011e-04 - val_loss: 8.1674e-04 - val_mae: 0.0210 - val_mse: 7.2883e-04 - lr: 0.0384
Epoch 42/200
228/243 [===========================>..] - ETA: 0s - loss: 8.9325e-04 - mae: 0.0215 - mse: 7.4998e-04
Epoch 42: ReduceLROnPlateau reducing learning rate to 0.019185075536370277.
243/243 [==============================] - 1s 2ms/step - loss: 9.0106e-04 - mae: 0.0216 - mse: 7.5812e-04 - val_loss: 0.0014 - val_mae: 0.0280 - val_mse: 0.0012 - lr: 0.0384
Epoch 43/200
243/243 [==============================] - 1s 3ms/step - loss: 8.1503e-04 - mae: 0.0210 - mse: 7.1426e-04 - val_loss: 9.1371e-04 - val_mae: 0.0221 - val_mse: 8.0661e-04 - lr: 0.0192
Epoch 44/200
231/243 [===========================>..] - ETA: 0s - loss: 8.0655e-04 - mae: 0.0208 - mse: 7.1821e-04
243/243 [==============================] - 2s 8ms/step - loss: 8.1040e-04 - mae: 0.0208 - mse: 7.1932e-04 - val_loss: 7.4665e-04 - val_mae: 0.0199 - val_mse: 6.2655e-04 - lr: 0.0192
Epoch 45/200
243/243 [==============================] - 1s 3ms/step - loss: 7.9657e-04 - mae: 0.0207 - mse: 7.0641e-04 - val_loss: 8.1863e-04 - val_mae: 0.0223 - val_mse: 7.6853e-04 - lr: 0.0192
Epoch 46/200
231/243 [===========================>..] - ETA: 0s - loss: 7.8443e-04 - mae: 0.0206 - mse: 6.9490e-04
243/243 [==============================] - 2s 7ms/step - loss: 7.8512e-04 - mae: 0.0206 - mse: 6.9690e-04 - val_loss: 7.4516e-04 - val_mae: 0.0201 - val_mse: 6.6767e-04 - lr: 0.0192
Epoch 47/200
243/243 [==============================] - 0s 2ms/step - loss: 7.8577e-04 - mae: 0.0206 - mse: 6.9774e-04 - val_loss: 7.7096e-04 - val_mae: 0.0203 - val_mse: 6.8521e-04 - lr: 0.0192
Epoch 48/200
243/243 [==============================] - 1s 2ms/step - loss: 7.8056e-04 - mae: 0.0207 - mse: 6.9530e-04 - val_loss: 9.5969e-04 - val_mae: 0.0233 - val_mse: 8.7525e-04 - lr: 0.0192
Epoch 49/200
243/243 [==============================] - 1s 3ms/step - loss: 7.7927e-04 - mae: 0.0207 - mse: 6.8836e-04 - val_loss: 9.7352e-04 - val_mae: 0.0233 - val_mse: 8.7758e-04 - lr: 0.0192
Epoch 50/200
243/243 [==============================] - 1s 2ms/step - loss: 7.6882e-04 - mae: 0.0203 - mse: 6.7494e-04 - val_loss: 8.9889e-04 - val_mae: 0.0235 - val_mse: 8.4634e-04 - lr: 0.0192
Epoch 51/200
225/243 [==========================>...] - ETA: 0s - loss: 8.0872e-04 - mae: 0.0209 - mse: 7.0951e-04
243/243 [==============================] - 0s 2ms/step - loss: 8.0927e-04 - mae: 0.0206 - mse: 6.9719e-04 - val_loss: 7.8733e-04 - val_mae: 0.0207 - val_mse: 6.6724e-04 - lr: 0.0192
Epoch 52/200
206/243 [========================>.....] - ETA: 0s - loss: 7.9787e-04 - mae: 0.0206 - mse: 6.9448e-04
Epoch 52: ReduceLROnPlateau reducing learning rate to 0.009592537768185139.
243/243 [==============================] - 0s 2ms/step - loss: 8.0927e-04 - mae: 0.0206 - mse: 6.9719e-04 - val_loss: 7.8733e-04 - val_mae: 0.0207 - val_mse: 6.6724e-04 - lr: 0.0192
Epoch 53/200
229/243 [===========================>..] - ETA: 0s - loss: 7.3026e-04 - mae: 0.0199 - mse: 6.4889e-04
243/243 [==============================] - 2s 7ms/step - loss: 7.3756e-04 - mae: 0.0200 - mse: 6.5543e-04 - val_loss: 7.1859e-04 - val_mae: 0.0200 - val_mse: 6.2900e-04 - lr: 0.0096
Epoch 54/200
217/243 [=========================>....] - ETA: 0s - loss: 7.1461e-04 - mae: 0.0198 - mse: 6.4672e-04
243/243 [==============================] - 2s 7ms/step - loss: 7.3756e-04 - mae: 0.0200 - mse: 6.5543e-04 - val_loss: 7.1859e-04 - val_mae: 0.0200 - val_mse: 6.2900e-04 - lr: 0.0096
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
215/243 [=========================>....] - ETA: 0s - loss: 7.1424e-04 - mae: 0.0198 - mse: 6.4141e-04e-04 - val_loss: 6.9991e-04 - val_mae: 0.0201 - val_mse: 6.4899e-04 - lr: 0.0096
215/243 [=========================>....] - ETA: 0s - loss: 7.1424e-04 - mae: 0.0198 - mse: 6.4141e-04e-04 - val_loss: 6.9991e-04 - val_mae: 0.0201 - val_mse: 6.4899e-04 - lr: 0.0096
243/243 [==============================] - 2s 7ms/step - loss: 7.1530e-04 - mae: 0.0198 - mse: 6.4373e-04 - val_loss: 6.8350e-04 - val_mae: 0.0198 - val_mse: 6.3111e-04 - lr: 0.0096
243/243 [==============================] - 2s 7ms/step - loss: 7.1530e-04 - mae: 0.0198 - mse: 6.4373e-04 - val_loss: 6.8350e-04 - val_mae: 0.0198 - val_mse: 6.3111e-04 - lr: 0.0096
222/243 [==========================>...] - ETA: 0s - loss: 7.1989e-04 - mae: 0.0198 - mse: 6.4837e-04e-04 - val_loss: 6.8350e-04 - val_mae: 0.0198 - val_mse: 6.3111e-04 - lr: 0.0096
222/243 [==========================>...] - ETA: 0s - loss: 7.1989e-04 - mae: 0.0198 - mse: 6.4837e-04e-04 - val_loss: 6.8350e-04 - val_mae: 0.0198 - val_mse: 6.3111e-04 - lr: 0.0096
243/243 [==============================] - 1s 3ms/step - loss: 6.8580e-04 - mae: 0.0195 - mse: 6.2771e-04 - val_loss: 7.0334e-04 - val_mae: 0.0203 - val_mse: 6.4508e-04 - lr: 0.0048
243/243 [==============================] - 1s 3ms/step - loss: 6.8580e-04 - mae: 0.0195 - mse: 6.2771e-04 - val_loss: 7.0334e-04 - val_mae: 0.0203 - val_mse: 6.4508e-04 - lr: 0.0048
243/243 [==============================] - 1s 3ms/step - loss: 6.8235e-04 - mae: 0.0194 - mse: 6.2578e-04 - val_loss: 6.7259e-04 - val_mae: 0.0194 - val_mse: 6.1939e-04 - lr: 0.0048
243/243 [==============================] - 1s 3ms/step - loss: 6.8235e-04 - mae: 0.0194 - mse: 6.2578e-04 - val_loss: 6.7259e-04 - val_mae: 0.0194 - val_mse: 6.1939e-04 - lr: 0.0048
243/243 [==============================] - 1s 3ms/step - loss: 6.7566e-04 - mae: 0.0194 - mse: 6.2048e-04 - val_loss: 6.7192e-04 - val_mae: 0.0197 - val_mse: 6.2060e-04 - lr: 0.0048
243/243 [==============================] - 1s 3ms/step - loss: 6.7566e-04 - mae: 0.0194 - mse: 6.2048e-04 - val_loss: 6.7192e-04 - val_mae: 0.0197 - val_mse: 6.2060e-04 - lr: 0.0048
243/243 [==============================] - 1s 3ms/step - loss: 6.6591e-04 - mae: 0.0192 - mse: 6.1151e-04 - val_loss: 6.6218e-04 - val_mae: 0.0195 - val_mse: 6.0856e-04 - lr: 0.0024
Epoch 76/200
220/243 [==========================>...] - ETA: 0s - loss: 6.6603e-04 - mae: 0.0193 - mse: 6.1350e-04
231/243 [===========================>..] - ETA: 0s - loss: 6.6666e-04 - mae: 0.0193 - mse: 6.1367e-04e-04 - val_loss: 6.6218e-04 - val_mae: 0.0195 - val_mse: 6.0856e-04 - lr: 0.0024
231/243 [===========================>..] - ETA: 0s - loss: 6.6666e-04 - mae: 0.0193 - mse: 6.1367e-04e-04 - val_loss: 6.6218e-04 - val_mae: 0.0195 - val_mse: 6.0856e-04 - lr: 0.0024
216/243 [=========================>....] - ETA: 0s - loss: 6.5762e-04 - mae: 0.0191 - mse: 6.0503e-04e-04 - val_loss: 6.5811e-04 - val_mae: 0.0192 - val_mse: 6.0018e-04 - lr: 0.0024
216/243 [=========================>....] - ETA: 0s - loss: 6.5762e-04 - mae: 0.0191 - mse: 6.0503e-04e-04 - val_loss: 6.5811e-04 - val_mae: 0.0192 - val_mse: 6.0018e-04 - lr: 0.0024
243/243 [==============================] - 2s 7ms/step - loss: 6.6388e-04 - mae: 0.0193 - mse: 6.1181e-04 - val_loss: 6.5494e-04 - val_mae: 0.0192 - val_mse: 6.0442e-04 - lr: 0.0024
243/243 [==============================] - 2s 7ms/step - loss: 6.6388e-04 - mae: 0.0193 - mse: 6.1181e-04 - val_loss: 6.5494e-04 - val_mae: 0.0192 - val_mse: 6.0442e-04 - lr: 0.0024
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 3ms/step - loss: 6.5826e-04 - mae: 0.0191 - mse: 6.0531e-04 - val_loss: 6.5553e-04 - val_mae: 0.0191 - val_mse: 5.9825e-04 - lr: 0.0012
243/243 [==============================] - 1s 3ms/step - loss: 6.5826e-04 - mae: 0.0191 - mse: 6.0531e-04 - val_loss: 6.5553e-04 - val_mae: 0.0191 - val_mse: 5.9825e-04 - lr: 0.0012
243/243 [==============================] - 1s 3ms/step - loss: 6.5826e-04 - mae: 0.0191 - mse: 6.0531e-04 - val_loss: 6.5553e-04 - val_mae: 0.0191 - val_mse: 5.9825e-04 - lr: 0.0012
243/243 [==============================] - 1s 3ms/step - loss: 6.5668e-04 - mae: 0.0191 - mse: 6.0779e-04 - val_loss: 6.8890e-04 - val_mae: 0.0195 - val_mse: 6.3321e-04 - lr: 0.0012
243/243 [==============================] - 1s 3ms/step - loss: 6.5668e-04 - mae: 0.0191 - mse: 6.0779e-04 - val_loss: 6.8890e-04 - val_mae: 0.0195 - val_mse: 6.3321e-04 - lr: 0.0012
243/243 [==============================] - 1s 2ms/step - loss: 6.4718e-04 - mae: 0.0190 - mse: 5.9910e-04 - val_loss: 6.6699e-04 - val_mae: 0.0193 - val_mse: 6.1518e-04 - lr: 5.9953e-04
Epoch 95/200
234/243 [===========================>..] - ETA: 0s - loss: 6.4381e-04 - mae: 0.0189 - mse: 5.9392e-04
243/243 [==============================] - 1s 2ms/step - loss: 6.4718e-04 - mae: 0.0190 - mse: 5.9910e-04 - val_loss: 6.6699e-04 - val_mae: 0.0193 - val_mse: 6.1518e-04 - lr: 5.9953e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 3ms/step - loss: 6.4696e-04 - mae: 0.0190 - mse: 5.9693e-04 - val_loss: 6.4736e-04 - val_mae: 0.0192 - val_mse: 6.0059e-04 - lr: 5.9953e-04
Epoch 98/200
238/243 [============================>.] - ETA: 0s - loss: 6.4376e-04 - mae: 0.0189 - mse: 5.9631e-04
243/243 [==============================] - 1s 3ms/step - loss: 6.4810e-04 - mae: 0.0190 - mse: 5.9838e-04 - val_loss: 6.8971e-04 - val_mae: 0.0196 - val_mse: 6.3978e-04 - lr: 5.9953e-04
Epoch 101/200
243/243 [==============================] - 1s 3ms/step - loss: 6.4333e-04 - mae: 0.0189 - mse: 5.9499e-04 - val_loss: 6.4764e-04 - val_mae: 0.0192 - val_mse: 6.0155e-04 - lr: 5.9953e-04
Epoch 102/200
221/243 [==========================>...] - ETA: 0s - loss: 6.5187e-04 - mae: 0.0191 - mse: 6.0437e-04
Epoch 102: ReduceLROnPlateau reducing learning rate to 0.0002997668052557856.
243/243 [==============================] - 1s 3ms/step - loss: 6.4810e-04 - mae: 0.0190 - mse: 5.9838e-04 - val_loss: 6.8971e-04 - val_mae: 0.0196 - val_mse: 6.3978e-04 - lr: 5.9953e-04
243/243 [==============================] - 2s 7ms/step - loss: 6.4913e-04 - mae: 0.0191 - mse: 6.0161e-04 - val_loss: 6.4403e-04 - val_mae: 0.0192 - val_mse: 5.9541e-04 - lr: 5.9953e-04
Epoch 103/200
243/243 [==============================] - 1s 3ms/step - loss: 6.4424e-04 - mae: 0.0189 - mse: 5.9559e-04 - val_loss: 6.4855e-04 - val_mae: 0.0191 - val_mse: 5.9949e-04 - lr: 2.9977e-04
Epoch 104/200
232/243 [===========================>..] - ETA: 0s - loss: 6.4612e-04 - mae: 0.0190 - mse: 5.9640e-04
243/243 [==============================] - 2s 7ms/step - loss: 6.4913e-04 - mae: 0.0191 - mse: 6.0161e-04 - val_loss: 6.4403e-04 - val_mae: 0.0192 - val_mse: 5.9541e-04 - lr: 5.9953e-04
235/243 [============================>.] - ETA: 0s - loss: 6.4806e-04 - mae: 0.0190 - mse: 5.9995e-04e-04 - val_loss: 6.4403e-04 - val_mae: 0.0192 - val_mse: 5.9541e-04 - lr: 5.9953e-04
235/243 [============================>.] - ETA: 0s - loss: 6.4806e-04 - mae: 0.0190 - mse: 5.9995e-04e-04 - val_loss: 6.4403e-04 - val_mae: 0.0192 - val_mse: 5.9541e-04 - lr: 5.9953e-04
234/243 [===========================>..] - ETA: 0s - loss: 6.4025e-04 - mae: 0.0188 - mse: 5.9069e-04e-04 - val_loss: 6.4382e-04 - val_mae: 0.0192 - val_mse: 5.9667e-04 - lr: 2.9977e-04
234/243 [===========================>..] - ETA: 0s - loss: 6.4025e-04 - mae: 0.0188 - mse: 5.9069e-04e-04 - val_loss: 6.4382e-04 - val_mae: 0.0192 - val_mse: 5.9667e-04 - lr: 2.9977e-04
243/243 [==============================] - 1s 2ms/step - loss: 6.4168e-04 - mae: 0.0189 - mse: 5.9238e-04 - val_loss: 6.5576e-04 - val_mae: 0.0191 - val_mse: 6.0554e-04 - lr: 2.9977e-04
Epoch 112/200
228/243 [===========================>..] - ETA: 0s - loss: 6.4249e-04 - mae: 0.0189 - mse: 5.9415e-04
Epoch 112: ReduceLROnPlateau reducing learning rate to 0.0001498834026278928.
243/243 [==============================] - 1s 2ms/step - loss: 6.4168e-04 - mae: 0.0189 - mse: 5.9238e-04 - val_loss: 6.5576e-04 - val_mae: 0.0191 - val_mse: 6.0554e-04 - lr: 2.9977e-04
243/243 [==============================] - 1s 3ms/step - loss: 6.4267e-04 - mae: 0.0189 - mse: 5.9493e-04 - val_loss: 6.4546e-04 - val_mae: 0.0191 - val_mse: 5.9700e-04 - lr: 1.4988e-04
Epoch 114/200
243/243 [==============================] - 1s 3ms/step - loss: 6.4167e-04 - mae: 0.0189 - mse: 5.9318e-04 - val_loss: 6.4396e-04 - val_mae: 0.0191 - val_mse: 5.9575e-04 - lr: 1.4988e-04
Epoch 115/200
231/243 [===========================>..] - ETA: 0s - loss: 6.3342e-04 - mae: 0.0188 - mse: 5.8513e-04
243/243 [==============================] - 1s 3ms/step - loss: 6.4267e-04 - mae: 0.0189 - mse: 5.9493e-04 - val_loss: 6.4546e-04 - val_mae: 0.0191 - val_mse: 5.9700e-04 - lr: 1.4988e-04
243/243 [==============================] - 1s 3ms/step - loss: 6.4091e-04 - mae: 0.0189 - mse: 5.9264e-04 - val_loss: 6.4544e-04 - val_mae: 0.0191 - val_mse: 5.9665e-04 - lr: 1.4988e-04
Epoch 117/200
243/243 [==============================] - 1s 3ms/step - loss: 6.4128e-04 - mae: 0.0189 - mse: 5.9321e-04 - val_loss: 6.4857e-04 - val_mae: 0.0191 - val_mse: 5.9957e-04 - lr: 1.4988e-04
Epoch 118/200
243/243 [==============================] - 1s 3ms/step - loss: 6.4146e-04 - mae: 0.0189 - mse: 5.9313e-04 - val_loss: 6.4320e-04 - val_mae: 0.0191 - val_mse: 5.9532e-04 - lr: 1.4988e-04
Epoch 119/200
243/243 [==============================] - 1s 3ms/step - loss: 6.4091e-04 - mae: 0.0189 - mse: 5.9264e-04 - val_loss: 6.4544e-04 - val_mae: 0.0191 - val_mse: 5.9665e-04 - lr: 1.4988e-04
Epoch 120/200
243/243 [==============================] - 1s 3ms/step - loss: 6.4198e-04 - mae: 0.0189 - mse: 5.9349e-04 - val_loss: 6.4425e-04 - val_mae: 0.0191 - val_mse: 5.9620e-04 - lr: 1.4988e-04
Epoch 121/200
243/243 [==============================] - 1s 3ms/step - loss: 6.4136e-04 - mae: 0.0189 - mse: 5.9295e-04 - val_loss: 6.4660e-04 - val_mae: 0.0191 - val_mse: 5.9772e-04 - lr: 1.4988e-04
Epoch 122/200
224/243 [==========================>...] - ETA: 0s - loss: 6.4711e-04 - mae: 0.0190 - mse: 5.9914e-04
Epoch 122: ReduceLROnPlateau reducing learning rate to 7.49417013139464e-05.
243/243 [==============================] - 1s 3ms/step - loss: 6.4145e-04 - mae: 0.0189 - mse: 5.9351e-04 - val_loss: 6.4370e-04 - val_mae: 0.0191 - val_mse: 5.9563e-04 - lr: 1.4988e-04
Epoch 123/200
243/243 [==============================] - 1s 3ms/step - loss: 6.4122e-04 - mae: 0.0189 - mse: 5.9281e-04 - val_loss: 6.4290e-04 - val_mae: 0.0191 - val_mse: 5.9509e-04 - lr: 7.4942e-05
Epoch 124/200
233/243 [===========================>..] - ETA: 0s - loss: 6.4238e-04 - mae: 0.0189 - mse: 5.9408e-04
243/243 [==============================] - 1s 3ms/step - loss: 6.4078e-04 - mae: 0.0189 - mse: 5.9258e-04 - val_loss: 6.4619e-04 - val_mae: 0.0191 - val_mse: 5.9743e-04 - lr: 7.4942e-05
Epoch 126/200
243/243 [==============================] - 1s 2ms/step - loss: 6.4057e-04 - mae: 0.0189 - mse: 5.9224e-04 - val_loss: 6.4405e-04 - val_mae: 0.0191 - val_mse: 5.9588e-04 - lr: 7.4942e-05
Epoch 127/200
243/243 [==============================] - 1s 3ms/step - loss: 6.4020e-04 - mae: 0.0189 - mse: 5.9224e-04 - val_loss: 6.5013e-04 - val_mae: 0.0191 - val_mse: 6.0085e-04 - lr: 7.4942e-05
Epoch 128/200
 69/243 [=======>......................] - ETA: 0s - loss: 6.6996e-04 - mae: 0.0194 - mse: 6.2168e-04
243/243 [==============================] - 1s 3ms/step - loss: 6.4034e-04 - mae: 0.0189 - mse: 5.9199e-04 - val_loss: 6.4666e-04 - val_mae: 0.0191 - val_mse: 5.9789e-04 - lr: 7.4942e-05
Epoch 131/200
169/243 [===================>..........] - ETA: 0s - loss: 6.4589e-04 - mae: 0.0189 - mse: 5.9776e-04
189/243 [======================>.......] - ETA: 0s - loss: 6.3613e-04 - mae: 0.0188 - mse: 5.8812e-04e-04 - val_loss: 6.4666e-04 - val_mae: 0.0191 - val_mse: 5.9789e-04 - lr: 7.4942e-05
243/243 [==============================] - 1s 3ms/step - loss: 6.4029e-04 - mae: 0.0189 - mse: 5.9220e-04 - val_loss: 6.4491e-04 - val_mae: 0.0191 - val_mse: 5.9631e-04 - lr: 3.7471e-05
243/243 [==============================] - 1s 3ms/step - loss: 6.4001e-04 - mae: 0.0189 - mse: 5.9191e-04 - val_loss: 6.4479e-04 - val_mae: 0.0191 - val_mse: 5.9631e-04 - lr: 3.7471e-05
243/243 [==============================] - 1s 3ms/step - loss: 6.3974e-04 - mae: 0.0189 - mse: 5.9118e-04 - val_loss: 6.4352e-04 - val_mae: 0.0191 - val_mse: 5.9532e-04 - lr: 1.8735e-05
 88/243 [=========>....................] - ETA: 0s - loss: 6.7017e-04 - mae: 0.0193 - mse: 6.2192e-04e-04 - val_loss: 6.4352e-04 - val_mae: 0.0191 - val_mse: 5.9532e-04 - lr: 1.8735e-05
243/243 [==============================] - 1s 2ms/step - loss: 6.3973e-04 - mae: 0.0189 - mse: 5.9149e-04 - val_loss: 6.4356e-04 - val_mae: 0.0191 - val_mse: 5.9530e-04 - lr: 1.8735e-05
243/243 [==============================] - 1s 2ms/step - loss: 6.3969e-04 - mae: 0.0189 - mse: 5.9141e-04 - val_loss: 6.4351e-04 - val_mae: 0.0191 - val_mse: 5.9521e-04 - lr: 1.8735e-05
243/243 [==============================] - 1s 2ms/step - loss: 6.3967e-04 - mae: 0.0189 - mse: 5.9140e-04 - val_loss: 6.4342e-04 - val_mae: 0.0191 - val_mse: 5.9513e-04 - lr: 1.0000e-05
243/243 [==============================] - 1s 2ms/step - loss: 6.3967e-04 - mae: 0.0189 - mse: 5.9140e-04 - val_loss: 6.4342e-04 - val_mae: 0.0191 - val_mse: 5.9513e-04 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 6.3961e-04 - mae: 0.0189 - mse: 5.9125e-04 - val_loss: 6.4352e-04 - val_mae: 0.0191 - val_mse: 5.9520e-04 - lr: 1.0000e-05
231/243 [===========================>..] - ETA: 0s - loss: 6.3581e-04 - mae: 0.0188 - mse: 5.8754e-04e-04 - val_loss: 6.4352e-04 - val_mae: 0.0191 - val_mse: 5.9520e-04 - lr: 1.0000e-05
243/243 [==============================] - 1s 2ms/step - loss: 6.3960e-04 - mae: 0.0189 - mse: 5.9133e-04 - val_loss: 6.4346e-04 - val_mae: 0.0191 - val_mse: 5.9514e-04 - lr: 1.0000e-05
243/243 [==============================] - 1s 2ms/step - loss: 6.3964e-04 - mae: 0.0189 - mse: 5.9129e-04 - val_loss: 6.4336e-04 - val_mae: 0.0191 - val_mse: 5.9507e-04 - lr: 1.0000e-05
237/243 [============================>.] - ETA: 0s - loss: 6.4093e-04 - mae: 0.0189 - mse: 5.9251e-04e-04 - val_loss: 6.4336e-04 - val_mae: 0.0191 - val_mse: 5.9507e-04 - lr: 1.0000e-05
243/243 [==============================] - 0s 2ms/step - loss: 6.3959e-04 - mae: 0.0189 - mse: 5.9117e-04 - val_loss: 6.4340e-04 - val_mae: 0.0191 - val_mse: 5.9507e-04 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 6.3955e-04 - mae: 0.0189 - mse: 5.9126e-04 - val_loss: 6.4345e-04 - val_mae: 0.0191 - val_mse: 5.9513e-04 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 6.3955e-04 - mae: 0.0189 - mse: 5.9126e-04 - val_loss: 6.4345e-04 - val_mae: 0.0191 - val_mse: 5.9513e-04 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 6.3952e-04 - mae: 0.0189 - mse: 5.9123e-04 - val_loss: 6.4338e-04 - val_mae: 0.0191 - val_mse: 5.9508e-04 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 6.3950e-04 - mae: 0.0189 - mse: 5.9114e-04 - val_loss: 6.4337e-04 - val_mae: 0.0191 - val_mse: 5.9506e-04 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 6.3950e-04 - mae: 0.0189 - mse: 5.9114e-04 - val_loss: 6.4337e-04 - val_mae: 0.0191 - val_mse: 5.9506e-04 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 6.3952e-04 - mae: 0.0189 - mse: 5.9118e-04 - val_loss: 6.4337e-04 - val_mae: 0.0191 - val_mse: 5.9506e-04 - lr: 1.0000e-05
243/243 [==============================] - 1s 3ms/step - loss: 6.3952e-04 - mae: 0.0189 - mse: 5.9118e-04 - val_loss: 6.4337e-04 - val_mae: 0.0191 - val_mse: 5.9506e-04 - lr: 1.0000e-05
323/323 [==============================] - 2s 3ms/step - loss: 0.0199 - mae: 0.0541 - mse: 0.0044 - val_loss: 0.0037 - val_mae: 0.0489 - val_mse: 0.0033 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 2s 3ms/step - loss: 0.0199 - mae: 0.0541 - mse: 0.0044 - val_loss: 0.0037 - val_mae: 0.0489 - val_mse: 0.0033 - lr: 0.0384-04 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_end` time: 0.0030s). Check your callbacks.
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
323/323 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 98/200===========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 98/200===========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 98/200===========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 98/200===========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 98/200===========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 98/200===========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 98/200===========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 117/200==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 117/200==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 117/200==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 129/200==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 134/200==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 138/200==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 143/200==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 147/200==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 152/200==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 157/200==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 162/200==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 167/200==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 172/200==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 182/200==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 182/200==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 192/200==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 197/200==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 1/20000==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 1/20000==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0007s vs `on_train_batch_end` time: 0.0027s). Check your callbacks.
Epoch 11/2000==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 16/2000==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 20/2000==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 25/2000==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 30/2000==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 34/2000==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 39/2000==========================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 43: ReduceLROnPlateau reducing learning rate to 0.004796268884092569.: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 48/200duceLROnPlateau reducing learning rate to 0.004796268884092569.: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 57/200duceLROnPlateau reducing learning rate to 0.004796268884092569.: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 62/200duceLROnPlateau reducing learning rate to 0.004796268884092569.: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 66/200duceLROnPlateau reducing learning rate to 0.004796268884092569.: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 71/200duceLROnPlateau reducing learning rate to 0.004796268884092569.: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 80/200duceLROnPlateau reducing learning rate to 0.004796268884092569.: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 84/200duceLROnPlateau reducing learning rate to 0.004796268884092569.: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 89/200duceLROnPlateau reducing learning rate to 0.004796268884092569.: 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 98/200duceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 103/200uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 107/200uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 112/200uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 116/200uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 125/200uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 130/200uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 139/200uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 139/200uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 144/200uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 149/200uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 154/200uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 159/200uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 164/200uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 169/200uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 174/200uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 179/200uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 184/200uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 189/200uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 194/200uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 199/200uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 3/20000uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 3/20000uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 8/20000uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 13/2000uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 18/2000uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 23/2000uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 28/2000uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 32/2000uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 41/2000uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 46/2000uceLROnPlateau reducing learning rate to 0.0001498834026278928. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 50: ReduceLROnPlateau reducing learning rate to 0.004796268884092569.. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 55/200duceLROnPlateau reducing learning rate to 0.004796268884092569.. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 64/200duceLROnPlateau reducing learning rate to 0.004796268884092569.. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 69/200duceLROnPlateau reducing learning rate to 0.004796268884092569.. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 73/200duceLROnPlateau reducing learning rate to 0.004796268884092569.. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 82/200duceLROnPlateau reducing learning rate to 0.004796268884092569.. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 87/200duceLROnPlateau reducing learning rate to 0.004796268884092569.. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 91/200duceLROnPlateau reducing learning rate to 0.004796268884092569.. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 96/200duceLROnPlateau reducing learning rate to 0.004796268884092569.. 0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 100: ReduceLROnPlateau reducing learning rate to 0.0001498834026278928.0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 105/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 110/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 119/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 123/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 128/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 132/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 141/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
160/243 [==================>...........] - ETA: 0s - loss: 8.1673e-04 - mae: 0.0219 - mse: 7.8039e-04
Epoch 146/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
197/243 [=======================>......] - ETA: 0s - loss: 8.2877e-04 - mae: 0.0221 - mse: 7.9257e-04
Epoch 151/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
210/243 [========================>.....] - ETA: 0s - loss: 8.3463e-04 - mae: 0.0222 - mse: 7.9844e-04
Epoch 156/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
 45/243 [====>.........................] - ETA: 0s - loss: 8.0988e-04 - mae: 0.0218 - mse: 7.7362e-04
Epoch 161/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
 34/243 [===>..........................] - ETA: 0s - loss: 8.5168e-04 - mae: 0.0225 - mse: 8.1550e-04
Epoch 161/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 166/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 176/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
203/243 [========================>.....] - ETA: 0s - loss: 8.1779e-04 - mae: 0.0220 - mse: 7.8170e-04
Epoch 181/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
  1/243 [..............................] - ETA: 0s - loss: 0.0010 - mae: 0.0236 - mse: 9.7473e-04
Epoch 186/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
  1/243 [..............................] - ETA: 0s - loss: 6.9613e-04 - mae: 0.0204 - mse: 6.5997e-04
Epoch 191/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
193/243 [======================>.......] - ETA: 0s - loss: 8.1246e-04 - mae: 0.0218 - mse: 7.7624e-04
Epoch 196/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.0.0323 - mse: 0.0017 - val_loss: 0.0020 - val_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
243/243 [==============================] - 0s 2ms/step - loss: 8.2757e-04 - mae: 0.0221 - mse: 7.9138e-04 - val_loss: 8.4086e-04 - val_mae: 0.0225 - val_mse: 8.0478e-04 - lr: 1.0000e-05
Epoch 197/200
 85/243 [=========>....................] - ETA: 0s - loss: 8.2595e-04 - mae: 0.0221 - mse: 7.8983e-04
>Saved ../trained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_4.h5l_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
>Saved ../trained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_4.h5l_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_4.h5l_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 5/200rained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_4.h5l_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
Epoch 14/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_4.h5l_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
191/243 [======================>.......] - ETA: 0s - loss: 0.0015 - mae: 0.0303 - mse: 0.0014
Epoch 19/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_4.h5l_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0286 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0279 - val_mse: 0.0012 - lr: 0.0192
Epoch 20/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0287 - mse: 0.0012 - val_loss: 0.0016 - val_mae: 0.0333 - val_mse: 0.0015 - lr: 0.0192
Epoch 21/200
  1/243 [..............................] - ETA: 0s - loss: 0.0017 - mae: 0.0356 - mse: 0.0016
Epoch 24/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_4.h5l_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
225/243 [==========================>...] - ETA: 0s - loss: 0.0013 - mae: 0.0285 - mse: 0.0012
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.009592537768185139.
243/243 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0286 - mse: 0.0012 - val_loss: 0.0014 - val_mae: 0.0279 - val_mse: 0.0012 - lr: 0.0192
Epoch 25/200
243/243 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0283 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0285 - val_mse: 0.0012 - lr: 0.0096
Epoch 26/200
243/243 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0284 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0277 - val_mse: 0.0012 - lr: 0.0096
Epoch 27/200
 51/243 [=====>........................] - ETA: 0s - loss: 0.0013 - mae: 0.0292 - mse: 0.0012
Epoch 28/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_4.h5l_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
243/243 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0284 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0295 - val_mse: 0.0012 - lr: 0.0096
Epoch 29/200
243/243 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0282 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0287 - val_mse: 0.0012 - lr: 0.0096
Epoch 30/200
243/243 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0284 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0277 - val_mse: 0.0012 - lr: 0.0096
Epoch 31/200
190/243 [======================>.......] - ETA: 0s - loss: 0.0012 - mae: 0.0285 - mse: 0.0012
Epoch 37/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_4.h5l_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
243/243 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0283 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0277 - val_mse: 0.0012 - lr: 0.0096
Epoch 34/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0283 - mse: 0.0012 - val_loss: 0.0014 - val_mae: 0.0320 - val_mse: 0.0014 - lr: 0.0096
Epoch 35/200
190/243 [======================>.......] - ETA: 0s - loss: 0.0012 - mae: 0.0280 - mse: 0.0012
Epoch 35: ReduceLROnPlateau reducing learning rate to 0.004796268884092569.
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0283 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0284 - val_mse: 0.0011 - lr: 0.0096
Epoch 36/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0281 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0296 - val_mse: 0.0012 - lr: 0.0048
Epoch 37/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_4.h5l_mae: 0.0311 - val_mse: 0.0016 - lr: 0.0384-04 - lr: 1.0000e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0282 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0294 - val_mse: 0.0012 - lr: 0.0048
Epoch 38/200
243/243 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0281 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0011 - lr: 0.0048
Epoch 39/200
243/243 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0281 - mse: 0.0011 - val_loss: 0.0014 - val_mae: 0.0322 - val_mse: 0.0014 - lr: 0.0048
Epoch 40/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0282 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0277 - val_mse: 0.0012 - lr: 0.0048
Epoch 41/200
242/243 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0280 - mse: 0.0011
243/243 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0281 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0276 - val_mse: 0.0012 - lr: 0.0024
243/243 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0281 - mse: 0.0011 - val_loss: 0.0014 - val_mae: 0.0312 - val_mse: 0.0013 - lr: 0.0048
Epoch 44/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0281 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0290 - val_mse: 0.0012 - lr: 0.0048
Epoch 45/200
185/243 [=====================>........] - ETA: 0s - loss: 0.0012 - mae: 0.0282 - mse: 0.0011
Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0023981344420462847.
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0281 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0277 - val_mse: 0.0012 - lr: 0.0048
Epoch 46/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0278 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0011 - lr: 0.0024
Epoch 47/200
243/243 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0281 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0276 - val_mse: 0.0012 - lr: 0.0024
Epoch 48/200
243/243 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0280 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0277 - val_mse: 0.0011 - lr: 0.0024
Epoch 49/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0280 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0276 - val_mse: 0.0012 - lr: 0.0024
Epoch 50/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0280 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0284 - val_mse: 0.0011 - lr: 0.0024
Epoch 51/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0281 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 0.0024
Epoch 52/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0280 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0276 - val_mse: 0.0012 - lr: 0.0024
Epoch 53/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0280 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0011 - lr: 0.0024
Epoch 54/200
167/243 [===================>..........] - ETA: 0s - loss: 0.0012 - mae: 0.0279 - mse: 0.0011
194/243 [======================>.......] - ETA: 0s - loss: 0.0011 - mae: 0.0274 - mse: 0.0011        al_loss: 0.0012 - val_mae: 0.0277 - val_mse: 0.0011 - lr: 0.0024
185/243 [=====================>........] - ETA: 0s - loss: 0.0012 - mae: 0.0281 - mse: 0.0011
Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0011990672210231423.
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0280 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 0.0024
Epoch 56/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0279 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0011 - lr: 0.0012
Epoch 57/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0279 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 0.0012
Epoch 58/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0279 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 0.0012
Epoch 59/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0278 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0276 - val_mse: 0.0011 - lr: 0.0012
Epoch 60/200
Epoch 66/200===========================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0295 - val_mse: 0.0012 - lr: 0.0012
Epoch 61/200
243/243 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0278 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 0.0012
Epoch 62/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0279 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0279 - val_mse: 0.0011 - lr: 0.0012
Epoch 63/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0279 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0278 - val_mse: 0.0011 - lr: 0.0012
Epoch 64/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0278 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0278 - val_mse: 0.0011 - lr: 0.0012
Epoch 65/200
177/243 [====================>.........] - ETA: 0s - loss: 0.0011 - mae: 0.0278 - mse: 0.0011
Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0005995336105115712.
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0278 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0276 - val_mse: 0.0012 - lr: 0.0012
Epoch 66/200===========================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0295 - val_mse: 0.0012 - lr: 0.0012
243/243 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0278 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0287 - val_mse: 0.0012 - lr: 5.9953e-04
Epoch 67/200
243/243 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0283 - val_mse: 0.0011 - lr: 5.9953e-04
Epoch 68/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0278 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0283 - val_mse: 0.0011 - lr: 5.9953e-04
Epoch 69/200
243/243 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0278 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0279 - val_mse: 0.0011 - lr: 5.9953e-04
Epoch 70/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0278 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0287 - val_mse: 0.0012 - lr: 5.9953e-04
Epoch 71/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0278 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0283 - val_mse: 0.0011 - lr: 5.9953e-04
Epoch 72/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0283 - val_mse: 0.0011 - lr: 5.9953e-04
Epoch 73/200
  1/243 [..............................] - ETA: 0s - loss: 8.6087e-04 - mae: 0.0242 - mse: 8.2731e-04
205/243 [========================>.....] - ETA: 0s - loss: 0.0012 - mae: 0.0279 - mse: 0.00110011 - val_loss: 0.0012 - val_mae: 0.0283 - val_mse: 0.0011 - lr: 5.9953e-04
Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0002997668052557856.
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 5.9953e-04
Epoch 76/200
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 2.9977e-04
Epoch 77/200
243/243 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0284 - val_mse: 0.0011 - lr: 2.9977e-04
Epoch 78/200
205/243 [========================>.....] - ETA: 0s - loss: 0.0011 - mae: 0.0276 - mse: 0.0011
243/243 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0278 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0011 - lr: 2.9977e-04
Epoch 83/200
243/243 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0278 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0279 - val_mse: 0.0011 - lr: 2.9977e-04
Epoch 84/200
 84/243 [=========>....................] - ETA: 0s - loss: 0.0012 - mae: 0.0282 - mse: 0.0011
 45/243 [====>.........................] - ETA: 0s - loss: 0.0012 - mae: 0.0284 - mse: 0.00120011 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0011 - lr: 2.9977e-04
243/243 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 1.4988e-04
243/243 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0281 - val_mse: 0.0011 - lr: 7.4942e-05
243/243 [==============================] - 1s 2ms/step - loss: 0.0011 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0281 - val_mse: 0.0011 - lr: 7.4942e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 7.4942e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 3.7471e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 1.8735e-05
243/243 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0278 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 1.8735e-05
243/243 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0278 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 1.8735e-05
243/243 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
163/243 [===================>..........] - ETA: 0s - loss: 0.0011 - mae: 0.0272 - mse: 0.0011        al_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
243/243 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
243/243 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
243/243 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
243/243 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
243/243 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
203/243 [========================>.....] - ETA: 0s - loss: 0.0011 - mae: 0.0279 - mse: 0.00110011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 189/200==========================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 196/200==========================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0277 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 3/200rained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 8/200rained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 15/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 20/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 23/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 29/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 34/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 39/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 44/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 50/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 63/200duceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 68/200duceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 75/200duceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 81/200duceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 87/200duceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 92/200duceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 96/200duceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 101/200uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 107/200uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 113/200uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 118/200uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 125/200uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 131/200uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 137/200uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 142/200uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 147/200uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 152/200uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 156/200uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 163/200uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 168/200uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 173/200uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 178/200uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 183/200uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 188/200uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 193/200uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 198/200uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 198/200uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 1/20000uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 5/20000uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 10/2000uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 14/2000uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 18/2000uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 24/2000uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 29/2000uceLROnPlateau reducing learning rate to 0.0023981344420462847.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 33: ReduceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 39/200duceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 43/200duceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 49/200duceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 54/200duceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 61/200duceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 61/200duceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
Epoch 61/200duceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 69/200duceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 69/200duceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 71/200duceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 71/200duceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 76/200duceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 76/200duceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 79/200duceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 79/200duceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 81/200duceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 81/200duceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 86/200duceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 86/200duceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 90/200duceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 90/200duceLROnPlateau reducing learning rate to 0.019185075536370277..[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0005995336105115712.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0005995336105115712.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0005995336105115712.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 99/200duceLROnPlateau reducing learning rate to 0.0005995336105115712.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 99/200duceLROnPlateau reducing learning rate to 0.0005995336105115712.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
Epoch 99/200duceLROnPlateau reducing learning rate to 0.0005995336105115712.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 102/200uceLROnPlateau reducing learning rate to 0.0005995336105115712.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 102/200uceLROnPlateau reducing learning rate to 0.0005995336105115712.[35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 103: ReduceLROnPlateau reducing learning rate to 0.0002997668052557856.35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 103: ReduceLROnPlateau reducing learning rate to 0.0002997668052557856.35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 109/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 109/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 116/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 116/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 121/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 143/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 150/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 150/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 157/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 157/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 165/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 171/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 177/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 183/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 189/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 195/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 195/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.35]HN_16BS_10P_val_mseM_200epochs/model_5.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 4/200rained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 10/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 14/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 19/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 24/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 31/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 37/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 43/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 49/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 54/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 60/200ained_models/models_segments_overlap_adam_0.03837015216285987LR_[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0005995336105115712.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 69/200duceLROnPlateau reducing learning rate to 0.0005995336105115712.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 78/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 82/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 87/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 92/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 97/200duceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 102/200uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 107/200uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 112/200uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 116/200uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 121/200uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 126/200uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 131/200uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 135/200uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 140/200uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 146/200uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 152/200uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 157/200uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 162/200uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 167/200uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 171/200uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 175/200uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 181/200uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 185/200uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 191/200uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 196/200uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 196/200uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 1/20000uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 5/20000uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 11/2000uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 17/2000uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 22/2000uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 26/2000uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 31/2000uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 38/2000uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 43/2000uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 49/2000uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 54/2000uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 60/2000uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 67/2000uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 67/2000uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
Epoch 67/2000uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 73/2000uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 73/2000uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
Epoch 73/2000uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
Epoch 73/2000uceLROnPlateau reducing learning rate to 0.0002997668052557856.[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 77: ReduceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 77: ReduceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
Epoch 77: ReduceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 82/200duceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 82/200duceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 86/200duceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 86/200duceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
Epoch 86/200duceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 91/200duceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 91/200duceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
Epoch 91/200duceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 94/200duceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 94/200duceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 97/200duceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 97/200duceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
Epoch 97/200duceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 102/200uceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 109/200uceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 109/200uceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
Epoch 109/200uceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 112/200uceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 112/200uceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
Epoch 112/200uceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
Epoch 112/200uceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
Epoch 112/200uceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 117/200uceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 117/200uceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
Epoch 117/200uceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 121/200uceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 121/200uceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 123/200uceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 123/200uceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 126/200uceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 126/200uceLROnPlateau reducing learning rate to 0.004796268884092569..[35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 127: ReduceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 133/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 133/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
Epoch 133/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
Epoch 140/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 140/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 142/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 142/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 145/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 145/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
Epoch 145/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
Epoch 145/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 152/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 152/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 159/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 159/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
Epoch 173/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 181/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 189/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 189/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_235037-w1mhcw1u\files\model-best)... Done. 0.0s
Epoch 189/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 195/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05
Epoch 195/200duceLROnPlateau reducing learning rate to 0.0001498834026278928.35]HN_16BS_10P_val_mseM_200epochs/model_7.h5l_mae: 0.0282 - val_mse: 0.0011 - lr: 1.0000e-05