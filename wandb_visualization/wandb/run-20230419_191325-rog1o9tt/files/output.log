Epoch 1/150
66/98 [===================>..........] - ETA: 0s - loss: 0.0508 - mae: 0.0538 - mse: 0.0066
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0018s). Check your callbacks.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191325-rog1o9tt\files\model-best)... Done. 0.0s
98/98 [==============================] - 1s 9ms/step - loss: 0.0362 - mae: 0.0514 - mse: 0.0055 - val_loss: 0.0051 - val_mae: 0.0557 - val_mse: 0.0046 - lr: 0.0927
Epoch 2/150
98/98 [==============================] - 1s 9ms/step - loss: 0.0026 - mae: 0.0380 - mse: 0.0021 - val_loss: 0.0024 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 0.0927
Epoch 3/150
64/98 [==================>...........] - ETA: 0s - loss: 0.0024 - mae: 0.0380 - mse: 0.0021
98/98 [==============================] - 1s 8ms/step - loss: 0.0024 - mae: 0.0377 - mse: 0.0021 - val_loss: 0.0021 - val_mae: 0.0370 - val_mse: 0.0019 - lr: 0.0927
Epoch 4/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0362 - mse: 0.0018 - val_loss: 0.0029 - val_mae: 0.0398 - val_mse: 0.0024 - lr: 0.0927
Epoch 5/150
64/98 [==================>...........] - ETA: 0s - loss: 0.0021 - mae: 0.0363 - mse: 0.0019
98/98 [==============================] - 1s 9ms/step - loss: 0.0021 - mae: 0.0357 - mse: 0.0018 - val_loss: 0.0019 - val_mae: 0.0335 - val_mse: 0.0016 - lr: 0.0927
Epoch 6/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0018 - mae: 0.0333 - mse: 0.0016 - val_loss: 0.0023 - val_mae: 0.0350 - val_mse: 0.0018 - lr: 0.0927
Epoch 7/150
68/98 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0326 - mse: 0.0016
98/98 [==============================] - 1s 12ms/step - loss: 0.0018 - mae: 0.0321 - mse: 0.0015 - val_loss: 0.0019 - val_mae: 0.0344 - val_mse: 0.0017 - lr: 0.0927
Epoch 8/150
56/98 [================>.............] - ETA: 0s - loss: 0.0016 - mae: 0.0304 - mse: 0.0014
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191325-rog1o9tt\files\model-best)... Done. 0.0s
98/98 [==============================] - 1s 9ms/step - loss: 0.0016 - mae: 0.0302 - mse: 0.0014 - val_loss: 0.0014 - val_mae: 0.0285 - val_mse: 0.0012 - lr: 0.0927
Epoch 9/150
98/98 [==============================] - 1s 8ms/step - loss: 0.0015 - mae: 0.0281 - mse: 0.0012 - val_loss: 0.0014 - val_mae: 0.0272 - val_mse: 0.0012 - lr: 0.0927
Epoch 10/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0283 - mse: 0.0012 - val_loss: 0.0023 - val_mae: 0.0342 - val_mse: 0.0017 - lr: 0.0927
Epoch 11/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0272 - mse: 0.0012 - val_loss: 0.0015 - val_mae: 0.0289 - val_mse: 0.0013 - lr: 0.0927
Epoch 12/150
63/98 [==================>...........] - ETA: 0s - loss: 0.0015 - mae: 0.0271 - mse: 0.0012
98/98 [==============================] - 1s 9ms/step - loss: 0.0015 - mae: 0.0267 - mse: 0.0011 - val_loss: 0.0014 - val_mae: 0.0276 - val_mse: 0.0012 - lr: 0.0927
Epoch 13/150
59/98 [=================>............] - ETA: 0s - loss: 0.0013 - mae: 0.0251 - mse: 0.0010
98/98 [==============================] - 1s 9ms/step - loss: 0.0013 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0927
Epoch 14/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0255 - mse: 0.0011 - val_loss: 0.0015 - val_mae: 0.0295 - val_mse: 0.0014 - lr: 0.0927
Epoch 15/150
68/98 [===================>..........] - ETA: 0s - loss: 0.0012 - mae: 0.0246 - mse: 9.8660e-04
98/98 [==============================] - 1s 8ms/step - loss: 0.0013 - mae: 0.0257 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0249 - val_mse: 9.8566e-04 - lr: 0.0927
Epoch 16/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0249 - mse: 0.0010 - val_loss: 0.0015 - val_mae: 0.0264 - val_mse: 0.0011 - lr: 0.0927
Epoch 17/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0254 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 9.8619e-04 - lr: 0.0927
Epoch 18/150
71/98 [====================>.........] - ETA: 0s - loss: 0.0012 - mae: 0.0237 - mse: 9.2025e-04
98/98 [==============================] - 1s 8ms/step - loss: 0.0011 - mae: 0.0235 - mse: 9.0782e-04 - val_loss: 9.9529e-04 - val_mae: 0.0228 - val_mse: 8.3788e-04 - lr: 0.0927
Epoch 19/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0240 - mse: 9.4963e-04 - val_loss: 0.0010 - val_mae: 0.0221 - val_mse: 7.8714e-04 - lr: 0.0927
Epoch 20/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0270 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0248 - val_mse: 9.8191e-04 - lr: 0.0927
Epoch 21/150
69/98 [====================>.........] - ETA: 0s - loss: 0.0013 - mae: 0.0250 - mse: 0.0010
98/98 [==============================] - 1s 9ms/step - loss: 0.0012 - mae: 0.0244 - mse: 9.7319e-04 - val_loss: 9.8032e-04 - val_mae: 0.0236 - val_mse: 8.9882e-04 - lr: 0.0927
Epoch 22/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0229 - mse: 8.6345e-04 - val_loss: 0.0011 - val_mae: 0.0218 - val_mse: 7.5736e-04 - lr: 0.0927
Epoch 23/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0230 - mse: 8.7341e-04 - val_loss: 0.0011 - val_mae: 0.0238 - val_mse: 8.7997e-04 - lr: 0.0927
Epoch 24/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0236 - mse: 9.0503e-04 - val_loss: 0.0014 - val_mae: 0.0275 - val_mse: 0.0012 - lr: 0.0927
Epoch 25/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0246 - mse: 9.7042e-04 - val_loss: 0.0013 - val_mae: 0.0265 - val_mse: 0.0011 - lr: 0.0927
Epoch 26/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0226 - mse: 8.4227e-04 - val_loss: 0.0011 - val_mae: 0.0238 - val_mse: 9.3228e-04 - lr: 0.0927
Epoch 27/150
98/98 [==============================] - 0s 1ms/step - loss: 9.8387e-04 - mae: 0.0221 - mse: 8.1349e-04 - val_loss: 0.0019 - val_mae: 0.0322 - val_mse: 0.0015 - lr: 0.0927
Epoch 28/150
71/98 [====================>.........] - ETA: 0s - loss: 0.0010 - mae: 0.0220 - mse: 8.1216e-04
98/98 [==============================] - 1s 8ms/step - loss: 0.0010 - mae: 0.0222 - mse: 8.2006e-04 - val_loss: 9.2165e-04 - val_mae: 0.0208 - val_mse: 6.8041e-04 - lr: 0.0927
Epoch 29/150
98/98 [==============================] - 0s 1ms/step - loss: 9.7846e-04 - mae: 0.0219 - mse: 7.9341e-04 - val_loss: 0.0029 - val_mae: 0.0416 - val_mse: 0.0026 - lr: 0.0927
Epoch 30/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0231 - mse: 8.8107e-04 - val_loss: 9.5202e-04 - val_mae: 0.0219 - val_mse: 7.3453e-04 - lr: 0.0927
Epoch 31/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0224 - mse: 8.3193e-04 - val_loss: 9.8738e-04 - val_mae: 0.0229 - val_mse: 8.0518e-04 - lr: 0.0927
Epoch 32/150
73/98 [=====================>........] - ETA: 0s - loss: 0.0010 - mae: 0.0227 - mse: 8.4305e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191325-rog1o9tt\files\model-best)... Done. 0.0s
98/98 [==============================] - 1s 9ms/step - loss: 9.9897e-04 - mae: 0.0223 - mse: 8.1144e-04 - val_loss: 8.9068e-04 - val_mae: 0.0221 - val_mse: 7.8433e-04 - lr: 0.0927
Epoch 33/150
98/98 [==============================] - 0s 1ms/step - loss: 9.5318e-04 - mae: 0.0218 - mse: 7.8720e-04 - val_loss: 0.0019 - val_mae: 0.0326 - val_mse: 0.0016 - lr: 0.0927
Epoch 34/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0224 - mse: 8.2986e-04 - val_loss: 0.0024 - val_mae: 0.0304 - val_mse: 0.0014 - lr: 0.0927
Epoch 35/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0226 - mse: 8.5119e-04 - val_loss: 0.0019 - val_mae: 0.0334 - val_mse: 0.0017 - lr: 0.0927
Epoch 36/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0222 - mse: 8.2633e-04 - val_loss: 0.0010 - val_mae: 0.0247 - val_mse: 9.3486e-04 - lr: 0.0927
Epoch 37/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6945e-04 - mae: 0.0217 - mse: 7.8402e-04 - val_loss: 0.0011 - val_mae: 0.0241 - val_mse: 9.0049e-04 - lr: 0.0927
Epoch 38/150
70/98 [====================>.........] - ETA: 0s - loss: 0.0011 - mae: 0.0219 - mse: 7.9127e-04
Epoch 38: ReduceLROnPlateau reducing learning rate to 0.046370577067136765.
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0221 - mse: 7.9806e-04 - val_loss: 0.0010 - val_mae: 0.0206 - val_mse: 7.1628e-04 - lr: 0.0927
Epoch 39/150
98/98 [==============================] - 0s 1ms/step - loss: 8.7956e-04 - mae: 0.0205 - mse: 7.0890e-04 - val_loss: 8.9627e-04 - val_mae: 0.0212 - val_mse: 7.6626e-04 - lr: 0.0464
Epoch 40/150
98/98 [==============================] - 1s 9ms/step - loss: 8.3908e-04 - mae: 0.0207 - mse: 7.1109e-04 - val_loss: 8.3847e-04 - val_mae: 0.0219 - val_mse: 7.4115e-04 - lr: 0.0464
Epoch 41/150
98/98 [==============================] - 0s 1ms/step - loss: 7.8608e-04 - mae: 0.0200 - mse: 6.7866e-04 - val_loss: 0.0016 - val_mae: 0.0310 - val_mse: 0.0015 - lr: 0.0464
Epoch 42/150
98/98 [==============================] - 0s 1ms/step - loss: 8.7175e-04 - mae: 0.0214 - mse: 7.4874e-04 - val_loss: 0.0018 - val_mae: 0.0331 - val_mse: 0.0017 - lr: 0.0464
Epoch 43/150
71/98 [====================>.........] - ETA: 0s - loss: 8.7211e-04 - mae: 0.0211 - mse: 7.5001e-04
98/98 [==============================] - 1s 12ms/step - loss: 8.5414e-04 - mae: 0.0209 - mse: 7.3413e-04 - val_loss: 7.4365e-04 - val_mae: 0.0197 - val_mse: 6.4849e-04 - lr: 0.0464
Epoch 44/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2660e-04 - mae: 0.0206 - mse: 7.1531e-04 - val_loss: 7.4667e-04 - val_mae: 0.0195 - val_mse: 6.2985e-04 - lr: 0.0464
Epoch 45/150
98/98 [==============================] - 0s 1ms/step - loss: 7.9610e-04 - mae: 0.0202 - mse: 6.8763e-04 - val_loss: 9.2618e-04 - val_mae: 0.0238 - val_mse: 8.7504e-04 - lr: 0.0464
Epoch 46/150
98/98 [==============================] - 0s 1ms/step - loss: 7.7394e-04 - mae: 0.0199 - mse: 6.6848e-04 - val_loss: 9.4030e-04 - val_mae: 0.0238 - val_mse: 8.7493e-04 - lr: 0.0464
Epoch 47/150
98/98 [==============================] - 0s 1ms/step - loss: 7.6226e-04 - mae: 0.0198 - mse: 6.6473e-04 - val_loss: 9.8435e-04 - val_mae: 0.0225 - val_mse: 8.5801e-04 - lr: 0.0464
Epoch 48/150
72/98 [=====================>........] - ETA: 0s - loss: 8.1137e-04 - mae: 0.0206 - mse: 7.0039e-04
Epoch 48: ReduceLROnPlateau reducing learning rate to 0.023185288533568382.
98/98 [==============================] - 0s 1ms/step - loss: 8.0126e-04 - mae: 0.0204 - mse: 6.9367e-04 - val_loss: 8.5638e-04 - val_mae: 0.0207 - val_mse: 7.3610e-04 - lr: 0.0464
Epoch 49/150
69/98 [====================>.........] - ETA: 0s - loss: 7.2460e-04 - mae: 0.0191 - mse: 6.3147e-04
98/98 [==============================] - 0s 1ms/step - loss: 7.4571e-04 - mae: 0.0197 - mse: 6.5039e-04 - val_loss: 7.1683e-04 - val_mae: 0.0201 - val_mse: 6.4070e-04 - lr: 0.0232
Epoch 50/150
98/98 [==============================] - 0s 1ms/step - loss: 7.4571e-04 - mae: 0.0197 - mse: 6.5039e-04 - val_loss: 7.1683e-04 - val_mae: 0.0201 - val_mse: 6.4070e-04 - lr: 0.0232
Epoch 51/150
68/98 [===================>..........] - ETA: 0s - loss: 7.1853e-04 - mae: 0.0191 - mse: 6.2691e-04
98/98 [==============================] - 0s 1ms/step - loss: 6.9639e-04 - mae: 0.0187 - mse: 6.0980e-04 - val_loss: 7.0317e-04 - val_mae: 0.0185 - val_mse: 6.0741e-04 - lr: 0.0232
Epoch 52/150
98/98 [==============================] - 0s 1ms/step - loss: 7.0095e-04 - mae: 0.0188 - mse: 6.1069e-04 - val_loss: 7.5449e-04 - val_mae: 0.0211 - val_mse: 6.8422e-04 - lr: 0.0232
Epoch 53/150
98/98 [==============================] - 0s 1ms/step - loss: 6.9639e-04 - mae: 0.0187 - mse: 6.0980e-04 - val_loss: 7.0317e-04 - val_mae: 0.0185 - val_mse: 6.0741e-04 - lr: 0.0232
Epoch 54/150
98/98 [==============================] - 0s 1ms/step - loss: 6.9155e-04 - mae: 0.0187 - mse: 6.0562e-04 - val_loss: 7.1369e-04 - val_mae: 0.0186 - val_mse: 6.0643e-04 - lr: 0.0232
Epoch 55/150
68/98 [===================>..........] - ETA: 0s - loss: 7.2643e-04 - mae: 0.0194 - mse: 6.3142e-04
98/98 [==============================] - 1s 9ms/step - loss: 7.1769e-04 - mae: 0.0192 - mse: 6.2581e-04 - val_loss: 6.6994e-04 - val_mae: 0.0186 - val_mse: 5.7951e-04 - lr: 0.0232
Epoch 56/150
98/98 [==============================] - 0s 1ms/step - loss: 7.1320e-04 - mae: 0.0191 - mse: 6.2472e-04 - val_loss: 8.9745e-04 - val_mae: 0.0210 - val_mse: 7.7199e-04 - lr: 0.0232
Epoch 57/150
98/98 [==============================] - 0s 1ms/step - loss: 7.5963e-04 - mae: 0.0198 - mse: 6.5370e-04 - val_loss: 7.5778e-04 - val_mae: 0.0199 - val_mse: 6.7731e-04 - lr: 0.0232
Epoch 58/150
73/98 [=====================>........] - ETA: 0s - loss: 6.8176e-04 - mae: 0.0185 - mse: 5.9030e-04
98/98 [==============================] - 1s 9ms/step - loss: 7.1769e-04 - mae: 0.0192 - mse: 6.2581e-04 - val_loss: 6.6994e-04 - val_mae: 0.0186 - val_mse: 5.7951e-04 - lr: 0.0232
98/98 [==============================] - 0s 1ms/step - loss: 6.6416e-04 - mae: 0.0182 - mse: 5.7563e-04 - val_loss: 6.7129e-04 - val_mae: 0.0179 - val_mse: 5.6272e-04 - lr: 0.0232
Epoch 60/150
98/98 [==============================] - 0s 1ms/step - loss: 7.1120e-04 - mae: 0.0188 - mse: 6.0434e-04 - val_loss: 8.2482e-04 - val_mae: 0.0203 - val_mse: 7.1765e-04 - lr: 0.0232
Epoch 61/150
98/98 [==============================] - 0s 1ms/step - loss: 7.3163e-04 - mae: 0.0193 - mse: 6.2876e-04 - val_loss: 8.3377e-04 - val_mae: 0.0202 - val_mse: 7.0915e-04 - lr: 0.0232
Epoch 62/150
98/98 [==============================] - 0s 1ms/step - loss: 6.8279e-04 - mae: 0.0184 - mse: 5.8832e-04 - val_loss: 7.5196e-04 - val_mae: 0.0191 - val_mse: 6.6207e-04 - lr: 0.0232
Epoch 63/150
98/98 [==============================] - 0s 1ms/step - loss: 6.6416e-04 - mae: 0.0182 - mse: 5.7563e-04 - val_loss: 6.7129e-04 - val_mae: 0.0179 - val_mse: 5.6272e-04 - lr: 0.0232
Epoch 64/150
98/98 [==============================] - 0s 1ms/step - loss: 6.7007e-04 - mae: 0.0181 - mse: 5.7662e-04 - val_loss: 6.6655e-04 - val_mae: 0.0193 - val_mse: 5.8639e-04 - lr: 0.0232
Epoch 65/150
66/98 [===================>..........] - ETA: 0s - loss: 6.6011e-04 - mae: 0.0179 - mse: 5.7002e-04
Epoch 65: ReduceLROnPlateau reducing learning rate to 0.011592644266784191.
98/98 [==============================] - 0s 1ms/step - loss: 6.6172e-04 - mae: 0.0179 - mse: 5.6987e-04 - val_loss: 8.0700e-04 - val_mae: 0.0219 - val_mse: 7.2626e-04 - lr: 0.0232
Epoch 66/150
68/98 [===================>..........] - ETA: 0s - loss: 7.0217e-04 - mae: 0.0185 - mse: 5.9961e-04
98/98 [==============================] - 1s 9ms/step - loss: 6.6477e-04 - mae: 0.0180 - mse: 5.6718e-04 - val_loss: 6.3416e-04 - val_mae: 0.0179 - val_mse: 5.4727e-04 - lr: 0.0116
Epoch 67/150
98/98 [==============================] - 0s 1ms/step - loss: 6.1707e-04 - mae: 0.0170 - mse: 5.2735e-04 - val_loss: 7.8987e-04 - val_mae: 0.0201 - val_mse: 7.0507e-04 - lr: 0.0116
Epoch 68/150
65/98 [==================>...........] - ETA: 0s - loss: 6.2350e-04 - mae: 0.0173 - mse: 5.3385e-04
98/98 [==============================] - 1s 9ms/step - loss: 6.6477e-04 - mae: 0.0180 - mse: 5.6718e-04 - val_loss: 6.3416e-04 - val_mae: 0.0179 - val_mse: 5.4727e-04 - lr: 0.0116
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191325-rog1o9tt\files\model-best)... Done. 0.0s
98/98 [==============================] - 1s 9ms/step - loss: 6.6477e-04 - mae: 0.0180 - mse: 5.6718e-04 - val_loss: 6.3416e-04 - val_mae: 0.0179 - val_mse: 5.4727e-04 - lr: 0.0116
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191325-rog1o9tt\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 6.0859e-04 - mae: 0.0168 - mse: 5.1400e-04 - val_loss: 6.0874e-04 - val_mae: 0.0161 - val_mse: 5.0677e-04 - lr: 0.0116
98/98 [==============================] - 0s 1ms/step - loss: 6.0859e-04 - mae: 0.0168 - mse: 5.1400e-04 - val_loss: 6.0874e-04 - val_mae: 0.0161 - val_mse: 5.0677e-04 - lr: 0.0116
98/98 [==============================] - 0s 1ms/step - loss: 6.0859e-04 - mae: 0.0168 - mse: 5.1400e-04 - val_loss: 6.0874e-04 - val_mae: 0.0161 - val_mse: 5.0677e-04 - lr: 0.0116
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191325-rog1o9tt\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 6.0859e-04 - mae: 0.0168 - mse: 5.1400e-04 - val_loss: 6.0874e-04 - val_mae: 0.0161 - val_mse: 5.0677e-04 - lr: 0.0116
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191325-rog1o9tt\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 6.0859e-04 - mae: 0.0168 - mse: 5.1400e-04 - val_loss: 6.0874e-04 - val_mae: 0.0161 - val_mse: 5.0677e-04 - lr: 0.0116
63/98 [==================>...........] - ETA: 0s - loss: 5.5960e-04 - mae: 0.0157 - mse: 4.6852e-04e-04 - val_loss: 6.0874e-04 - val_mae: 0.0161 - val_mse: 5.0677e-04 - lr: 0.0116
63/98 [==================>...........] - ETA: 0s - loss: 5.5960e-04 - mae: 0.0157 - mse: 4.6852e-04e-04 - val_loss: 6.0874e-04 - val_mae: 0.0161 - val_mse: 5.0677e-04 - lr: 0.0116
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191325-rog1o9tt\files\model-best)... Done. 0.0s
98/98 [==============================] - 1s 8ms/step - loss: 5.7661e-04 - mae: 0.0161 - mse: 4.8649e-04 - val_loss: 5.7390e-04 - val_mae: 0.0163 - val_mse: 4.8449e-04 - lr: 0.0058
98/98 [==============================] - 1s 8ms/step - loss: 5.7661e-04 - mae: 0.0161 - mse: 4.8649e-04 - val_loss: 5.7390e-04 - val_mae: 0.0163 - val_mse: 4.8449e-04 - lr: 0.0058
98/98 [==============================] - 1s 8ms/step - loss: 5.7661e-04 - mae: 0.0161 - mse: 4.8649e-04 - val_loss: 5.7390e-04 - val_mae: 0.0163 - val_mse: 4.8449e-04 - lr: 0.0058
98/98 [==============================] - 0s 1ms/step - loss: 5.4453e-04 - mae: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
98/98 [==============================] - 0s 1ms/step - loss: 5.4453e-04 - mae: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191325-rog1o9tt\files\model-best)... Done. 0.0s
98/98 [==============================] - 0s 1ms/step - loss: 5.4453e-04 - mae: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 96/150=========================] - 0s 1ms/step - loss: 5.4453e-04 - mae: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 96/150=========================] - 0s 1ms/step - loss: 5.4453e-04 - mae: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 98/150=========================] - 0s 1ms/step - loss: 5.4453e-04 - mae: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 98/150=========================] - 0s 1ms/step - loss: 5.4453e-04 - mae: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 103: ReduceLROnPlateau reducing learning rate to 0.0014490805333480239.: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 103: ReduceLROnPlateau reducing learning rate to 0.0014490805333480239.: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191325-rog1o9tt\files\model-best)... Done. 0.0s
Epoch 103: ReduceLROnPlateau reducing learning rate to 0.0014490805333480239.: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191325-rog1o9tt\files\model-best)... Done. 0.0s
Epoch 108/150duceLROnPlateau reducing learning rate to 0.0014490805333480239.: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 111/150duceLROnPlateau reducing learning rate to 0.0014490805333480239.: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 111/150duceLROnPlateau reducing learning rate to 0.0014490805333480239.: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0014490805333480239.: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 117/150duceLROnPlateau reducing learning rate to 0.0014490805333480239.: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0014490805333480239.: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 119/150duceLROnPlateau reducing learning rate to 0.0014490805333480239.: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0014490805333480239.: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 126/150duceLROnPlateau reducing learning rate to 0.0014490805333480239.: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191325-rog1o9tt\files\model-best)... Done. 0.0s
Epoch 128/150duceLROnPlateau reducing learning rate to 0.0014490805333480239.: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0014490805333480239.: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 131/150duceLROnPlateau reducing learning rate to 0.0014490805333480239.: 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_191325-rog1o9tt\files\model-best)... Done. 0.0s
Epoch 133: ReduceLROnPlateau reducing learning rate to 0.00018113506666850299. 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 133: ReduceLROnPlateau reducing learning rate to 0.00018113506666850299. 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 135/150duceLROnPlateau reducing learning rate to 0.00018113506666850299. 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 138/150duceLROnPlateau reducing learning rate to 0.00018113506666850299. 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 138/150duceLROnPlateau reducing learning rate to 0.00018113506666850299. 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 145/150duceLROnPlateau reducing learning rate to 0.00018113506666850299. 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 145/150duceLROnPlateau reducing learning rate to 0.00018113506666850299. 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
Epoch 50: ReduceLROnPlateau reducing learning rate to 0.023185288533568382.99. 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
130/130 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0252 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0464
Epoch 44/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0247 - val_mse: 0.0010 - lr: 0.0464
Epoch 45/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0274 - mse: 0.0013 - val_loss: 0.0025 - val_mae: 0.0399 - val_mse: 0.0023 - lr: 0.0464
Epoch 46/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0233 - val_mse: 9.6674e-04 - lr: 0.0464
Epoch 47/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0246 - mse: 0.0010 - val_loss: 0.0015 - val_mae: 0.0286 - val_mse: 0.0013 - lr: 0.0464
Epoch 48/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0265 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0247 - val_mse: 0.0010 - lr: 0.0464
Epoch 49/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0250 - mse: 0.0011 - val_loss: 0.0020 - val_mae: 0.0351 - val_mse: 0.0019 - lr: 0.0464
Epoch 50/150
 68/130 [==============>...............] - ETA: 0s - loss: 0.0014 - mae: 0.0267 - mse: 0.0012
Epoch 50: ReduceLROnPlateau reducing learning rate to 0.023185288533568382.99. 0.0154 - mse: 4.5814e-04 - val_loss: 5.9130e-04 - val_mae: 0.0173 - val_mse: 4.9598e-04 - lr: 0.0058
130/130 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0016 - val_mae: 0.0287 - val_mse: 0.0013 - lr: 0.0464
Epoch 51/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0241 - mse: 9.8708e-04 - val_loss: 0.0018 - val_mae: 0.0326 - val_mse: 0.0016 - lr: 0.0232
Epoch 52/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0257 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0232 - val_mse: 9.7865e-04 - lr: 0.0232
Epoch 53/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0238 - mse: 9.6221e-04 - val_loss: 0.0031 - val_mae: 0.0464 - val_mse: 0.0029 - lr: 0.0232
Epoch 54/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0250 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0241 - val_mse: 9.8612e-04 - lr: 0.0232
Epoch 55/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0239 - mse: 9.6998e-04 - val_loss: 0.0011 - val_mae: 0.0232 - val_mse: 9.2313e-04 - lr: 0.0232
Epoch 56/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0241 - mse: 9.8971e-04 - val_loss: 0.0010 - val_mae: 0.0221 - val_mse: 8.8549e-04 - lr: 0.0232
Epoch 57/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0231 - mse: 9.2053e-04 - val_loss: 0.0011 - val_mae: 0.0233 - val_mse: 9.5507e-04 - lr: 0.0232
Epoch 58/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0242 - mse: 9.8462e-04 - val_loss: 0.0010 - val_mae: 0.0221 - val_mse: 8.9042e-04 - lr: 0.0232
Epoch 59/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0230 - mse: 9.1478e-04 - val_loss: 0.0011 - val_mae: 0.0232 - val_mse: 9.3845e-04 - lr: 0.0232
Epoch 60/150
 72/130 [===============>..............] - ETA: 0s - loss: 0.0012 - mae: 0.0248 - mse: 0.0010
Epoch 60: ReduceLROnPlateau reducing learning rate to 0.011592644266784191.
130/130 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0246 - mse: 0.0010 - val_loss: 0.0013 - val_mae: 0.0265 - val_mse: 0.0011 - lr: 0.0232
Epoch 61/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0228 - mse: 9.0236e-04 - val_loss: 0.0010 - val_mae: 0.0226 - val_mse: 8.7770e-04 - lr: 0.0116
Epoch 62/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0223 - mse: 8.7004e-04 - val_loss: 0.0010 - val_mae: 0.0220 - val_mse: 8.7017e-04 - lr: 0.0116
Epoch 63/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0226 - mse: 8.9221e-04 - val_loss: 0.0010 - val_mae: 0.0216 - val_mse: 8.3297e-04 - lr: 0.0116
Epoch 64/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0226 - mse: 8.8302e-04 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0010 - lr: 0.0116
Epoch 65/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0223 - mse: 8.6284e-04 - val_loss: 0.0015 - val_mae: 0.0304 - val_mse: 0.0014 - lr: 0.0116
Epoch 66/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0230 - mse: 9.0567e-04 - val_loss: 0.0014 - val_mae: 0.0287 - val_mse: 0.0012 - lr: 0.0116
Epoch 67/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0238 - mse: 9.7879e-04 - val_loss: 9.8606e-04 - val_mae: 0.0218 - val_mse: 8.3413e-04 - lr: 0.0116
Epoch 68/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0222 - mse: 8.5506e-04 - val_loss: 0.0011 - val_mae: 0.0225 - val_mse: 9.0333e-04 - lr: 0.0116
Epoch 69/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0223 - mse: 8.5635e-04 - val_loss: 9.4415e-04 - val_mae: 0.0208 - val_mse: 7.9159e-04 - lr: 0.0116
Epoch 70/150
130/130 [==============================] - 0s 1ms/step - loss: 9.8227e-04 - mae: 0.0218 - mse: 8.2719e-04 - val_loss: 9.4779e-04 - val_mae: 0.0212 - val_mse: 7.9834e-04 - lr: 0.0116
Epoch 71/150
130/130 [==============================] - 0s 1ms/step - loss: 9.9299e-04 - mae: 0.0221 - mse: 8.4208e-04 - val_loss: 9.3575e-04 - val_mae: 0.0206 - val_mse: 7.7013e-04 - lr: 0.0116
Epoch 72/150
130/130 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0225 - mse: 8.6732e-04 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0010 - lr: 0.0116
Epoch 73/150
 70/130 [===============>..............] - ETA: 0s - loss: 9.8324e-04 - mae: 0.0217 - mse: 8.1950e-04
Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0057963221333920956.
130/130 [==============================] - 0s 1ms/step - loss: 9.9438e-04 - mae: 0.0221 - mse: 8.3578e-04 - val_loss: 0.0011 - val_mae: 0.0237 - val_mse: 9.3774e-04 - lr: 0.0116
Epoch 74/150
130/130 [==============================] - 0s 1ms/step - loss: 9.8454e-04 - mae: 0.0221 - mse: 8.3539e-04 - val_loss: 0.0010 - val_mae: 0.0226 - val_mse: 8.6516e-04 - lr: 0.0058
Epoch 75/150
130/130 [==============================] - 0s 1ms/step - loss: 9.7523e-04 - mae: 0.0218 - mse: 8.2292e-04 - val_loss: 9.1909e-04 - val_mae: 0.0207 - val_mse: 7.6971e-04 - lr: 0.0058
Epoch 76/150
130/130 [==============================] - 0s 1ms/step - loss: 9.3579e-04 - mae: 0.0212 - mse: 7.8925e-04 - val_loss: 9.7565e-04 - val_mae: 0.0215 - val_mse: 8.2976e-04 - lr: 0.0058
Epoch 77/150
130/130 [==============================] - 0s 1ms/step - loss: 9.4471e-04 - mae: 0.0214 - mse: 7.9988e-04 - val_loss: 0.0010 - val_mae: 0.0227 - val_mse: 8.5753e-04 - lr: 0.0058
Epoch 78/150
130/130 [==============================] - 0s 1ms/step - loss: 9.5485e-04 - mae: 0.0217 - mse: 8.0947e-04 - val_loss: 0.0010 - val_mae: 0.0224 - val_mse: 8.5246e-04 - lr: 0.0058
Epoch 79/150
130/130 [==============================] - 0s 1ms/step - loss: 9.3547e-04 - mae: 0.0213 - mse: 7.8919e-04 - val_loss: 0.0010 - val_mae: 0.0231 - val_mse: 8.6612e-04 - lr: 0.0058
Epoch 80/150
130/130 [==============================] - 0s 1ms/step - loss: 9.6956e-04 - mae: 0.0219 - mse: 8.1669e-04 - val_loss: 9.5465e-04 - val_mae: 0.0215 - val_mse: 8.1417e-04 - lr: 0.0058
Epoch 81/150
130/130 [==============================] - 0s 1ms/step - loss: 9.3624e-04 - mae: 0.0214 - mse: 7.9271e-04 - val_loss: 9.1826e-04 - val_mae: 0.0212 - val_mse: 7.7097e-04 - lr: 0.0058
Epoch 82/150
130/130 [==============================] - 0s 1ms/step - loss: 9.2684e-04 - mae: 0.0213 - mse: 7.8709e-04 - val_loss: 9.4591e-04 - val_mae: 0.0217 - val_mse: 8.0792e-04 - lr: 0.0058
Epoch 83/150
 65/130 [==============>...............] - ETA: 0s - loss: 9.3180e-04 - mae: 0.0213 - mse: 7.9125e-04
Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0028981610666960478.
130/130 [==============================] - 0s 1ms/step - loss: 9.3281e-04 - mae: 0.0214 - mse: 7.9123e-04 - val_loss: 9.0816e-04 - val_mae: 0.0208 - val_mse: 7.7327e-04 - lr: 0.0058
Epoch 84/150
130/130 [==============================] - 0s 1ms/step - loss: 9.2039e-04 - mae: 0.0212 - mse: 7.8307e-04 - val_loss: 9.0215e-04 - val_mae: 0.0208 - val_mse: 7.5556e-04 - lr: 0.0029
Epoch 85/150
130/130 [==============================] - 0s 1ms/step - loss: 9.1428e-04 - mae: 0.0211 - mse: 7.7129e-04 - val_loss: 0.0011 - val_mae: 0.0231 - val_mse: 9.1484e-04 - lr: 0.0029
Epoch 86/150
130/130 [==============================] - 0s 1ms/step - loss: 9.4917e-04 - mae: 0.0216 - mse: 8.0239e-04 - val_loss: 8.8836e-04 - val_mae: 0.0204 - val_mse: 7.4585e-04 - lr: 0.0029
Epoch 87/150
130/130 [==============================] - 0s 1ms/step - loss: 9.0873e-04 - mae: 0.0210 - mse: 7.6764e-04 - val_loss: 9.5767e-04 - val_mae: 0.0222 - val_mse: 8.1425e-04 - lr: 0.0029
Epoch 88/150
130/130 [==============================] - 0s 1ms/step - loss: 9.1119e-04 - mae: 0.0210 - mse: 7.6970e-04 - val_loss: 8.9454e-04 - val_mae: 0.0207 - val_mse: 7.5468e-04 - lr: 0.0029
Epoch 89/150
130/130 [==============================] - 0s 1ms/step - loss: 9.0506e-04 - mae: 0.0210 - mse: 7.6529e-04 - val_loss: 8.8945e-04 - val_mae: 0.0204 - val_mse: 7.4936e-04 - lr: 0.0029
Epoch 90/150
130/130 [==============================] - 0s 1ms/step - loss: 9.0239e-04 - mae: 0.0210 - mse: 7.6635e-04 - val_loss: 9.3557e-04 - val_mae: 0.0219 - val_mse: 7.9080e-04 - lr: 0.0029
Epoch 91/150
130/130 [==============================] - 0s 1ms/step - loss: 9.2083e-04 - mae: 0.0212 - mse: 7.8503e-04 - val_loss: 9.0442e-04 - val_mae: 0.0204 - val_mse: 7.6663e-04 - lr: 0.0029
Epoch 92/150
130/130 [==============================] - 0s 1ms/step - loss: 8.9720e-04 - mae: 0.0208 - mse: 7.5983e-04 - val_loss: 8.7840e-04 - val_mae: 0.0203 - val_mse: 7.3886e-04 - lr: 0.0029
Epoch 93/150
 71/130 [===============>..............] - ETA: 0s - loss: 9.2715e-04 - mae: 0.0214 - mse: 7.8658e-04
Epoch 93: ReduceLROnPlateau reducing learning rate to 0.0014490805333480239.
130/130 [==============================] - 0s 1ms/step - loss: 9.0229e-04 - mae: 0.0210 - mse: 7.6242e-04 - val_loss: 9.2303e-04 - val_mae: 0.0217 - val_mse: 7.8468e-04 - lr: 0.0029
Epoch 94/150
130/130 [==============================] - 0s 1ms/step - loss: 8.9446e-04 - mae: 0.0209 - mse: 7.5811e-04 - val_loss: 8.8576e-04 - val_mae: 0.0202 - val_mse: 7.4956e-04 - lr: 0.0014
Epoch 95/150
130/130 [==============================] - 0s 1ms/step - loss: 8.8414e-04 - mae: 0.0206 - mse: 7.4587e-04 - val_loss: 8.7240e-04 - val_mae: 0.0202 - val_mse: 7.3391e-04 - lr: 0.0014
Epoch 96/150
130/130 [==============================] - 0s 2ms/step - loss: 8.8710e-04 - mae: 0.0206 - mse: 7.4687e-04 - val_loss: 8.8541e-04 - val_mae: 0.0207 - val_mse: 7.4701e-04 - lr: 0.0014
Epoch 97/150
130/130 [==============================] - 0s 2ms/step - loss: 8.8644e-04 - mae: 0.0207 - mse: 7.4796e-04 - val_loss: 8.7235e-04 - val_mae: 0.0203 - val_mse: 7.3410e-04 - lr: 0.0014
Epoch 98/150
130/130 [==============================] - 0s 1ms/step - loss: 9.0086e-04 - mae: 0.0209 - mse: 7.6067e-04 - val_loss: 8.8145e-04 - val_mae: 0.0206 - val_mse: 7.4168e-04 - lr: 0.0014
Epoch 99/150
130/130 [==============================] - 0s 1ms/step - loss: 8.7955e-04 - mae: 0.0206 - mse: 7.4365e-04 - val_loss: 9.1356e-04 - val_mae: 0.0207 - val_mse: 7.7986e-04 - lr: 0.0014
Epoch 100/150
130/130 [==============================] - 0s 1ms/step - loss: 8.8145e-04 - mae: 0.0206 - mse: 7.4688e-04 - val_loss: 8.7316e-04 - val_mae: 0.0200 - val_mse: 7.3994e-04 - lr: 0.0014
Epoch 101/150
130/130 [==============================] - 0s 1ms/step - loss: 8.7427e-04 - mae: 0.0205 - mse: 7.3815e-04 - val_loss: 9.4979e-04 - val_mae: 0.0216 - val_mse: 8.1837e-04 - lr: 0.0014
Epoch 102/150
130/130 [==============================] - 0s 1ms/step - loss: 9.0516e-04 - mae: 0.0211 - mse: 7.6813e-04 - val_loss: 8.6381e-04 - val_mae: 0.0201 - val_mse: 7.2681e-04 - lr: 0.0014
Epoch 103/150
130/130 [==============================] - 0s 2ms/step - loss: 8.8513e-04 - mae: 0.0207 - mse: 7.4763e-04 - val_loss: 8.7027e-04 - val_mae: 0.0204 - val_mse: 7.3436e-04 - lr: 0.0014
Epoch 104/150
130/130 [==============================] - 0s 2ms/step - loss: 8.8207e-04 - mae: 0.0207 - mse: 7.4868e-04 - val_loss: 8.7691e-04 - val_mae: 0.0207 - val_mse: 7.4151e-04 - lr: 0.0014
Epoch 105/150
130/130 [==============================] - 0s 2ms/step - loss: 8.7231e-04 - mae: 0.0205 - mse: 7.3789e-04 - val_loss: 8.6451e-04 - val_mae: 0.0201 - val_mse: 7.3022e-04 - lr: 0.0014
Epoch 106/150
130/130 [==============================] - 0s 2ms/step - loss: 8.7968e-04 - mae: 0.0206 - mse: 7.4244e-04 - val_loss: 8.6367e-04 - val_mae: 0.0201 - val_mse: 7.2765e-04 - lr: 0.0014
Epoch 107/150
130/130 [==============================] - 0s 2ms/step - loss: 8.7436e-04 - mae: 0.0205 - mse: 7.3916e-04 - val_loss: 8.6563e-04 - val_mae: 0.0204 - val_mse: 7.3030e-04 - lr: 0.0014
Epoch 108/150
130/130 [==============================] - 0s 2ms/step - loss: 8.7528e-04 - mae: 0.0206 - mse: 7.4099e-04 - val_loss: 8.6939e-04 - val_mae: 0.0199 - val_mse: 7.3513e-04 - lr: 0.0014
Epoch 109/150
130/130 [==============================] - 0s 2ms/step - loss: 8.8142e-04 - mae: 0.0207 - mse: 7.4604e-04 - val_loss: 8.5840e-04 - val_mae: 0.0199 - val_mse: 7.2468e-04 - lr: 0.0014
Epoch 110/150
130/130 [==============================] - 0s 2ms/step - loss: 8.7250e-04 - mae: 0.0206 - mse: 7.4015e-04 - val_loss: 8.5879e-04 - val_mae: 0.0202 - val_mse: 7.2475e-04 - lr: 0.0014
Epoch 111/150
130/130 [==============================] - 0s 2ms/step - loss: 8.7069e-04 - mae: 0.0205 - mse: 7.3899e-04 - val_loss: 8.6475e-04 - val_mae: 0.0204 - val_mse: 7.2987e-04 - lr: 0.0014
Epoch 112/150
104/130 [=======================>......] - ETA: 0s - loss: 8.7787e-04 - mae: 0.0207 - mse: 7.4596e-04
Epoch 112: ReduceLROnPlateau reducing learning rate to 0.0007245402666740119.
130/130 [==============================] - 0s 2ms/step - loss: 8.6886e-04 - mae: 0.0205 - mse: 7.3624e-04 - val_loss: 8.6534e-04 - val_mae: 0.0205 - val_mse: 7.2989e-04 - lr: 0.0014
Epoch 113/150
130/130 [==============================] - 0s 2ms/step - loss: 8.6532e-04 - mae: 0.0205 - mse: 7.3285e-04 - val_loss: 8.5266e-04 - val_mae: 0.0199 - val_mse: 7.1991e-04 - lr: 7.2454e-04
Epoch 114/150
130/130 [==============================] - 0s 2ms/step - loss: 8.6294e-04 - mae: 0.0204 - mse: 7.3104e-04 - val_loss: 8.5433e-04 - val_mae: 0.0199 - val_mse: 7.2307e-04 - lr: 7.2454e-04
Epoch 115/150
130/130 [==============================] - 0s 2ms/step - loss: 8.6226e-04 - mae: 0.0204 - mse: 7.3051e-04 - val_loss: 8.5639e-04 - val_mae: 0.0202 - val_mse: 7.2434e-04 - lr: 7.2454e-04
Epoch 116/150
130/130 [==============================] - 0s 1ms/step - loss: 8.6325e-04 - mae: 0.0205 - mse: 7.3367e-04 - val_loss: 8.5151e-04 - val_mae: 0.0200 - val_mse: 7.2036e-04 - lr: 7.2454e-04
Epoch 117/150
130/130 [==============================] - 0s 1ms/step - loss: 8.6109e-04 - mae: 0.0204 - mse: 7.2884e-04 - val_loss: 8.5100e-04 - val_mae: 0.0199 - val_mse: 7.1908e-04 - lr: 7.2454e-04
Epoch 118/150
130/130 [==============================] - 0s 2ms/step - loss: 8.6334e-04 - mae: 0.0205 - mse: 7.3138e-04 - val_loss: 8.5405e-04 - val_mae: 0.0199 - val_mse: 7.2279e-04 - lr: 7.2454e-04
Epoch 119/150
130/130 [==============================] - 0s 2ms/step - loss: 8.5993e-04 - mae: 0.0204 - mse: 7.2773e-04 - val_loss: 8.5535e-04 - val_mae: 0.0202 - val_mse: 7.2328e-04 - lr: 7.2454e-04
Epoch 120/150
130/130 [==============================] - 0s 2ms/step - loss: 8.5967e-04 - mae: 0.0204 - mse: 7.2800e-04 - val_loss: 8.5191e-04 - val_mae: 0.0200 - val_mse: 7.2032e-04 - lr: 7.2454e-04
Epoch 121/150
130/130 [==============================] - 0s 2ms/step - loss: 8.6265e-04 - mae: 0.0204 - mse: 7.3047e-04 - val_loss: 8.4850e-04 - val_mae: 0.0199 - val_mse: 7.1582e-04 - lr: 7.2454e-04
Epoch 122/150
105/130 [=======================>......] - ETA: 0s - loss: 8.6947e-04 - mae: 0.0206 - mse: 7.3673e-04
Epoch 122: ReduceLROnPlateau reducing learning rate to 0.00036227013333700597.
130/130 [==============================] - 0s 1ms/step - loss: 8.6143e-04 - mae: 0.0204 - mse: 7.2877e-04 - val_loss: 8.4763e-04 - val_mae: 0.0198 - val_mse: 7.1596e-04 - lr: 7.2454e-04
Epoch 123/150
130/130 [==============================] - 0s 1ms/step - loss: 8.5502e-04 - mae: 0.0203 - mse: 7.2393e-04 - val_loss: 8.4766e-04 - val_mae: 0.0199 - val_mse: 7.1609e-04 - lr: 3.6227e-04
Epoch 124/150
130/130 [==============================] - 0s 1ms/step - loss: 8.5719e-04 - mae: 0.0203 - mse: 7.2385e-04 - val_loss: 8.4687e-04 - val_mae: 0.0199 - val_mse: 7.1388e-04 - lr: 3.6227e-04
Epoch 125/150
130/130 [==============================] - 0s 1ms/step - loss: 8.5313e-04 - mae: 0.0202 - mse: 7.2066e-04 - val_loss: 8.4696e-04 - val_mae: 0.0198 - val_mse: 7.1477e-04 - lr: 3.6227e-04
Epoch 126/150
130/130 [==============================] - 0s 1ms/step - loss: 8.5278e-04 - mae: 0.0202 - mse: 7.1958e-04 - val_loss: 8.4839e-04 - val_mae: 0.0198 - val_mse: 7.1673e-04 - lr: 3.6227e-04
Epoch 127/150
130/130 [==============================] - 0s 1ms/step - loss: 8.5501e-04 - mae: 0.0203 - mse: 7.2295e-04 - val_loss: 8.4697e-04 - val_mae: 0.0199 - val_mse: 7.1463e-04 - lr: 3.6227e-04
Epoch 128/150
130/130 [==============================] - 0s 1ms/step - loss: 8.5295e-04 - mae: 0.0203 - mse: 7.2040e-04 - val_loss: 8.4638e-04 - val_mae: 0.0199 - val_mse: 7.1287e-04 - lr: 3.6227e-04
Epoch 129/150
130/130 [==============================] - 0s 2ms/step - loss: 8.5452e-04 - mae: 0.0203 - mse: 7.2211e-04 - val_loss: 8.5601e-04 - val_mae: 0.0199 - val_mse: 7.2505e-04 - lr: 3.6227e-04
Epoch 130/150
130/130 [==============================] - 0s 2ms/step - loss: 8.5460e-04 - mae: 0.0203 - mse: 7.2300e-04 - val_loss: 8.4546e-04 - val_mae: 0.0199 - val_mse: 7.1338e-04 - lr: 3.6227e-04
Epoch 131/150
130/130 [==============================] - 0s 2ms/step - loss: 8.5562e-04 - mae: 0.0204 - mse: 7.2374e-04 - val_loss: 8.5238e-04 - val_mae: 0.0198 - val_mse: 7.2135e-04 - lr: 3.6227e-04
Epoch 132/150
112/130 [========================>.....] - ETA: 0s - loss: 8.5815e-04 - mae: 0.0203 - mse: 7.2632e-04
Epoch 132: ReduceLROnPlateau reducing learning rate to 0.00018113506666850299.
130/130 [==============================] - 0s 1ms/step - loss: 8.5389e-04 - mae: 0.0203 - mse: 7.2204e-04 - val_loss: 8.4553e-04 - val_mae: 0.0200 - val_mse: 7.1341e-04 - lr: 3.6227e-04
Epoch 133/150
130/130 [==============================] - 0s 1ms/step - loss: 8.5119e-04 - mae: 0.0203 - mse: 7.2000e-04 - val_loss: 8.5046e-04 - val_mae: 0.0198 - val_mse: 7.2007e-04 - lr: 1.8114e-04
Epoch 134/150
130/130 [==============================] - 0s 1ms/step - loss: 8.5068e-04 - mae: 0.0202 - mse: 7.1983e-04 - val_loss: 8.4606e-04 - val_mae: 0.0200 - val_mse: 7.1423e-04 - lr: 1.8114e-04
Epoch 135/150
130/130 [==============================] - 0s 1ms/step - loss: 8.5035e-04 - mae: 0.0203 - mse: 7.1925e-04 - val_loss: 8.4605e-04 - val_mae: 0.0198 - val_mse: 7.1579e-04 - lr: 1.8114e-04
Epoch 136/150
130/130 [==============================] - 0s 1ms/step - loss: 8.5069e-04 - mae: 0.0202 - mse: 7.1970e-04 - val_loss: 8.4361e-04 - val_mae: 0.0198 - val_mse: 7.1208e-04 - lr: 1.8114e-04
Epoch 137/150
130/130 [==============================] - 0s 1ms/step - loss: 8.5125e-04 - mae: 0.0203 - mse: 7.2014e-04 - val_loss: 8.4410e-04 - val_mae: 0.0199 - val_mse: 7.1285e-04 - lr: 1.8114e-04
Epoch 138/150
130/130 [==============================] - 0s 1ms/step - loss: 8.5063e-04 - mae: 0.0202 - mse: 7.1951e-04 - val_loss: 8.4411e-04 - val_mae: 0.0198 - val_mse: 7.1339e-04 - lr: 1.8114e-04
Epoch 139/150
130/130 [==============================] - 0s 1ms/step - loss: 8.4958e-04 - mae: 0.0202 - mse: 7.1888e-04 - val_loss: 8.4877e-04 - val_mae: 0.0198 - val_mse: 7.1856e-04 - lr: 1.8114e-04
Epoch 140/150
130/130 [==============================] - 0s 1ms/step - loss: 8.5516e-04 - mae: 0.0203 - mse: 7.2454e-04 - val_loss: 8.4424e-04 - val_mae: 0.0198 - val_mse: 7.1406e-04 - lr: 1.8114e-04
Epoch 141/150
130/130 [==============================] - 0s 1ms/step - loss: 8.4938e-04 - mae: 0.0202 - mse: 7.1915e-04 - val_loss: 8.4903e-04 - val_mae: 0.0198 - val_mse: 7.1925e-04 - lr: 1.8114e-04
Epoch 142/150
 68/130 [==============>...............] - ETA: 0s - loss: 8.3646e-04 - mae: 0.0200 - mse: 7.0607e-04
Epoch 142: ReduceLROnPlateau reducing learning rate to 9.056753333425149e-05.
130/130 [==============================] - 0s 1ms/step - loss: 8.5001e-04 - mae: 0.0202 - mse: 7.1956e-04 - val_loss: 8.4410e-04 - val_mae: 0.0198 - val_mse: 7.1404e-04 - lr: 1.8114e-04
Epoch 143/150
130/130 [==============================] - 0s 1ms/step - loss: 8.4857e-04 - mae: 0.0202 - mse: 7.1830e-04 - val_loss: 8.4273e-04 - val_mae: 0.0198 - val_mse: 7.1245e-04 - lr: 9.0568e-05
Epoch 144/150
130/130 [==============================] - 0s 1ms/step - loss: 8.4938e-04 - mae: 0.0202 - mse: 7.1888e-04 - val_loss: 8.4537e-04 - val_mae: 0.0198 - val_mse: 7.1513e-04 - lr: 9.0568e-05
Epoch 145/150
130/130 [==============================] - 0s 1ms/step - loss: 8.4899e-04 - mae: 0.0202 - mse: 7.1838e-04 - val_loss: 8.4241e-04 - val_mae: 0.0198 - val_mse: 7.1160e-04 - lr: 9.0568e-05
Epoch 146/150
130/130 [==============================] - 0s 1ms/step - loss: 8.4857e-04 - mae: 0.0202 - mse: 7.1777e-04 - val_loss: 8.4333e-04 - val_mae: 0.0198 - val_mse: 7.1288e-04 - lr: 9.0568e-05
Epoch 147/150
130/130 [==============================] - 0s 1ms/step - loss: 8.4863e-04 - mae: 0.0202 - mse: 7.1810e-04 - val_loss: 8.4228e-04 - val_mae: 0.0199 - val_mse: 7.1141e-04 - lr: 9.0568e-05
Epoch 148/150
130/130 [==============================] - 0s 1ms/step - loss: 8.4790e-04 - mae: 0.0202 - mse: 7.1748e-04 - val_loss: 8.4208e-04 - val_mae: 0.0198 - val_mse: 7.1152e-04 - lr: 9.0568e-05
Epoch 149/150
130/130 [==============================] - 0s 1ms/step - loss: 8.4921e-04 - mae: 0.0202 - mse: 7.1830e-04 - val_loss: 8.4208e-04 - val_mae: 0.0198 - val_mse: 7.1158e-04 - lr: 9.0568e-05
Epoch 150/150
130/130 [==============================] - 0s 1ms/step - loss: 8.4795e-04 - mae: 0.0202 - mse: 7.1755e-04 - val_loss: 8.4206e-04 - val_mae: 0.0198 - val_mse: 7.1169e-04 - lr: 9.0568e-05
>Saved ../trained_models/models_segments_overlap_adam_0.09274115666742028LR_[30]HN_40BS_10P_val_mseM_150epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0279 - mae: 0.0403 - mse: 0.0024 - val_loss: 0.0021 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0927
Epoch 2/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0927
Epoch 3/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0927
Epoch 4/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0927
Epoch 5/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0927
Epoch 6/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0927
Epoch 7/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0927
Epoch 8/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.0026 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0927
Epoch 9/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0367 - mse: 0.0019 - val_loss: 0.0036 - val_mae: 0.0457 - val_mse: 0.0031 - lr: 0.0927
Epoch 10/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0025 - mae: 0.0346 - mse: 0.0017 - val_loss: 0.0047 - val_mae: 0.0527 - val_mse: 0.0041 - lr: 0.0927
Epoch 11/150
68/98 [===================>..........] - ETA: 0s - loss: 0.0041 - mae: 0.0406 - mse: 0.0024
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.046370577067136765.
98/98 [==============================] - 0s 1ms/step - loss: 0.0040 - mae: 0.0397 - mse: 0.0023 - val_loss: 0.0056 - val_mae: 0.0528 - val_mse: 0.0042 - lr: 0.0927
Epoch 12/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0024 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0363 - val_mse: 0.0018 - lr: 0.0464
Epoch 13/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0342 - mse: 0.0017 - val_loss: 0.0017 - val_mae: 0.0298 - val_mse: 0.0013 - lr: 0.0464
Epoch 14/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0016 - mae: 0.0288 - mse: 0.0013 - val_loss: 0.0022 - val_mae: 0.0364 - val_mse: 0.0020 - lr: 0.0464
Epoch 15/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0015 - mae: 0.0275 - mse: 0.0012 - val_loss: 0.0017 - val_mae: 0.0326 - val_mse: 0.0016 - lr: 0.0464
Epoch 16/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0260 - mse: 0.0011 - val_loss: 0.0049 - val_mae: 0.0570 - val_mse: 0.0047 - lr: 0.0464
Epoch 17/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0271 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0251 - val_mse: 0.0010 - lr: 0.0464
Epoch 18/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0253 - mse: 0.0010 - val_loss: 0.0013 - val_mae: 0.0285 - val_mse: 0.0012 - lr: 0.0464
Epoch 19/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0013 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0015 - val_mae: 0.0287 - val_mse: 0.0013 - lr: 0.0464
Epoch 20/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0255 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0270 - val_mse: 0.0011 - lr: 0.0464
Epoch 21/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0253 - mse: 0.0010 - val_loss: 0.0016 - val_mae: 0.0304 - val_mse: 0.0015 - lr: 0.0464
Epoch 22/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0254 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0246 - val_mse: 9.4401e-04 - lr: 0.0464
Epoch 23/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0245 - mse: 9.4787e-04 - val_loss: 0.0010 - val_mae: 0.0245 - val_mse: 9.3154e-04 - lr: 0.0464
Epoch 24/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0252 - mse: 9.9560e-04 - val_loss: 0.0011 - val_mae: 0.0242 - val_mse: 9.4816e-04 - lr: 0.0464
Epoch 25/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0252 - mse: 9.9575e-04 - val_loss: 0.0011 - val_mae: 0.0255 - val_mse: 9.6885e-04 - lr: 0.0464
Epoch 26/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0248 - mse: 9.7332e-04 - val_loss: 0.0025 - val_mae: 0.0403 - val_mse: 0.0024 - lr: 0.0464
Epoch 27/150
73/98 [=====================>........] - ETA: 0s - loss: 0.0013 - mae: 0.0268 - mse: 0.0011
Epoch 27: ReduceLROnPlateau reducing learning rate to 0.023185288533568382.
98/98 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0259 - mse: 0.0011 - val_loss: 0.0019 - val_mae: 0.0357 - val_mse: 0.0018 - lr: 0.0464
Epoch 28/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0239 - mse: 9.1218e-04 - val_loss: 0.0011 - val_mae: 0.0245 - val_mse: 0.0010 - lr: 0.0232
Epoch 29/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0239 - mse: 9.0542e-04 - val_loss: 0.0010 - val_mae: 0.0237 - val_mse: 9.0913e-04 - lr: 0.0232
Epoch 30/150
98/98 [==============================] - 0s 1ms/step - loss: 9.5843e-04 - mae: 0.0231 - mse: 8.6180e-04 - val_loss: 0.0011 - val_mae: 0.0264 - val_mse: 0.0010 - lr: 0.0232
Epoch 31/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6109e-04 - mae: 0.0232 - mse: 8.6271e-04 - val_loss: 0.0011 - val_mae: 0.0240 - val_mse: 9.8920e-04 - lr: 0.0232
Epoch 32/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6164e-04 - mae: 0.0231 - mse: 8.5966e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.5343e-04 - lr: 0.0232
Epoch 33/150
98/98 [==============================] - 0s 1ms/step - loss: 9.3488e-04 - mae: 0.0227 - mse: 8.3926e-04 - val_loss: 0.0011 - val_mae: 0.0247 - val_mse: 0.0010 - lr: 0.0232
Epoch 34/150
98/98 [==============================] - 0s 1ms/step - loss: 9.2729e-04 - mae: 0.0227 - mse: 8.3554e-04 - val_loss: 9.9383e-04 - val_mae: 0.0220 - val_mse: 8.6111e-04 - lr: 0.0232
Epoch 35/150
98/98 [==============================] - 0s 1ms/step - loss: 9.5013e-04 - mae: 0.0230 - mse: 8.5704e-04 - val_loss: 0.0011 - val_mae: 0.0264 - val_mse: 0.0010 - lr: 0.0232
Epoch 36/150
98/98 [==============================] - 0s 1ms/step - loss: 9.2787e-04 - mae: 0.0227 - mse: 8.2749e-04 - val_loss: 0.0013 - val_mae: 0.0272 - val_mse: 0.0012 - lr: 0.0232
Epoch 37/150
98/98 [==============================] - 0s 1ms/step - loss: 9.2322e-04 - mae: 0.0225 - mse: 8.1997e-04 - val_loss: 9.0704e-04 - val_mae: 0.0226 - val_mse: 8.2362e-04 - lr: 0.0232
Epoch 38/150
98/98 [==============================] - 0s 1ms/step - loss: 9.1318e-04 - mae: 0.0225 - mse: 8.1506e-04 - val_loss: 9.4434e-04 - val_mae: 0.0226 - val_mse: 8.2873e-04 - lr: 0.0232
Epoch 39/150
98/98 [==============================] - 0s 1ms/step - loss: 9.0586e-04 - mae: 0.0222 - mse: 8.0292e-04 - val_loss: 0.0024 - val_mae: 0.0402 - val_mse: 0.0023 - lr: 0.0232
Epoch 40/150
98/98 [==============================] - 0s 1ms/step - loss: 9.9674e-04 - mae: 0.0234 - mse: 8.9164e-04 - val_loss: 9.4080e-04 - val_mae: 0.0235 - val_mse: 8.5036e-04 - lr: 0.0232
Epoch 41/150
98/98 [==============================] - 0s 1ms/step - loss: 9.1124e-04 - mae: 0.0224 - mse: 8.0960e-04 - val_loss: 9.1510e-04 - val_mae: 0.0213 - val_mse: 8.0367e-04 - lr: 0.0232
Epoch 42/150
98/98 [==============================] - 0s 1ms/step - loss: 9.4946e-04 - mae: 0.0230 - mse: 8.4766e-04 - val_loss: 0.0012 - val_mae: 0.0282 - val_mse: 0.0011 - lr: 0.0232
Epoch 43/150
98/98 [==============================] - 0s 1ms/step - loss: 9.7885e-04 - mae: 0.0232 - mse: 8.6379e-04 - val_loss: 0.0010 - val_mae: 0.0254 - val_mse: 9.6067e-04 - lr: 0.0232
Epoch 44/150
71/98 [====================>.........] - ETA: 0s - loss: 9.2253e-04 - mae: 0.0225 - mse: 8.2002e-04
Epoch 44: ReduceLROnPlateau reducing learning rate to 0.011592644266784191.
98/98 [==============================] - 0s 1ms/step - loss: 8.9680e-04 - mae: 0.0221 - mse: 7.9728e-04 - val_loss: 0.0011 - val_mae: 0.0239 - val_mse: 9.5076e-04 - lr: 0.0232
Epoch 45/150
98/98 [==============================] - 0s 1ms/step - loss: 8.5592e-04 - mae: 0.0214 - mse: 7.5700e-04 - val_loss: 8.8595e-04 - val_mae: 0.0217 - val_mse: 7.8313e-04 - lr: 0.0116
Epoch 46/150
98/98 [==============================] - 0s 1ms/step - loss: 8.6822e-04 - mae: 0.0216 - mse: 7.6814e-04 - val_loss: 8.7876e-04 - val_mae: 0.0222 - val_mse: 7.8411e-04 - lr: 0.0116
Epoch 47/150
98/98 [==============================] - 0s 1ms/step - loss: 8.6225e-04 - mae: 0.0216 - mse: 7.6288e-04 - val_loss: 9.3395e-04 - val_mae: 0.0227 - val_mse: 8.4421e-04 - lr: 0.0116
Epoch 48/150
98/98 [==============================] - 0s 1ms/step - loss: 8.4301e-04 - mae: 0.0212 - mse: 7.5200e-04 - val_loss: 8.7966e-04 - val_mae: 0.0209 - val_mse: 7.7134e-04 - lr: 0.0116
Epoch 49/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2604e-04 - mae: 0.0209 - mse: 7.3066e-04 - val_loss: 8.4932e-04 - val_mae: 0.0219 - val_mse: 7.6499e-04 - lr: 0.0116
Epoch 50/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2528e-04 - mae: 0.0209 - mse: 7.3173e-04 - val_loss: 8.5127e-04 - val_mae: 0.0206 - val_mse: 7.3714e-04 - lr: 0.0116
Epoch 51/150
98/98 [==============================] - 0s 1ms/step - loss: 8.3953e-04 - mae: 0.0211 - mse: 7.4159e-04 - val_loss: 8.2328e-04 - val_mae: 0.0205 - val_mse: 7.2254e-04 - lr: 0.0116
Epoch 52/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2641e-04 - mae: 0.0209 - mse: 7.3272e-04 - val_loss: 0.0010 - val_mae: 0.0241 - val_mse: 9.3915e-04 - lr: 0.0116
Epoch 53/150
98/98 [==============================] - 0s 1ms/step - loss: 8.6985e-04 - mae: 0.0218 - mse: 7.7175e-04 - val_loss: 8.1277e-04 - val_mae: 0.0207 - val_mse: 7.2277e-04 - lr: 0.0116
Epoch 54/150
98/98 [==============================] - 0s 1ms/step - loss: 7.9276e-04 - mae: 0.0202 - mse: 6.9516e-04 - val_loss: 9.0519e-04 - val_mae: 0.0229 - val_mse: 7.9718e-04 - lr: 0.0116
Epoch 55/150
98/98 [==============================] - 0s 1ms/step - loss: 8.5665e-04 - mae: 0.0215 - mse: 7.5340e-04 - val_loss: 8.8768e-04 - val_mae: 0.0209 - val_mse: 7.7570e-04 - lr: 0.0116
Epoch 56/150
98/98 [==============================] - 0s 1ms/step - loss: 7.8466e-04 - mae: 0.0201 - mse: 6.9109e-04 - val_loss: 8.0416e-04 - val_mae: 0.0205 - val_mse: 7.1050e-04 - lr: 0.0116
Epoch 57/150
98/98 [==============================] - 0s 1ms/step - loss: 8.1618e-04 - mae: 0.0207 - mse: 7.2076e-04 - val_loss: 8.4190e-04 - val_mae: 0.0214 - val_mse: 7.5586e-04 - lr: 0.0116
Epoch 58/150
98/98 [==============================] - 0s 2ms/step - loss: 7.8188e-04 - mae: 0.0202 - mse: 6.8887e-04 - val_loss: 7.9520e-04 - val_mae: 0.0197 - val_mse: 6.8123e-04 - lr: 0.0116
Epoch 59/150
98/98 [==============================] - 0s 1ms/step - loss: 8.1208e-04 - mae: 0.0206 - mse: 7.1462e-04 - val_loss: 7.9838e-04 - val_mae: 0.0201 - val_mse: 6.9909e-04 - lr: 0.0116
Epoch 60/150
53/98 [===============>..............] - ETA: 0s - loss: 7.7549e-04 - mae: 0.0202 - mse: 6.8094e-04
Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0057963221333920956.
98/98 [==============================] - 0s 2ms/step - loss: 7.9247e-04 - mae: 0.0202 - mse: 6.8841e-04 - val_loss: 8.0527e-04 - val_mae: 0.0213 - val_mse: 7.2004e-04 - lr: 0.0116
Epoch 61/150
98/98 [==============================] - 0s 2ms/step - loss: 7.7020e-04 - mae: 0.0200 - mse: 6.7883e-04 - val_loss: 8.7128e-04 - val_mae: 0.0219 - val_mse: 7.8058e-04 - lr: 0.0058
Epoch 62/150
98/98 [==============================] - 0s 2ms/step - loss: 7.7578e-04 - mae: 0.0200 - mse: 6.7801e-04 - val_loss: 8.5844e-04 - val_mae: 0.0223 - val_mse: 7.7505e-04 - lr: 0.0058
Epoch 63/150
98/98 [==============================] - 0s 2ms/step - loss: 7.5811e-04 - mae: 0.0198 - mse: 6.6642e-04 - val_loss: 7.9800e-04 - val_mae: 0.0207 - val_mse: 7.0513e-04 - lr: 0.0058
Epoch 64/150
98/98 [==============================] - 0s 2ms/step - loss: 7.6424e-04 - mae: 0.0199 - mse: 6.7236e-04 - val_loss: 7.7250e-04 - val_mae: 0.0199 - val_mse: 6.7671e-04 - lr: 0.0058
Epoch 65/150
98/98 [==============================] - 0s 2ms/step - loss: 7.4651e-04 - mae: 0.0194 - mse: 6.4907e-04 - val_loss: 7.8934e-04 - val_mae: 0.0205 - val_mse: 7.0192e-04 - lr: 0.0058
Epoch 66/150
98/98 [==============================] - 0s 2ms/step - loss: 7.4140e-04 - mae: 0.0194 - mse: 6.5229e-04 - val_loss: 7.4908e-04 - val_mae: 0.0194 - val_mse: 6.5804e-04 - lr: 0.0058
Epoch 67/150
98/98 [==============================] - 0s 2ms/step - loss: 7.4810e-04 - mae: 0.0196 - mse: 6.5815e-04 - val_loss: 7.5973e-04 - val_mae: 0.0204 - val_mse: 6.7677e-04 - lr: 0.0058
Epoch 68/150
98/98 [==============================] - 0s 2ms/step - loss: 7.5618e-04 - mae: 0.0197 - mse: 6.6575e-04 - val_loss: 7.4099e-04 - val_mae: 0.0195 - val_mse: 6.5161e-04 - lr: 0.0058
Epoch 69/150
98/98 [==============================] - 0s 2ms/step - loss: 7.4620e-04 - mae: 0.0196 - mse: 6.5335e-04 - val_loss: 7.5751e-04 - val_mae: 0.0198 - val_mse: 6.6781e-04 - lr: 0.0058
Epoch 70/150
51/98 [==============>...............] - ETA: 0s - loss: 7.4524e-04 - mae: 0.0195 - mse: 6.5420e-04
Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0028981610666960478.
98/98 [==============================] - 0s 2ms/step - loss: 7.5159e-04 - mae: 0.0196 - mse: 6.5870e-04 - val_loss: 8.0141e-04 - val_mae: 0.0211 - val_mse: 7.0799e-04 - lr: 0.0058
Epoch 71/150
98/98 [==============================] - 0s 2ms/step - loss: 7.3555e-04 - mae: 0.0193 - mse: 6.4320e-04 - val_loss: 7.4314e-04 - val_mae: 0.0191 - val_mse: 6.4867e-04 - lr: 0.0029
Epoch 72/150
98/98 [==============================] - 0s 2ms/step - loss: 7.1880e-04 - mae: 0.0189 - mse: 6.2801e-04 - val_loss: 7.3714e-04 - val_mae: 0.0189 - val_mse: 6.4504e-04 - lr: 0.0029
Epoch 73/150
98/98 [==============================] - 0s 2ms/step - loss: 7.1506e-04 - mae: 0.0188 - mse: 6.2561e-04 - val_loss: 7.3434e-04 - val_mae: 0.0191 - val_mse: 6.4526e-04 - lr: 0.0029
Epoch 74/150
98/98 [==============================] - 0s 2ms/step - loss: 7.1766e-04 - mae: 0.0189 - mse: 6.2712e-04 - val_loss: 7.2773e-04 - val_mae: 0.0190 - val_mse: 6.4139e-04 - lr: 0.0029
Epoch 75/150
98/98 [==============================] - 0s 3ms/step - loss: 7.2153e-04 - mae: 0.0191 - mse: 6.3354e-04 - val_loss: 7.3756e-04 - val_mae: 0.0195 - val_mse: 6.4548e-04 - lr: 0.0029
Epoch 76/150
98/98 [==============================] - 0s 2ms/step - loss: 7.0927e-04 - mae: 0.0187 - mse: 6.1663e-04 - val_loss: 7.5258e-04 - val_mae: 0.0199 - val_mse: 6.6312e-04 - lr: 0.0029
Epoch 77/150
98/98 [==============================] - 0s 2ms/step - loss: 7.2803e-04 - mae: 0.0193 - mse: 6.3819e-04 - val_loss: 7.2443e-04 - val_mae: 0.0192 - val_mse: 6.3775e-04 - lr: 0.0029
Epoch 78/150
98/98 [==============================] - 0s 2ms/step - loss: 7.1019e-04 - mae: 0.0188 - mse: 6.2098e-04 - val_loss: 7.2066e-04 - val_mae: 0.0194 - val_mse: 6.3653e-04 - lr: 0.0029
Epoch 79/150
98/98 [==============================] - 0s 2ms/step - loss: 7.0467e-04 - mae: 0.0187 - mse: 6.1452e-04 - val_loss: 7.2045e-04 - val_mae: 0.0191 - val_mse: 6.3144e-04 - lr: 0.0029
Epoch 80/150
98/98 [==============================] - 0s 2ms/step - loss: 7.1055e-04 - mae: 0.0188 - mse: 6.1818e-04 - val_loss: 7.1597e-04 - val_mae: 0.0190 - val_mse: 6.3179e-04 - lr: 0.0029
Epoch 81/150
98/98 [==============================] - 0s 2ms/step - loss: 7.0296e-04 - mae: 0.0188 - mse: 6.1738e-04 - val_loss: 7.3460e-04 - val_mae: 0.0195 - val_mse: 6.4779e-04 - lr: 0.0029
Epoch 82/150
98/98 [==============================] - 0s 2ms/step - loss: 7.0072e-04 - mae: 0.0186 - mse: 6.0972e-04 - val_loss: 7.3470e-04 - val_mae: 0.0191 - val_mse: 6.4233e-04 - lr: 0.0029
Epoch 83/150
98/98 [==============================] - 0s 2ms/step - loss: 7.0032e-04 - mae: 0.0186 - mse: 6.0918e-04 - val_loss: 7.2579e-04 - val_mae: 0.0189 - val_mse: 6.3527e-04 - lr: 0.0029
Epoch 84/150
98/98 [==============================] - 0s 2ms/step - loss: 6.9785e-04 - mae: 0.0185 - mse: 6.0897e-04 - val_loss: 7.0611e-04 - val_mae: 0.0186 - val_mse: 6.1814e-04 - lr: 0.0029
Epoch 85/150
98/98 [==============================] - 0s 2ms/step - loss: 7.0096e-04 - mae: 0.0187 - mse: 6.1234e-04 - val_loss: 7.0177e-04 - val_mae: 0.0185 - val_mse: 6.1000e-04 - lr: 0.0029
Epoch 86/150
98/98 [==============================] - 0s 1ms/step - loss: 7.0198e-04 - mae: 0.0188 - mse: 6.1637e-04 - val_loss: 7.0404e-04 - val_mae: 0.0187 - val_mse: 6.1372e-04 - lr: 0.0029
Epoch 87/150
98/98 [==============================] - 0s 2ms/step - loss: 6.9730e-04 - mae: 0.0187 - mse: 6.1062e-04 - val_loss: 7.1292e-04 - val_mae: 0.0191 - val_mse: 6.2734e-04 - lr: 0.0029
Epoch 88/150
53/98 [===============>..............] - ETA: 0s - loss: 6.8704e-04 - mae: 0.0185 - mse: 5.9504e-04
Epoch 88: ReduceLROnPlateau reducing learning rate to 0.0014490805333480239.
98/98 [==============================] - 0s 2ms/step - loss: 6.9847e-04 - mae: 0.0186 - mse: 6.0807e-04 - val_loss: 6.9596e-04 - val_mae: 0.0187 - val_mse: 6.1130e-04 - lr: 0.0029
Epoch 89/150
98/98 [==============================] - 0s 2ms/step - loss: 6.8605e-04 - mae: 0.0183 - mse: 5.9791e-04 - val_loss: 6.9732e-04 - val_mae: 0.0186 - val_mse: 6.0941e-04 - lr: 0.0014
Epoch 90/150
98/98 [==============================] - 0s 1ms/step - loss: 6.8527e-04 - mae: 0.0183 - mse: 5.9699e-04 - val_loss: 7.0954e-04 - val_mae: 0.0186 - val_mse: 6.1934e-04 - lr: 0.0014
Epoch 91/150
98/98 [==============================] - 0s 1ms/step - loss: 6.7792e-04 - mae: 0.0181 - mse: 5.9029e-04 - val_loss: 6.9555e-04 - val_mae: 0.0184 - val_mse: 6.0653e-04 - lr: 0.0014
Epoch 92/150
98/98 [==============================] - 0s 1ms/step - loss: 6.7893e-04 - mae: 0.0182 - mse: 5.9133e-04 - val_loss: 7.0599e-04 - val_mae: 0.0187 - val_mse: 6.1469e-04 - lr: 0.0014
Epoch 93/150
98/98 [==============================] - 0s 2ms/step - loss: 6.8075e-04 - mae: 0.0182 - mse: 5.9182e-04 - val_loss: 6.9012e-04 - val_mae: 0.0183 - val_mse: 6.0220e-04 - lr: 0.0014
Epoch 94/150
98/98 [==============================] - 0s 2ms/step - loss: 6.7522e-04 - mae: 0.0181 - mse: 5.8541e-04 - val_loss: 7.3303e-04 - val_mae: 0.0192 - val_mse: 6.3977e-04 - lr: 0.0014
Epoch 95/150
98/98 [==============================] - 0s 2ms/step - loss: 6.7812e-04 - mae: 0.0182 - mse: 5.8986e-04 - val_loss: 6.8804e-04 - val_mae: 0.0185 - val_mse: 6.0213e-04 - lr: 0.0014
Epoch 96/150
98/98 [==============================] - 0s 2ms/step - loss: 6.8280e-04 - mae: 0.0183 - mse: 5.9323e-04 - val_loss: 6.8425e-04 - val_mae: 0.0185 - val_mse: 5.9938e-04 - lr: 0.0014
Epoch 97/150
98/98 [==============================] - 0s 2ms/step - loss: 6.7968e-04 - mae: 0.0182 - mse: 5.9101e-04 - val_loss: 6.8920e-04 - val_mae: 0.0184 - val_mse: 6.0008e-04 - lr: 0.0014
Epoch 98/150
57/98 [================>.............] - ETA: 0s - loss: 6.9136e-04 - mae: 0.0183 - mse: 6.0376e-04
Epoch 98: ReduceLROnPlateau reducing learning rate to 0.0007245402666740119.
98/98 [==============================] - 0s 2ms/step - loss: 6.7496e-04 - mae: 0.0181 - mse: 5.8619e-04 - val_loss: 6.8044e-04 - val_mae: 0.0182 - val_mse: 5.9044e-04 - lr: 0.0014
Epoch 99/150
98/98 [==============================] - 0s 2ms/step - loss: 6.6868e-04 - mae: 0.0179 - mse: 5.7799e-04 - val_loss: 6.8487e-04 - val_mae: 0.0185 - val_mse: 5.9641e-04 - lr: 7.2454e-04
Epoch 100/150
98/98 [==============================] - 0s 1ms/step - loss: 6.6953e-04 - mae: 0.0180 - mse: 5.8154e-04 - val_loss: 6.8294e-04 - val_mae: 0.0181 - val_mse: 5.9342e-04 - lr: 7.2454e-04
Epoch 101/150
98/98 [==============================] - 0s 1ms/step - loss: 6.6681e-04 - mae: 0.0179 - mse: 5.7771e-04 - val_loss: 6.8686e-04 - val_mae: 0.0182 - val_mse: 5.9663e-04 - lr: 7.2454e-04
Epoch 102/150
98/98 [==============================] - 0s 1ms/step - loss: 6.6869e-04 - mae: 0.0180 - mse: 5.7994e-04 - val_loss: 6.8380e-04 - val_mae: 0.0183 - val_mse: 5.9479e-04 - lr: 7.2454e-04
Epoch 103/150
98/98 [==============================] - 0s 1ms/step - loss: 6.6931e-04 - mae: 0.0179 - mse: 5.8063e-04 - val_loss: 6.8708e-04 - val_mae: 0.0183 - val_mse: 5.9716e-04 - lr: 7.2454e-04
Epoch 104/150
98/98 [==============================] - 0s 1ms/step - loss: 6.6647e-04 - mae: 0.0179 - mse: 5.7767e-04 - val_loss: 6.8073e-04 - val_mae: 0.0181 - val_mse: 5.9047e-04 - lr: 7.2454e-04
Epoch 105/150
98/98 [==============================] - 0s 1ms/step - loss: 6.6477e-04 - mae: 0.0179 - mse: 5.7582e-04 - val_loss: 6.7948e-04 - val_mae: 0.0181 - val_mse: 5.9000e-04 - lr: 7.2454e-04
Epoch 106/150
98/98 [==============================] - 0s 1ms/step - loss: 6.6824e-04 - mae: 0.0179 - mse: 5.7941e-04 - val_loss: 6.8387e-04 - val_mae: 0.0182 - val_mse: 5.9346e-04 - lr: 7.2454e-04
Epoch 107/150
98/98 [==============================] - 0s 1ms/step - loss: 6.6476e-04 - mae: 0.0179 - mse: 5.7552e-04 - val_loss: 6.7517e-04 - val_mae: 0.0183 - val_mse: 5.8837e-04 - lr: 7.2454e-04
Epoch 108/150
71/98 [====================>.........] - ETA: 0s - loss: 6.5518e-04 - mae: 0.0177 - mse: 5.6594e-04
Epoch 108: ReduceLROnPlateau reducing learning rate to 0.00036227013333700597.
98/98 [==============================] - 0s 1ms/step - loss: 6.6219e-04 - mae: 0.0179 - mse: 5.7239e-04 - val_loss: 6.8689e-04 - val_mae: 0.0181 - val_mse: 5.9468e-04 - lr: 7.2454e-04
Epoch 109/150
98/98 [==============================] - 0s 1ms/step - loss: 6.6211e-04 - mae: 0.0178 - mse: 5.7243e-04 - val_loss: 6.7472e-04 - val_mae: 0.0181 - val_mse: 5.8580e-04 - lr: 3.6227e-04
Epoch 110/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5986e-04 - mae: 0.0178 - mse: 5.7050e-04 - val_loss: 6.8224e-04 - val_mae: 0.0181 - val_mse: 5.9042e-04 - lr: 3.6227e-04
Epoch 111/150
98/98 [==============================] - 0s 1ms/step - loss: 6.6179e-04 - mae: 0.0178 - mse: 5.7204e-04 - val_loss: 6.7527e-04 - val_mae: 0.0181 - val_mse: 5.8572e-04 - lr: 3.6227e-04
Epoch 112/150
98/98 [==============================] - 0s 1ms/step - loss: 6.6001e-04 - mae: 0.0178 - mse: 5.7017e-04 - val_loss: 6.7310e-04 - val_mae: 0.0181 - val_mse: 5.8426e-04 - lr: 3.6227e-04
Epoch 113/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5977e-04 - mae: 0.0178 - mse: 5.7044e-04 - val_loss: 6.8052e-04 - val_mae: 0.0183 - val_mse: 5.9010e-04 - lr: 3.6227e-04
Epoch 114/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5940e-04 - mae: 0.0177 - mse: 5.6930e-04 - val_loss: 6.7881e-04 - val_mae: 0.0183 - val_mse: 5.8899e-04 - lr: 3.6227e-04
Epoch 115/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5868e-04 - mae: 0.0177 - mse: 5.6913e-04 - val_loss: 6.7547e-04 - val_mae: 0.0182 - val_mse: 5.8601e-04 - lr: 3.6227e-04
Epoch 116/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5908e-04 - mae: 0.0177 - mse: 5.6965e-04 - val_loss: 6.7177e-04 - val_mae: 0.0181 - val_mse: 5.8293e-04 - lr: 3.6227e-04
Epoch 117/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5805e-04 - mae: 0.0177 - mse: 5.6857e-04 - val_loss: 6.7857e-04 - val_mae: 0.0187 - val_mse: 5.9273e-04 - lr: 3.6227e-04
Epoch 118/150
71/98 [====================>.........] - ETA: 0s - loss: 6.6689e-04 - mae: 0.0179 - mse: 5.7805e-04
Epoch 118: ReduceLROnPlateau reducing learning rate to 0.00018113506666850299.
98/98 [==============================] - 0s 1ms/step - loss: 6.6060e-04 - mae: 0.0178 - mse: 5.7126e-04 - val_loss: 6.7050e-04 - val_mae: 0.0180 - val_mse: 5.8082e-04 - lr: 3.6227e-04
Epoch 119/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5685e-04 - mae: 0.0177 - mse: 5.6676e-04 - val_loss: 6.7531e-04 - val_mae: 0.0182 - val_mse: 5.8463e-04 - lr: 1.8114e-04
Epoch 120/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5720e-04 - mae: 0.0177 - mse: 5.6682e-04 - val_loss: 6.7217e-04 - val_mae: 0.0182 - val_mse: 5.8253e-04 - lr: 1.8114e-04
Epoch 121/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5652e-04 - mae: 0.0177 - mse: 5.6668e-04 - val_loss: 6.7328e-04 - val_mae: 0.0182 - val_mse: 5.8379e-04 - lr: 1.8114e-04
Epoch 122/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5726e-04 - mae: 0.0177 - mse: 5.6693e-04 - val_loss: 6.7041e-04 - val_mae: 0.0180 - val_mse: 5.8046e-04 - lr: 1.8114e-04
Epoch 123/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5636e-04 - mae: 0.0177 - mse: 5.6690e-04 - val_loss: 6.6942e-04 - val_mae: 0.0180 - val_mse: 5.8081e-04 - lr: 1.8114e-04
Epoch 124/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5635e-04 - mae: 0.0177 - mse: 5.6722e-04 - val_loss: 6.6859e-04 - val_mae: 0.0180 - val_mse: 5.8068e-04 - lr: 1.8114e-04
Epoch 125/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5635e-04 - mae: 0.0177 - mse: 5.6753e-04 - val_loss: 6.6975e-04 - val_mae: 0.0180 - val_mse: 5.8050e-04 - lr: 1.8114e-04
Epoch 126/150
98/98 [==============================] - 0s 2ms/step - loss: 6.5665e-04 - mae: 0.0177 - mse: 5.6726e-04 - val_loss: 6.7395e-04 - val_mae: 0.0181 - val_mse: 5.8399e-04 - lr: 1.8114e-04
Epoch 127/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5685e-04 - mae: 0.0177 - mse: 5.6728e-04 - val_loss: 6.6972e-04 - val_mae: 0.0181 - val_mse: 5.8093e-04 - lr: 1.8114e-04
Epoch 128/150
67/98 [===================>..........] - ETA: 0s - loss: 6.4651e-04 - mae: 0.0176 - mse: 5.5750e-04
Epoch 128: ReduceLROnPlateau reducing learning rate to 9.056753333425149e-05.
98/98 [==============================] - 0s 1ms/step - loss: 6.5520e-04 - mae: 0.0177 - mse: 5.6605e-04 - val_loss: 6.7009e-04 - val_mae: 0.0180 - val_mse: 5.8076e-04 - lr: 1.8114e-04
Epoch 129/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5403e-04 - mae: 0.0177 - mse: 5.6508e-04 - val_loss: 6.7480e-04 - val_mae: 0.0182 - val_mse: 5.8486e-04 - lr: 9.0568e-05
Epoch 130/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5480e-04 - mae: 0.0177 - mse: 5.6515e-04 - val_loss: 6.7065e-04 - val_mae: 0.0180 - val_mse: 5.8093e-04 - lr: 9.0568e-05
Epoch 131/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5481e-04 - mae: 0.0176 - mse: 5.6576e-04 - val_loss: 6.7187e-04 - val_mae: 0.0181 - val_mse: 5.8268e-04 - lr: 9.0568e-05
Epoch 132/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5437e-04 - mae: 0.0177 - mse: 5.6456e-04 - val_loss: 6.6867e-04 - val_mae: 0.0180 - val_mse: 5.7954e-04 - lr: 9.0568e-05
Epoch 133/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5441e-04 - mae: 0.0177 - mse: 5.6521e-04 - val_loss: 6.7096e-04 - val_mae: 0.0180 - val_mse: 5.8123e-04 - lr: 9.0568e-05
Epoch 134/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5444e-04 - mae: 0.0176 - mse: 5.6477e-04 - val_loss: 6.7019e-04 - val_mae: 0.0180 - val_mse: 5.8063e-04 - lr: 9.0568e-05
Epoch 135/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5428e-04 - mae: 0.0177 - mse: 5.6479e-04 - val_loss: 6.6982e-04 - val_mae: 0.0180 - val_mse: 5.8004e-04 - lr: 9.0568e-05
Epoch 136/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5470e-04 - mae: 0.0176 - mse: 5.6543e-04 - val_loss: 6.7079e-04 - val_mae: 0.0181 - val_mse: 5.8153e-04 - lr: 9.0568e-05
Epoch 137/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5497e-04 - mae: 0.0177 - mse: 5.6516e-04 - val_loss: 6.7010e-04 - val_mae: 0.0180 - val_mse: 5.8087e-04 - lr: 9.0568e-05
Epoch 138/150
71/98 [====================>.........] - ETA: 0s - loss: 6.5703e-04 - mae: 0.0177 - mse: 5.6798e-04
Epoch 138: ReduceLROnPlateau reducing learning rate to 4.5283766667125747e-05.
98/98 [==============================] - 0s 1ms/step - loss: 6.5361e-04 - mae: 0.0176 - mse: 5.6450e-04 - val_loss: 6.6801e-04 - val_mae: 0.0179 - val_mse: 5.7937e-04 - lr: 9.0568e-05
Epoch 139/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5370e-04 - mae: 0.0176 - mse: 5.6512e-04 - val_loss: 6.6834e-04 - val_mae: 0.0180 - val_mse: 5.7965e-04 - lr: 4.5284e-05
Epoch 140/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5368e-04 - mae: 0.0176 - mse: 5.6492e-04 - val_loss: 6.6897e-04 - val_mae: 0.0180 - val_mse: 5.7997e-04 - lr: 4.5284e-05
Epoch 141/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5339e-04 - mae: 0.0176 - mse: 5.6433e-04 - val_loss: 6.6825e-04 - val_mae: 0.0180 - val_mse: 5.7935e-04 - lr: 4.5284e-05
Epoch 142/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5332e-04 - mae: 0.0176 - mse: 5.6455e-04 - val_loss: 6.6799e-04 - val_mae: 0.0180 - val_mse: 5.7911e-04 - lr: 4.5284e-05
Epoch 143/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5334e-04 - mae: 0.0176 - mse: 5.6438e-04 - val_loss: 6.6876e-04 - val_mae: 0.0180 - val_mse: 5.7978e-04 - lr: 4.5284e-05
Epoch 144/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5332e-04 - mae: 0.0176 - mse: 5.6421e-04 - val_loss: 6.6813e-04 - val_mae: 0.0180 - val_mse: 5.7924e-04 - lr: 4.5284e-05
Epoch 145/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5308e-04 - mae: 0.0176 - mse: 5.6400e-04 - val_loss: 6.6963e-04 - val_mae: 0.0180 - val_mse: 5.8025e-04 - lr: 4.5284e-05
Epoch 146/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5325e-04 - mae: 0.0176 - mse: 5.6377e-04 - val_loss: 6.6879e-04 - val_mae: 0.0180 - val_mse: 5.7946e-04 - lr: 4.5284e-05
Epoch 147/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5320e-04 - mae: 0.0176 - mse: 5.6405e-04 - val_loss: 6.6822e-04 - val_mae: 0.0180 - val_mse: 5.7883e-04 - lr: 4.5284e-05
Epoch 148/150
67/98 [===================>..........] - ETA: 0s - loss: 6.4593e-04 - mae: 0.0175 - mse: 5.5657e-04
Epoch 148: ReduceLROnPlateau reducing learning rate to 2.2641883333562873e-05.
98/98 [==============================] - 0s 1ms/step - loss: 6.5293e-04 - mae: 0.0176 - mse: 5.6362e-04 - val_loss: 6.6977e-04 - val_mae: 0.0181 - val_mse: 5.8048e-04 - lr: 4.5284e-05
Epoch 149/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5301e-04 - mae: 0.0176 - mse: 5.6359e-04 - val_loss: 6.6896e-04 - val_mae: 0.0180 - val_mse: 5.7950e-04 - lr: 2.2642e-05
Epoch 150/150
98/98 [==============================] - 0s 1ms/step - loss: 6.5289e-04 - mae: 0.0176 - mse: 5.6337e-04 - val_loss: 6.6836e-04 - val_mae: 0.0180 - val_mse: 5.7893e-04 - lr: 2.2642e-05
>Saved ../trained_models/models_segments_overlap_adam_0.09274115666742028LR_[30]HN_40BS_10P_val_mseM_150epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
98/98 [==============================] - 1s 3ms/step - loss: 0.0275 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0927
Epoch 2/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 0.0927
Epoch 3/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0927
Epoch 4/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0927
Epoch 5/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0927
Epoch 6/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0927
Epoch 7/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0380 - mse: 0.0020 - val_loss: 0.0053 - val_mae: 0.0558 - val_mse: 0.0046 - lr: 0.0927
Epoch 8/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0029 - mae: 0.0365 - mse: 0.0019 - val_loss: 0.0028 - val_mae: 0.0379 - val_mse: 0.0020 - lr: 0.0927
Epoch 9/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0311 - mse: 0.0014 - val_loss: 0.0076 - val_mae: 0.0689 - val_mse: 0.0062 - lr: 0.0927
Epoch 10/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0308 - mse: 0.0015 - val_loss: 0.0018 - val_mae: 0.0283 - val_mse: 0.0012 - lr: 0.0927
Epoch 11/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0016 - mae: 0.0285 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0277 - val_mse: 0.0012 - lr: 0.0927
Epoch 12/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0266 - mse: 0.0011 - val_loss: 0.0035 - val_mae: 0.0487 - val_mse: 0.0034 - lr: 0.0927
Epoch 13/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0281 - mse: 0.0012 - val_loss: 0.0018 - val_mae: 0.0296 - val_mse: 0.0013 - lr: 0.0927
Epoch 14/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0014 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0014 - val_mae: 0.0268 - val_mse: 0.0011 - lr: 0.0927
Epoch 15/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0014 - mae: 0.0269 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0266 - val_mse: 0.0011 - lr: 0.0927
Epoch 16/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0256 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0252 - val_mse: 9.8499e-04 - lr: 0.0927
Epoch 17/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0260 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0248 - val_mse: 9.8061e-04 - lr: 0.0927
Epoch 18/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0248 - mse: 9.7683e-04 - val_loss: 0.0022 - val_mae: 0.0369 - val_mse: 0.0020 - lr: 0.0927
Epoch 19/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0256 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0238 - val_mse: 8.9165e-04 - lr: 0.0927
Epoch 20/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0248 - mse: 9.7705e-04 - val_loss: 0.0014 - val_mae: 0.0277 - val_mse: 0.0012 - lr: 0.0927
Epoch 21/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0015 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0016 - val_mae: 0.0304 - val_mse: 0.0014 - lr: 0.0927
Epoch 22/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0250 - mse: 9.8227e-04 - val_loss: 0.0011 - val_mae: 0.0234 - val_mse: 8.7225e-04 - lr: 0.0927
Epoch 23/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0245 - mse: 9.6672e-04 - val_loss: 0.0025 - val_mae: 0.0404 - val_mse: 0.0024 - lr: 0.0927
Epoch 24/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0248 - mse: 9.8111e-04 - val_loss: 0.0014 - val_mae: 0.0275 - val_mse: 0.0012 - lr: 0.0927
Epoch 25/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0244 - mse: 9.4926e-04 - val_loss: 0.0010 - val_mae: 0.0236 - val_mse: 8.8253e-04 - lr: 0.0927
Epoch 26/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0252 - mse: 0.0010 - val_loss: 0.0013 - val_mae: 0.0262 - val_mse: 0.0011 - lr: 0.0927
Epoch 27/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0246 - mse: 9.6173e-04 - val_loss: 0.0036 - val_mae: 0.0483 - val_mse: 0.0034 - lr: 0.0927
Epoch 28/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0013 - mae: 0.0254 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0232 - val_mse: 8.4982e-04 - lr: 0.0927
Epoch 29/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0012 - mae: 0.0245 - mse: 9.5161e-04 - val_loss: 0.0011 - val_mae: 0.0228 - val_mse: 8.3146e-04 - lr: 0.0927
Epoch 30/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0242 - mse: 9.4031e-04 - val_loss: 0.0014 - val_mae: 0.0237 - val_mse: 8.9516e-04 - lr: 0.0927
Epoch 31/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0241 - mse: 9.2903e-04 - val_loss: 0.0012 - val_mae: 0.0235 - val_mse: 8.7175e-04 - lr: 0.0927
Epoch 32/150
58/98 [================>.............] - ETA: 0s - loss: 0.0011 - mae: 0.0248 - mse: 9.7048e-04
Epoch 32: ReduceLROnPlateau reducing learning rate to 0.046370577067136765.
98/98 [==============================] - 0s 1ms/step - loss: 0.0011 - mae: 0.0245 - mse: 9.5445e-04 - val_loss: 0.0014 - val_mae: 0.0269 - val_mse: 0.0011 - lr: 0.0927
Epoch 33/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6387e-04 - mae: 0.0231 - mse: 8.5815e-04 - val_loss: 0.0010 - val_mae: 0.0247 - val_mse: 9.4807e-04 - lr: 0.0464
Epoch 34/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0246 - mse: 9.5800e-04 - val_loss: 0.0010 - val_mae: 0.0247 - val_mse: 9.4622e-04 - lr: 0.0464
Epoch 35/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6088e-04 - mae: 0.0234 - mse: 8.7621e-04 - val_loss: 9.4086e-04 - val_mae: 0.0231 - val_mse: 8.4733e-04 - lr: 0.0464
Epoch 36/150
98/98 [==============================] - 0s 1ms/step - loss: 9.7100e-04 - mae: 0.0236 - mse: 8.8943e-04 - val_loss: 0.0012 - val_mae: 0.0278 - val_mse: 0.0012 - lr: 0.0464
Epoch 37/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0246 - mse: 9.5614e-04 - val_loss: 9.7942e-04 - val_mae: 0.0235 - val_mse: 8.6745e-04 - lr: 0.0464
Epoch 38/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6515e-04 - mae: 0.0234 - mse: 8.8164e-04 - val_loss: 0.0014 - val_mae: 0.0294 - val_mse: 0.0013 - lr: 0.0464
Epoch 39/150
98/98 [==============================] - 0s 1ms/step - loss: 9.6459e-04 - mae: 0.0234 - mse: 8.8120e-04 - val_loss: 0.0012 - val_mae: 0.0263 - val_mse: 0.0011 - lr: 0.0464
Epoch 40/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0239 - mse: 9.1665e-04 - val_loss: 0.0011 - val_mae: 0.0261 - val_mse: 0.0010 - lr: 0.0464
Epoch 41/150
98/98 [==============================] - 0s 1ms/step - loss: 9.5075e-04 - mae: 0.0233 - mse: 8.7497e-04 - val_loss: 0.0010 - val_mae: 0.0246 - val_mse: 9.3524e-04 - lr: 0.0464
Epoch 42/150
68/98 [===================>..........] - ETA: 0s - loss: 9.8349e-04 - mae: 0.0239 - mse: 9.0793e-04
Epoch 42: ReduceLROnPlateau reducing learning rate to 0.023185288533568382.
98/98 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0241 - mse: 9.1695e-04 - val_loss: 0.0019 - val_mae: 0.0353 - val_mse: 0.0018 - lr: 0.0464
Epoch 43/150
98/98 [==============================] - 0s 1ms/step - loss: 9.8243e-04 - mae: 0.0231 - mse: 8.6669e-04 - val_loss: 9.5980e-04 - val_mae: 0.0238 - val_mse: 8.9189e-04 - lr: 0.0232
Epoch 44/150
98/98 [==============================] - 0s 1ms/step - loss: 9.5936e-04 - mae: 0.0235 - mse: 8.8316e-04 - val_loss: 9.0815e-04 - val_mae: 0.0228 - val_mse: 8.2975e-04 - lr: 0.0232
Epoch 45/150
98/98 [==============================] - 0s 1ms/step - loss: 8.9453e-04 - mae: 0.0226 - mse: 8.2488e-04 - val_loss: 8.8942e-04 - val_mae: 0.0227 - val_mse: 8.2404e-04 - lr: 0.0232
Epoch 46/150
98/98 [==============================] - 0s 1ms/step - loss: 9.0715e-04 - mae: 0.0229 - mse: 8.4472e-04 - val_loss: 0.0017 - val_mae: 0.0335 - val_mse: 0.0016 - lr: 0.0232
Epoch 47/150
98/98 [==============================] - 0s 1ms/step - loss: 9.8687e-04 - mae: 0.0239 - mse: 9.1552e-04 - val_loss: 9.2562e-04 - val_mae: 0.0233 - val_mse: 8.5399e-04 - lr: 0.0232
Epoch 48/150
98/98 [==============================] - 0s 1ms/step - loss: 9.3683e-04 - mae: 0.0234 - mse: 8.6597e-04 - val_loss: 9.0309e-04 - val_mae: 0.0228 - val_mse: 8.2364e-04 - lr: 0.0232
Epoch 49/150
98/98 [==============================] - 0s 1ms/step - loss: 9.0136e-04 - mae: 0.0228 - mse: 8.3667e-04 - val_loss: 0.0011 - val_mae: 0.0258 - val_mse: 0.0010 - lr: 0.0232
Epoch 50/150
98/98 [==============================] - 0s 1ms/step - loss: 9.0774e-04 - mae: 0.0229 - mse: 8.4538e-04 - val_loss: 9.3173e-04 - val_mae: 0.0236 - val_mse: 8.6879e-04 - lr: 0.0232
Epoch 51/150
98/98 [==============================] - 0s 1ms/step - loss: 9.1140e-04 - mae: 0.0230 - mse: 8.5153e-04 - val_loss: 9.5302e-04 - val_mae: 0.0236 - val_mse: 8.7816e-04 - lr: 0.0232
Epoch 52/150
64/98 [==================>...........] - ETA: 0s - loss: 9.1008e-04 - mae: 0.0229 - mse: 8.4957e-04
Epoch 52: ReduceLROnPlateau reducing learning rate to 0.011592644266784191.
98/98 [==============================] - 0s 1ms/step - loss: 9.1621e-04 - mae: 0.0231 - mse: 8.5579e-04 - val_loss: 0.0011 - val_mae: 0.0258 - val_mse: 0.0010 - lr: 0.0232
Epoch 53/150
98/98 [==============================] - 0s 2ms/step - loss: 8.9827e-04 - mae: 0.0228 - mse: 8.3834e-04 - val_loss: 9.0354e-04 - val_mae: 0.0232 - val_mse: 8.4879e-04 - lr: 0.0116
Epoch 54/150
98/98 [==============================] - 0s 1ms/step - loss: 9.3945e-04 - mae: 0.0235 - mse: 8.7916e-04 - val_loss: 8.9495e-04 - val_mae: 0.0231 - val_mse: 8.4394e-04 - lr: 0.0116
Epoch 55/150
98/98 [==============================] - 0s 1ms/step - loss: 8.7142e-04 - mae: 0.0224 - mse: 8.1393e-04 - val_loss: 9.4314e-04 - val_mae: 0.0239 - val_mse: 8.9366e-04 - lr: 0.0116
Epoch 56/150
98/98 [==============================] - 0s 1ms/step - loss: 8.9111e-04 - mae: 0.0228 - mse: 8.3286e-04 - val_loss: 8.6494e-04 - val_mae: 0.0225 - val_mse: 8.0970e-04 - lr: 0.0116
Epoch 57/150
98/98 [==============================] - 0s 1ms/step - loss: 8.7722e-04 - mae: 0.0226 - mse: 8.2342e-04 - val_loss: 8.6193e-04 - val_mae: 0.0225 - val_mse: 8.1082e-04 - lr: 0.0116
Epoch 58/150
98/98 [==============================] - 0s 1ms/step - loss: 8.7351e-04 - mae: 0.0226 - mse: 8.2063e-04 - val_loss: 9.7399e-04 - val_mae: 0.0244 - val_mse: 9.3117e-04 - lr: 0.0116
Epoch 59/150
98/98 [==============================] - 0s 1ms/step - loss: 8.7436e-04 - mae: 0.0226 - mse: 8.2360e-04 - val_loss: 9.4708e-04 - val_mae: 0.0238 - val_mse: 8.8603e-04 - lr: 0.0116
Epoch 60/150
98/98 [==============================] - 0s 1ms/step - loss: 8.6880e-04 - mae: 0.0225 - mse: 8.1914e-04 - val_loss: 0.0010 - val_mae: 0.0253 - val_mse: 9.8942e-04 - lr: 0.0116
Epoch 61/150
98/98 [==============================] - 0s 1ms/step - loss: 8.9151e-04 - mae: 0.0229 - mse: 8.4248e-04 - val_loss: 8.6848e-04 - val_mae: 0.0227 - val_mse: 8.2196e-04 - lr: 0.0116
Epoch 62/150
68/98 [===================>..........] - ETA: 0s - loss: 8.6591e-04 - mae: 0.0226 - mse: 8.1511e-04
Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0057963221333920956.
98/98 [==============================] - 0s 1ms/step - loss: 8.9294e-04 - mae: 0.0229 - mse: 8.4159e-04 - val_loss: 0.0010 - val_mae: 0.0253 - val_mse: 9.8340e-04 - lr: 0.0116
Epoch 63/150
98/98 [==============================] - 0s 1ms/step - loss: 8.5572e-04 - mae: 0.0224 - mse: 8.0703e-04 - val_loss: 8.5463e-04 - val_mae: 0.0225 - val_mse: 8.0708e-04 - lr: 0.0058
Epoch 64/150
98/98 [==============================] - 0s 1ms/step - loss: 8.5449e-04 - mae: 0.0224 - mse: 8.0832e-04 - val_loss: 8.5483e-04 - val_mae: 0.0225 - val_mse: 8.0852e-04 - lr: 0.0058
Epoch 65/150
98/98 [==============================] - 0s 1ms/step - loss: 8.6004e-04 - mae: 0.0225 - mse: 8.1171e-04 - val_loss: 8.8076e-04 - val_mae: 0.0230 - val_mse: 8.3882e-04 - lr: 0.0058
Epoch 66/150
98/98 [==============================] - 0s 1ms/step - loss: 8.7362e-04 - mae: 0.0227 - mse: 8.2863e-04 - val_loss: 8.7041e-04 - val_mae: 0.0228 - val_mse: 8.2609e-04 - lr: 0.0058
Epoch 67/150
98/98 [==============================] - 0s 1ms/step - loss: 8.8164e-04 - mae: 0.0228 - mse: 8.3226e-04 - val_loss: 9.6608e-04 - val_mae: 0.0242 - val_mse: 9.1531e-04 - lr: 0.0058
Epoch 68/150
98/98 [==============================] - 0s 1ms/step - loss: 8.6002e-04 - mae: 0.0224 - mse: 8.1169e-04 - val_loss: 9.1945e-04 - val_mae: 0.0237 - val_mse: 8.8357e-04 - lr: 0.0058
Epoch 69/150
98/98 [==============================] - 0s 1ms/step - loss: 8.5058e-04 - mae: 0.0224 - mse: 8.0725e-04 - val_loss: 8.8440e-04 - val_mae: 0.0231 - val_mse: 8.4191e-04 - lr: 0.0058
Epoch 70/150
98/98 [==============================] - 0s 1ms/step - loss: 8.7774e-04 - mae: 0.0227 - mse: 8.3315e-04 - val_loss: 8.7306e-04 - val_mae: 0.0228 - val_mse: 8.2294e-04 - lr: 0.0058
Epoch 71/150
98/98 [==============================] - 0s 1ms/step - loss: 8.6993e-04 - mae: 0.0226 - mse: 8.2481e-04 - val_loss: 8.5829e-04 - val_mae: 0.0226 - val_mse: 8.1285e-04 - lr: 0.0058
Epoch 72/150
71/98 [====================>.........] - ETA: 0s - loss: 8.4322e-04 - mae: 0.0222 - mse: 7.9824e-04
Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0028981610666960478.
98/98 [==============================] - 0s 1ms/step - loss: 8.5594e-04 - mae: 0.0224 - mse: 8.1073e-04 - val_loss: 8.7146e-04 - val_mae: 0.0228 - val_mse: 8.2270e-04 - lr: 0.0058
Epoch 73/150
98/98 [==============================] - 0s 1ms/step - loss: 8.4501e-04 - mae: 0.0222 - mse: 8.0269e-04 - val_loss: 8.5320e-04 - val_mae: 0.0225 - val_mse: 8.0956e-04 - lr: 0.0029
Epoch 74/150
98/98 [==============================] - 0s 1ms/step - loss: 8.4504e-04 - mae: 0.0223 - mse: 8.0114e-04 - val_loss: 8.5011e-04 - val_mae: 0.0225 - val_mse: 8.0780e-04 - lr: 0.0029
Epoch 75/150
98/98 [==============================] - 0s 1ms/step - loss: 8.5218e-04 - mae: 0.0224 - mse: 8.1014e-04 - val_loss: 8.6356e-04 - val_mae: 0.0227 - val_mse: 8.2091e-04 - lr: 0.0029
Epoch 76/150
98/98 [==============================] - 0s 1ms/step - loss: 8.4310e-04 - mae: 0.0222 - mse: 8.0152e-04 - val_loss: 8.4785e-04 - val_mae: 0.0225 - val_mse: 8.0487e-04 - lr: 0.0029
Epoch 77/150
98/98 [==============================] - 0s 1ms/step - loss: 8.5379e-04 - mae: 0.0224 - mse: 8.1138e-04 - val_loss: 8.7721e-04 - val_mae: 0.0230 - val_mse: 8.3778e-04 - lr: 0.0029
Epoch 78/150
98/98 [==============================] - 0s 1ms/step - loss: 8.4694e-04 - mae: 0.0223 - mse: 8.0525e-04 - val_loss: 8.4605e-04 - val_mae: 0.0224 - val_mse: 8.0465e-04 - lr: 0.0029
Epoch 79/150
98/98 [==============================] - 0s 1ms/step - loss: 8.4707e-04 - mae: 0.0223 - mse: 8.0762e-04 - val_loss: 8.5663e-04 - val_mae: 0.0226 - val_mse: 8.1174e-04 - lr: 0.0029
Epoch 80/150
98/98 [==============================] - 0s 1ms/step - loss: 8.4066e-04 - mae: 0.0222 - mse: 7.9956e-04 - val_loss: 8.4608e-04 - val_mae: 0.0225 - val_mse: 8.0225e-04 - lr: 0.0029
Epoch 81/150
98/98 [==============================] - 0s 1ms/step - loss: 8.4227e-04 - mae: 0.0222 - mse: 8.0142e-04 - val_loss: 8.4500e-04 - val_mae: 0.0224 - val_mse: 8.0517e-04 - lr: 0.0029
Epoch 82/150
66/98 [===================>..........] - ETA: 0s - loss: 8.4498e-04 - mae: 0.0223 - mse: 8.0344e-04
Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0014490805333480239.
98/98 [==============================] - 0s 1ms/step - loss: 8.4214e-04 - mae: 0.0223 - mse: 8.0080e-04 - val_loss: 8.4968e-04 - val_mae: 0.0225 - val_mse: 8.1057e-04 - lr: 0.0029
Epoch 83/150
98/98 [==============================] - 0s 1ms/step - loss: 8.4299e-04 - mae: 0.0223 - mse: 8.0355e-04 - val_loss: 8.5563e-04 - val_mae: 0.0226 - val_mse: 8.1781e-04 - lr: 0.0014
Epoch 84/150
98/98 [==============================] - 0s 1ms/step - loss: 8.3826e-04 - mae: 0.0222 - mse: 7.9831e-04 - val_loss: 8.7747e-04 - val_mae: 0.0230 - val_mse: 8.4114e-04 - lr: 0.0014
Epoch 85/150
98/98 [==============================] - 0s 1ms/step - loss: 8.3550e-04 - mae: 0.0222 - mse: 7.9682e-04 - val_loss: 8.4527e-04 - val_mae: 0.0225 - val_mse: 8.0658e-04 - lr: 0.0014
Epoch 86/150
98/98 [==============================] - 0s 1ms/step - loss: 8.3633e-04 - mae: 0.0221 - mse: 7.9716e-04 - val_loss: 8.4878e-04 - val_mae: 0.0225 - val_mse: 8.1011e-04 - lr: 0.0014
Epoch 87/150
98/98 [==============================] - 0s 1ms/step - loss: 8.3694e-04 - mae: 0.0222 - mse: 7.9735e-04 - val_loss: 8.4554e-04 - val_mae: 0.0225 - val_mse: 8.0532e-04 - lr: 0.0014
Epoch 88/150
98/98 [==============================] - 0s 1ms/step - loss: 8.3549e-04 - mae: 0.0222 - mse: 7.9591e-04 - val_loss: 8.4318e-04 - val_mae: 0.0225 - val_mse: 8.0350e-04 - lr: 0.0014
Epoch 89/150
98/98 [==============================] - 0s 1ms/step - loss: 8.3681e-04 - mae: 0.0222 - mse: 7.9799e-04 - val_loss: 8.9712e-04 - val_mae: 0.0234 - val_mse: 8.6358e-04 - lr: 0.0014
Epoch 90/150
98/98 [==============================] - 0s 1ms/step - loss: 8.3906e-04 - mae: 0.0223 - mse: 8.0075e-04 - val_loss: 8.5470e-04 - val_mae: 0.0227 - val_mse: 8.1787e-04 - lr: 0.0014
Epoch 91/150
98/98 [==============================] - 0s 1ms/step - loss: 8.3605e-04 - mae: 0.0222 - mse: 7.9687e-04 - val_loss: 8.4301e-04 - val_mae: 0.0225 - val_mse: 8.0524e-04 - lr: 0.0014
Epoch 92/150
64/98 [==================>...........] - ETA: 0s - loss: 8.5101e-04 - mae: 0.0226 - mse: 8.1363e-04
Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0007245402666740119.
98/98 [==============================] - 0s 1ms/step - loss: 8.3570e-04 - mae: 0.0222 - mse: 7.9850e-04 - val_loss: 8.4197e-04 - val_mae: 0.0224 - val_mse: 8.0440e-04 - lr: 0.0014
Epoch 93/150
98/98 [==============================] - 0s 1ms/step - loss: 8.3408e-04 - mae: 0.0222 - mse: 7.9596e-04 - val_loss: 8.4513e-04 - val_mae: 0.0225 - val_mse: 8.0707e-04 - lr: 7.2454e-04
Epoch 94/150
98/98 [==============================] - 0s 1ms/step - loss: 8.3721e-04 - mae: 0.0222 - mse: 7.9920e-04 - val_loss: 8.5088e-04 - val_mae: 0.0226 - val_mse: 8.1374e-04 - lr: 7.2454e-04
Epoch 95/150
98/98 [==============================] - 0s 2ms/step - loss: 8.3517e-04 - mae: 0.0222 - mse: 7.9750e-04 - val_loss: 8.4117e-04 - val_mae: 0.0224 - val_mse: 8.0313e-04 - lr: 7.2454e-04
Epoch 96/150
98/98 [==============================] - 0s 2ms/step - loss: 8.3379e-04 - mae: 0.0222 - mse: 7.9661e-04 - val_loss: 8.4719e-04 - val_mae: 0.0225 - val_mse: 8.1097e-04 - lr: 7.2454e-04
Epoch 97/150
98/98 [==============================] - 0s 2ms/step - loss: 8.3199e-04 - mae: 0.0222 - mse: 7.9449e-04 - val_loss: 8.6678e-04 - val_mae: 0.0229 - val_mse: 8.3214e-04 - lr: 7.2454e-04
Epoch 98/150
98/98 [==============================] - 0s 2ms/step - loss: 8.3519e-04 - mae: 0.0222 - mse: 7.9780e-04 - val_loss: 8.4636e-04 - val_mae: 0.0225 - val_mse: 8.0686e-04 - lr: 7.2454e-04
Epoch 99/150
98/98 [==============================] - 0s 2ms/step - loss: 8.3347e-04 - mae: 0.0221 - mse: 7.9738e-04 - val_loss: 8.6126e-04 - val_mae: 0.0228 - val_mse: 8.2646e-04 - lr: 7.2454e-04
Epoch 100/150
98/98 [==============================] - 0s 2ms/step - loss: 8.3287e-04 - mae: 0.0222 - mse: 7.9534e-04 - val_loss: 8.4699e-04 - val_mae: 0.0225 - val_mse: 8.1068e-04 - lr: 7.2454e-04
Epoch 101/150
98/98 [==============================] - 0s 2ms/step - loss: 8.3253e-04 - mae: 0.0222 - mse: 7.9611e-04 - val_loss: 8.4023e-04 - val_mae: 0.0224 - val_mse: 8.0232e-04 - lr: 7.2454e-04
Epoch 102/150
50/98 [==============>...............] - ETA: 0s - loss: 8.4483e-04 - mae: 0.0222 - mse: 8.0925e-04
Epoch 102: ReduceLROnPlateau reducing learning rate to 0.00036227013333700597.
98/98 [==============================] - 0s 2ms/step - loss: 8.3178e-04 - mae: 0.0221 - mse: 7.9609e-04 - val_loss: 8.5091e-04 - val_mae: 0.0226 - val_mse: 8.1553e-04 - lr: 7.2454e-04
Epoch 103/150
98/98 [==============================] - 0s 2ms/step - loss: 8.3191e-04 - mae: 0.0221 - mse: 7.9548e-04 - val_loss: 8.4161e-04 - val_mae: 0.0225 - val_mse: 8.0489e-04 - lr: 3.6227e-04
Epoch 104/150
98/98 [==============================] - 0s 2ms/step - loss: 8.3131e-04 - mae: 0.0221 - mse: 7.9481e-04 - val_loss: 8.4046e-04 - val_mae: 0.0224 - val_mse: 8.0318e-04 - lr: 3.6227e-04
Epoch 105/150
98/98 [==============================] - 0s 2ms/step - loss: 8.3312e-04 - mae: 0.0222 - mse: 7.9655e-04 - val_loss: 8.4304e-04 - val_mae: 0.0225 - val_mse: 8.0664e-04 - lr: 3.6227e-04
Epoch 106/150
98/98 [==============================] - 0s 2ms/step - loss: 8.2988e-04 - mae: 0.0221 - mse: 7.9348e-04 - val_loss: 8.4047e-04 - val_mae: 0.0224 - val_mse: 8.0285e-04 - lr: 3.6227e-04
Epoch 107/150
98/98 [==============================] - 0s 2ms/step - loss: 8.3137e-04 - mae: 0.0221 - mse: 7.9543e-04 - val_loss: 8.3980e-04 - val_mae: 0.0224 - val_mse: 8.0294e-04 - lr: 3.6227e-04
Epoch 108/150
98/98 [==============================] - 0s 2ms/step - loss: 8.3065e-04 - mae: 0.0221 - mse: 7.9446e-04 - val_loss: 8.4063e-04 - val_mae: 0.0224 - val_mse: 8.0411e-04 - lr: 3.6227e-04
Epoch 109/150
98/98 [==============================] - 0s 2ms/step - loss: 8.3031e-04 - mae: 0.0221 - mse: 7.9376e-04 - val_loss: 8.4042e-04 - val_mae: 0.0224 - val_mse: 8.0363e-04 - lr: 3.6227e-04
Epoch 110/150
98/98 [==============================] - 0s 2ms/step - loss: 8.3008e-04 - mae: 0.0221 - mse: 7.9378e-04 - val_loss: 8.4118e-04 - val_mae: 0.0225 - val_mse: 8.0304e-04 - lr: 3.6227e-04
Epoch 111/150
98/98 [==============================] - 0s 2ms/step - loss: 8.3401e-04 - mae: 0.0221 - mse: 7.9735e-04 - val_loss: 8.4015e-04 - val_mae: 0.0224 - val_mse: 8.0320e-04 - lr: 3.6227e-04
Epoch 112/150
51/98 [==============>...............] - ETA: 0s - loss: 8.2504e-04 - mae: 0.0221 - mse: 7.8910e-04
Epoch 112: ReduceLROnPlateau reducing learning rate to 0.00018113506666850299.
98/98 [==============================] - 0s 2ms/step - loss: 8.3183e-04 - mae: 0.0221 - mse: 7.9567e-04 - val_loss: 8.4066e-04 - val_mae: 0.0225 - val_mse: 8.0374e-04 - lr: 3.6227e-04
Epoch 113/150
98/98 [==============================] - 0s 2ms/step - loss: 8.2956e-04 - mae: 0.0221 - mse: 7.9289e-04 - val_loss: 8.4535e-04 - val_mae: 0.0225 - val_mse: 8.0931e-04 - lr: 1.8114e-04
Epoch 114/150
98/98 [==============================] - 0s 2ms/step - loss: 8.3079e-04 - mae: 0.0222 - mse: 7.9443e-04 - val_loss: 8.4230e-04 - val_mae: 0.0225 - val_mse: 8.0597e-04 - lr: 1.8114e-04
Epoch 115/150
98/98 [==============================] - 0s 2ms/step - loss: 8.3067e-04 - mae: 0.0222 - mse: 7.9425e-04 - val_loss: 8.4018e-04 - val_mae: 0.0224 - val_mse: 8.0338e-04 - lr: 1.8114e-04
Epoch 116/150
98/98 [==============================] - 0s 2ms/step - loss: 8.2979e-04 - mae: 0.0221 - mse: 7.9334e-04 - val_loss: 8.4529e-04 - val_mae: 0.0225 - val_mse: 8.0938e-04 - lr: 1.8114e-04
Epoch 117/150
98/98 [==============================] - 0s 2ms/step - loss: 8.2997e-04 - mae: 0.0221 - mse: 7.9398e-04 - val_loss: 8.3946e-04 - val_mae: 0.0224 - val_mse: 8.0285e-04 - lr: 1.8114e-04
Epoch 118/150
98/98 [==============================] - 0s 2ms/step - loss: 8.2962e-04 - mae: 0.0221 - mse: 7.9365e-04 - val_loss: 8.4251e-04 - val_mae: 0.0225 - val_mse: 8.0674e-04 - lr: 1.8114e-04
Epoch 119/150
98/98 [==============================] - 0s 2ms/step - loss: 8.2942e-04 - mae: 0.0221 - mse: 7.9328e-04 - val_loss: 8.4402e-04 - val_mae: 0.0225 - val_mse: 8.0823e-04 - lr: 1.8114e-04
Epoch 120/150
98/98 [==============================] - 0s 2ms/step - loss: 8.2980e-04 - mae: 0.0221 - mse: 7.9374e-04 - val_loss: 8.4308e-04 - val_mae: 0.0225 - val_mse: 8.0724e-04 - lr: 1.8114e-04
Epoch 121/150
98/98 [==============================] - 0s 2ms/step - loss: 8.2963e-04 - mae: 0.0221 - mse: 7.9353e-04 - val_loss: 8.4243e-04 - val_mae: 0.0225 - val_mse: 8.0651e-04 - lr: 1.8114e-04
Epoch 122/150
56/98 [================>.............] - ETA: 0s - loss: 8.1843e-04 - mae: 0.0220 - mse: 7.8259e-04
Epoch 122: ReduceLROnPlateau reducing learning rate to 9.056753333425149e-05.
98/98 [==============================] - 0s 2ms/step - loss: 8.2977e-04 - mae: 0.0222 - mse: 7.9374e-04 - val_loss: 8.3926e-04 - val_mae: 0.0224 - val_mse: 8.0183e-04 - lr: 1.8114e-04
Epoch 123/150
98/98 [==============================] - 0s 2ms/step - loss: 8.2970e-04 - mae: 0.0221 - mse: 7.9298e-04 - val_loss: 8.4238e-04 - val_mae: 0.0225 - val_mse: 8.0626e-04 - lr: 9.0568e-05
Epoch 124/150
98/98 [==============================] - 0s 2ms/step - loss: 8.2961e-04 - mae: 0.0221 - mse: 7.9354e-04 - val_loss: 8.4117e-04 - val_mae: 0.0225 - val_mse: 8.0511e-04 - lr: 9.0568e-05
Epoch 125/150
98/98 [==============================] - 0s 2ms/step - loss: 8.2888e-04 - mae: 0.0221 - mse: 7.9262e-04 - val_loss: 8.4358e-04 - val_mae: 0.0225 - val_mse: 8.0788e-04 - lr: 9.0568e-05
Epoch 126/150
98/98 [==============================] - 0s 2ms/step - loss: 8.2896e-04 - mae: 0.0221 - mse: 7.9313e-04 - val_loss: 8.4092e-04 - val_mae: 0.0225 - val_mse: 8.0485e-04 - lr: 9.0568e-05
Epoch 127/150
98/98 [==============================] - 0s 2ms/step - loss: 8.2893e-04 - mae: 0.0221 - mse: 7.9305e-04 - val_loss: 8.4440e-04 - val_mae: 0.0225 - val_mse: 8.0877e-04 - lr: 9.0568e-05
Epoch 128/150
98/98 [==============================] - 0s 2ms/step - loss: 8.2891e-04 - mae: 0.0221 - mse: 7.9300e-04 - val_loss: 8.3992e-04 - val_mae: 0.0224 - val_mse: 8.0361e-04 - lr: 9.0568e-05
Epoch 129/150
98/98 [==============================] - 0s 2ms/step - loss: 8.2878e-04 - mae: 0.0221 - mse: 7.9256e-04 - val_loss: 8.4259e-04 - val_mae: 0.0225 - val_mse: 8.0670e-04 - lr: 9.0568e-05
Epoch 130/150
98/98 [==============================] - 0s 2ms/step - loss: 8.2951e-04 - mae: 0.0221 - mse: 7.9357e-04 - val_loss: 8.4238e-04 - val_mae: 0.0225 - val_mse: 8.0654e-04 - lr: 9.0568e-05
Epoch 131/150
98/98 [==============================] - 0s 2ms/step - loss: 8.2924e-04 - mae: 0.0221 - mse: 7.9341e-04 - val_loss: 8.4117e-04 - val_mae: 0.0225 - val_mse: 8.0488e-04 - lr: 9.0568e-05
Epoch 132/150
87/98 [=========================>....] - ETA: 0s - loss: 8.3170e-04 - mae: 0.0222 - mse: 7.9557e-04
Epoch 132: ReduceLROnPlateau reducing learning rate to 4.5283766667125747e-05.
98/98 [==============================] - 0s 2ms/step - loss: 8.2903e-04 - mae: 0.0221 - mse: 7.9285e-04 - val_loss: 8.3948e-04 - val_mae: 0.0224 - val_mse: 8.0289e-04 - lr: 9.0568e-05
Epoch 133/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2875e-04 - mae: 0.0221 - mse: 7.9240e-04 - val_loss: 8.4140e-04 - val_mae: 0.0225 - val_mse: 8.0537e-04 - lr: 4.5284e-05
Epoch 134/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2859e-04 - mae: 0.0221 - mse: 7.9253e-04 - val_loss: 8.4170e-04 - val_mae: 0.0225 - val_mse: 8.0563e-04 - lr: 4.5284e-05
Epoch 135/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2872e-04 - mae: 0.0221 - mse: 7.9253e-04 - val_loss: 8.4167e-04 - val_mae: 0.0225 - val_mse: 8.0556e-04 - lr: 4.5284e-05
Epoch 136/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2877e-04 - mae: 0.0221 - mse: 7.9260e-04 - val_loss: 8.4253e-04 - val_mae: 0.0225 - val_mse: 8.0660e-04 - lr: 4.5284e-05
Epoch 137/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2874e-04 - mae: 0.0221 - mse: 7.9276e-04 - val_loss: 8.4195e-04 - val_mae: 0.0225 - val_mse: 8.0599e-04 - lr: 4.5284e-05
Epoch 138/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2853e-04 - mae: 0.0221 - mse: 7.9277e-04 - val_loss: 8.4098e-04 - val_mae: 0.0225 - val_mse: 8.0492e-04 - lr: 4.5284e-05
Epoch 139/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2881e-04 - mae: 0.0221 - mse: 7.9271e-04 - val_loss: 8.4189e-04 - val_mae: 0.0225 - val_mse: 8.0604e-04 - lr: 4.5284e-05
Epoch 140/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2856e-04 - mae: 0.0221 - mse: 7.9264e-04 - val_loss: 8.4062e-04 - val_mae: 0.0225 - val_mse: 8.0456e-04 - lr: 4.5284e-05
Epoch 141/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2863e-04 - mae: 0.0221 - mse: 7.9246e-04 - val_loss: 8.4137e-04 - val_mae: 0.0225 - val_mse: 8.0550e-04 - lr: 4.5284e-05
Epoch 142/150
67/98 [===================>..........] - ETA: 0s - loss: 8.1469e-04 - mae: 0.0220 - mse: 7.7918e-04
Epoch 142: ReduceLROnPlateau reducing learning rate to 2.2641883333562873e-05.
98/98 [==============================] - 0s 1ms/step - loss: 8.2892e-04 - mae: 0.0221 - mse: 7.9330e-04 - val_loss: 8.4078e-04 - val_mae: 0.0225 - val_mse: 8.0491e-04 - lr: 4.5284e-05
Epoch 143/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2854e-04 - mae: 0.0221 - mse: 7.9270e-04 - val_loss: 8.4122e-04 - val_mae: 0.0225 - val_mse: 8.0541e-04 - lr: 2.2642e-05
Epoch 144/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2855e-04 - mae: 0.0221 - mse: 7.9291e-04 - val_loss: 8.4145e-04 - val_mae: 0.0225 - val_mse: 8.0574e-04 - lr: 2.2642e-05
Epoch 145/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2845e-04 - mae: 0.0221 - mse: 7.9266e-04 - val_loss: 8.4083e-04 - val_mae: 0.0225 - val_mse: 8.0505e-04 - lr: 2.2642e-05
Epoch 146/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2852e-04 - mae: 0.0221 - mse: 7.9267e-04 - val_loss: 8.4133e-04 - val_mae: 0.0225 - val_mse: 8.0564e-04 - lr: 2.2642e-05
Epoch 147/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2859e-04 - mae: 0.0221 - mse: 7.9294e-04 - val_loss: 8.4135e-04 - val_mae: 0.0225 - val_mse: 8.0565e-04 - lr: 2.2642e-05
Epoch 148/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2847e-04 - mae: 0.0221 - mse: 7.9281e-04 - val_loss: 8.4109e-04 - val_mae: 0.0225 - val_mse: 8.0535e-04 - lr: 2.2642e-05
Epoch 149/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2855e-04 - mae: 0.0221 - mse: 7.9274e-04 - val_loss: 8.4151e-04 - val_mae: 0.0225 - val_mse: 8.0585e-04 - lr: 2.2642e-05
Epoch 150/150
98/98 [==============================] - 0s 1ms/step - loss: 8.2849e-04 - mae: 0.0221 - mse: 7.9283e-04 - val_loss: 8.4190e-04 - val_mae: 0.0225 - val_mse: 8.0630e-04 - lr: 2.2642e-05
>Saved ../trained_models/models_segments_overlap_adam_0.09274115666742028LR_[30]HN_40BS_10P_val_mseM_150epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0262 - mae: 0.0392 - mse: 0.0021 - val_loss: 0.0021 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0927
Epoch 2/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0927
Epoch 3/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0927
Epoch 4/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0927
Epoch 5/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0400 - val_mse: 0.0022 - lr: 0.0927
Epoch 6/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0927
Epoch 7/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0927
Epoch 8/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0927
Epoch 9/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0927
Epoch 10/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0927
Epoch 11/150
66/98 [===================>..........] - ETA: 0s - loss: 0.0020 - mae: 0.0377 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.046370577067136765.
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0927
Epoch 12/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0464
Epoch 13/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0464
Epoch 14/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0464
Epoch 15/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0464
Epoch 16/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0464
Epoch 17/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0464
Epoch 18/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0464
Epoch 19/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0464
Epoch 20/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0464
Epoch 21/150
54/98 [===============>..............] - ETA: 0s - loss: 0.0020 - mae: 0.0387 - mse: 0.0020
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.023185288533568382.
98/98 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0464
Epoch 22/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0232
Epoch 23/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0232
Epoch 24/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0232
Epoch 25/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0232
Epoch 26/150
98/98 [==============================] - 0s 3ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0232
Epoch 27/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0232
Epoch 28/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0232
Epoch 29/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0232
Epoch 30/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0232
Epoch 31/150
55/98 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.011592644266784191.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0232
Epoch 32/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0116
Epoch 33/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0116
Epoch 34/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0116
Epoch 35/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0116
Epoch 36/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0116
Epoch 37/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0116
Epoch 38/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0116
Epoch 39/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0116
Epoch 40/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0116
Epoch 41/150
71/98 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0057963221333920956.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0116
Epoch 42/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0058
Epoch 43/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0058
Epoch 44/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0058
Epoch 45/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0058
Epoch 46/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0058
Epoch 47/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0058
Epoch 48/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0058
Epoch 49/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0058
Epoch 50/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0058
Epoch 51/150
70/98 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0028981610666960478.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0058
Epoch 52/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 53/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0029
Epoch 54/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 55/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 56/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 57/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 58/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0029
Epoch 59/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 60/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0029
Epoch 61/150
68/98 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0014490805333480239.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 62/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 63/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 64/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 65/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 66/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 67/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 68/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 69/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 70/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0016s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0004s vs `on_train_batch_end` time: 0.0011s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0004s vs `on_train_batch_end` time: 0.0018s). Check your callbacks.
Epoch 132/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.1321e-05
Epoch 133/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.1321e-05
Epoch 134/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.1321e-05
Epoch 135/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.1321e-05
Epoch 136/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.1321e-05
Epoch 137/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.1321e-05
Epoch 138/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.1321e-05
Epoch 139/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.1321e-05
Epoch 140/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.1321e-05
Epoch 141/150
54/98 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 141: ReduceLROnPlateau reducing learning rate to 1e-05.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.1321e-05
Epoch 142/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 143/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 144/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 145/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 146/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 147/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 148/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 149/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 150/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_adam_0.09274115666742028LR_[30]HN_40BS_10P_val_mseM_150epochs/model_5.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
98/98 [==============================] - 1s 2ms/step - loss: 0.0275 - mae: 0.0403 - mse: 0.0023 - val_loss: 0.0021 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0927
Epoch 2/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0927
Epoch 3/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0927
Epoch 4/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 0.0927
Epoch 5/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0927
Epoch 6/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0389 - val_mse: 0.0020 - lr: 0.0927
Epoch 7/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0927
Epoch 8/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0927
Epoch 9/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0927
Epoch 10/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0927
Epoch 11/150
69/98 [====================>.........] - ETA: 0s - loss: 0.0020 - mae: 0.0379 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.046370577067136765.
98/98 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0388 - val_mse: 0.0021 - lr: 0.0927
Epoch 12/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0464
Epoch 13/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0389 - val_mse: 0.0020 - lr: 0.0464
Epoch 14/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0464
Epoch 15/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0464
Epoch 16/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0464
Epoch 17/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0464
Epoch 18/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0402 - val_mse: 0.0022 - lr: 0.0464
Epoch 19/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0464
Epoch 20/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0464
Epoch 21/150
69/98 [====================>.........] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.023185288533568382.
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0464
Epoch 22/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0232
Epoch 23/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0232
Epoch 24/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0232
Epoch 25/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0232
Epoch 26/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0232
Epoch 27/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0232
Epoch 28/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0232
Epoch 29/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0232
Epoch 30/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0232
Epoch 31/150
65/98 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.011592644266784191.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0232
Epoch 32/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0116
Epoch 33/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0116
Epoch 34/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0116
Epoch 35/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0116
Epoch 36/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0116
Epoch 37/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0116
Epoch 38/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0116
Epoch 39/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0116
Epoch 40/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0116
Epoch 41/150
73/98 [=====================>........] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0057963221333920956.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0116
Epoch 42/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0058
Epoch 43/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0058
Epoch 44/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0058
Epoch 45/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0058
Epoch 46/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0058
Epoch 47/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0058
Epoch 48/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0058
Epoch 49/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0058
Epoch 50/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0058
Epoch 51/150
70/98 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0028981610666960478.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0058
Epoch 52/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 53/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 54/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0029
Epoch 55/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0029
Epoch 56/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 57/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0029
Epoch 58/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0029
Epoch 59/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 60/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0029
Epoch 61/150
49/98 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0014490805333480239.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0029
Epoch 62/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 63/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 64/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 65/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 66/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 67/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 68/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 69/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 70/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 71/150
87/98 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0007245402666740119.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 72/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.2454e-04
Epoch 73/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.2454e-04
Epoch 74/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.2454e-04
Epoch 75/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.2454e-04
Epoch 76/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.2454e-04
Epoch 77/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.2454e-04
Epoch 78/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.2454e-04
Epoch 79/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.2454e-04
Epoch 80/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.2454e-04
Epoch 81/150
57/98 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 81: ReduceLROnPlateau reducing learning rate to 0.00036227013333700597.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.2454e-04
Epoch 82/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.6227e-04
Epoch 83/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.6227e-04
Epoch 84/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.6227e-04
Epoch 85/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.6227e-04
Epoch 86/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.6227e-04
Epoch 87/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.6227e-04
Epoch 88/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.6227e-04
Epoch 89/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.6227e-04
Epoch 90/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.6227e-04
Epoch 91/150
55/98 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 91: ReduceLROnPlateau reducing learning rate to 0.00018113506666850299.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.6227e-04
Epoch 92/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.8114e-04
Epoch 93/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.8114e-04
Epoch 94/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.8114e-04
Epoch 95/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.8114e-04
Epoch 96/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.8114e-04
Epoch 97/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.8114e-04
Epoch 98/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.8114e-04
Epoch 99/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.8114e-04
Epoch 100/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.8114e-04
Epoch 101/150
65/98 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 101: ReduceLROnPlateau reducing learning rate to 9.056753333425149e-05.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.8114e-04
Epoch 102/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.0568e-05
Epoch 103/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.0568e-05
Epoch 104/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.0568e-05
Epoch 105/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.0568e-05
Epoch 106/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.0568e-05
Epoch 107/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.0568e-05
Epoch 108/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 9.0568e-05
Epoch 109/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.0568e-05
Epoch 110/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.0568e-05
Epoch 111/150
58/98 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 111: ReduceLROnPlateau reducing learning rate to 4.5283766667125747e-05.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 9.0568e-05
Epoch 112/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.5284e-05
Epoch 113/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.5284e-05
Epoch 114/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.5284e-05
Epoch 115/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.5284e-05
Epoch 116/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.5284e-05
Epoch 117/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.5284e-05
Epoch 118/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.5284e-05
Epoch 119/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.5284e-05
Epoch 120/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.5284e-05
Epoch 121/150
69/98 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 121: ReduceLROnPlateau reducing learning rate to 2.2641883333562873e-05.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 4.5284e-05
Epoch 122/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.2642e-05
Epoch 123/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.2642e-05
Epoch 124/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.2642e-05
Epoch 125/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.2642e-05
Epoch 126/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.2642e-05
Epoch 127/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.2642e-05
Epoch 128/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.2642e-05
Epoch 129/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.2642e-05
Epoch 130/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
Epoch 131/150
63/98 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 131: ReduceLROnPlateau reducing learning rate to 1.1320941666781437e-05.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 2.2642e-05
Epoch 132/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.1321e-05
Epoch 133/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.1321e-05
Epoch 134/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.1321e-05
Epoch 135/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.1321e-05
Epoch 136/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.1321e-05
Epoch 137/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.1321e-05
Epoch 138/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.1321e-05
Epoch 139/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.1321e-05
Epoch 140/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.1321e-05
Epoch 141/150
71/98 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 141: ReduceLROnPlateau reducing learning rate to 1e-05.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.1321e-05
Epoch 142/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 143/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 144/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 145/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 146/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 147/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 148/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 149/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
Epoch 150/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_adam_0.09274115666742028LR_[30]HN_40BS_10P_val_mseM_150epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/150
98/98 [==============================] - 1s 2ms/step - loss: 0.0257 - mae: 0.0438 - mse: 0.0032 - val_loss: 0.0021 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0927
Epoch 2/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0031 - val_mae: 0.0440 - val_mse: 0.0028 - lr: 0.0927
Epoch 3/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0927
Epoch 4/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0927
Epoch 5/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0927
Epoch 6/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0927
Epoch 7/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0927
Epoch 8/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0927
Epoch 9/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0021 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0397 - val_mse: 0.0022 - lr: 0.0927
Epoch 10/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0927
Epoch 11/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0927
Epoch 12/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0927
Epoch 13/150
96/98 [============================>.] - ETA: 0s - loss: 0.0021 - mae: 0.0382 - mse: 0.0020
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.046370577067136765.
98/98 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0027 - val_mae: 0.0419 - val_mse: 0.0025 - lr: 0.0927
Epoch 14/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0022 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0464
Epoch 15/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0464
Epoch 16/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0464
Epoch 17/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0464
Epoch 18/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0464
Epoch 19/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0464
Epoch 20/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0464
Epoch 21/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0464
Epoch 22/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0464
Epoch 23/150
51/98 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.023185288533568382.
98/98 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0393 - val_mse: 0.0021 - lr: 0.0464
Epoch 24/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0232
Epoch 25/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0232
Epoch 26/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0232
Epoch 27/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0232
Epoch 28/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0232
Epoch 29/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0232
Epoch 30/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0232
Epoch 31/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0232
Epoch 32/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0232
Epoch 33/150
53/98 [===============>..............] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.0019
Epoch 33: ReduceLROnPlateau reducing learning rate to 0.011592644266784191.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0232
Epoch 34/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0116
Epoch 35/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0116
Epoch 36/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0116
Epoch 37/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0116
Epoch 38/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0116
Epoch 39/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0116
Epoch 40/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0116
Epoch 41/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0116
Epoch 42/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0116
Epoch 43/150
72/98 [=====================>........] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0057963221333920956.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0116
Epoch 44/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0058
Epoch 45/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0058
Epoch 46/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0058
Epoch 47/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0058
Epoch 48/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0058
Epoch 49/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0058
Epoch 50/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0058
Epoch 51/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0058
Epoch 52/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0058
Epoch 53/150
69/98 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0028981610666960478.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0058
Epoch 54/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 55/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 56/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 57/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 58/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0029
Epoch 59/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0029
Epoch 60/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0029
Epoch 61/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0029
Epoch 62/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0029
Epoch 63/150
49/98 [==============>...............] - ETA: 0s - loss: 0.0019 - mae: 0.0372 - mse: 0.0019
Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0014490805333480239.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0029
Epoch 64/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 65/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 66/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 67/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 68/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 69/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 70/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 71/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 72/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0014
Epoch 73/150
47/98 [=============>................] - ETA: 0s - loss: 0.0019 - mae: 0.0382 - mse: 0.0019
Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0007245402666740119.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0014
Epoch 74/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.2454e-04
Epoch 75/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.2454e-04
Epoch 76/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.2454e-04
Epoch 77/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.2454e-04
Epoch 78/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.2454e-04
Epoch 79/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.2454e-04
Epoch 80/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.2454e-04
Epoch 81/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.2454e-04
Epoch 82/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.2454e-04
Epoch 83/150
98/98 [==============================] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 83: ReduceLROnPlateau reducing learning rate to 0.00036227013333700597.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.2454e-04
Epoch 84/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.6227e-04
Epoch 85/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0382 - val_mse: 0.0019 - lr: 3.6227e-04
Epoch 86/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0382 - val_mse: 0.0019 - lr: 3.6227e-04
Epoch 87/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0382 - val_mse: 0.0019 - lr: 3.6227e-04
Epoch 88/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0382 - val_mse: 0.0019 - lr: 3.6227e-04
Epoch 89/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0382 - val_mse: 0.0019 - lr: 3.6227e-04
Epoch 90/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0382 - val_mse: 0.0019 - lr: 3.6227e-04
Epoch 91/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0382 - val_mse: 0.0019 - lr: 3.6227e-04
Epoch 92/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0382 - val_mse: 0.0019 - lr: 3.6227e-04
Epoch 93/150
72/98 [=====================>........] - ETA: 0s - loss: 0.0019 - mae: 0.0376 - mse: 0.0019
Epoch 93: ReduceLROnPlateau reducing learning rate to 0.00018113506666850299.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 3.6227e-04
Epoch 94/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0382 - val_mse: 0.0019 - lr: 1.8114e-04
Epoch 95/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 1.8114e-04
Epoch 96/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 1.8114e-04
Epoch 97/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 1.8114e-04
Epoch 98/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 1.8114e-04
Epoch 99/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 1.8114e-04
Epoch 100/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 1.8114e-04
Epoch 101/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 1.8114e-04
Epoch 102/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 1.8114e-04
Epoch 103/150
63/98 [==================>...........] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.0019
Epoch 103: ReduceLROnPlateau reducing learning rate to 9.056753333425149e-05.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 1.8114e-04
Epoch 104/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 9.0568e-05
Epoch 105/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 9.0568e-05
Epoch 106/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0375 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 9.0568e-05
Epoch 107/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0375 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 9.0568e-05
Epoch 108/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0375 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 9.0568e-05
Epoch 109/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0375 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 9.0568e-05
Epoch 110/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0375 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 9.0568e-05
Epoch 111/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0375 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 9.0568e-05
Epoch 112/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0375 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 9.0568e-05
Epoch 113/150
61/98 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 113: ReduceLROnPlateau reducing learning rate to 4.5283766667125747e-05.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0375 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 9.0568e-05
Epoch 114/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0375 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 4.5284e-05
Epoch 115/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0375 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 4.5284e-05
Epoch 116/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 4.5284e-05
Epoch 117/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 4.5284e-05
Epoch 118/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 4.5284e-05
Epoch 119/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 4.5284e-05
Epoch 120/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 4.5284e-05
Epoch 121/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 4.5284e-05
Epoch 122/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 4.5284e-05
Epoch 123/150
70/98 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0375 - mse: 0.0019
Epoch 123: ReduceLROnPlateau reducing learning rate to 2.2641883333562873e-05.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 4.5284e-05
Epoch 124/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 2.2642e-05
Epoch 125/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 2.2642e-05
Epoch 126/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 2.2642e-05
Epoch 127/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 2.2642e-05
Epoch 128/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 2.2642e-05
Epoch 129/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 2.2642e-05
Epoch 130/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 2.2642e-05
Epoch 131/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 2.2642e-05
Epoch 132/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 2.2642e-05
Epoch 133/150
73/98 [=====================>........] - ETA: 0s - loss: 0.0019 - mae: 0.0372 - mse: 0.0019
Epoch 133: ReduceLROnPlateau reducing learning rate to 1.1320941666781437e-05.
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 2.2642e-05
Epoch 134/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 1.1321e-05
Epoch 135/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 1.1321e-05
Epoch 136/150
98/98 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 1.1321e-05
Epoch 137/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 1.1321e-05
Epoch 138/150
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0378 - val_mse: 0.0019 - lr: 1.1321e-05
Epoch 139/150
 1/98 [..............................] - ETA: 0s - loss: 0.0020 - mae: 0.0399 - mse: 0.0020
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0012s). Check your callbacks.
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05
98/98 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 2.2642e-05