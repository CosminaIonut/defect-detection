Epoch 1/30
37/70 [==============>...............] - ETA: 0s - loss: 1.5783 - mae: 0.3246 - mse: 0.1114
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.
70/70 [==============================] - 2s 24ms/step - loss: 1.4955 - mae: 0.2473 - mse: 0.0725 - val_loss: 1.3414 - val_mae: 0.1113 - val_mse: 0.0143 - lr: 0.0099
Epoch 2/30
40/70 [================>.............] - ETA: 0s - loss: 1.2871 - mae: 0.0850 - mse: 0.0093
70/70 [==============================] - 1s 17ms/step - loss: 1.2497 - mae: 0.0742 - mse: 0.0075 - val_loss: 1.1613 - val_mae: 0.0536 - val_mse: 0.0043 - lr: 0.0099
Epoch 3/30
17/70 [======>.......................] - ETA: 0s - loss: 1.1431 - mae: 0.0528 - mse: 0.0041
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
70/70 [==============================] - 1s 13ms/step - loss: 1.0861 - mae: 0.0485 - mse: 0.0035 - val_loss: 1.0110 - val_mae: 0.0450 - val_mse: 0.0029 - lr: 0.0099
Epoch 4/30
70/70 [==============================] - 1s 13ms/step - loss: 0.9459 - mae: 0.0435 - mse: 0.0027 - val_loss: 0.8808 - val_mae: 0.0426 - val_mse: 0.0026 - lr: 0.0099
Epoch 5/30
 1/70 [..............................] - ETA: 0s - loss: 0.8808 - mae: 0.0419 - mse: 0.0026
70/70 [==============================] - 1s 12ms/step - loss: 0.8241 - mae: 0.0419 - mse: 0.0025 - val_loss: 0.7675 - val_mae: 0.0418 - val_mse: 0.0025 - lr: 0.0099
Epoch 6/30
 1/70 [..............................] - ETA: 0s - loss: 0.7675 - mae: 0.0417 - mse: 0.0025
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
70/70 [==============================] - 1s 10ms/step - loss: 0.7182 - mae: 0.0413 - mse: 0.0024 - val_loss: 0.6689 - val_mae: 0.0414 - val_mse: 0.0024 - lr: 0.0099
Epoch 7/30
70/70 [==============================] - 1s 14ms/step - loss: 0.6260 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.5830 - val_mae: 0.0413 - val_mse: 0.0024 - lr: 0.0099
Epoch 8/30
 1/70 [..............................] - ETA: 0s - loss: 0.5829 - mae: 0.0404 - mse: 0.0023
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.004927715752273798.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
70/70 [==============================] - 1s 10ms/step - loss: 0.5457 - mae: 0.0410 - mse: 0.0024 - val_loss: 0.5083 - val_mae: 0.0413 - val_mse: 0.0024 - lr: 0.0099
Epoch 9/30
 1/70 [..............................] - ETA: 0s - loss: 0.5081 - mae: 0.0408 - mse: 0.0022
70/70 [==============================] - 1s 10ms/step - loss: 0.4899 - mae: 0.0410 - mse: 0.0024 - val_loss: 0.4728 - val_mae: 0.0413 - val_mse: 0.0024 - lr: 0.0049
Epoch 10/30
 1/70 [..............................] - ETA: 0s - loss: 0.4727 - mae: 0.0397 - mse: 0.0022
70/70 [==============================] - 1s 10ms/step - loss: 0.4574 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.4416 - val_mae: 0.0413 - val_mse: 0.0024 - lr: 0.0049
Epoch 11/30
67/70 [===========================>..] - ETA: 0s - loss: 0.4277 - mae: 0.0411 - mse: 0.0024
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.002463857876136899.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
70/70 [==============================] - 1s 11ms/step - loss: 0.4272 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.4125 - val_mae: 0.0413 - val_mse: 0.0024 - lr: 0.0049
Epoch 12/30
 1/70 [..............................] - ETA: 0s - loss: 0.4124 - mae: 0.0406 - mse: 0.0023
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
70/70 [==============================] - 1s 10ms/step - loss: 0.4050 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.3979 - val_mae: 0.0413 - val_mse: 0.0024 - lr: 0.0025
Epoch 13/30
70/70 [==============================] - 1s 10ms/step - loss: 0.3914 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.3846 - val_mae: 0.0413 - val_mse: 0.0024 - lr: 0.0025
Epoch 14/30
48/70 [===================>..........] - ETA: 0s - loss: 0.3803 - mae: 0.0416 - mse: 0.0024
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0012319289380684495.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
70/70 [==============================] - 1s 13ms/step - loss: 0.3783 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.3717 - val_mae: 0.0414 - val_mse: 0.0024 - lr: 0.0025
Epoch 15/30
 1/70 [..............................] - ETA: 0s - loss: 0.3719 - mae: 0.0435 - mse: 0.0026
70/70 [==============================] - 1s 10ms/step - loss: 0.3683 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.3651 - val_mae: 0.0414 - val_mse: 0.0024 - lr: 0.0012
Epoch 16/30
 1/70 [..............................] - ETA: 0s - loss: 0.3653 - mae: 0.0450 - mse: 0.0026
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
70/70 [==============================] - 1s 10ms/step - loss: 0.3621 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.3589 - val_mae: 0.0414 - val_mse: 0.0024 - lr: 0.0012
Epoch 17/30
 1/70 [..............................] - ETA: 0s - loss: 0.3591 - mae: 0.0430 - mse: 0.0026
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006159644690342247.
70/70 [==============================] - 1s 10ms/step - loss: 0.3560 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.3529 - val_mae: 0.0414 - val_mse: 0.0024 - lr: 0.0012
Epoch 18/30
 1/70 [..............................] - ETA: 0s - loss: 0.3524 - mae: 0.0362 - mse: 0.0018
70/70 [==============================] - 1s 10ms/step - loss: 0.3513 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.3498 - val_mae: 0.0414 - val_mse: 0.0024 - lr: 6.1596e-04
Epoch 19/30
69/70 [============================>.] - ETA: 0s - loss: 0.3483 - mae: 0.0411 - mse: 0.0024
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
70/70 [==============================] - 1s 10ms/step - loss: 0.3483 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.3468 - val_mae: 0.0414 - val_mse: 0.0024 - lr: 6.1596e-04
Epoch 20/30
 1/70 [..............................] - ETA: 0s - loss: 0.3466 - mae: 0.0377 - mse: 0.0022
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0003079822345171124.
70/70 [==============================] - 1s 10ms/step - loss: 0.3454 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.3439 - val_mae: 0.0414 - val_mse: 0.0024 - lr: 6.1596e-04
Epoch 21/30
 1/70 [..............................] - ETA: 0s - loss: 0.3436 - mae: 0.0375 - mse: 0.0021
70/70 [==============================] - 1s 11ms/step - loss: 0.3431 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.3423 - val_mae: 0.0414 - val_mse: 0.0024 - lr: 3.0798e-04
Epoch 22/30
 1/70 [..............................] - ETA: 0s - loss: 0.3423 - mae: 0.0399 - mse: 0.0023
70/70 [==============================] - 1s 10ms/step - loss: 0.3416 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.3409 - val_mae: 0.0414 - val_mse: 0.0024 - lr: 3.0798e-04
Epoch 23/30
 1/70 [..............................] - ETA: 0s - loss: 0.3413 - mae: 0.0449 - mse: 0.0028
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001539911172585562.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
70/70 [==============================] - 1s 12ms/step - loss: 0.3402 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.3394 - val_mae: 0.0414 - val_mse: 0.0024 - lr: 3.0798e-04
Epoch 24/30
70/70 [==============================] - 1s 10ms/step - loss: 0.3390 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.3387 - val_mae: 0.0414 - val_mse: 0.0024 - lr: 1.5399e-04
Epoch 25/30
 1/70 [..............................] - ETA: 0s - loss: 0.3389 - mae: 0.0433 - mse: 0.0026
70/70 [==============================] - 1s 10ms/step - loss: 0.3383 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.3380 - val_mae: 0.0414 - val_mse: 0.0024 - lr: 1.5399e-04
Epoch 26/30
 1/70 [..............................] - ETA: 0s - loss: 0.3380 - mae: 0.0427 - mse: 0.0024
Epoch 26: ReduceLROnPlateau reducing learning rate to 7.69955586292781e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
70/70 [==============================] - 1s 10ms/step - loss: 0.3376 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.3372 - val_mae: 0.0414 - val_mse: 0.0024 - lr: 1.5399e-04
Epoch 27/30
 1/70 [..............................] - ETA: 0s - loss: 0.3371 - mae: 0.0402 - mse: 0.0022
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
70/70 [==============================] - 1s 10ms/step - loss: 0.3370 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.3369 - val_mae: 0.0414 - val_mse: 0.0024 - lr: 7.6996e-05
Epoch 28/30
70/70 [==============================] - 1s 11ms/step - loss: 0.3367 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.3365 - val_mae: 0.0414 - val_mse: 0.0024 - lr: 7.6996e-05
Epoch 29/30
 1/70 [..............................] - ETA: 0s - loss: 0.3364 - mae: 0.0417 - mse: 0.0023
Epoch 29: ReduceLROnPlateau reducing learning rate to 3.849777931463905e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
70/70 [==============================] - 1s 11ms/step - loss: 0.3363 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.3362 - val_mae: 0.0414 - val_mse: 0.0024 - lr: 7.6996e-05
Epoch 30/30
 1/70 [..............................] - ETA: 0s - loss: 0.3366 - mae: 0.0461 - mse: 0.0028
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0007s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.
70/70 [==============================] - 1s 10ms/step - loss: 0.3360 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.3360 - val_mae: 0.0414 - val_mse: 0.0024 - lr: 3.8498e-05
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.009855431697256887_70_56_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
93/93 [==============================] - 0s 2ms/step - loss: 1.3762 - mae: 0.1747 - mse: 0.0383 - val_loss: 1.2279 - val_mae: 0.0829 - val_mse: 0.0099 - lr: 0.0099
Epoch 2/30
93/93 [==============================] - 0s 1ms/step - loss: 1.1209 - mae: 0.0626 - mse: 0.0058 - val_loss: 1.0183 - val_mae: 0.0546 - val_mse: 0.0042 - lr: 0.0099
Epoch 3/30
93/93 [==============================] - 0s 1ms/step - loss: 0.9320 - mae: 0.0527 - mse: 0.0038 - val_loss: 0.8477 - val_mae: 0.0520 - val_mse: 0.0037 - lr: 0.0099
Epoch 4/30
93/93 [==============================] - 0s 1ms/step - loss: 0.7760 - mae: 0.0516 - mse: 0.0036 - val_loss: 0.7060 - val_mae: 0.0516 - val_mse: 0.0036 - lr: 0.0099
Epoch 5/30
93/93 [==============================] - 0s 1ms/step - loss: 0.6464 - mae: 0.0515 - mse: 0.0036 - val_loss: 0.5881 - val_mae: 0.0515 - val_mse: 0.0036 - lr: 0.0099
Epoch 6/30
93/93 [==============================] - 0s 1ms/step - loss: 0.5385 - mae: 0.0514 - mse: 0.0035 - val_loss: 0.4900 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 0.0099
Epoch 7/30
93/93 [==============================] - 0s 1ms/step - loss: 0.4488 - mae: 0.0514 - mse: 0.0035 - val_loss: 0.4085 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 0.0099
Epoch 8/30
93/93 [==============================] - 0s 1ms/step - loss: 0.3741 - mae: 0.0514 - mse: 0.0035 - val_loss: 0.3406 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 0.0099
Epoch 9/30
83/93 [=========================>....] - ETA: 0s - loss: 0.3147 - mae: 0.0515 - mse: 0.0036
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.004927715752273798.
93/93 [==============================] - 1s 8ms/step - loss: 0.3120 - mae: 0.0514 - mse: 0.0035 - val_loss: 0.2841 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 0.0099
Epoch 10/30
78/93 [========================>.....] - ETA: 0s - loss: 0.2728 - mae: 0.0516 - mse: 0.0036
93/93 [==============================] - 1s 8ms/step - loss: 0.2709 - mae: 0.0514 - mse: 0.0035 - val_loss: 0.2586 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 0.0049
Epoch 11/30
74/93 [======================>.......] - ETA: 0s - loss: 0.2496 - mae: 0.0513 - mse: 0.0035
76/93 [=======================>......] - ETA: 0s - loss: 0.2280 - mae: 0.0514 - mse: 0.00350035 - val_loss: 0.2363 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 0.0049
Epoch 12/30
76/93 [=======================>......] - ETA: 0s - loss: 0.2280 - mae: 0.0514 - mse: 0.00350035 - val_loss: 0.2363 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 0.0049
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.002463857876136899.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
93/93 [==============================] - 1s 8ms/step - loss: 0.2262 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.2160 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 0.0049
Epoch 13/30
93/93 [==============================] - 1s 8ms/step - loss: 0.2109 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.2062 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 0.0025
Epoch 14/30
80/93 [========================>.....] - ETA: 0s - loss: 0.2022 - mae: 0.0512 - mse: 0.0035
93/93 [==============================] - 1s 9ms/step - loss: 0.2017 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.1971 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 0.0025
Epoch 15/30
67/93 [====================>.........] - ETA: 0s - loss: 0.1940 - mae: 0.0513 - mse: 0.0035
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0012319289380684495.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
93/93 [==============================] - 1s 8ms/step - loss: 0.1928 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.1885 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 0.0025
Epoch 16/30
77/93 [=======================>......] - ETA: 0s - loss: 0.1866 - mae: 0.0515 - mse: 0.0036
93/93 [==============================] - 1s 8ms/step - loss: 0.1863 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.1842 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 0.0012
Epoch 17/30
80/93 [========================>.....] - ETA: 0s - loss: 0.1824 - mae: 0.0511 - mse: 0.0035
93/93 [==============================] - 1s 8ms/step - loss: 0.1821 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.1801 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 0.0012
Epoch 18/30
79/93 [========================>.....] - ETA: 0s - loss: 0.1784 - mae: 0.0510 - mse: 0.0035
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006159644690342247.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
93/93 [==============================] - 1s 8ms/step - loss: 0.1781 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.1761 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 0.0012
Epoch 19/30
93/93 [==============================] - 1s 8ms/step - loss: 0.1751 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.1741 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 6.1596e-04
Epoch 20/30
79/93 [========================>.....] - ETA: 0s - loss: 0.1732 - mae: 0.0511 - mse: 0.0035
93/93 [==============================] - 6s 70ms/step - loss: 0.1731 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.1722 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 6.1596e-04
Epoch 21/30
80/93 [========================>.....] - ETA: 0s - loss: 0.1714 - mae: 0.0518 - mse: 0.0036
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0003079822345171124.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
93/93 [==============================] - 1s 8ms/step - loss: 0.1712 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.1702 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 6.1596e-04
Epoch 22/30
73/93 [======================>.......] - ETA: 0s - loss: 0.1698 - mae: 0.0511 - mse: 0.0035
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
93/93 [==============================] - 1s 8ms/step - loss: 0.1697 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.1693 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 3.0798e-04
Epoch 23/30
93/93 [==============================] - 1s 9ms/step - loss: 0.1688 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.1683 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 3.0798e-04
Epoch 24/30
59/93 [==================>...........] - ETA: 0s - loss: 0.1680 - mae: 0.0516 - mse: 0.0035
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001539911172585562.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
93/93 [==============================] - 1s 8ms/step - loss: 0.1678 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.1674 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 3.0798e-04
Epoch 25/30
78/93 [========================>.....] - ETA: 0s - loss: 0.1672 - mae: 0.0514 - mse: 0.0035
93/93 [==============================] - 1s 8ms/step - loss: 0.1671 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.1669 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 1.5399e-04
Epoch 26/30
72/93 [======================>.......] - ETA: 0s - loss: 0.1667 - mae: 0.0512 - mse: 0.0035
93/93 [==============================] - 1s 8ms/step - loss: 0.1667 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.1664 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 1.5399e-04
Epoch 27/30
80/93 [========================>.....] - ETA: 0s - loss: 0.1662 - mae: 0.0515 - mse: 0.0035
Epoch 27: ReduceLROnPlateau reducing learning rate to 7.69955586292781e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
93/93 [==============================] - 1s 8ms/step - loss: 0.1662 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.1660 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 1.5399e-04
Epoch 28/30
79/93 [========================>.....] - ETA: 0s - loss: 0.1659 - mae: 0.0513 - mse: 0.0035
93/93 [==============================] - 1s 8ms/step - loss: 0.1658 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.1657 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 7.6996e-05
Epoch 29/30
75/93 [=======================>......] - ETA: 0s - loss: 0.1656 - mae: 0.0511 - mse: 0.0035
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_182827-5qhgayfp\files\model-best)... Done. 0.0s
93/93 [==============================] - 1s 8ms/step - loss: 0.1656 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.1655 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 7.6996e-05
Epoch 30/30
74/93 [======================>.......] - ETA: 0s - loss: 0.1654 - mae: 0.0517 - mse: 0.0036
Epoch 30: ReduceLROnPlateau reducing learning rate to 3.849777931463905e-05.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0022s). Check your callbacks.
93/93 [==============================] - 1s 8ms/step - loss: 0.1654 - mae: 0.0513 - mse: 0.0035 - val_loss: 0.1653 - val_mae: 0.0514 - val_mse: 0.0036 - lr: 7.6996e-05
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.009855431697256887_70_56_30epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
70/70 [==============================] - 0s 2ms/step - loss: 1.4026 - mae: 0.0903 - mse: 0.0115 - val_loss: 1.2987 - val_mae: 0.0437 - val_mse: 0.0028 - lr: 0.0099
Epoch 2/30
70/70 [==============================] - 0s 1ms/step - loss: 1.2145 - mae: 0.0396 - mse: 0.0022 - val_loss: 1.1305 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0099
Epoch 3/30
70/70 [==============================] - 0s 1ms/step - loss: 1.0575 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.9845 - val_mae: 0.0381 - val_mse: 0.0020 - lr: 0.0099
Epoch 4/30
70/70 [==============================] - 0s 1ms/step - loss: 0.9209 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.8574 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 0.0099
Epoch 5/30
 1/70 [..............................] - ETA: 0s - loss: 0.8572 - mae: 0.0351 - mse: 0.0018
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.004927715752273798.
70/70 [==============================] - 0s 1ms/step - loss: 0.8021 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.7468 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 0.0099
Epoch 6/30
70/70 [==============================] - 0s 1ms/step - loss: 0.7195 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.6943 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 0.0049
Epoch 7/30
70/70 [==============================] - 0s 1ms/step - loss: 0.6714 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.6481 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 0.0049
Epoch 8/30
 1/70 [..............................] - ETA: 0s - loss: 0.6483 - mae: 0.0393 - mse: 0.0021
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.002463857876136899.
70/70 [==============================] - 0s 1ms/step - loss: 0.6268 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.6050 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 0.0049
Epoch 9/30
70/70 [==============================] - 0s 1ms/step - loss: 0.5938 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.5834 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 0.0025
Epoch 10/30
70/70 [==============================] - 0s 1ms/step - loss: 0.5737 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.5637 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 0.0025
Epoch 11/30
 1/70 [..............................] - ETA: 0s - loss: 0.5634 - mae: 0.0354 - mse: 0.0017
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0012319289380684495.
70/70 [==============================] - 0s 1ms/step - loss: 0.5543 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.5446 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 0.0025
Epoch 12/30
70/70 [==============================] - 0s 1ms/step - loss: 0.5396 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.5348 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 0.0012
Epoch 13/30
70/70 [==============================] - 0s 1ms/step - loss: 0.5303 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.5257 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 0.0012
Epoch 14/30
 1/70 [..............................] - ETA: 0s - loss: 0.5256 - mae: 0.0366 - mse: 0.0018
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0006159644690342247.
70/70 [==============================] - 0s 1ms/step - loss: 0.5213 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.5168 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 0.0012
Epoch 15/30
70/70 [==============================] - 0s 2ms/step - loss: 0.5143 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.5121 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 6.1596e-04
Epoch 16/30
70/70 [==============================] - 0s 2ms/step - loss: 0.5099 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.5077 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 6.1596e-04
Epoch 17/30
 1/70 [..............................] - ETA: 0s - loss: 0.5076 - mae: 0.0381 - mse: 0.0019
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0003079822345171124.
70/70 [==============================] - 0s 1ms/step - loss: 0.5056 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.5034 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 6.1596e-04
Epoch 18/30
70/70 [==============================] - 0s 1ms/step - loss: 0.5022 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.5011 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 3.0798e-04
Epoch 19/30
70/70 [==============================] - 0s 3ms/step - loss: 0.5000 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.4990 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 3.0798e-04
Epoch 20/30
63/70 [==========================>...] - ETA: 0s - loss: 0.4980 - mae: 0.0379 - mse: 0.0019
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001539911172585562.
70/70 [==============================] - 0s 1ms/step - loss: 0.4979 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.4968 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 3.0798e-04
Epoch 21/30
70/70 [==============================] - 0s 3ms/step - loss: 0.4962 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.4957 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 1.5399e-04
Epoch 22/30
70/70 [==============================] - 0s 2ms/step - loss: 0.4951 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.4946 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 1.5399e-04
Epoch 23/30
 1/70 [..............................] - ETA: 0s - loss: 0.4950 - mae: 0.0409 - mse: 0.0023
Epoch 23: ReduceLROnPlateau reducing learning rate to 7.69955586292781e-05.
70/70 [==============================] - 0s 1ms/step - loss: 0.4941 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.4936 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 1.5399e-04
Epoch 24/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4933 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.4930 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 7.6996e-05
Epoch 25/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4927 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.4925 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 7.6996e-05
Epoch 26/30
 1/70 [..............................] - ETA: 0s - loss: 0.4924 - mae: 0.0372 - mse: 0.0018
Epoch 26: ReduceLROnPlateau reducing learning rate to 3.849777931463905e-05.
70/70 [==============================] - 0s 1ms/step - loss: 0.4922 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.4920 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 7.6996e-05
Epoch 27/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4918 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.4917 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 3.8498e-05
Epoch 28/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4915 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.4914 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 3.8498e-05
Epoch 29/30
47/70 [===================>..........] - ETA: 0s - loss: 0.4913 - mae: 0.0380 - mse: 0.0019
Epoch 29: ReduceLROnPlateau reducing learning rate to 1.9248889657319523e-05.
70/70 [==============================] - 0s 2ms/step - loss: 0.4913 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.4912 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 3.8498e-05
Epoch 30/30
70/70 [==============================] - 0s 2ms/step - loss: 0.4911 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.4910 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 1.9249e-05
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.009855431697256887_70_56_30epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
70/70 [==============================] - 0s 2ms/step - loss: 1.3356 - mae: 0.0573 - mse: 0.0049 - val_loss: 1.2424 - val_mae: 0.0446 - val_mse: 0.0029 - lr: 0.0099
Epoch 2/30
70/70 [==============================] - 0s 1ms/step - loss: 1.1618 - mae: 0.0410 - mse: 0.0024 - val_loss: 1.0813 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0099
Epoch 3/30
70/70 [==============================] - 0s 1ms/step - loss: 1.0114 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.9415 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 0.0099
Epoch 4/30
70/70 [==============================] - 0s 1ms/step - loss: 0.8807 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.8199 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 0.0099
Epoch 5/30
70/70 [==============================] - 0s 1ms/step - loss: 0.7670 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.7140 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 0.0099
Epoch 6/30
 1/70 [..............................] - ETA: 0s - loss: 0.7139 - mae: 0.0353 - mse: 0.0017
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.004927715752273798.
70/70 [==============================] - 0s 1ms/step - loss: 0.6680 - mae: 0.0375 - mse: 0.0019 - val_loss: 0.6219 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 0.0099
Epoch 7/30
70/70 [==============================] - 0s 1ms/step - loss: 0.5992 - mae: 0.0375 - mse: 0.0019 - val_loss: 0.5782 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 0.0049
Epoch 8/30
70/70 [==============================] - 0s 1ms/step - loss: 0.5591 - mae: 0.0375 - mse: 0.0019 - val_loss: 0.5397 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 0.0049
Epoch 9/30
 1/70 [..............................] - ETA: 0s - loss: 0.5398 - mae: 0.0390 - mse: 0.0020
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.002463857876136899.
70/70 [==============================] - 0s 1ms/step - loss: 0.5219 - mae: 0.0375 - mse: 0.0019 - val_loss: 0.5038 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 0.0049
Epoch 10/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4945 - mae: 0.0375 - mse: 0.0019 - val_loss: 0.4858 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 0.0025
Epoch 11/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4777 - mae: 0.0375 - mse: 0.0019 - val_loss: 0.4694 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 0.0025
Epoch 12/30
 1/70 [..............................] - ETA: 0s - loss: 0.4694 - mae: 0.0387 - mse: 0.0020
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0012319289380684495.
70/70 [==============================] - 0s 1ms/step - loss: 0.4615 - mae: 0.0375 - mse: 0.0019 - val_loss: 0.4535 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 0.0025
Epoch 13/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4493 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.4453 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 0.0012
Epoch 14/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4416 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.4378 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 0.0012
Epoch 15/30
 1/70 [..............................] - ETA: 0s - loss: 0.4379 - mae: 0.0403 - mse: 0.0021
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006159644690342247.
70/70 [==============================] - 0s 1ms/step - loss: 0.4341 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.4303 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 0.0012
Epoch 16/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4283 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.4264 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 6.1596e-04
Epoch 17/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4246 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.4228 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 6.1596e-04
Epoch 18/30
 1/70 [..............................] - ETA: 0s - loss: 0.4229 - mae: 0.0399 - mse: 0.0021
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0003079822345171124.
70/70 [==============================] - 0s 1ms/step - loss: 0.4210 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.4191 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 6.1596e-04
Epoch 19/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4181 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.4173 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 3.0798e-04
Epoch 20/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4163 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.4155 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 3.0798e-04
Epoch 21/30
 1/70 [..............................] - ETA: 0s - loss: 0.4151 - mae: 0.0327 - mse: 0.0015
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001539911172585562.
70/70 [==============================] - 0s 1ms/step - loss: 0.4146 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.4137 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 3.0798e-04
Epoch 22/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4132 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.4127 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 1.5399e-04
Epoch 23/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4123 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.4119 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 1.5399e-04
Epoch 24/30
 1/70 [..............................] - ETA: 0s - loss: 0.4117 - mae: 0.0363 - mse: 0.0018
Epoch 24: ReduceLROnPlateau reducing learning rate to 7.69955586292781e-05.
70/70 [==============================] - 0s 1ms/step - loss: 0.4114 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.4110 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 1.5399e-04
Epoch 25/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4107 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.4105 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 7.6996e-05
Epoch 26/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4103 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.4101 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 7.6996e-05
Epoch 27/30
 1/70 [..............................] - ETA: 0s - loss: 0.4102 - mae: 0.0394 - mse: 0.0020
Epoch 27: ReduceLROnPlateau reducing learning rate to 3.849777931463905e-05.
70/70 [==============================] - 0s 1ms/step - loss: 0.4098 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.4096 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 7.6996e-05
Epoch 28/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4095 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.4094 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 3.8498e-05
Epoch 29/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4093 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.4092 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 3.8498e-05
Epoch 30/30
 1/70 [..............................] - ETA: 0s - loss: 0.4092 - mae: 0.0374 - mse: 0.0019
Epoch 30: ReduceLROnPlateau reducing learning rate to 1.9248889657319523e-05.
70/70 [==============================] - 0s 1ms/step - loss: 0.4090 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.4090 - val_mae: 0.0380 - val_mse: 0.0019 - lr: 3.8498e-05
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.009855431697256887_70_56_30epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
70/70 [==============================] - 1s 4ms/step - loss: 1.3257 - mae: 0.0402 - mse: 0.0023 - val_loss: 1.2347 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0099
Epoch 2/30
70/70 [==============================] - 0s 1ms/step - loss: 1.1548 - mae: 0.0381 - mse: 0.0020 - val_loss: 1.0750 - val_mae: 0.0380 - val_mse: 0.0020 - lr: 0.0099
Epoch 3/30
70/70 [==============================] - 0s 1ms/step - loss: 1.0056 - mae: 0.0375 - mse: 0.0019 - val_loss: 0.9361 - val_mae: 0.0377 - val_mse: 0.0019 - lr: 0.0099
Epoch 4/30
70/70 [==============================] - 0s 2ms/step - loss: 0.8757 - mae: 0.0373 - mse: 0.0019 - val_loss: 0.8152 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 0.0099
Epoch 5/30
 1/70 [..............................] - ETA: 0s - loss: 0.8147 - mae: 0.0321 - mse: 0.0014
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.004927715752273798.
70/70 [==============================] - 0s 1ms/step - loss: 0.7626 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.7100 - val_mae: 0.0375 - val_mse: 0.0019 - lr: 0.0099
Epoch 6/30
70/70 [==============================] - 0s 1ms/step - loss: 0.6840 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.6600 - val_mae: 0.0375 - val_mse: 0.0019 - lr: 0.0049
Epoch 7/30
70/70 [==============================] - 0s 1ms/step - loss: 0.6383 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.6161 - val_mae: 0.0375 - val_mse: 0.0019 - lr: 0.0049
Epoch 8/30
 1/70 [..............................] - ETA: 0s - loss: 0.6159 - mae: 0.0361 - mse: 0.0018
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.002463857876136899.
70/70 [==============================] - 0s 1ms/step - loss: 0.5958 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.5750 - val_mae: 0.0375 - val_mse: 0.0019 - lr: 0.0049
Epoch 9/30
70/70 [==============================] - 0s 1ms/step - loss: 0.5644 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.5545 - val_mae: 0.0375 - val_mse: 0.0019 - lr: 0.0025
Epoch 10/30
70/70 [==============================] - 0s 2ms/step - loss: 0.5452 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.5357 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 0.0025
Epoch 11/30
67/70 [===========================>..] - ETA: 0s - loss: 0.5271 - mae: 0.0372 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0012319289380684495.
70/70 [==============================] - 0s 1ms/step - loss: 0.5268 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.5176 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 0.0025
Epoch 12/30
70/70 [==============================] - 0s 1ms/step - loss: 0.5128 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.5083 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 0.0012
Epoch 13/30
70/70 [==============================] - 0s 1ms/step - loss: 0.5040 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.4996 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 0.0012
Epoch 14/30
63/70 [==========================>...] - ETA: 0s - loss: 0.4958 - mae: 0.0371 - mse: 0.0019
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0006159644690342247.
70/70 [==============================] - 0s 2ms/step - loss: 0.4954 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.4911 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 0.0012
Epoch 15/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4888 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.4867 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 6.1596e-04
Epoch 16/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4846 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.4825 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 6.1596e-04
Epoch 17/30
 1/70 [..............................] - ETA: 0s - loss: 0.4824 - mae: 0.0364 - mse: 0.0018
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0003079822345171124.
70/70 [==============================] - 0s 1ms/step - loss: 0.4805 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.4784 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 6.1596e-04
Epoch 18/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4772 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.4762 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 3.0798e-04
Epoch 19/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4752 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.4742 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 3.0798e-04
Epoch 20/30
63/70 [==========================>...] - ETA: 0s - loss: 0.4732 - mae: 0.0373 - mse: 0.0019
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001539911172585562.
70/70 [==============================] - 0s 1ms/step - loss: 0.4731 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.4721 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 3.0798e-04
Epoch 21/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4716 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.4711 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 1.5399e-04
Epoch 22/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4705 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.4701 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 1.5399e-04
Epoch 23/30
 1/70 [..............................] - ETA: 0s - loss: 0.4701 - mae: 0.0386 - mse: 0.0020
Epoch 23: ReduceLROnPlateau reducing learning rate to 7.69955586292781e-05.
70/70 [==============================] - 0s 1ms/step - loss: 0.4695 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.4690 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 1.5399e-04
Epoch 24/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4687 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.4685 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 7.6996e-05
Epoch 25/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4682 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.4680 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 7.6996e-05
Epoch 26/30
 1/70 [..............................] - ETA: 0s - loss: 0.4680 - mae: 0.0373 - mse: 0.0019
Epoch 26: ReduceLROnPlateau reducing learning rate to 3.849777931463905e-05.
70/70 [==============================] - 0s 1ms/step - loss: 0.4677 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.4675 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 7.6996e-05
Epoch 27/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4673 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.4672 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 3.8498e-05
Epoch 28/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4671 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.4670 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 3.8498e-05
Epoch 29/30
 1/70 [..............................] - ETA: 0s - loss: 0.4670 - mae: 0.0374 - mse: 0.0019
Epoch 29: ReduceLROnPlateau reducing learning rate to 1.9248889657319523e-05.
70/70 [==============================] - 0s 1ms/step - loss: 0.4668 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.4667 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 3.8498e-05
Epoch 30/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4666 - mae: 0.0372 - mse: 0.0019 - val_loss: 0.4666 - val_mae: 0.0376 - val_mse: 0.0019 - lr: 1.9249e-05
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.009855431697256887_70_56_30epochs/model_5.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
70/70 [==============================] - 0s 2ms/step - loss: 1.3613 - mae: 0.0793 - mse: 0.0086 - val_loss: 1.2635 - val_mae: 0.0485 - val_mse: 0.0035 - lr: 0.0099
Epoch 2/30
70/70 [==============================] - 0s 1ms/step - loss: 1.1811 - mae: 0.0416 - mse: 0.0025 - val_loss: 1.0992 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0099
Epoch 3/30
70/70 [==============================] - 0s 1ms/step - loss: 1.0282 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.9572 - val_mae: 0.0382 - val_mse: 0.0020 - lr: 0.0099
Epoch 4/30
70/70 [==============================] - 0s 1ms/step - loss: 0.8954 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.8336 - val_mae: 0.0381 - val_mse: 0.0020 - lr: 0.0099
Epoch 5/30
70/70 [==============================] - 0s 1ms/step - loss: 0.7798 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.7260 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 0.0099
Epoch 6/30
 1/70 [..............................] - ETA: 0s - loss: 0.7257 - mae: 0.0355 - mse: 0.0017
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.004927715752273798.
70/70 [==============================] - 0s 1ms/step - loss: 0.6791 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.6323 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 0.0099
Epoch 7/30
70/70 [==============================] - 0s 1ms/step - loss: 0.6092 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.5879 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 0.0049
Epoch 8/30
70/70 [==============================] - 0s 1ms/step - loss: 0.5685 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.5488 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 0.0049
Epoch 9/30
 1/70 [..............................] - ETA: 0s - loss: 0.5488 - mae: 0.0382 - mse: 0.0020
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.002463857876136899.
70/70 [==============================] - 0s 1ms/step - loss: 0.5307 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.5123 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 0.0049
Epoch 10/30
70/70 [==============================] - 0s 1ms/step - loss: 0.5028 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.4940 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 0.0025
Epoch 11/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4857 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.4773 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 0.0025
Epoch 12/30
 1/70 [..............................] - ETA: 0s - loss: 0.4774 - mae: 0.0405 - mse: 0.0020
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0012319289380684495.
70/70 [==============================] - 0s 1ms/step - loss: 0.4693 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.4612 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 0.0025
Epoch 13/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4569 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.4529 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 0.0012
Epoch 14/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4490 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.4452 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 0.0012
Epoch 15/30
 1/70 [..............................] - ETA: 0s - loss: 0.4454 - mae: 0.0419 - mse: 0.0022
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0006159644690342247.
70/70 [==============================] - 0s 1ms/step - loss: 0.4414 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.4376 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 0.0012
Epoch 16/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4355 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.4336 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 6.1596e-04
Epoch 17/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4318 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.4299 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 6.1596e-04
Epoch 18/30
 1/70 [..............................] - ETA: 0s - loss: 0.4298 - mae: 0.0376 - mse: 0.0018
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0003079822345171124.
70/70 [==============================] - 0s 1ms/step - loss: 0.4281 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.4262 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 6.1596e-04
Epoch 19/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4252 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.4243 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 3.0798e-04
Epoch 20/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4234 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.4225 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 3.0798e-04
Epoch 21/30
 1/70 [..............................] - ETA: 0s - loss: 0.4224 - mae: 0.0367 - mse: 0.0019
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001539911172585562.
70/70 [==============================] - 0s 1ms/step - loss: 0.4216 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.4207 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 3.0798e-04
Epoch 22/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4202 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.4197 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 1.5399e-04
Epoch 23/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4193 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.4188 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 1.5399e-04
Epoch 24/30
 1/70 [..............................] - ETA: 0s - loss: 0.4187 - mae: 0.0360 - mse: 0.0018
Epoch 24: ReduceLROnPlateau reducing learning rate to 7.69955586292781e-05.
70/70 [==============================] - 0s 1ms/step - loss: 0.4184 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.4179 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 1.5399e-04
Epoch 25/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4177 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.4175 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 7.6996e-05
Epoch 26/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4172 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.4170 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 7.6996e-05
Epoch 27/30
 1/70 [..............................] - ETA: 0s - loss: 0.4171 - mae: 0.0399 - mse: 0.0020
Epoch 27: ReduceLROnPlateau reducing learning rate to 3.849777931463905e-05.
70/70 [==============================] - 0s 1ms/step - loss: 0.4168 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.4166 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 7.6996e-05
Epoch 28/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4164 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.4163 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 3.8498e-05
Epoch 29/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4162 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.4161 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 3.8498e-05
Epoch 30/30
 1/70 [..............................] - ETA: 0s - loss: 0.4162 - mae: 0.0404 - mse: 0.0021
Epoch 30: ReduceLROnPlateau reducing learning rate to 1.9248889657319523e-05.
70/70 [==============================] - 0s 1ms/step - loss: 0.4160 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.4159 - val_mae: 0.0381 - val_mse: 0.0019 - lr: 3.8498e-05
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.009855431697256887_70_56_30epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
70/70 [==============================] - 0s 2ms/step - loss: 1.3574 - mae: 0.1502 - mse: 0.0264 - val_loss: 1.2488 - val_mae: 0.0821 - val_mse: 0.0087 - lr: 0.0099
Epoch 2/30
70/70 [==============================] - 0s 1ms/step - loss: 1.1648 - mae: 0.0556 - mse: 0.0046 - val_loss: 1.0830 - val_mae: 0.0430 - val_mse: 0.0027 - lr: 0.0099
Epoch 3/30
70/70 [==============================] - 0s 1ms/step - loss: 1.0128 - mae: 0.0399 - mse: 0.0022 - val_loss: 0.9428 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0099
Epoch 4/30
70/70 [==============================] - 0s 2ms/step - loss: 0.8820 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.8212 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0099
Epoch 5/30
70/70 [==============================] - 0s 1ms/step - loss: 0.7682 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.7152 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0099
Epoch 6/30
70/70 [==============================] - 0s 1ms/step - loss: 0.6691 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.6230 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0099
Epoch 7/30
70/70 [==============================] - 0s 1ms/step - loss: 0.5829 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.5428 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0099
Epoch 8/30
70/70 [==============================] - 0s 1ms/step - loss: 0.5078 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.4729 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0099
Epoch 9/30
 1/70 [..............................] - ETA: 0s - loss: 0.4732 - mae: 0.0426 - mse: 0.0023
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.004927715752273798.
70/70 [==============================] - 0s 1ms/step - loss: 0.4424 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.4120 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0099
Epoch 10/30
70/70 [==============================] - 0s 1ms/step - loss: 0.3970 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.3832 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0049
Epoch 11/30
70/70 [==============================] - 0s 1ms/step - loss: 0.3706 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.3578 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0049
Epoch 12/30
 1/70 [..............................] - ETA: 0s - loss: 0.3575 - mae: 0.0373 - mse: 0.0017
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.002463857876136899.
70/70 [==============================] - 0s 2ms/step - loss: 0.3460 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.3341 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0049
Epoch 13/30
70/70 [==============================] - 0s 1ms/step - loss: 0.3279 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.3222 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0025
Epoch 14/30
70/70 [==============================] - 0s 1ms/step - loss: 0.3168 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.3113 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0025
Epoch 15/30
 1/70 [..............................] - ETA: 0s - loss: 0.3111 - mae: 0.0349 - mse: 0.0017
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0012319289380684495.
70/70 [==============================] - 0s 1ms/step - loss: 0.3061 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.3009 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0025
Epoch 16/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2980 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.2955 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0012
Epoch 17/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2930 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.2905 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0012
Epoch 18/30
 1/70 [..............................] - ETA: 0s - loss: 0.2903 - mae: 0.0371 - mse: 0.0019
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0006159644690342247.
70/70 [==============================] - 0s 1ms/step - loss: 0.2880 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.2855 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0012
Epoch 19/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2842 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.2830 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 6.1596e-04
Epoch 20/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2818 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.2806 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 6.1596e-04
Epoch 21/30
 1/70 [..............................] - ETA: 0s - loss: 0.2802 - mae: 0.0324 - mse: 0.0016
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0003079822345171124.
70/70 [==============================] - 0s 1ms/step - loss: 0.2794 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.2782 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 6.1596e-04
Epoch 22/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2775 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.2769 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 3.0798e-04
Epoch 23/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2763 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.2757 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 3.0798e-04
Epoch 24/30
 1/70 [..............................] - ETA: 0s - loss: 0.2762 - mae: 0.0434 - mse: 0.0024
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001539911172585562.
70/70 [==============================] - 0s 1ms/step - loss: 0.2751 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.2746 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 3.0798e-04
Epoch 25/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2742 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.2740 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 1.5399e-04
Epoch 26/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2736 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.2734 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 1.5399e-04
Epoch 27/30
 1/70 [..............................] - ETA: 0s - loss: 0.2736 - mae: 0.0422 - mse: 0.0022
Epoch 27: ReduceLROnPlateau reducing learning rate to 7.69955586292781e-05.
70/70 [==============================] - 0s 1ms/step - loss: 0.2730 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.2728 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 1.5399e-04
Epoch 28/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2726 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.2725 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 7.6996e-05
Epoch 29/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2723 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.2722 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 7.6996e-05
Epoch 30/30
 1/70 [..............................] - ETA: 0s - loss: 0.2719 - mae: 0.0352 - mse: 0.0017
Epoch 30: ReduceLROnPlateau reducing learning rate to 3.849777931463905e-05.
70/70 [==============================] - 0s 1ms/step - loss: 0.2720 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.2719 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 7.6996e-05
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.009855431697256887_70_56_30epochs/model_7.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
70/70 [==============================] - 1s 4ms/step - loss: 1.3422 - mae: 0.1965 - mse: 0.0462 - val_loss: 1.2179 - val_mae: 0.0887 - val_mse: 0.0098 - lr: 0.0099
Epoch 2/30
70/70 [==============================] - 0s 1ms/step - loss: 1.1355 - mae: 0.0577 - mse: 0.0049 - val_loss: 1.0557 - val_mae: 0.0442 - val_mse: 0.0029 - lr: 0.0099
Epoch 3/30
70/70 [==============================] - 0s 1ms/step - loss: 0.9874 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.9192 - val_mae: 0.0398 - val_mse: 0.0022 - lr: 0.0099
Epoch 4/30
70/70 [==============================] - 0s 1ms/step - loss: 0.8600 - mae: 0.0391 - mse: 0.0021 - val_loss: 0.8008 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0099
Epoch 5/30
70/70 [==============================] - 0s 1ms/step - loss: 0.7492 - mae: 0.0387 - mse: 0.0021 - val_loss: 0.6976 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0099
Epoch 6/30
70/70 [==============================] - 0s 1ms/step - loss: 0.6527 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.6079 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0099
Epoch 7/30
55/70 [======================>.......] - ETA: 0s - loss: 0.5767 - mae: 0.0387 - mse: 0.0020
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.004927715752273798.
70/70 [==============================] - 0s 2ms/step - loss: 0.5687 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.5297 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0099
Epoch 8/30
70/70 [==============================] - 0s 1ms/step - loss: 0.5104 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.4926 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0049
Epoch 9/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4764 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.4600 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0049
Epoch 10/30
 1/70 [..............................] - ETA: 0s - loss: 0.4598 - mae: 0.0378 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.002463857876136899.
70/70 [==============================] - 0s 1ms/step - loss: 0.4449 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.4295 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0049
Epoch 11/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4216 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.4142 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0025
Epoch 12/30
70/70 [==============================] - 0s 1ms/step - loss: 0.4074 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.4003 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0025
Epoch 13/30
 1/70 [..............................] - ETA: 0s - loss: 0.4004 - mae: 0.0392 - mse: 0.0021
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0012319289380684495.
70/70 [==============================] - 0s 1ms/step - loss: 0.3937 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.3869 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0025
Epoch 14/30
70/70 [==============================] - 0s 1ms/step - loss: 0.3833 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.3799 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0012
Epoch 15/30
70/70 [==============================] - 0s 1ms/step - loss: 0.3767 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.3735 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0012
Epoch 16/30
 1/70 [..............................] - ETA: 0s - loss: 0.3733 - mae: 0.0378 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0006159644690342247.
70/70 [==============================] - 0s 1ms/step - loss: 0.3704 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.3672 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0012
Epoch 17/30
70/70 [==============================] - 0s 1ms/step - loss: 0.3654 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.3639 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 6.1596e-04
Epoch 18/30
70/70 [==============================] - 0s 1ms/step - loss: 0.3623 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.3608 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 6.1596e-04
Epoch 19/30
56/70 [=======================>......] - ETA: 0s - loss: 0.3595 - mae: 0.0386 - mse: 0.0020
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0003079822345171124.
70/70 [==============================] - 0s 2ms/step - loss: 0.3592 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.3577 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 6.1596e-04
Epoch 20/30
70/70 [==============================] - 0s 1ms/step - loss: 0.3569 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.3561 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 3.0798e-04
Epoch 21/30
70/70 [==============================] - 0s 1ms/step - loss: 0.3553 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.3546 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 3.0798e-04
Epoch 22/30
 1/70 [..............................] - ETA: 0s - loss: 0.3552 - mae: 0.0437 - mse: 0.0027
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0001539911172585562.
70/70 [==============================] - 0s 1ms/step - loss: 0.3538 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.3531 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 3.0798e-04
Epoch 23/30
70/70 [==============================] - 0s 1ms/step - loss: 0.3526 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.3523 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 1.5399e-04
Epoch 24/30
70/70 [==============================] - 0s 1ms/step - loss: 0.3519 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.3516 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 1.5399e-04
Epoch 25/30
 1/70 [..............................] - ETA: 0s - loss: 0.3515 - mae: 0.0385 - mse: 0.0020
Epoch 25: ReduceLROnPlateau reducing learning rate to 7.69955586292781e-05.
70/70 [==============================] - 0s 1ms/step - loss: 0.3511 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.3508 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 1.5399e-04
Epoch 26/30
70/70 [==============================] - 0s 1ms/step - loss: 0.3506 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.3504 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 7.6996e-05
Epoch 27/30
70/70 [==============================] - 0s 1ms/step - loss: 0.3502 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.3500 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 7.6996e-05
Epoch 28/30
 1/70 [..............................] - ETA: 0s - loss: 0.3495 - mae: 0.0345 - mse: 0.0016
Epoch 28: ReduceLROnPlateau reducing learning rate to 3.849777931463905e-05.
70/70 [==============================] - 0s 1ms/step - loss: 0.3498 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.3497 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 7.6996e-05
Epoch 29/30
70/70 [==============================] - 0s 1ms/step - loss: 0.3495 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.3495 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 3.8498e-05
Epoch 30/30
70/70 [==============================] - 0s 1ms/step - loss: 0.3493 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.3493 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 3.8498e-05
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.009855431697256887_70_56_30epochs/model_8.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
70/70 [==============================] - 0s 3ms/step - loss: 1.4226 - mae: 0.2823 - mse: 0.0883 - val_loss: 1.2721 - val_mae: 0.1607 - val_mse: 0.0277 - lr: 0.0099
Epoch 2/30
70/70 [==============================] - 0s 1ms/step - loss: 1.1794 - mae: 0.1091 - mse: 0.0144 - val_loss: 1.0930 - val_mae: 0.0748 - val_mse: 0.0075 - lr: 0.0099
Epoch 3/30
70/70 [==============================] - 0s 1ms/step - loss: 1.0212 - mae: 0.0608 - mse: 0.0054 - val_loss: 0.9503 - val_mae: 0.0528 - val_mse: 0.0042 - lr: 0.0099
Epoch 4/30
70/70 [==============================] - 0s 1ms/step - loss: 0.8889 - mae: 0.0486 - mse: 0.0035 - val_loss: 0.8276 - val_mae: 0.0464 - val_mse: 0.0032 - lr: 0.0099
Epoch 5/30
70/70 [==============================] - 0s 1ms/step - loss: 0.7743 - mae: 0.0446 - mse: 0.0029 - val_loss: 0.7212 - val_mae: 0.0440 - val_mse: 0.0028 - lr: 0.0099
Epoch 6/30
70/70 [==============================] - 0s 1ms/step - loss: 0.6748 - mae: 0.0429 - mse: 0.0027 - val_loss: 0.6285 - val_mae: 0.0429 - val_mse: 0.0027 - lr: 0.0099
Epoch 7/30
70/70 [==============================] - 0s 1ms/step - loss: 0.5882 - mae: 0.0421 - mse: 0.0026 - val_loss: 0.5479 - val_mae: 0.0423 - val_mse: 0.0026 - lr: 0.0099
Epoch 8/30
70/70 [==============================] - 0s 1ms/step - loss: 0.5128 - mae: 0.0418 - mse: 0.0025 - val_loss: 0.4777 - val_mae: 0.0421 - val_mse: 0.0026 - lr: 0.0099
Epoch 9/30
70/70 [==============================] - 0s 2ms/step - loss: 0.4471 - mae: 0.0416 - mse: 0.0025 - val_loss: 0.4166 - val_mae: 0.0420 - val_mse: 0.0025 - lr: 0.0099
Epoch 10/30
70/70 [==============================] - 0s 1ms/step - loss: 0.3900 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.3634 - val_mae: 0.0419 - val_mse: 0.0025 - lr: 0.0099
Epoch 11/30
 1/70 [..............................] - ETA: 0s - loss: 0.3633 - mae: 0.0412 - mse: 0.0024
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.004927715752273798.
70/70 [==============================] - 0s 1ms/step - loss: 0.3402 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.3171 - val_mae: 0.0419 - val_mse: 0.0025 - lr: 0.0099
Epoch 12/30
70/70 [==============================] - 0s 1ms/step - loss: 0.3057 - mae: 0.0414 - mse: 0.0025 - val_loss: 0.2952 - val_mae: 0.0418 - val_mse: 0.0025 - lr: 0.0049
Epoch 13/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2855 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.2758 - val_mae: 0.0419 - val_mse: 0.0025 - lr: 0.0049
Epoch 14/30
 1/70 [..............................] - ETA: 0s - loss: 0.2751 - mae: 0.0327 - mse: 0.0018
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.002463857876136899.
70/70 [==============================] - 0s 1ms/step - loss: 0.2668 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.2578 - val_mae: 0.0419 - val_mse: 0.0025 - lr: 0.0049
Epoch 15/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2530 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.2487 - val_mae: 0.0419 - val_mse: 0.0025 - lr: 0.0025
Epoch 16/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2446 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.2405 - val_mae: 0.0419 - val_mse: 0.0025 - lr: 0.0025
Epoch 17/30
 1/70 [..............................] - ETA: 0s - loss: 0.2403 - mae: 0.0410 - mse: 0.0024
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0012319289380684495.
70/70 [==============================] - 0s 1ms/step - loss: 0.2365 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.2325 - val_mae: 0.0419 - val_mse: 0.0025 - lr: 0.0025
Epoch 18/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2303 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.2284 - val_mae: 0.0418 - val_mse: 0.0025 - lr: 0.0012
Epoch 19/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2265 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.2246 - val_mae: 0.0418 - val_mse: 0.0025 - lr: 0.0012
Epoch 20/30
 1/70 [..............................] - ETA: 0s - loss: 0.2245 - mae: 0.0411 - mse: 0.0025
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0006159644690342247.
70/70 [==============================] - 0s 1ms/step - loss: 0.2227 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.2208 - val_mae: 0.0418 - val_mse: 0.0025 - lr: 0.0012
Epoch 21/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2198 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.2189 - val_mae: 0.0418 - val_mse: 0.0025 - lr: 6.1596e-04
Epoch 22/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2179 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.2170 - val_mae: 0.0419 - val_mse: 0.0025 - lr: 6.1596e-04
Epoch 23/30
 1/70 [..............................] - ETA: 0s - loss: 0.2165 - mae: 0.0375 - mse: 0.0020
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0003079822345171124.
70/70 [==============================] - 0s 1ms/step - loss: 0.2161 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.2152 - val_mae: 0.0419 - val_mse: 0.0025 - lr: 6.1596e-04
Epoch 24/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2147 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.2143 - val_mae: 0.0419 - val_mse: 0.0025 - lr: 3.0798e-04
Epoch 25/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2138 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.2134 - val_mae: 0.0419 - val_mse: 0.0025 - lr: 3.0798e-04
Epoch 26/30
 1/70 [..............................] - ETA: 0s - loss: 0.2135 - mae: 0.0442 - mse: 0.0027
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001539911172585562.
70/70 [==============================] - 0s 1ms/step - loss: 0.2129 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.2125 - val_mae: 0.0418 - val_mse: 0.0025 - lr: 3.0798e-04
Epoch 27/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2122 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.2120 - val_mae: 0.0418 - val_mse: 0.0025 - lr: 1.5399e-04
Epoch 28/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2117 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.2116 - val_mae: 0.0418 - val_mse: 0.0025 - lr: 1.5399e-04
Epoch 29/30
 1/70 [..............................] - ETA: 0s - loss: 0.2119 - mae: 0.0446 - mse: 0.0029
Epoch 29: ReduceLROnPlateau reducing learning rate to 7.69955586292781e-05.
70/70 [==============================] - 0s 1ms/step - loss: 0.2113 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.2111 - val_mae: 0.0418 - val_mse: 0.0025 - lr: 1.5399e-04
Epoch 30/30
70/70 [==============================] - 0s 1ms/step - loss: 0.2109 - mae: 0.0415 - mse: 0.0025 - val_loss: 0.2109 - val_mae: 0.0418 - val_mse: 0.0025 - lr: 7.6996e-05
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_sgd_0.009855431697256887_70_56_30epochs/model_9.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0018s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0021s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0016s). Check your callbacks.