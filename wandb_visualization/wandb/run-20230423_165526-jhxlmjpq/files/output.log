Epoch 1/20
235/243 [============================>.] - ETA: 0s - loss: 0.8577 - mae: 0.9251 - mse: 0.8577
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0012s vs `on_train_batch_end` time: 0.0013s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0012s vs `on_train_batch_end` time: 0.0013s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.0203e-04
Epoch 2/20
237/243 [============================>.] - ETA: 0s - loss: 0.8580 - mae: 0.9252 - mse: 0.8580
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0003010169311892241.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.0203e-04
Epoch 3/20
196/243 [=======================>......] - ETA: 0s - loss: 0.8581 - mae: 0.9253 - mse: 0.8581
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.00015050846559461206.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 3.0102e-04
Epoch 4/20
209/243 [========================>.....] - ETA: 0s - loss: 0.8571 - mae: 0.9248 - mse: 0.8571
Epoch 4: ReduceLROnPlateau reducing learning rate to 7.525423279730603e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.5051e-04
Epoch 5/20
193/243 [======================>.......] - ETA: 0s - loss: 0.8568 - mae: 0.9246 - mse: 0.8568
Epoch 5: ReduceLROnPlateau reducing learning rate to 3.7627116398653015e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 7.5254e-05
Epoch 6/20
197/243 [=======================>......] - ETA: 0s - loss: 0.8578 - mae: 0.9251 - mse: 0.8578
Epoch 6: ReduceLROnPlateau reducing learning rate to 1.8813558199326508e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 3.7627e-05
Epoch 7/20
230/243 [===========================>..] - ETA: 0s - loss: 0.8577 - mae: 0.9251 - mse: 0.8577
Epoch 7: ReduceLROnPlateau reducing learning rate to 1e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.8814e-05
Epoch 8/20
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 9/20
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 10/20
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 11/20
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 12/20
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 13/20
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 14/20
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 15/20
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 16/20
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 17/20
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 18/20
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 19/20
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 20/20
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.0006020338622474198LR_[28]CHN_64CNNI_16BS_1P_val_mseM_20epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0012s vs `on_train_batch_end` time: 0.0016s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0012s vs `on_train_batch_end` time: 0.0016s). Check your callbacks.
309/323 [===========================>..] - ETA: 0s - loss: 0.6428 - mae: 0.7996 - mse: 0.6428
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
323/323 [==============================] - 2s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 6.0203e-04
Epoch 2/20
319/323 [============================>.] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0003010169311892241.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 6.0203e-04
Epoch 3/20
264/323 [=======================>......] - ETA: 0s - loss: 0.6434 - mae: 0.8000 - mse: 0.6434
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.00015050846559461206.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 3.0102e-04
Epoch 4/20
287/323 [=========================>....] - ETA: 0s - loss: 0.6428 - mae: 0.7996 - mse: 0.6428
Epoch 4: ReduceLROnPlateau reducing learning rate to 7.525423279730603e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.5051e-04
Epoch 5/20
262/323 [=======================>......] - ETA: 0s - loss: 0.6425 - mae: 0.7994 - mse: 0.6425
Epoch 5: ReduceLROnPlateau reducing learning rate to 3.7627116398653015e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 7.5254e-05
Epoch 6/20
260/323 [=======================>......] - ETA: 0s - loss: 0.6424 - mae: 0.7994 - mse: 0.6424
Epoch 6: ReduceLROnPlateau reducing learning rate to 1.8813558199326508e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 3.7627e-05
Epoch 7/20
267/323 [=======================>......] - ETA: 0s - loss: 0.6427 - mae: 0.7995 - mse: 0.6427
Epoch 7: ReduceLROnPlateau reducing learning rate to 1e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.8814e-05
Epoch 8/20
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 9/20
323/323 [==============================] - 1s 2ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 10/20
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 11/20
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 12/20
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 13/20
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 14/20
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 15/20
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 16/20
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 17/20
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 18/20
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 19/20
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 20/20
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.0006020338622474198LR_[28]CHN_64CNNI_16BS_1P_val_mseM_20epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 1/20
235/243 [============================>.] - ETA: 0s - loss: 0.4577 - mae: 0.6752 - mse: 0.4577
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0023s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0023s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
187/243 [======================>.......] - ETA: 0s - loss: 0.4570 - mae: 0.6746 - mse: 0.45704578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 6.0203e-04
Epoch 2/20
222/243 [==========================>...] - ETA: 0s - loss: 0.4576 - mae: 0.6750 - mse: 0.4576
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0003010169311892241.
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 6.0203e-04
Epoch 3/20
187/243 [======================>.......] - ETA: 0s - loss: 0.4570 - mae: 0.6746 - mse: 0.45704578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 6.0203e-04
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.00015050846559461206.
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 3.0102e-04
Epoch 4/20
196/243 [=======================>......] - ETA: 0s - loss: 0.4581 - mae: 0.6754 - mse: 0.4581
Epoch 4: ReduceLROnPlateau reducing learning rate to 7.525423279730603e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.5051e-04
Epoch 5/20
225/243 [==========================>...] - ETA: 0s - loss: 0.4580 - mae: 0.6754 - mse: 0.4580
Epoch 5: ReduceLROnPlateau reducing learning rate to 3.7627116398653015e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 7.5254e-05
Epoch 6/20
197/243 [=======================>......] - ETA: 0s - loss: 0.4572 - mae: 0.6747 - mse: 0.4572
Epoch 6: ReduceLROnPlateau reducing learning rate to 1.8813558199326508e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 3.7627e-05
Epoch 7/20
195/243 [=======================>......] - ETA: 0s - loss: 0.4568 - mae: 0.6744 - mse: 0.4568
Epoch 7: ReduceLROnPlateau reducing learning rate to 1e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.8814e-05
Epoch 8/20
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 9/20
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 10/20
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 11/20
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 12/20
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 13/20
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 14/20
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 15/20
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 16/20
243/243 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 17/20
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 18/20
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 19/20
243/243 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 20/20
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_adam_0.0006020338622474198LR_[28]CHN_64CNNI_16BS_1P_val_mseM_20epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0015s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0015s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 6: ReduceLROnPlateau reducing learning rate to 1.8813558199326508e-05. 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 6: ReduceLROnPlateau reducing learning rate to 1.8813558199326508e-05. 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 6: ReduceLROnPlateau reducing learning rate to 1.8813558199326508e-05. 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 6: ReduceLROnPlateau reducing learning rate to 1.8813558199326508e-05. 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0025s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0025s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230423_165526-jhxlmjpq\files\model-best)... Done. 0.0s
Epoch 6: ReduceLROnPlateau reducing learning rate to 1.8813558199326508e-05. 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 6: ReduceLROnPlateau reducing learning rate to 1.8813558199326508e-05. 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 6: ReduceLROnPlateau reducing learning rate to 1.8813558199326508e-05. 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.
Epoch 6: ReduceLROnPlateau reducing learning rate to 1.8813558199326508e-05. 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230423_165526-jhxlmjpq\files\model-best)... Done. 0.0s
Epoch 6: ReduceLROnPlateau reducing learning rate to 1.8813558199326508e-05. 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 6: ReduceLROnPlateau reducing learning rate to 1.8813558199326508e-05. 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 6: ReduceLROnPlateau reducing learning rate to 1.8813558199326508e-05. 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230423_165526-jhxlmjpq\files\model-best)... Done. 0.0s
Epoch 6: ReduceLROnPlateau reducing learning rate to 1.8813558199326508e-05. 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 6: ReduceLROnPlateau reducing learning rate to 1.8813558199326508e-05. 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 6: ReduceLROnPlateau reducing learning rate to 1.8813558199326508e-05. 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_train_batch_end` time: 0.0021s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_train_batch_end` time: 0.0021s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230423_165526-jhxlmjpq\files\model-best)... Done. 0.0s
Epoch 6: ReduceLROnPlateau reducing learning rate to 1.8813558199326508e-05. 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 6: ReduceLROnPlateau reducing learning rate to 1.8813558199326508e-05. 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 6: ReduceLROnPlateau reducing learning rate to 1.8813558199326508e-05. 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05