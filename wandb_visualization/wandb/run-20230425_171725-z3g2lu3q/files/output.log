(3883, 8)
(1665, 8)
Epoch 1/20

156/162 [===========================>..] - ETA: 0s - loss: 0.1174 - mae: 0.1847 - mse: 0.1174 - root_mean_squared_error: 0.3426 - R2: -68.6380
162/162 [==============================] - 4s 18ms/step - loss: 0.1133 - mae: 0.1799 - mse: 0.1133 - root_mean_squared_error: 0.3367 - R2: -66.1302 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0445 - val_R2: -0.0675 - lr: 0.0438
Epoch 2/20
162/162 [==============================] - 1s 5ms/step - loss: 0.0032 - mae: 0.0458 - mse: 0.0032 - root_mean_squared_error: 0.0561 - R2: -0.7199 - val_loss: 0.0022 - val_mae: 0.0397 - val_mse: 0.0022 - val_root_mean_squared_error: 0.0468 - val_R2: -0.1804 - lr: 0.0438
Epoch 3/20
162/162 [==============================] - 1s 5ms/step - loss: 0.0048 - mae: 0.0557 - mse: 0.0048 - root_mean_squared_error: 0.0691 - R2: -1.6468 - val_loss: 0.0102 - val_mae: 0.0909 - val_mse: 0.0102 - val_root_mean_squared_error: 0.1011 - val_R2: -4.6204 - lr: 0.0438
Epoch 4/20
151/162 [==========================>...] - ETA: 0s - loss: 0.0067 - mae: 0.0659 - mse: 0.0067 - root_mean_squared_error: 0.0821 - R2: -2.7667
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.02187584899365902.
162/162 [==============================] - 1s 5ms/step - loss: 0.0066 - mae: 0.0654 - mse: 0.0066 - root_mean_squared_error: 0.0814 - R2: -2.7037 - val_loss: 0.0021 - val_mae: 0.0396 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0464 - val_R2: -0.1754 - lr: 0.0438
Epoch 5/20
162/162 [==============================] - 1s 5ms/step - loss: 0.0031 - mae: 0.0455 - mse: 0.0031 - root_mean_squared_error: 0.0554 - R2: -0.7267 - val_loss: 0.0020 - val_mae: 0.0388 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0452 - val_R2: -0.1007 - lr: 0.0219
Epoch 6/20
162/162 [==============================] - 1s 6ms/step - loss: 0.0026 - mae: 0.0425 - mse: 0.0026 - root_mean_squared_error: 0.0513 - R2: -0.4186 - val_loss: 0.0076 - val_mae: 0.0752 - val_mse: 0.0076 - val_root_mean_squared_error: 0.0872 - val_R2: -3.2651 - lr: 0.0219
Epoch 7/20
155/162 [===========================>..] - ETA: 0s - loss: 0.0037 - mae: 0.0498 - mse: 0.0037 - root_mean_squared_error: 0.0609 - R2: -1.0628
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.01093792449682951.
162/162 [==============================] - 1s 5ms/step - loss: 0.0036 - mae: 0.0492 - mse: 0.0036 - root_mean_squared_error: 0.0603 - R2: -1.0197 - val_loss: 0.0028 - val_mae: 0.0440 - val_mse: 0.0028 - val_root_mean_squared_error: 0.0532 - val_R2: -0.5270 - lr: 0.0219
Epoch 8/20
162/162 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0397 - mse: 0.0022 - root_mean_squared_error: 0.0469 - R2: -0.2009 - val_loss: 0.0026 - val_mae: 0.0424 - val_mse: 0.0026 - val_root_mean_squared_error: 0.0510 - val_R2: -0.4015 - lr: 0.0109
Epoch 9/20
162/162 [==============================] - 1s 5ms/step - loss: 0.0025 - mae: 0.0420 - mse: 0.0025 - root_mean_squared_error: 0.0502 - R2: -0.3993 - val_loss: 0.0047 - val_mae: 0.0563 - val_mse: 0.0047 - val_root_mean_squared_error: 0.0686 - val_R2: -1.5581 - lr: 0.0109
Epoch 10/20
160/162 [============================>.] - ETA: 0s - loss: 0.0025 - mae: 0.0416 - mse: 0.0025 - root_mean_squared_error: 0.0500 - R2: -0.3619
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.005468962248414755.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230425_171725-z3g2lu3q\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230425_171725-z3g2lu3q\files\model-best)... Done. 0.0s
162/162 [==============================] - 4s 24ms/step - loss: 0.0025 - mae: 0.0416 - mse: 0.0025 - root_mean_squared_error: 0.0500 - R2: -0.3588 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -0.0562 - lr: 0.0109
Epoch 11/20
162/162 [==============================] - 3s 20ms/step - loss: 0.0020 - mae: 0.0386 - mse: 0.0020 - root_mean_squared_error: 0.0450 - R2: -0.1116 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -0.0551 - lr: 0.0055
Epoch 12/20
162/162 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0389 - mse: 0.0021 - root_mean_squared_error: 0.0456 - R2: -0.1437 - val_loss: 0.0024 - val_mae: 0.0411 - val_mse: 0.0024 - val_root_mean_squared_error: 0.0487 - val_R2: -0.3024 - lr: 0.0055
Epoch 13/20
157/162 [============================>.] - ETA: 0s - loss: 0.0021 - mae: 0.0391 - mse: 0.0021 - root_mean_squared_error: 0.0458 - R2: -0.1498
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0027344811242073774.
162/162 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0391 - mse: 0.0021 - root_mean_squared_error: 0.0458 - R2: -0.1464 - val_loss: 0.0021 - val_mae: 0.0396 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0462 - val_R2: -0.1694 - lr: 0.0055
Epoch 14/20
162/162 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0387 - mse: 0.0020 - root_mean_squared_error: 0.0450 - R2: -0.1020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0443 - val_R2: -0.0597 - lr: 0.0027
Epoch 15/20
162/162 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0388 - mse: 0.0020 - root_mean_squared_error: 0.0450 - R2: -0.1056 - val_loss: 0.0021 - val_mae: 0.0390 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0456 - val_R2: -0.1181 - lr: 0.0027
Epoch 16/20
151/162 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0388 - mse: 0.0020 - root_mean_squared_error: 0.0452 - R2: -0.1320
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0013672405621036887.
162/162 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0389 - mse: 0.0021 - root_mean_squared_error: 0.0453 - R2: -0.1287 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0442 - val_R2: -0.0605 - lr: 0.0027
Epoch 17/20
162/162 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0385 - mse: 0.0020 - root_mean_squared_error: 0.0451 - R2: -0.1127 - val_loss: 0.0020 - val_mae: 0.0388 - val_mse: 0.0020 - val_root_mean_squared_error: 0.0451 - val_R2: -0.0975 - lr: 0.0014
Epoch 18/20
162/162 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0388 - mse: 0.0020 - root_mean_squared_error: 0.0452 - R2: -0.1321 - val_loss: 0.0021 - val_mae: 0.0392 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0459 - val_R2: -0.1321 - lr: 0.0014
Epoch 19/20
147/162 [==========================>...] - ETA: 0s - loss: 0.0021 - mae: 0.0389 - mse: 0.0021 - root_mean_squared_error: 0.0454 - R2: -0.1279
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006836202810518444.
162/162 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0388 - mse: 0.0021 - root_mean_squared_error: 0.0453 - R2: -0.1265 - val_loss: 0.0021 - val_mae: 0.0391 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0458 - val_R2: -0.1274 - lr: 0.0014
Epoch 20/20

162/162 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - root_mean_squared_error: 0.0444 - R2: -0.0700 - val_loss: 0.0021 - val_mae: 0.0392 - val_mse: 0.0021 - val_root_mean_squared_error: 0.0456 - val_R2: -0.1336 - lr: 6.8362e-04