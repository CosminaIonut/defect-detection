wandb_version: 1

activation:
  value:
  - tanh
  - sigmoid
  - softmax
batch_size:
  value: 8
dense_units:
  value: 5
epochs:
  value: 50
hidden_layer_size:
  value:
  - 10
learning_rate:
  value: 0.07732129142030657
monitor:
  value: val_loss
optimizer:
  value: adam
patience:
  value: 20
