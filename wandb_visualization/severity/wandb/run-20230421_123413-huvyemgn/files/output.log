Epoch 1/20
 1/22 [>.............................] - ETA: 15s - loss: 0.9364 - mae: 0.4504 - mse: 0.2049
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0025s). Check your callbacks.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\severity\wandb\run-20230421_123413-huvyemgn\files\model-best)... Done. 0.0s
22/22 [==============================] - 2s 51ms/step - loss: 0.0745 - mae: 0.0692 - mse: 0.0139 - val_loss: 0.0128 - val_mae: 0.0381 - val_mse: 0.0028 - lr: 0.0977
Epoch 2/20
22/22 [==============================] - 1s 51ms/step - loss: 0.0134 - mae: 0.0470 - mse: 0.0039 - val_loss: 0.0082 - val_mae: 0.0401 - val_mse: 0.0021 - lr: 0.0977
Epoch 3/20
22/22 [==============================] - 0s 3ms/step - loss: 0.0146 - mae: 0.0466 - mse: 0.0038 - val_loss: 0.0109 - val_mae: 0.0364 - val_mse: 0.0023 - lr: 0.0977
Epoch 4/20
22/22 [==============================] - 0s 3ms/step - loss: 0.0165 - mae: 0.0485 - mse: 0.0042 - val_loss: 0.0127 - val_mae: 0.0439 - val_mse: 0.0038 - lr: 0.0977
Epoch 5/20
22/22 [==============================] - 0s 5ms/step - loss: 0.0138 - mae: 0.0448 - mse: 0.0035 - val_loss: 0.0088 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0977
Epoch 6/20
22/22 [==============================] - 0s 5ms/step - loss: 0.0106 - mae: 0.0403 - mse: 0.0026 - val_loss: 0.0095 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0977
Epoch 7/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0380 - mse: 0.0020 - val_loss: 0.0108 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0977
Epoch 8/20
22/22 [==============================] - 0s 5ms/step - loss: 0.0101 - mae: 0.0371 - mse: 0.0020 - val_loss: 0.0102 - val_mae: 0.0359 - val_mse: 0.0022 - lr: 0.0977
Epoch 9/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0370 - mse: 0.0020 - val_loss: 0.0098 - val_mae: 0.0376 - val_mse: 0.0020 - lr: 0.0977
Epoch 10/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0369 - mse: 0.0019 - val_loss: 0.0106 - val_mae: 0.0360 - val_mse: 0.0021 - lr: 0.0977
Epoch 11/20
22/22 [==============================] - 0s 3ms/step - loss: 0.0101 - mae: 0.0368 - mse: 0.0019 - val_loss: 0.0105 - val_mae: 0.0407 - val_mse: 0.0021 - lr: 0.0977
Epoch 12/20
22/22 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0372 - mse: 0.0020 - val_loss: 0.0100 - val_mae: 0.0373 - val_mse: 0.0020 - lr: 0.0977
Epoch 13/20
22/22 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0368 - mse: 0.0019 - val_loss: 0.0103 - val_mae: 0.0366 - val_mse: 0.0020 - lr: 0.0977
Epoch 14/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0102 - mae: 0.0369 - mse: 0.0019 - val_loss: 0.0100 - val_mae: 0.0362 - val_mse: 0.0020 - lr: 0.0977
Epoch 15/20
 1/22 [>.............................] - ETA: 0s - loss: 0.0100 - mae: 0.0368 - mse: 0.0021
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.04885760694742203.
22/22 [==============================] - 0s 5ms/step - loss: 0.0101 - mae: 0.0369 - mse: 0.0019 - val_loss: 0.0103 - val_mae: 0.0367 - val_mse: 0.0020 - lr: 0.0977
Epoch 16/20
 1/22 [>.............................] - ETA: 0s - loss: 0.0103 - mae: 0.0356 - mse: 0.0019
22/22 [==============================] - 1s 44ms/step - loss: 0.0023 - mae: 0.0369 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0390 - val_mse: 0.0020 - lr: 0.0489
Epoch 17/20
22/22 [==============================] - 0s 3ms/step - loss: 0.0037 - mae: 0.0369 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0369 - val_mse: 0.0020 - lr: 0.0489
Epoch 18/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0368 - mse: 0.0019 - val_loss: 0.0026 - val_mae: 0.0362 - val_mse: 0.0020 - lr: 0.0489
Epoch 19/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0368 - mse: 0.0019 - val_loss: 0.0044 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0489
Epoch 20/20
22/22 [==============================] - 0s 5ms/step - loss: 0.0037 - mae: 0.0369 - mse: 0.0019 - val_loss: 0.0035 - val_mae: 0.0374 - val_mse: 0.0020 - lr: 0.0489
>Saved ../trained_models/severity/models__rmsprop_0.09771521328568716LR_[38]HN_184BS_10P_val_mseM_20epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
29/29 [==============================] - 1s 9ms/step - loss: 0.0716 - mae: 0.1128 - mse: 0.0209 - val_loss: 0.0151 - val_mae: 0.0969 - val_mse: 0.0117 - lr: 0.0977
Epoch 2/20
29/29 [==============================] - 0s 4ms/step - loss: 0.0188 - mae: 0.0941 - mse: 0.0121 - val_loss: 0.0169 - val_mae: 0.0902 - val_mse: 0.0102 - lr: 0.0977
Epoch 3/20
29/29 [==============================] - 0s 4ms/step - loss: 0.0189 - mae: 0.0920 - mse: 0.0108 - val_loss: 0.0180 - val_mae: 0.0902 - val_mse: 0.0103 - lr: 0.0977
Epoch 4/20
29/29 [==============================] - 0s 3ms/step - loss: 0.0184 - mae: 0.0906 - mse: 0.0101 - val_loss: 0.0236 - val_mae: 0.0918 - val_mse: 0.0140 - lr: 0.0977
Epoch 5/20
29/29 [==============================] - 0s 3ms/step - loss: 0.0183 - mae: 0.0908 - mse: 0.0103 - val_loss: 0.0187 - val_mae: 0.0902 - val_mse: 0.0104 - lr: 0.0977
Epoch 6/20
29/29 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.0908 - mse: 0.0102 - val_loss: 0.0180 - val_mae: 0.0905 - val_mse: 0.0100 - lr: 0.0977
Epoch 7/20
29/29 [==============================] - 0s 3ms/step - loss: 0.0182 - mae: 0.0908 - mse: 0.0101 - val_loss: 0.0180 - val_mae: 0.0904 - val_mse: 0.0100 - lr: 0.0977
Epoch 8/20
29/29 [==============================] - 0s 3ms/step - loss: 0.0185 - mae: 0.0908 - mse: 0.0102 - val_loss: 0.0177 - val_mae: 0.0910 - val_mse: 0.0101 - lr: 0.0977
Epoch 9/20
29/29 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 0.0908 - mse: 0.0102 - val_loss: 0.0185 - val_mae: 0.0926 - val_mse: 0.0104 - lr: 0.0977
Epoch 10/20
29/29 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.0908 - mse: 0.0101 - val_loss: 0.0182 - val_mae: 0.0902 - val_mse: 0.0103 - lr: 0.0977
Epoch 11/20
29/29 [==============================] - 0s 3ms/step - loss: 0.0182 - mae: 0.0907 - mse: 0.0101 - val_loss: 0.0178 - val_mae: 0.0902 - val_mse: 0.0102 - lr: 0.0977
Epoch 12/20
29/29 [==============================] - 0s 3ms/step - loss: 0.0185 - mae: 0.0908 - mse: 0.0102 - val_loss: 0.0174 - val_mae: 0.0905 - val_mse: 0.0100 - lr: 0.0977
Epoch 13/20
29/29 [==============================] - 0s 4ms/step - loss: 0.0187 - mae: 0.0910 - mse: 0.0103 - val_loss: 0.0179 - val_mae: 0.0905 - val_mse: 0.0100 - lr: 0.0977
Epoch 14/20
29/29 [==============================] - 0s 3ms/step - loss: 0.0179 - mae: 0.0906 - mse: 0.0101 - val_loss: 0.0183 - val_mae: 0.0903 - val_mse: 0.0100 - lr: 0.0977
Epoch 15/20
29/29 [==============================] - 0s 4ms/step - loss: 0.0185 - mae: 0.0908 - mse: 0.0102 - val_loss: 0.0175 - val_mae: 0.0902 - val_mse: 0.0101 - lr: 0.0977
Epoch 16/20
26/29 [=========================>....] - ETA: 0s - loss: 0.0182 - mae: 0.0905 - mse: 0.0101
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.04885760694742203.
29/29 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.0907 - mse: 0.0101 - val_loss: 0.0179 - val_mae: 0.0905 - val_mse: 0.0100 - lr: 0.0977
Epoch 17/20
29/29 [==============================] - 0s 3ms/step - loss: 0.0104 - mae: 0.0906 - mse: 0.0100 - val_loss: 0.0103 - val_mae: 0.0902 - val_mse: 0.0102 - lr: 0.0489
Epoch 18/20
29/29 [==============================] - 0s 3ms/step - loss: 0.0115 - mae: 0.0906 - mse: 0.0101 - val_loss: 0.0131 - val_mae: 0.0902 - val_mse: 0.0101 - lr: 0.0489
Epoch 19/20
29/29 [==============================] - 0s 3ms/step - loss: 0.0120 - mae: 0.0906 - mse: 0.0101 - val_loss: 0.0126 - val_mae: 0.0902 - val_mse: 0.0103 - lr: 0.0489
Epoch 20/20
29/29 [==============================] - 0s 3ms/step - loss: 0.0118 - mae: 0.0905 - mse: 0.0101 - val_loss: 0.0120 - val_mae: 0.0907 - val_mse: 0.0100 - lr: 0.0489
>Saved ../trained_models/severity/models__rmsprop_0.09771521328568716LR_[38]HN_184BS_10P_val_mseM_20epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_train_batch_end` time: 0.0029s). Check your callbacks.
Epoch 1/20
22/22 [==============================] - 1s 11ms/step - loss: 0.0987 - mae: 0.1616 - mse: 0.0355 - val_loss: 0.0311 - val_mae: 0.1532 - val_mse: 0.0260 - lr: 0.0977
Epoch 2/20
22/22 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1525 - mse: 0.0256 - val_loss: 0.0325 - val_mae: 0.1532 - val_mse: 0.0264 - lr: 0.0977
Epoch 3/20
22/22 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1525 - mse: 0.0249 - val_loss: 0.0344 - val_mae: 0.1532 - val_mse: 0.0250 - lr: 0.0977
Epoch 4/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0328 - mae: 0.1525 - mse: 0.0246 - val_loss: 0.0331 - val_mae: 0.1532 - val_mse: 0.0246 - lr: 0.0977
Epoch 5/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0360 - mae: 0.1532 - mse: 0.0265 - val_loss: 0.0317 - val_mae: 0.1532 - val_mse: 0.0246 - lr: 0.0977
Epoch 6/20
22/22 [==============================] - 0s 3ms/step - loss: 0.0320 - mae: 0.1525 - mse: 0.0245 - val_loss: 0.0350 - val_mae: 0.1532 - val_mse: 0.0254 - lr: 0.0977
Epoch 7/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0325 - mae: 0.1525 - mse: 0.0245 - val_loss: 0.0332 - val_mae: 0.1532 - val_mse: 0.0246 - lr: 0.0977
Epoch 8/20
22/22 [==============================] - 0s 3ms/step - loss: 0.0333 - mae: 0.1525 - mse: 0.0248 - val_loss: 0.0323 - val_mae: 0.1532 - val_mse: 0.0247 - lr: 0.0977
Epoch 9/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0329 - mae: 0.1525 - mse: 0.0246 - val_loss: 0.0322 - val_mae: 0.1532 - val_mse: 0.0247 - lr: 0.0977
Epoch 10/20
22/22 [==============================] - 0s 5ms/step - loss: 0.0360 - mae: 0.1549 - mse: 0.0267 - val_loss: 0.0357 - val_mae: 0.1532 - val_mse: 0.0263 - lr: 0.0977
Epoch 11/20
22/22 [==============================] - 0s 5ms/step - loss: 0.0323 - mae: 0.1525 - mse: 0.0246 - val_loss: 0.0322 - val_mae: 0.1532 - val_mse: 0.0247 - lr: 0.0977
Epoch 12/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0331 - mae: 0.1525 - mse: 0.0249 - val_loss: 0.0322 - val_mae: 0.1532 - val_mse: 0.0247 - lr: 0.0977
Epoch 13/20
 1/22 [>.............................] - ETA: 0s - loss: 0.0327 - mae: 0.1548 - mse: 0.0252
22/22 [==============================] - 0s 4ms/step - loss: 0.0264 - mae: 0.1525 - mse: 0.0245 - val_loss: 0.0266 - val_mae: 0.1532 - val_mse: 0.0248 - lr: 0.0489
Epoch 14/20
 1/22 [>.............................] - ETA: 0s - loss: 0.0324 - mae: 0.1522 - mse: 0.0244
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.04885760694742203.
22/22 [==============================] - 0s 5ms/step - loss: 0.0330 - mae: 0.1525 - mse: 0.0246 - val_loss: 0.0321 - val_mae: 0.1532 - val_mse: 0.0247 - lr: 0.0977
Epoch 15/20
22/22 [==============================] - 0s 5ms/step - loss: 0.0248 - mae: 0.1525 - mse: 0.0244 - val_loss: 0.0247 - val_mae: 0.1532 - val_mse: 0.0246 - lr: 0.0489
Epoch 16/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0263 - mae: 0.1525 - mse: 0.0244 - val_loss: 0.0253 - val_mae: 0.1532 - val_mse: 0.0247 - lr: 0.0489
Epoch 17/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0260 - mae: 0.1525 - mse: 0.0245 - val_loss: 0.0250 - val_mae: 0.1532 - val_mse: 0.0246 - lr: 0.0489
Epoch 18/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0262 - mae: 0.1525 - mse: 0.0245 - val_loss: 0.0271 - val_mae: 0.1532 - val_mse: 0.0246 - lr: 0.0489
Epoch 19/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0264 - mae: 0.1525 - mse: 0.0245 - val_loss: 0.0266 - val_mae: 0.1532 - val_mse: 0.0248 - lr: 0.0489
Epoch 20/20
22/22 [==============================] - 0s 3ms/step - loss: 0.0263 - mae: 0.1525 - mse: 0.0244 - val_loss: 0.0264 - val_mae: 0.1532 - val_mse: 0.0247 - lr: 0.0489
>Saved ../trained_models/severity/models__rmsprop_0.09771521328568716LR_[38]HN_184BS_10P_val_mseM_20epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
 1/22 [>.............................] - ETA: 12s - loss: 0.8717 - mae: 0.2801 - mse: 0.1200
22/22 [==============================] - 0s 4ms/step - loss: 0.0497 - mae: 0.2025 - mse: 0.0422 - val_loss: 0.0499 - val_mae: 0.2032 - val_mse: 0.0425 - lr: 0.09777
Epoch 2/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0481 - mae: 0.2025 - mse: 0.0437 - val_loss: 0.0466 - val_mae: 0.2032 - val_mse: 0.0429 - lr: 0.0977
Epoch 3/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0491 - mae: 0.2025 - mse: 0.0423 - val_loss: 0.0528 - val_mae: 0.2032 - val_mse: 0.0426 - lr: 0.0977
Epoch 4/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0533 - mae: 0.2025 - mse: 0.0441 - val_loss: 0.0511 - val_mae: 0.2032 - val_mse: 0.0425 - lr: 0.0977
Epoch 5/20
22/22 [==============================] - 0s 3ms/step - loss: 0.0509 - mae: 0.2025 - mse: 0.0426 - val_loss: 0.0495 - val_mae: 0.2032 - val_mse: 0.0425 - lr: 0.0977
Epoch 6/20
22/22 [==============================] - 0s 5ms/step - loss: 0.0501 - mae: 0.2025 - mse: 0.0423 - val_loss: 0.0560 - val_mae: 0.2032 - val_mse: 0.0452 - lr: 0.0977
Epoch 7/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0503 - mae: 0.2025 - mse: 0.0424 - val_loss: 0.0509 - val_mae: 0.2032 - val_mse: 0.0425 - lr: 0.0977
Epoch 8/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0509 - mae: 0.2025 - mse: 0.0425 - val_loss: 0.0504 - val_mae: 0.2032 - val_mse: 0.0425 - lr: 0.0977
Epoch 9/20
22/22 [==============================] - 0s 3ms/step - loss: 0.0506 - mae: 0.2025 - mse: 0.0424 - val_loss: 0.0499 - val_mae: 0.2032 - val_mse: 0.0425 - lr: 0.0977
Epoch 10/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0564 - mae: 0.2040 - mse: 0.0467 - val_loss: 0.0498 - val_mae: 0.2032 - val_mse: 0.0425 - lr: 0.0977
Epoch 11/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0497 - mae: 0.2025 - mse: 0.0422 - val_loss: 0.0499 - val_mae: 0.2032 - val_mse: 0.0425 - lr: 0.09777
Epoch 12/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0508 - mae: 0.2025 - mse: 0.0425 - val_loss: 0.0499 - val_mae: 0.2032 - val_mse: 0.0426 - lr: 0.0977
Epoch 13/20
22/22 [==============================] - 0s 5ms/step - loss: 0.0522 - mae: 0.2025 - mse: 0.0435 - val_loss: 0.0556 - val_mae: 0.2032 - val_mse: 0.0454 - lr: 0.0977
Epoch 14/20
 1/22 [>.............................] - ETA: 0s - loss: 0.0554 - mae: 0.2026 - mse: 0.0451
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.04885760694742203.
22/22 [==============================] - 0s 5ms/step - loss: 0.0500 - mae: 0.2025 - mse: 0.0423 - val_loss: 0.0501 - val_mae: 0.2032 - val_mse: 0.0425 - lr: 0.0977
Epoch 15/20
22/22 [==============================] - 0s 5ms/step - loss: 0.0426 - mae: 0.2025 - mse: 0.0422 - val_loss: 0.0427 - val_mae: 0.2032 - val_mse: 0.0425 - lr: 0.0489
Epoch 16/20
22/22 [==============================] - 0s 5ms/step - loss: 0.0440 - mae: 0.2025 - mse: 0.0422 - val_loss: 0.0435 - val_mae: 0.2032 - val_mse: 0.0426 - lr: 0.0489
Epoch 17/20
22/22 [==============================] - 0s 5ms/step - loss: 0.0436 - mae: 0.2025 - mse: 0.0422 - val_loss: 0.0431 - val_mae: 0.2032 - val_mse: 0.0425 - lr: 0.0489
Epoch 18/20
22/22 [==============================] - 0s 5ms/step - loss: 0.0440 - mae: 0.2025 - mse: 0.0422 - val_loss: 0.0453 - val_mae: 0.2032 - val_mse: 0.0426 - lr: 0.0489
Epoch 19/20
22/22 [==============================] - 0s 5ms/step - loss: 0.0440 - mae: 0.2025 - mse: 0.0422 - val_loss: 0.0445 - val_mae: 0.2032 - val_mse: 0.0427 - lr: 0.0489
Epoch 20/20
22/22 [==============================] - 0s 6ms/step - loss: 0.0441 - mae: 0.2025 - mse: 0.0422 - val_loss: 0.0450 - val_mae: 0.2032 - val_mse: 0.0426 - lr: 0.0489
>Saved ../trained_models/severity/models__rmsprop_0.09771521328568716LR_[38]HN_184BS_10P_val_mseM_20epochs/model_4.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
22/22 [==============================] - 1s 12ms/step - loss: 0.1296 - mae: 0.2530 - mse: 0.0736 - val_loss: 0.0690 - val_mae: 0.2532 - val_mse: 0.0662 - lr: 0.0977
Epoch 2/20
22/22 [==============================] - 0s 3ms/step - loss: 0.0687 - mae: 0.2525 - mse: 0.0652 - val_loss: 0.0707 - val_mae: 0.2532 - val_mse: 0.0653 - lr: 0.0977
Epoch 3/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0761 - mae: 0.2525 - mse: 0.0680 - val_loss: 0.0734 - val_mae: 0.2532 - val_mse: 0.0654 - lr: 0.0977
Epoch 4/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0724 - mae: 0.2525 - mse: 0.0650 - val_loss: 0.0743 - val_mae: 0.2532 - val_mse: 0.0653 - lr: 0.0977
Epoch 5/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0800 - mae: 0.2529 - mse: 0.0704 - val_loss: 0.0727 - val_mae: 0.2532 - val_mse: 0.0653 - lr: 0.0977
Epoch 6/20
 1/22 [>.............................] - ETA: 0s - loss: 0.0727 - mae: 0.2533 - mse: 0.0653
22/22 [==============================] - 0s 6ms/step - loss: 0.0441 - mae: 0.2025 - mse: 0.0422 - val_loss: 0.0450 - val_mae: 0.2032 - val_mse: 0.0426 - lr: 0.0489
22/22 [==============================] - 0s 4ms/step - loss: 0.0670 - mae: 0.2525 - mse: 0.0650 - val_loss: 0.0676 - val_mae: 0.2532 - val_mse: 0.0655 - lr: 0.0489
Epoch 19/20
22/22 [==============================] - 0s 5ms/step - loss: 0.0670 - mae: 0.2525 - mse: 0.0650 - val_loss: 0.0674 - val_mae: 0.2532 - val_mse: 0.0653 - lr: 0.0489
Epoch 20/20
22/22 [==============================] - 0s 4ms/step - loss: 0.0672 - mae: 0.2525 - mse: 0.0650 - val_loss: 0.0671 - val_mae: 0.2532 - val_mse: 0.0653 - lr: 0.0489
>Saved ../trained_models/severity/models__rmsprop_0.09771521328568716LR_[38]HN_184BS_10P_val_mseM_20epochs/model_5.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
22/22 [==============================] - 0s 4ms/step - loss: 0.0670 - mae: 0.2525 - mse: 0.0650 - val_loss: 0.0676 - val_mae: 0.2532 - val_mse: 0.0655 - lr: 0.0489
22/22 [==============================] - 0s 5ms/step - loss: 0.0942 - mae: 0.3025 - mse: 0.0927 - val_loss: 0.0938 - val_mae: 0.3032 - val_mse: 0.0931 - lr: 0.0489
22/22 [==============================] - 0s 5ms/step - loss: 0.1275 - mae: 0.3525 - mse: 0.1255 - val_loss: 0.1265 - val_mae: 0.3532 - val_mse: 0.1260 - lr: 0.0489
22/22 [==============================] - 0s 5ms/step - loss: 0.1275 - mae: 0.3525 - mse: 0.1255 - val_loss: 0.1265 - val_mae: 0.3532 - val_mse: 0.1260 - lr: 0.0489
Epoch 12/20==========================] - 0s 5ms/step - loss: 0.1275 - mae: 0.3525 - mse: 0.1255 - val_loss: 0.1265 - val_mae: 0.3532 - val_mse: 0.1260 - lr: 0.0489
Epoch 12/20==========================] - 0s 5ms/step - loss: 0.1275 - mae: 0.3525 - mse: 0.1255 - val_loss: 0.1265 - val_mae: 0.3532 - val_mse: 0.1260 - lr: 0.0489
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.04885760694742203. 0.3525 - mse: 0.1255 - val_loss: 0.1265 - val_mae: 0.3532 - val_mse: 0.1260 - lr: 0.0489
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.04885760694742203. 0.3525 - mse: 0.1255 - val_loss: 0.1265 - val_mae: 0.3532 - val_mse: 0.1260 - lr: 0.0489