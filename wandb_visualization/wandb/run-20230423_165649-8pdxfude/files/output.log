Epoch 1/30
204/243 [========================>.....] - ETA: 0s - loss: 0.8587 - mae: 0.9256 - mse: 0.8587
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0012s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0012s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
243/243 [==============================] - 1s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0011
Epoch 2/30
233/243 [===========================>..] - ETA: 0s - loss: 0.8574 - mae: 0.9249 - mse: 0.8574
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0005252745468169451.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 0.0011
Epoch 3/30
181/243 [=====================>........] - ETA: 0s - loss: 0.8574 - mae: 0.9249 - mse: 0.8574
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.00026263727340847254.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 5.2527e-04
Epoch 4/30
213/243 [=========================>....] - ETA: 0s - loss: 0.8571 - mae: 0.9247 - mse: 0.8571
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00013131863670423627.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 2.6264e-04
Epoch 5/30
198/243 [=======================>......] - ETA: 0s - loss: 0.8568 - mae: 0.9246 - mse: 0.8568
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.
243/243 [==============================] - 0s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.3132e-04
Epoch 6/30
224/243 [==========================>...] - ETA: 0s - loss: 0.8573 - mae: 0.9249 - mse: 0.8573
Epoch 6: ReduceLROnPlateau reducing learning rate to 3.282965917605907e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 6.5659e-05
Epoch 7/30
218/243 [=========================>....] - ETA: 0s - loss: 0.8582 - mae: 0.9253 - mse: 0.8582
Epoch 7: ReduceLROnPlateau reducing learning rate to 1.6414829588029534e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 3.2830e-05
Epoch 8/30
216/243 [=========================>....] - ETA: 0s - loss: 0.8578 - mae: 0.9251 - mse: 0.8578
Epoch 8: ReduceLROnPlateau reducing learning rate to 1e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.6415e-05
Epoch 9/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 10/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 11/30
243/243 [==============================] - 0s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 12/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 13/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 14/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 15/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 16/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 17/30
243/243 [==============================] - 0s 2ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 18/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 19/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 20/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 21/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 22/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 23/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 24/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 25/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 26/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 27/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 28/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 29/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
Epoch 30/30
243/243 [==============================] - 0s 1ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_sgd_0.0010505490546541152LR_[26]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
273/323 [========================>.....] - ETA: 0s - loss: 0.6424 - mae: 0.7994 - mse: 0.6424
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
323/323 [==============================] - 1s 4ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0011
Epoch 2/30
301/323 [==========================>...] - ETA: 0s - loss: 0.6427 - mae: 0.7996 - mse: 0.6427
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0005252745468169451.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 0.0011
Epoch 3/30
263/323 [=======================>......] - ETA: 0s - loss: 0.6437 - mae: 0.8002 - mse: 0.6437
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.00026263727340847254.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 5.2527e-04
Epoch 4/30
273/323 [========================>.....] - ETA: 0s - loss: 0.6432 - mae: 0.7999 - mse: 0.6432
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00013131863670423627.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 2.6264e-04
Epoch 5/30
307/323 [===========================>..] - ETA: 0s - loss: 0.6434 - mae: 0.8000 - mse: 0.6434
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.3132e-04
Epoch 6/30
318/323 [============================>.] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431
Epoch 6: ReduceLROnPlateau reducing learning rate to 3.282965917605907e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 6.5659e-05
Epoch 7/30
274/323 [========================>.....] - ETA: 0s - loss: 0.6422 - mae: 0.7993 - mse: 0.6422
Epoch 7: ReduceLROnPlateau reducing learning rate to 1.6414829588029534e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 3.2830e-05
Epoch 8/30
299/323 [==========================>...] - ETA: 0s - loss: 0.6428 - mae: 0.7996 - mse: 0.6428
Epoch 8: ReduceLROnPlateau reducing learning rate to 1e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.6415e-05
Epoch 9/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 10/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 11/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 12/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 13/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 14/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 15/30
  1/323 [..............................] - ETA: 0s - loss: 0.6413 - mae: 0.7982 - mse: 0.64136431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 16/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 17/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 18/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 19/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 20/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 21/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 22/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 23/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 24/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 25/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 26/30
294/323 [==========================>...] - ETA: 0s - loss: 0.6428 - mae: 0.7996 - mse: 0.6428
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 28/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 29/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 30/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_sgd_0.0010505490546541152LR_[26]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
323/323 [==============================] - 0s 1ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_train_batch_end` time: 0.0023s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_train_batch_end` time: 0.0023s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
205/243 [========================>.....] - ETA: 0s - loss: 0.4576 - mae: 0.6750 - mse: 0.45766431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.3132e-04
Epoch 6/30
198/243 [=======================>......] - ETA: 0s - loss: 0.4579 - mae: 0.6752 - mse: 0.4579
Epoch 6: ReduceLROnPlateau reducing learning rate to 3.282965917605907e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 6.5659e-05
Epoch 7/30
230/243 [===========================>..] - ETA: 0s - loss: 0.4576 - mae: 0.6751 - mse: 0.4576
Epoch 7: ReduceLROnPlateau reducing learning rate to 1.6414829588029534e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 3.2830e-05
Epoch 8/30
205/243 [========================>.....] - ETA: 0s - loss: 0.4576 - mae: 0.6750 - mse: 0.45766431 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - lr: 1.0000e-05
Epoch 8: ReduceLROnPlateau reducing learning rate to 1e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.6415e-05
Epoch 9/30
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 10/30
243/243 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 11/30
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 12/30
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 13/30
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 14/30
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 15/30
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 16/30
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 17/30
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 18/30
243/243 [==============================] - 0s 2ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 19/30
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 20/30
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 21/30
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 22/30
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 23/30
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 24/30
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 25/30
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 26/30
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 27/30
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 28/30
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 29/30
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
Epoch 30/30
243/243 [==============================] - 0s 1ms/step - loss: 0.4578 - mae: 0.6752 - mse: 0.4578 - val_loss: 0.4570 - val_mae: 0.6746 - val_mse: 0.4570 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap-cnn_sgd_0.0010505490546541152LR_[26]CHN_64CNNI_16BS_1P_val_lossM_30epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
221/243 [==========================>...] - ETA: 0s - loss: 0.3330 - mae: 0.5754 - mse: 0.3330
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
243/243 [==============================] - 1s 5ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0011
Epoch 2/30
229/243 [===========================>..] - ETA: 0s - loss: 0.3328 - mae: 0.5752 - mse: 0.3328
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0005252745468169451.
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 0.0011
Epoch 3/30
203/243 [========================>.....] - ETA: 0s - loss: 0.3332 - mae: 0.5756 - mse: 0.3332
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.00026263727340847254.
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 5.2527e-04
Epoch 4/30
186/243 [=====================>........] - ETA: 0s - loss: 0.3324 - mae: 0.5749 - mse: 0.3324
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00013131863670423627.
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 2.6264e-04
Epoch 5/30
212/243 [=========================>....] - ETA: 0s - loss: 0.3326 - mae: 0.5750 - mse: 0.3326
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.
243/243 [==============================] - 0s 2ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.3132e-04
Epoch 6/30
205/243 [========================>.....] - ETA: 0s - loss: 0.3326 - mae: 0.5751 - mse: 0.3326
Epoch 6: ReduceLROnPlateau reducing learning rate to 3.282965917605907e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 6.5659e-05
Epoch 7/30
184/243 [=====================>........] - ETA: 0s - loss: 0.3325 - mae: 0.5749 - mse: 0.3325
Epoch 7: ReduceLROnPlateau reducing learning rate to 1.6414829588029534e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 3.2830e-05
Epoch 8/30
211/243 [=========================>....] - ETA: 0s - loss: 0.3323 - mae: 0.5748 - mse: 0.3323
Epoch 8: ReduceLROnPlateau reducing learning rate to 1e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.6415e-05
Epoch 9/30
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 10/30
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 11/30
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 12/30
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 13/30
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 14/30
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 15/30
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 16/30
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 17/30
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 18/30
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 19/30
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 20/30
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 21/30
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
Epoch 22/30
 43/243 [====>.........................] - ETA: 0s - loss: 0.3306 - mae: 0.5733 - mse: 0.3306
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
243/243 [==============================] - 0s 1ms/step - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - val_loss: 0.3321 - val_mae: 0.5746 - val_mse: 0.3321 - lr: 1.0000e-05
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_train_batch_end` time: 0.0018s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_train_batch_end` time: 0.0018s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
243/243 [==============================] - 0s 1ms/step - loss: 0.2277 - mae: 0.4752 - mse: 0.2277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
  1/243 [..............................] - ETA: 0s - loss: 0.2286 - mae: 0.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
  1/243 [..............................] - ETA: 0s - loss: 0.2286 - mae: 0.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
  1/243 [..............................] - ETA: 0s - loss: 0.2286 - mae: 0.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
  1/243 [..............................] - ETA: 0s - loss: 0.2286 - mae: 0.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
  1/243 [..............................] - ETA: 0s - loss: 0.2286 - mae: 0.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0022s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0022s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0022s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0022s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230423_165649-8pdxfude\files\model-best)... Done. 0.3s
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0013s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230423_165649-8pdxfude\files\model-best)... Done. 0.0s
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230423_165649-8pdxfude\files\model-best)... Done. 0.0s
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04
Epoch 5: ReduceLROnPlateau reducing learning rate to 6.565931835211813e-05.4762 - mse: 0.22862277 - val_loss: 0.2272 - val_mae: 0.4746 - val_mse: 0.2272 - lr: 5.2527e-04