Epoch 1/30
225/243 [==========================>...] - ETA: 0s - loss: 0.0563 - mae: 0.0631 - mse: 0.0091
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_161024-sl8fj3u9\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 6ms/step - loss: 0.0524 - mae: 0.0614 - mse: 0.0086 - val_loss: 0.0024 - val_mae: 0.0374 - val_mse: 0.0019 - lr: 0.0072
Epoch 2/30
238/243 [============================>.] - ETA: 0s - loss: 0.0024 - mae: 0.0377 - mse: 0.0020
243/243 [==============================] - 2s 8ms/step - loss: 0.0024 - mae: 0.0377 - mse: 0.0020 - val_loss: 0.0021 - val_mae: 0.0358 - val_mse: 0.0018 - lr: 0.0072
Epoch 3/30
236/243 [============================>.] - ETA: 0s - loss: 0.0022 - mae: 0.0369 - mse: 0.0019
243/243 [==============================] - 2s 7ms/step - loss: 0.0022 - mae: 0.0369 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0351 - val_mse: 0.0017 - lr: 0.0072
Epoch 4/30
243/243 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0362 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0361 - val_mse: 0.0019 - lr: 0.0072
Epoch 5/30
243/243 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0351 - mse: 0.0018 - val_loss: 0.0022 - val_mae: 0.0358 - val_mse: 0.0019 - lr: 0.0072
Epoch 6/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0338 - mse: 0.0016 - val_loss: 0.0023 - val_mae: 0.0365 - val_mse: 0.0020 - lr: 0.0072
Epoch 7/30
226/243 [==========================>...] - ETA: 0s - loss: 0.0018 - mae: 0.0326 - mse: 0.0016
243/243 [==============================] - 2s 8ms/step - loss: 0.0018 - mae: 0.0325 - mse: 0.0016 - val_loss: 0.0017 - val_mae: 0.0312 - val_mse: 0.0014 - lr: 0.0072
Epoch 8/30
243/243 [==============================] - 1s 2ms/step - loss: 0.0017 - mae: 0.0311 - mse: 0.0015 - val_loss: 0.0017 - val_mae: 0.0321 - val_mse: 0.0016 - lr: 0.0072
Epoch 9/30
214/243 [=========================>....] - ETA: 0s - loss: 0.0016 - mae: 0.0296 - mse: 0.0013
243/243 [==============================] - 2s 6ms/step - loss: 0.0016 - mae: 0.0293 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0276 - val_mse: 0.0012 - lr: 0.0072
Epoch 10/30
243/243 [==============================] - 2s 6ms/step - loss: 0.0015 - mae: 0.0280 - mse: 0.0012 - val_loss: 0.0014 - val_mae: 0.0271 - val_mse: 0.0012 - lr: 0.0072
Epoch 11/30
243/243 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0268 - mse: 0.0011 - val_loss: 0.0018 - val_mae: 0.0303 - val_mse: 0.0014 - lr: 0.0072
Epoch 12/30
243/243 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0260 - mse: 0.0011
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_161024-sl8fj3u9\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 6ms/step - loss: 0.0013 - mae: 0.0260 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0257 - val_mse: 0.0011 - lr: 0.0072
Epoch 13/30
243/243 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0254 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0240 - val_mse: 9.2761e-04 - lr: 0.0072
Epoch 14/30
243/243 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0250 - mse: 0.0010 - val_loss: 0.0014 - val_mae: 0.0270 - val_mse: 0.0011 - lr: 0.0072
Epoch 15/30
235/243 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0251 - mse: 0.0010
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_161024-sl8fj3u9\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 6ms/step - loss: 0.0012 - mae: 0.0251 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0235 - val_mse: 9.0370e-04 - lr: 0.0072
Epoch 16/30
243/243 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0245 - mse: 9.9261e-04 - val_loss: 0.0012 - val_mae: 0.0246 - val_mse: 9.6124e-04 - lr: 0.0072
Epoch 17/30
243/243 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0246 - mse: 9.7630e-04 - val_loss: 0.0012 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0072
Epoch 18/30
216/243 [=========================>....] - ETA: 0s - loss: 0.0011 - mae: 0.0244 - mse: 9.6648e-04
243/243 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0243 - mse: 9.5957e-04 - val_loss: 0.0010 - val_mae: 0.0227 - val_mse: 8.3950e-04 - lr: 0.0072
Epoch 19/30
231/243 [===========================>..] - ETA: 0s - loss: 0.0011 - mae: 0.0241 - mse: 9.3615e-04
243/243 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0241 - mse: 9.4185e-04 - val_loss: 9.9533e-04 - val_mae: 0.0227 - val_mse: 8.3271e-04 - lr: 0.0072
Epoch 20/30
189/243 [======================>.......] - ETA: 0s - loss: 0.0011 - mae: 0.0240 - mse: 9.5018e-04
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0036104938481003046.
243/243 [==============================] - 0s 2ms/step - loss: 0.0011 - mae: 0.0241 - mse: 9.5061e-04 - val_loss: 9.9779e-04 - val_mae: 0.0234 - val_mse: 8.7640e-04 - lr: 0.0072
Epoch 21/30
223/243 [==========================>...] - ETA: 0s - loss: 9.9233e-04 - mae: 0.0228 - mse: 8.5743e-04
243/243 [==============================] - 1s 6ms/step - loss: 9.9183e-04 - mae: 0.0227 - mse: 8.5759e-04 - val_loss: 9.5310e-04 - val_mae: 0.0227 - val_mse: 8.2908e-04 - lr: 0.0036
Epoch 22/30
243/243 [==============================] - 1s 2ms/step - loss: 9.7995e-04 - mae: 0.0226 - mse: 8.5311e-04 - val_loss: 0.0010 - val_mae: 0.0239 - val_mse: 9.0137e-04 - lr: 0.0036
Epoch 23/30
243/243 [==============================] - 1s 2ms/step - loss: 9.7557e-04 - mae: 0.0228 - mse: 8.4903e-04 - val_loss: 9.9672e-04 - val_mae: 0.0229 - val_mse: 8.5612e-04 - lr: 0.0036
Epoch 24/30
243/243 [==============================] - 1s 3ms/step - loss: 9.5926e-04 - mae: 0.0224 - mse: 8.3705e-04 - val_loss: 0.0010 - val_mae: 0.0245 - val_mse: 9.4819e-04 - lr: 0.0036
Epoch 25/30
217/243 [=========================>....] - ETA: 0s - loss: 9.6485e-04 - mae: 0.0226 - mse: 8.4885e-04
243/243 [==============================] - 2s 6ms/step - loss: 9.5956e-04 - mae: 0.0225 - mse: 8.4313e-04 - val_loss: 9.1370e-04 - val_mae: 0.0220 - val_mse: 7.8075e-04 - lr: 0.0036
Epoch 26/30
212/243 [=========================>....] - ETA: 0s - loss: 9.5241e-04 - mae: 0.0225 - mse: 8.3614e-04
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0018052469240501523.
243/243 [==============================] - 1s 3ms/step - loss: 9.4325e-04 - mae: 0.0224 - mse: 8.2657e-04 - val_loss: 9.1759e-04 - val_mae: 0.0221 - val_mse: 7.9343e-04 - lr: 0.0036
Epoch 27/30
243/243 [==============================] - 1s 3ms/step - loss: 8.9960e-04 - mae: 0.0218 - mse: 7.9417e-04 - val_loss: 9.3548e-04 - val_mae: 0.0224 - val_mse: 8.2381e-04 - lr: 0.0018
Epoch 28/30
214/243 [=========================>....] - ETA: 0s - loss: 8.8684e-04 - mae: 0.0217 - mse: 7.8520e-04
243/243 [==============================] - 2s 7ms/step - loss: 8.9386e-04 - mae: 0.0218 - mse: 7.9204e-04 - val_loss: 8.8596e-04 - val_mae: 0.0223 - val_mse: 7.9913e-04 - lr: 0.0018
Epoch 29/30
222/243 [==========================>...] - ETA: 0s - loss: 8.9126e-04 - mae: 0.0218 - mse: 7.9312e-04
243/243 [==============================] - 2s 7ms/step - loss: 8.8685e-04 - mae: 0.0217 - mse: 7.8817e-04 - val_loss: 8.8067e-04 - val_mae: 0.0222 - val_mse: 7.9017e-04 - lr: 0.0018
Epoch 30/30
243/243 [==============================] - 2s 9ms/step - loss: 8.8096e-04 - mae: 0.0217 - mse: 7.8069e-04 - val_loss: 8.7292e-04 - val_mae: 0.0219 - val_mse: 7.6747e-04 - lr: 0.0018
>Saved ../trained_models/models_segments_overlap_rmsprop_0.0072209879071062355LR_[20]HN_16BS_5P_val_lossM_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0412 - mae: 0.0600 - mse: 0.0060 - val_loss: 0.0036 - val_mae: 0.0491 - val_mse: 0.0033 - lr: 0.0072
Epoch 2/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0499 - mse: 0.0034 - val_loss: 0.0059 - val_mae: 0.0601 - val_mse: 0.0054 - lr: 0.0072
Epoch 3/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0035 - mae: 0.0484 - mse: 0.0032 - val_loss: 0.0035 - val_mae: 0.0471 - val_mse: 0.0031 - lr: 0.0072
Epoch 4/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0454 - mse: 0.0029 - val_loss: 0.0040 - val_mae: 0.0479 - val_mse: 0.0033 - lr: 0.0072
Epoch 5/30
323/323 [==============================] - 1s 2ms/step - loss: 0.0029 - mae: 0.0405 - mse: 0.0025 - val_loss: 0.0026 - val_mae: 0.0376 - val_mse: 0.0022 - lr: 0.0072
Epoch 6/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0026 - mae: 0.0370 - mse: 0.0022 - val_loss: 0.0024 - val_mae: 0.0359 - val_mse: 0.0021 - lr: 0.0072
Epoch 7/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0359 - mse: 0.0021 - val_loss: 0.0021 - val_mae: 0.0326 - val_mse: 0.0018 - lr: 0.0072
Epoch 8/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0349 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0331 - val_mse: 0.0018 - lr: 0.0072
Epoch 9/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0343 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0309 - val_mse: 0.0016 - lr: 0.0072
Epoch 10/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0337 - mse: 0.0018 - val_loss: 0.0019 - val_mae: 0.0308 - val_mse: 0.0016 - lr: 0.0072
Epoch 11/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0337 - mse: 0.0018 - val_loss: 0.0023 - val_mae: 0.0360 - val_mse: 0.0020 - lr: 0.0072
Epoch 12/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0333 - mse: 0.0018 - val_loss: 0.0022 - val_mae: 0.0345 - val_mse: 0.0019 - lr: 0.0072
Epoch 13/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0326 - mse: 0.0017 - val_loss: 0.0029 - val_mae: 0.0420 - val_mse: 0.0027 - lr: 0.0072
Epoch 14/30
301/323 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0324 - mse: 0.0017
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0036104938481003046.
323/323 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0324 - mse: 0.0017 - val_loss: 0.0021 - val_mae: 0.0330 - val_mse: 0.0018 - lr: 0.0072
Epoch 15/30
323/323 [==============================] - 1s 2ms/step - loss: 0.0018 - mae: 0.0301 - mse: 0.0015 - val_loss: 0.0017 - val_mae: 0.0281 - val_mse: 0.0014 - lr: 0.0036
Epoch 16/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0298 - mse: 0.0015 - val_loss: 0.0016 - val_mae: 0.0282 - val_mse: 0.0014 - lr: 0.0036
Epoch 17/30
323/323 [==============================] - 1s 2ms/step - loss: 0.0017 - mae: 0.0295 - mse: 0.0015 - val_loss: 0.0016 - val_mae: 0.0288 - val_mse: 0.0014 - lr: 0.0036
Epoch 18/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0295 - mse: 0.0015 - val_loss: 0.0017 - val_mae: 0.0296 - val_mse: 0.0014 - lr: 0.0036
Epoch 19/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0278 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0267 - val_mse: 0.0013 - lr: 0.0018
Epoch 20/30
311/323 [===========================>..] - ETA: 0s - loss: 0.0016 - mae: 0.0289 - mse: 0.0014
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0018052469240501523.
323/323 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0289 - mse: 0.0014 - val_loss: 0.0017 - val_mae: 0.0296 - val_mse: 0.0015 - lr: 0.0036
Epoch 21/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0278 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0267 - val_mse: 0.0013 - lr: 0.0018
Epoch 22/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0277 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0267 - val_mse: 0.0013 - lr: 0.0018
Epoch 23/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0276 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0261 - val_mse: 0.0013 - lr: 0.0018
Epoch 24/30
201/323 [=================>............] - ETA: 0s - loss: 0.0015 - mae: 0.0275 - mse: 0.0013
306/323 [===========================>..] - ETA: 0s - loss: 0.0015 - mae: 0.0269 - mse: 0.00130013 - val_loss: 0.0015 - val_mae: 0.0267 - val_mse: 0.0013 - lr: 0.0018
306/323 [===========================>..] - ETA: 0s - loss: 0.0015 - mae: 0.0269 - mse: 0.00130013 - val_loss: 0.0015 - val_mae: 0.0267 - val_mse: 0.0013 - lr: 0.0018
323/323 [==============================] - 1s 2ms/step - loss: 0.0014 - mae: 0.0265 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0272 - val_mse: 0.0013 - lr: 9.0262e-04
118/243 [=============>................] - ETA: 0s - loss: 0.0021 - mae: 0.0376 - mse: 0.00190013 - val_loss: 0.0015 - val_mae: 0.0272 - val_mse: 0.0013 - lr: 9.0262e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0374 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0400 - val_mse: 0.0023 - lr: 0.0072e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0292 - mse: 0.0013 - val_loss: 0.0013 - val_mae: 0.0266 - val_mse: 0.0011 - lr: 0.0072e-04
117/243 [=============>................] - ETA: 0s - loss: 0.0014 - mae: 0.0275 - mse: 0.0012     - val_loss: 0.0013 - val_mae: 0.0266 - val_mse: 0.0011 - lr: 0.0072e-04
 88/243 [=========>....................] - ETA: 0s - loss: 0.0011 - mae: 0.0246 - mse: 9.5724e-04    al_loss: 0.0013 - val_mae: 0.0255 - val_mse: 0.0011 - lr: 0.0072e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0252 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0252 - val_mse: 0.0010 - lr: 0.0036e-04
235/243 [============================>.] - ETA: 0s - loss: 0.0011 - mae: 0.0249 - mse: 9.9132e-04    al_loss: 0.0012 - val_mae: 0.0252 - val_mse: 0.0010 - lr: 0.0036e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0243 - mse: 9.4207e-04 - val_loss: 0.0011 - val_mae: 0.0255 - val_mse: 9.9729e-04 - lr: 0.0018
243/243 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0242 - mse: 9.3468e-04 - val_loss: 0.0010 - val_mae: 0.0245 - val_mse: 9.6078e-04 - lr: 0.0018
243/243 [==============================] - 1s 3ms/step - loss: 9.8631e-04 - mae: 0.0237 - mse: 9.0479e-04 - val_loss: 0.0011 - val_mae: 0.0248 - val_mse: 0.0010 - lr: 9.0262e-04
243/243 [==============================] - 1s 3ms/step - loss: 9.7393e-04 - mae: 0.0236 - mse: 8.9645e-04 - val_loss: 0.0010 - val_mae: 0.0244 - val_mse: 9.5137e-04 - lr: 4.5131e-04
243/243 [==============================] - 1s 3ms/step - loss: 9.7393e-04 - mae: 0.0236 - mse: 8.9645e-04 - val_loss: 0.0010 - val_mae: 0.0244 - val_mse: 9.5137e-04 - lr: 4.5131e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0377 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0374 - val_mse: 0.0019 - lr: 0.0072- lr: 4.5131e-04
236/243 [============================>.] - ETA: 0s - loss: 0.0013 - mae: 0.0270 - mse: 0.0011     - val_loss: 0.0020 - val_mae: 0.0374 - val_mse: 0.0019 - lr: 0.0072- lr: 4.5131e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0269 - mse: 0.0011 - val_loss: 0.0013 - val_mae: 0.0272 - val_mse: 0.0012 - lr: 0.0072- lr: 4.5131e-04
243/243 [==============================] - 1s 2ms/step - loss: 0.0012 - mae: 0.0252 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0249 - val_mse: 0.0010 - lr: 0.0072- lr: 4.5131e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0239 - mse: 9.2259e-04 - val_loss: 0.0012 - val_mae: 0.0259 - val_mse: 0.0011 - lr: 0.0036: 4.5131e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0234 - mse: 9.0133e-04 - val_loss: 0.0013 - val_mae: 0.0287 - val_mse: 0.0012 - lr: 0.0036: 4.5131e-04
243/243 [==============================] - 1s 3ms/step - loss: 9.4044e-04 - mae: 0.0226 - mse: 8.3942e-04 - val_loss: 0.0011 - val_mae: 0.0244 - val_mse: 9.9121e-04 - lr: 0.0018e-04
243/243 [==============================] - 1s 3ms/step - loss: 9.2327e-04 - mae: 0.0224 - mse: 8.2706e-04 - val_loss: 9.6963e-04 - val_mae: 0.0234 - val_mse: 8.8064e-04 - lr: 0.0018
243/243 [==============================] - 1s 3ms/step - loss: 9.0905e-04 - mae: 0.0220 - mse: 8.1419e-04 - val_loss: 0.0010 - val_mae: 0.0252 - val_mse: 9.6963e-04 - lr: 0.00180018
243/243 [==============================] - 1s 3ms/step - loss: 9.0905e-04 - mae: 0.0220 - mse: 8.1419e-04 - val_loss: 0.0010 - val_mae: 0.0252 - val_mse: 9.6963e-04 - lr: 0.00180018
243/243 [==============================] - 1s 3ms/step - loss: 0.0373 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0390 - val_mse: 0.0020 - lr: 0.0072- lr: 0.00180018
 84/243 [=========>....................] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.00190019 - val_loss: 0.0021 - val_mae: 0.0390 - val_mse: 0.0020 - lr: 0.0072- lr: 0.00180018
243/243 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0382 - val_mse: 0.0019 - lr: 0.0072- lr: 0.00180018
243/243 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0323 - mse: 0.0015 - val_loss: 0.0019 - val_mae: 0.0364 - val_mse: 0.0017 - lr: 0.0072- lr: 0.00180018
243/243 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0304 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0302 - val_mse: 0.0013 - lr: 0.0072- lr: 0.00180018
243/243 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0295 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0313 - val_mse: 0.0014 - lr: 0.0072- lr: 0.00180018
 90/243 [==========>...................] - ETA: 0s - loss: 0.0013 - mae: 0.0283 - mse: 0.00120013 - val_loss: 0.0015 - val_mae: 0.0313 - val_mse: 0.0014 - lr: 0.0072- lr: 0.00180018
 55/243 [=====>........................] - ETA: 0s - loss: 0.0012 - mae: 0.0271 - mse: 0.0011        al_loss: 0.0013 - val_mae: 0.0285 - val_mse: 0.0012 - lr: 0.0036- lr: 0.00180018
243/243 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0277 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0289 - val_mse: 0.0012 - lr: 0.0018- lr: 0.00180018
239/243 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0272 - mse: 0.00110012 - val_loss: 0.0013 - val_mae: 0.0289 - val_mse: 0.0012 - lr: 0.0018- lr: 0.00180018
243/243 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0270 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0274 - val_mse: 0.0011 - lr: 9.0262e-04: 0.00180018
243/243 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0270 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0274 - val_mse: 0.0011 - lr: 9.0262e-04: 0.00180018
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0026s). Check your callbacks.
243/243 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0382 - val_mse: 0.0019 - lr: 0.0072e-04: 0.00180018
243/243 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0282 - mse: 0.0012 - val_loss: 0.0014 - val_mae: 0.0270 - val_mse: 0.0012 - lr: 0.0072e-04: 0.00180018
 84/243 [=========>....................] - ETA: 0s - loss: 0.0012 - mae: 0.0262 - mse: 0.0011        al_loss: 0.0014 - val_mae: 0.0270 - val_mse: 0.0012 - lr: 0.0072e-04: 0.00180018
243/243 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0267 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0252 - val_mse: 0.0010 - lr: 0.0072e-04: 0.00180018
243/243 [==============================] - ETA: 0s - loss: 0.0013 - mae: 0.0266 - mse: 0.00110011 - val_loss: 0.0012 - val_mae: 0.0252 - val_mse: 0.0010 - lr: 0.0072e-04: 0.00180018
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0249 - mse: 9.8528e-04 - val_loss: 0.0011 - val_mae: 0.0244 - val_mse: 9.4783e-04 - lr: 0.003600180018
223/243 [==========================>...] - ETA: 0s - loss: 0.0011 - mae: 0.0250 - mse: 9.9171e-04e-04 - val_loss: 0.0011 - val_mae: 0.0244 - val_mse: 9.4783e-04 - lr: 0.003600180018
230/243 [===========================>..] - ETA: 0s - loss: 0.0010 - mae: 0.0240 - mse: 9.2703e-04     - val_loss: 0.0011 - val_mae: 0.0249 - val_mse: 9.7423e-04 - lr: 0.003600180018
243/243 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0239 - mse: 9.2967e-04 - val_loss: 0.0010 - val_mae: 0.0238 - val_mse: 9.0842e-04 - lr: 0.001800180018
243/243 [==============================] - 1s 2ms/step - loss: 0.0010 - mae: 0.0239 - mse: 9.2967e-04 - val_loss: 0.0010 - val_mae: 0.0238 - val_mse: 9.0842e-04 - lr: 0.001800180018
243/243 [==============================] - 1s 3ms/step - loss: 0.0479 - mae: 0.0432 - mse: 0.0031 - val_loss: 0.0023 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 0.0072: 0.001800180018
218/243 [=========================>....] - ETA: 0s - loss: 0.0017 - mae: 0.0309 - mse: 0.00140031 - val_loss: 0.0023 - val_mae: 0.0379 - val_mse: 0.0019 - lr: 0.0072: 0.001800180018
243/243 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0307 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0283 - val_mse: 0.0012 - lr: 0.0072: 0.001800180018
243/243 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0274 - mse: 0.0012 - val_loss: 0.0018 - val_mae: 0.0322 - val_mse: 0.0015 - lr: 0.0072: 0.001800180018
243/243 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 16/30============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 19/30============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0018052469240501523. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 25/30educeLROnPlateau reducing learning rate to 0.0018052469240501523. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 25/30educeLROnPlateau reducing learning rate to 0.0018052469240501523. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_161024-sl8fj3u9\files\model-best)... Done. 0.0s
Epoch 25/30educeLROnPlateau reducing learning rate to 0.0018052469240501523. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 28/30educeLROnPlateau reducing learning rate to 0.0018052469240501523. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 28/30educeLROnPlateau reducing learning rate to 0.0018052469240501523. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_161024-sl8fj3u9\files\model-best)... Done. 0.0s
Epoch 28/30educeLROnPlateau reducing learning rate to 0.0018052469240501523. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_161024-sl8fj3u9\files\model-best)... Done. 0.0s
Epoch 28/30educeLROnPlateau reducing learning rate to 0.0018052469240501523. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 5/300educeLROnPlateau reducing learning rate to 0.0018052469240501523. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 9/300educeLROnPlateau reducing learning rate to 0.0018052469240501523. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 9/300educeLROnPlateau reducing learning rate to 0.0018052469240501523. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 13/30educeLROnPlateau reducing learning rate to 0.0018052469240501523. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 17/30educeLROnPlateau reducing learning rate to 0.0018052469240501523. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 19/30educeLROnPlateau reducing learning rate to 0.0018052469240501523. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 23/30educeLROnPlateau reducing learning rate to 0.0018052469240501523. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 25/30educeLROnPlateau reducing learning rate to 0.0018052469240501523. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 28/30educeLROnPlateau reducing learning rate to 0.0018052469240501523. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0009026234620250762. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 3/30ReduceLROnPlateau reducing learning rate to 0.0009026234620250762. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 5/30ReduceLROnPlateau reducing learning rate to 0.0009026234620250762. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 8/30ReduceLROnPlateau reducing learning rate to 0.0009026234620250762. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 11/30educeLROnPlateau reducing learning rate to 0.0009026234620250762. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 14/30educeLROnPlateau reducing learning rate to 0.0009026234620250762. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 17/30educeLROnPlateau reducing learning rate to 0.0009026234620250762. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 19/30educeLROnPlateau reducing learning rate to 0.0009026234620250762. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 23/30educeLROnPlateau reducing learning rate to 0.0009026234620250762. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 25/30educeLROnPlateau reducing learning rate to 0.0009026234620250762. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 29/30educeLROnPlateau reducing learning rate to 0.0009026234620250762. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018
Epoch 29/30educeLROnPlateau reducing learning rate to 0.0009026234620250762. 0.0250 - mse: 0.0010 - val_loss: 0.0012 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0036: 0.001800180018