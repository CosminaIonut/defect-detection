Epoch 1/20
 1/27 [>.............................] - ETA: 16s - loss: 4.0482 - mae: 0.4218 - mse: 0.1797
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_143343-q08xl380\files\model-best)... Done. 0.0s
27/27 [==============================] - 2s 34ms/step - loss: 0.3087 - mae: 0.0651 - mse: 0.0105 - val_loss: 0.0350 - val_mae: 0.0525 - val_mse: 0.0041 - lr: 0.0430
Epoch 2/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0424 - mae: 0.0468 - mse: 0.0032 - val_loss: 0.0430 - val_mae: 0.0436 - val_mse: 0.0028 - lr: 0.0430
Epoch 3/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0463 - mae: 0.0483 - mse: 0.0035 - val_loss: 0.0414 - val_mae: 0.0399 - val_mse: 0.0022 - lr: 0.0430
Epoch 4/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0464 - mae: 0.0480 - mse: 0.0035 - val_loss: 0.0508 - val_mae: 0.0618 - val_mse: 0.0055 - lr: 0.0430
Epoch 5/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0460 - mae: 0.0482 - mse: 0.0035 - val_loss: 0.0463 - val_mae: 0.0434 - val_mse: 0.0027 - lr: 0.0430
Epoch 6/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0452 - mae: 0.0452 - mse: 0.0030 - val_loss: 0.0415 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0430
Epoch 7/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0444 - mae: 0.0417 - mse: 0.0025 - val_loss: 0.0430 - val_mae: 0.0427 - val_mse: 0.0026 - lr: 0.0430
Epoch 8/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0440 - mae: 0.0408 - mse: 0.0024 - val_loss: 0.0439 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0430
Epoch 9/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0432 - mae: 0.0391 - mse: 0.0021 - val_loss: 0.0441 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0430
Epoch 10/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0428 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0432 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0430
Epoch 11/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0431 - mae: 0.0367 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.021508581936359406.
27/27 [==============================] - 0s 2ms/step - loss: 0.0431 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0427 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0430
Epoch 12/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0426 - mae: 0.0374 - mse: 0.0019
27/27 [==============================] - 1s 32ms/step - loss: 0.0035 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 13/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0124 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0311 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0215
Epoch 14/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0123 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0154 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0215
Epoch 15/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0123 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0127 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0215
Epoch 16/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0127 - mae: 0.0374 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.010754290968179703.
27/27 [==============================] - 0s 2ms/step - loss: 0.0122 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0124 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 17/20
27/27 [==============================] - 1s 31ms/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 18/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0107 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0108
Epoch 19/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0054 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0108
Epoch 20/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0047 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
>Saved ../trained_models/models_segments_overlap_rmsprop_0.043017164098787176LR_[64, 64, 64]HN_144BS_5P_val_mseM_20epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
36/36 [==============================] - 1s 4ms/step - loss: 0.2260 - mae: 0.0732 - mse: 0.0094 - val_loss: 0.0413 - val_mae: 0.0551 - val_mse: 0.0043 - lr: 0.0430
Epoch 2/20
36/36 [==============================] - 0s 2ms/step - loss: 0.0463 - mae: 0.0593 - mse: 0.0051 - val_loss: 0.0471 - val_mae: 0.0613 - val_mse: 0.0056 - lr: 0.0430
Epoch 3/20
36/36 [==============================] - 0s 2ms/step - loss: 0.0454 - mae: 0.0537 - mse: 0.0040 - val_loss: 0.0487 - val_mae: 0.0628 - val_mse: 0.0059 - lr: 0.0430
Epoch 4/20
36/36 [==============================] - 0s 1ms/step - loss: 0.0449 - mae: 0.0515 - mse: 0.0036 - val_loss: 0.0441 - val_mae: 0.0506 - val_mse: 0.0034 - lr: 0.0430
Epoch 5/20
36/36 [==============================] - 0s 2ms/step - loss: 0.0448 - mae: 0.0511 - mse: 0.0035 - val_loss: 0.0461 - val_mae: 0.0529 - val_mse: 0.0039 - lr: 0.0430
Epoch 6/20
36/36 [==============================] - 0s 2ms/step - loss: 0.0448 - mae: 0.0511 - mse: 0.0035 - val_loss: 0.0464 - val_mae: 0.0521 - val_mse: 0.0038 - lr: 0.0430
Epoch 7/20
36/36 [==============================] - 0s 2ms/step - loss: 0.0446 - mae: 0.0509 - mse: 0.0035 - val_loss: 0.0439 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0430
Epoch 8/20
36/36 [==============================] - 0s 2ms/step - loss: 0.0444 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0452 - val_mae: 0.0518 - val_mse: 0.0037 - lr: 0.0430
Epoch 9/20
 1/36 [..............................] - ETA: 0s - loss: 0.0449 - mae: 0.0490 - mse: 0.0033
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.021508581936359406.
36/36 [==============================] - 0s 2ms/step - loss: 0.0448 - mae: 0.0510 - mse: 0.0035 - val_loss: 0.0438 - val_mae: 0.0507 - val_mse: 0.0035 - lr: 0.0430
Epoch 10/20
36/36 [==============================] - 0s 2ms/step - loss: 0.0054 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0746 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0215
Epoch 11/20
36/36 [==============================] - 0s 2ms/step - loss: 0.0158 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0135 - val_mae: 0.0505 - val_mse: 0.0035 - lr: 0.0215
Epoch 12/20
36/36 [==============================] - 0s 2ms/step - loss: 0.0132 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0141 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0215
Epoch 13/20
36/36 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0135 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0215
Epoch 14/20
 1/36 [..............................] - ETA: 0s - loss: 0.0137 - mae: 0.0529 - mse: 0.0037
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.010754290968179703.
36/36 [==============================] - 0s 2ms/step - loss: 0.0136 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0136 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0215
Epoch 15/20
36/36 [==============================] - 0s 2ms/step - loss: 0.0040 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0141 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0108
Epoch 16/20
36/36 [==============================] - 0s 2ms/step - loss: 0.0064 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0059 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0108
Epoch 17/20
36/36 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0061 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0108
Epoch 18/20
36/36 [==============================] - 0s 2ms/step - loss: 0.0060 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0060 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0108
Epoch 19/20
 1/36 [..............................] - ETA: 0s - loss: 0.0063 - mae: 0.0538 - mse: 0.0037
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.005377145484089851.
36/36 [==============================] - 0s 2ms/step - loss: 0.0059 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0060 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0108
Epoch 20/20
36/36 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0048 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0054
>Saved ../trained_models/models_segments_overlap_rmsprop_0.043017164098787176LR_[64, 64, 64]HN_144BS_5P_val_mseM_20epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
27/27 [==============================] - 1s 6ms/step - loss: 0.3067 - mae: 0.0585 - mse: 0.0058 - val_loss: 0.0253 - val_mae: 0.0452 - val_mse: 0.0030 - lr: 0.0430
Epoch 2/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0392 - mae: 0.0416 - mse: 0.0025 - val_loss: 0.0396 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0430
Epoch 3/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0424 - mae: 0.0391 - mse: 0.0021 - val_loss: 0.0411 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0430
Epoch 4/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0430 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0424 - val_mae: 0.0396 - val_mse: 0.0021 - lr: 0.0430
Epoch 5/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0432 - mae: 0.0389 - mse: 0.0021 - val_loss: 0.0427 - val_mae: 0.0390 - val_mse: 0.0020 - lr: 0.0430
Epoch 6/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0433 - mae: 0.0398 - mse: 0.0022 - val_loss: 0.0429 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0430
Epoch 7/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0428 - mae: 0.0367 - mse: 0.0018
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.021508581936359406.
27/27 [==============================] - 0s 2ms/step - loss: 0.0433 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0438 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0430
Epoch 8/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0215
Epoch 9/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0125 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0298 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0215
Epoch 10/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0124 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0150 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0215
Epoch 11/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0124 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0128 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 12/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0128 - mae: 0.0393 - mse: 0.0020
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.010754290968179703.
27/27 [==============================] - 0s 2ms/step - loss: 0.0122 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0124 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 13/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0126 - mae: 0.0415 - mse: 0.0022
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0012s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.
27/27 [==============================] - 1s 32ms/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 14/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0106 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 15/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0055 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 16/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0047 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0108
Epoch 17/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0048 - mae: 0.0391 - mse: 0.0020
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.005377145484089851.
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0046 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0108
Epoch 18/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0046 - mae: 0.0393 - mse: 0.0020
27/27 [==============================] - 1s 32ms/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
 1/27 [>.............................] - ETA: 0s - loss: 0.0129 - mae: 0.0385 - mse: 0.00190020 - val_loss: 0.0446 - val_mae: 0.0421 - val_mse: 0.0025 - lr: 0.04308
Epoch 4/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0433 - mae: 0.0394 - mse: 0.0021 - val_loss: 0.0432 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0430
Epoch 5/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0433 - mae: 0.0387 - mse: 0.0021 - val_loss: 0.0445 - val_mae: 0.0471 - val_mse: 0.0033 - lr: 0.0430
Epoch 6/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0431 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0420 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0430
Epoch 7/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0419 - mae: 0.0364 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.021508581936359406.
27/27 [==============================] - 0s 2ms/step - loss: 0.0432 - mae: 0.0387 - mse: 0.0021 - val_loss: 0.0422 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0430
Epoch 8/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 9/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0130 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0289 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0215
Epoch 10/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0120 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0160 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0215
Epoch 11/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0124 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0130 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0215
Epoch 12/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0132 - mae: 0.0396 - mse: 0.0021
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.010754290968179703.
27/27 [==============================] - 0s 2ms/step - loss: 0.0123 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0129 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0215
Epoch 13/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0129 - mae: 0.0385 - mse: 0.00190020 - val_loss: 0.0446 - val_mae: 0.0421 - val_mse: 0.0025 - lr: 0.04308
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_143343-q08xl380\files\model-best)... Done. 0.0s
27/27 [==============================] - 1s 35ms/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 14/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0107 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0108
Epoch 15/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0054 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0108
Epoch 16/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0047 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 17/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0048 - mae: 0.0393 - mse: 0.0021
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.005377145484089851.
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0046 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0108
Epoch 18/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0044 - mae: 0.0362 - mse: 0.0018
27/27 [==============================] - 1s 35ms/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0033s). Check your callbacks.
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0102 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.01088
Epoch 4/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0431 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.0426 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0430
Epoch 5/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0436 - mae: 0.0412 - mse: 0.0024 - val_loss: 0.0424 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0430
Epoch 6/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0424 - mae: 0.0385 - mse: 0.0020
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.021508581936359406.
27/27 [==============================] - 0s 2ms/step - loss: 0.0435 - mae: 0.0391 - mse: 0.0021 - val_loss: 0.0420 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0430
Epoch 7/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0036 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 8/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0128 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0284 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0215
Epoch 9/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0123 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0149 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 10/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0124 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0128 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0215
Epoch 11/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0128 - mae: 0.0378 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.010754290968179703.
27/27 [==============================] - 0s 2ms/step - loss: 0.0123 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0124 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0215
Epoch 12/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0108
Epoch 13/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0102 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.01088
Epoch 14/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0054 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0108
Epoch 15/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0047 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 16/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0046 - mae: 0.0376 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.005377145484089851.
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0045 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 17/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0045 - mae: 0.0374 - mse: 0.0019
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0004s). Check your callbacks.
 1/27 [>.............................] - ETA: 0s - loss: 0.0122 - mae: 0.0363 - mse: 0.0018.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0054
Epoch 18/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0042 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0054
Epoch 19/20
27/27 [==============================] - 0s 1ms/step - loss: 0.0026 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0028 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 20/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0026 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
>Saved ../trained_models/models_segments_overlap_rmsprop_0.043017164098787176LR_[64, 64, 64]HN_144BS_5P_val_mseM_20epochs/model_5.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
27/27 [==============================] - 1s 6ms/step - loss: 0.3004 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0238 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0430
Epoch 2/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0372 - mae: 0.0392 - mse: 0.0021 - val_loss: 0.0420 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0430
Epoch 3/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0424 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0425 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0430
Epoch 4/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0432 - mae: 0.0390 - mse: 0.0021 - val_loss: 0.0439 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0430
Epoch 5/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0431 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0447 - val_mae: 0.0409 - val_mse: 0.0024 - lr: 0.0430
Epoch 6/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0448 - mae: 0.0430 - mse: 0.0025
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.021508581936359406.
27/27 [==============================] - 0s 2ms/step - loss: 0.0434 - mae: 0.0391 - mse: 0.0021 - val_loss: 0.0433 - val_mae: 0.0413 - val_mse: 0.0024 - lr: 0.0430
Epoch 7/20
27/27 [==============================] - 0s 1ms/step - loss: 0.0035 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0024 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 8/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0134 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0241 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0215
Epoch 9/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0119 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0150 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0215
Epoch 10/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0123 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0129 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 11/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0123 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0123 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 12/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0122 - mae: 0.0363 - mse: 0.0018.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0054
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.010754290968179703.
27/27 [==============================] - 0s 2ms/step - loss: 0.0122 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0122 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 13/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0108
Epoch 14/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0090 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 15/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0052 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0108
Epoch 16/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0046 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 17/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0046 - mae: 0.0391 - mse: 0.0020
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.005377145484089851.
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0045 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 18/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0046 - mae: 0.0390 - mse: 0.0020
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0045 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.01084
Epoch 19/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0043 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
Epoch 20/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0026 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0028 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0054
>Saved ../trained_models/models_segments_overlap_rmsprop_0.043017164098787176LR_[64, 64, 64]HN_144BS_5P_val_mseM_20epochs/model_6.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
27/27 [==============================] - 1s 5ms/step - loss: 0.2936 - mae: 0.0651 - mse: 0.0086 - val_loss: 0.0248 - val_mae: 0.0456 - val_mse: 0.0031 - lr: 0.0430
Epoch 2/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0389 - mae: 0.0458 - mse: 0.0031 - val_loss: 0.0484 - val_mae: 0.0422 - val_mse: 0.0025 - lr: 0.0430
Epoch 3/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0430 - mae: 0.0411 - mse: 0.0024 - val_loss: 0.0540 - val_mae: 0.0480 - val_mse: 0.0034 - lr: 0.0430
Epoch 4/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0432 - mae: 0.0396 - mse: 0.0022 - val_loss: 0.0432 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0430
Epoch 5/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0431 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0431 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0430
Epoch 6/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0433 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.0429 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0430
Epoch 7/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0431 - mae: 0.0388 - mse: 0.0021 - val_loss: 0.0433 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0430
Epoch 8/20
27/27 [==============================] - 0s 3ms/step - loss: 0.0432 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0448 - val_mae: 0.0418 - val_mse: 0.0025 - lr: 0.0430
Epoch 9/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0445 - mae: 0.0393 - mse: 0.0022
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.021508581936359406.
27/27 [==============================] - 0s 2ms/step - loss: 0.0432 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0429 - val_mae: 0.0389 - val_mse: 0.0020 - lr: 0.0430
Epoch 10/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 11/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0126 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0247 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 12/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0124 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0142 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 13/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0123 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0127 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 14/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0125 - mae: 0.0360 - mse: 0.0018
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.010754290968179703.
27/27 [==============================] - 0s 2ms/step - loss: 0.0123 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0124 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 15/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 16/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0047 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0089 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 17/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0054 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0108
Epoch 18/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0047 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0108
Epoch 19/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0047 - mae: 0.0394 - mse: 0.0020
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.005377145484089851.
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0045 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.01084
Epoch 20/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0020 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0054
>Saved ../trained_models/models_segments_overlap_rmsprop_0.043017164098787176LR_[64, 64, 64]HN_144BS_5P_val_mseM_20epochs/model_7.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
27/27 [==============================] - 1s 5ms/step - loss: 0.3055 - mae: 0.0703 - mse: 0.0100 - val_loss: 0.0277 - val_mae: 0.0468 - val_mse: 0.0032 - lr: 0.0430
Epoch 2/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0411 - mae: 0.0496 - mse: 0.0037 - val_loss: 0.0446 - val_mae: 0.0510 - val_mse: 0.0039 - lr: 0.0430
Epoch 3/20
27/27 [==============================] - 0s 1ms/step - loss: 0.0455 - mae: 0.0481 - mse: 0.0034 - val_loss: 0.0459 - val_mae: 0.0441 - val_mse: 0.0028 - lr: 0.0430
Epoch 4/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0452 - mae: 0.0447 - mse: 0.0029 - val_loss: 0.0412 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0430
Epoch 5/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0434 - mae: 0.0399 - mse: 0.0022 - val_loss: 0.0419 - val_mae: 0.0389 - val_mse: 0.0020 - lr: 0.0430
Epoch 6/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0429 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0432 - val_mae: 0.0389 - val_mse: 0.0020 - lr: 0.0430
Epoch 7/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0433 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0423 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0430
Epoch 8/20
27/27 [==============================] - 0s 1ms/step - loss: 0.0431 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0428 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0430
Epoch 9/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0431 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0423 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0430
Epoch 10/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0431 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0425 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0430
Epoch 11/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0431 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0427 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0430
Epoch 12/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0428 - mae: 0.0406 - mse: 0.0021
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.021508581936359406.
27/27 [==============================] - 0s 2ms/step - loss: 0.0431 - mae: 0.0383 - mse: 0.0020 - val_loss: 0.0457 - val_mae: 0.0393 - val_mse: 0.0021 - lr: 0.0430
Epoch 13/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0036 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 14/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0118 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0295 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 15/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0125 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0144 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 16/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0123 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0125 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0215
Epoch 17/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0124 - mae: 0.0380 - mse: 0.0019
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.010754290968179703.
27/27 [==============================] - 0s 2ms/step - loss: 0.0122 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0122 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0215
Epoch 18/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 19/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0101 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 20/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0054 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
>Saved ../trained_models/models_segments_overlap_rmsprop_0.043017164098787176LR_[64, 64, 64]HN_144BS_5P_val_mseM_20epochs/model_8.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
27/27 [==============================] - 1s 5ms/step - loss: 0.2969 - mae: 0.0689 - mse: 0.0122 - val_loss: 0.0264 - val_mae: 0.0429 - val_mse: 0.0027 - lr: 0.0430
Epoch 2/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0404 - mae: 0.0457 - mse: 0.0031 - val_loss: 0.0534 - val_mae: 0.0632 - val_mse: 0.0058 - lr: 0.0430
Epoch 3/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0465 - mae: 0.0491 - mse: 0.0036 - val_loss: 0.0509 - val_mae: 0.0668 - val_mse: 0.0063 - lr: 0.0430
Epoch 4/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0457 - mae: 0.0481 - mse: 0.0034 - val_loss: 0.0421 - val_mae: 0.0401 - val_mse: 0.0023 - lr: 0.0430
Epoch 5/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0455 - mae: 0.0457 - mse: 0.0031 - val_loss: 0.0437 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0430
Epoch 6/20
27/27 [==============================] - 0s 3ms/step - loss: 0.0442 - mae: 0.0424 - mse: 0.0026 - val_loss: 0.0429 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0430
Epoch 7/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0442 - mae: 0.0421 - mse: 0.0025 - val_loss: 0.0510 - val_mae: 0.0465 - val_mse: 0.0032 - lr: 0.0430
Epoch 8/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0438 - mae: 0.0403 - mse: 0.0023 - val_loss: 0.0434 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0430
Epoch 9/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0432 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0427 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0430
Epoch 10/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0427 - mae: 0.0393 - mse: 0.0020
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.021508581936359406.
27/27 [==============================] - 0s 2ms/step - loss: 0.0432 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0426 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0430
Epoch 11/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0035 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0215
Epoch 12/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0123 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0241 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0215
Epoch 13/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0125 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0141 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 14/20
27/27 [==============================] - 0s 1ms/step - loss: 0.0124 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0125 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 15/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0123 - mae: 0.0362 - mse: 0.0018
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.010754290968179703.
27/27 [==============================] - 0s 2ms/step - loss: 0.0123 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0122 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0215
Epoch 16/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0023 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 17/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0105 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0108
Epoch 18/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0055 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0108
Epoch 19/20
27/27 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0047 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0108
Epoch 20/20
 1/27 [>.............................] - ETA: 0s - loss: 0.0045 - mae: 0.0365 - mse: 0.0018
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.005377145484089851.
27/27 [==============================] - 0s 3ms/step - loss: 0.0045 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0046 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0108
>Saved ../trained_models/models_segments_overlap_rmsprop_0.043017164098787176LR_[64, 64, 64]HN_144BS_5P_val_mseM_20epochs/model_9.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0001s). Check your callbacks.