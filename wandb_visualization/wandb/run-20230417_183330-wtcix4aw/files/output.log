Epoch 1/30
191/243 [======================>.......] - ETA: 0s - loss: 0.0155 - mae: 0.0474 - mse: 0.0040
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
243/243 [==============================] - 1s 5ms/step - loss: 0.0139 - mae: 0.0455 - mse: 0.0036 - val_loss: 0.0087 - val_mae: 0.0416 - val_mse: 0.0025 - lr: 0.0962
Epoch 2/30
199/243 [=======================>......] - ETA: 0s - loss: 0.0083 - mae: 0.0386 - mse: 0.0020
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183330-wtcix4aw\files\model-best)... Done. 0.0s
243/243 [==============================] - 5s 21ms/step - loss: 0.0083 - mae: 0.0388 - mse: 0.0020 - val_loss: 0.0083 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0962
Epoch 3/30
243/243 [==============================] - 0s 913us/step - loss: 0.0083 - mae: 0.0386 - mse: 0.0020 - val_loss: 0.0087 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0962
Epoch 4/30
243/243 [==============================] - 1s 6ms/step - loss: 0.0083 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0082 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0962
Epoch 5/30
168/243 [===================>..........] - ETA: 0s - loss: 0.0082 - mae: 0.0380 - mse: 0.0020
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.04811529070138931.
243/243 [==============================] - 0s 897us/step - loss: 0.0083 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0087 - val_mae: 0.0391 - val_mse: 0.0021 - lr: 0.0962
Epoch 6/30
163/243 [===================>..........] - ETA: 0s - loss: 0.0029 - mae: 0.0378 - mse: 0.0019
243/243 [==============================] - 1s 4ms/step - loss: 0.0029 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0030 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0481
Epoch 7/30
243/243 [==============================] - 0s 923us/step - loss: 0.0030 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0032 - val_mae: 0.0396 - val_mse: 0.0021 - lr: 0.0481
Epoch 8/30
164/243 [===================>..........] - ETA: 0s - loss: 0.0031 - mae: 0.0387 - mse: 0.0020
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.024057645350694656.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183330-wtcix4aw\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 3ms/step - loss: 0.0030 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0030 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0481
Epoch 9/30
239/243 [============================>.] - ETA: 0s - loss: 0.0022 - mae: 0.0379 - mse: 0.0019
243/243 [==============================] - 1s 4ms/step - loss: 0.0022 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0241
Epoch 10/30
243/243 [==============================] - 0s 908us/step - loss: 0.0022 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0023 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0241
Epoch 11/30
166/243 [===================>..........] - ETA: 0s - loss: 0.0022 - mae: 0.0380 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.012028822675347328.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183330-wtcix4aw\files\model-best)... Done. 0.0s
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230417_183330-wtcix4aw\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0241
Epoch 12/30
162/243 [===================>..........] - ETA: 0s - loss: 0.0020 - mae: 0.0383 - mse: 0.0019
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0120
Epoch 13/30
243/243 [==============================] - 0s 908us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0120
Epoch 14/30
243/243 [==============================] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.006014411337673664.
243/243 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0120
Epoch 15/30
214/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
243/243 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0060
Epoch 16/30
243/243 [==============================] - 0s 916us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0060
Epoch 17/30
241/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 17: ReduceLROnPlateau reducing learning rate to 0.003007205668836832.
243/243 [==============================] - 0s 996us/step - loss: 0.0019 - mae: 0.0378 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0060
Epoch 18/30
243/243 [==============================] - 0s 914us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0030
Epoch 19/30
243/243 [==============================] - 0s 922us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0030
Epoch 20/30
239/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.001503602834418416.
243/243 [==============================] - 0s 923us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0030
Epoch 21/30
167/243 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0373 - mse: 0.0019
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0015
Epoch 22/30
243/243 [==============================] - 0s 915us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 23/30
163/243 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 23: ReduceLROnPlateau reducing learning rate to 0.000751801417209208.
243/243 [==============================] - 0s 909us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0015
Epoch 24/30
243/243 [==============================] - 0s 916us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.5180e-04
Epoch 25/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.5180e-04
Epoch 26/30
167/243 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.000375900708604604.
243/243 [==============================] - 0s 902us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.5180e-04
Epoch 27/30
243/243 [==============================] - 0s 906us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.7590e-04
Epoch 28/30
243/243 [==============================] - 0s 928us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.7590e-04
Epoch 29/30
163/243 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 29: ReduceLROnPlateau reducing learning rate to 0.000187950354302302.
243/243 [==============================] - 0s 902us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.7590e-04
Epoch 30/30
243/243 [==============================] - 0s 908us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 1.8795e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.0962305780563334_30_16_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
323/323 [==============================] - 1s 1ms/step - loss: 0.0135 - mae: 0.0557 - mse: 0.0047 - val_loss: 0.0092 - val_mae: 0.0506 - val_mse: 0.0035 - lr: 0.0962
Epoch 2/30
323/323 [==============================] - 0s 900us/step - loss: 0.0102 - mae: 0.0522 - mse: 0.0038 - val_loss: 0.0096 - val_mae: 0.0520 - val_mse: 0.0037 - lr: 0.0962
Epoch 3/30
323/323 [==============================] - 0s 884us/step - loss: 0.0102 - mae: 0.0528 - mse: 0.0039 - val_loss: 0.0093 - val_mae: 0.0519 - val_mse: 0.0037 - lr: 0.0962
Epoch 4/30
243/323 [=====================>........] - ETA: 0s - loss: 0.0104 - mae: 0.0535 - mse: 0.0040
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.04811529070138931.
323/323 [==============================] - 0s 889us/step - loss: 0.0103 - mae: 0.0530 - mse: 0.0039 - val_loss: 0.0375 - val_mae: 0.1616 - val_mse: 0.0295 - lr: 0.0962
Epoch 5/30
323/323 [==============================] - 0s 902us/step - loss: 0.0047 - mae: 0.0513 - mse: 0.0036 - val_loss: 0.0045 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0481
Epoch 6/30
323/323 [==============================] - 0s 932us/step - loss: 0.0047 - mae: 0.0511 - mse: 0.0035 - val_loss: 0.0045 - val_mae: 0.0507 - val_mse: 0.0035 - lr: 0.0481
Epoch 7/30
323/323 [==============================] - ETA: 0s - loss: 0.0047 - mae: 0.0510 - mse: 0.0035
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.024057645350694656.
323/323 [==============================] - 0s 899us/step - loss: 0.0047 - mae: 0.0510 - mse: 0.0035 - val_loss: 0.0047 - val_mae: 0.0518 - val_mse: 0.0037 - lr: 0.0481
Epoch 8/30
323/323 [==============================] - 0s 954us/step - loss: 0.0037 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0241
Epoch 9/30
323/323 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0038 - val_mae: 0.0507 - val_mse: 0.0035 - lr: 0.0241
Epoch 10/30
278/323 [========================>.....] - ETA: 0s - loss: 0.0037 - mae: 0.0507 - mse: 0.0034
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.012028822675347328.
323/323 [==============================] - 0s 1ms/step - loss: 0.0037 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0037 - val_mae: 0.0505 - val_mse: 0.0034 - lr: 0.0241
Epoch 11/30
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0120
Epoch 12/30
323/323 [==============================] - 0s 980us/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0120
Epoch 13/30
246/323 [=====================>........] - ETA: 0s - loss: 0.0035 - mae: 0.0510 - mse: 0.0034
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.006014411337673664.
323/323 [==============================] - 0s 882us/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0120
Epoch 14/30
323/323 [==============================] - 0s 891us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0060
Epoch 15/30
323/323 [==============================] - 0s 881us/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0060
Epoch 16/30
249/323 [======================>.......] - ETA: 0s - loss: 0.0035 - mae: 0.0510 - mse: 0.0034
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.003007205668836832.
323/323 [==============================] - 0s 884us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0060
Epoch 17/30
323/323 [==============================] - 0s 955us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0030
Epoch 18/30
323/323 [==============================] - 0s 898us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0030
Epoch 19/30
304/323 [===========================>..] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.001503602834418416.
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0030
Epoch 20/30
323/323 [==============================] - 0s 937us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0015
Epoch 21/30
323/323 [==============================] - 0s 949us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0015
Epoch 22/30
287/323 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.000751801417209208.
323/323 [==============================] - 0s 983us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0015
Epoch 23/30
323/323 [==============================] - 0s 879us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 7.5180e-04
Epoch 24/30
323/323 [==============================] - 0s 939us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 7.5180e-04
Epoch 25/30
245/323 [=====================>........] - ETA: 0s - loss: 0.0034 - mae: 0.0502 - mse: 0.0034
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.000375900708604604.
323/323 [==============================] - 0s 895us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 7.5180e-04
Epoch 26/30
323/323 [==============================] - 0s 892us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.7590e-04
Epoch 27/30
323/323 [==============================] - 0s 910us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.7590e-04
Epoch 28/30
289/323 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.000187950354302302.
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.7590e-04
Epoch 29/30
323/323 [==============================] - 0s 913us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.8795e-04
Epoch 30/30
323/323 [==============================] - 0s 913us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.8795e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.0962305780563334_30_16_30epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0007s vs `on_train_batch_end` time: 0.0015s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0016s). Check your callbacks.
Epoch 1/30
243/243 [==============================] - 1s 1ms/step - loss: 0.0126 - mae: 0.0443 - mse: 0.0033 - val_loss: 0.0076 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0962
Epoch 2/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0090 - mae: 0.0425 - mse: 0.0027 - val_loss: 0.0079 - val_mae: 0.0389 - val_mse: 0.0020 - lr: 0.0962
Epoch 3/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0092 - mae: 0.0427 - mse: 0.0028 - val_loss: 0.0280 - val_mae: 0.1148 - val_mse: 0.0151 - lr: 0.0962
Epoch 4/30
162/243 [===================>..........] - ETA: 0s - loss: 0.0089 - mae: 0.0417 - mse: 0.0026
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.04811529070138931.
243/243 [==============================] - 0s 917us/step - loss: 0.0091 - mae: 0.0429 - mse: 0.0027 - val_loss: 0.0078 - val_mae: 0.0389 - val_mse: 0.0021 - lr: 0.0962
Epoch 5/30
243/243 [==============================] - 0s 915us/step - loss: 0.0030 - mae: 0.0388 - mse: 0.0021 - val_loss: 0.0030 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0481
Epoch 6/30
243/243 [==============================] - 0s 932us/step - loss: 0.0031 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.0028 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0481
Epoch 7/30
164/243 [===================>..........] - ETA: 0s - loss: 0.0031 - mae: 0.0390 - mse: 0.0021
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.024057645350694656.
243/243 [==============================] - 0s 910us/step - loss: 0.0031 - mae: 0.0389 - mse: 0.0021 - val_loss: 0.0030 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0481
Epoch 8/30
243/243 [==============================] - 0s 909us/step - loss: 0.0022 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0241
Epoch 9/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0241
Epoch 10/30
219/243 [==========================>...] - ETA: 0s - loss: 0.0023 - mae: 0.0384 - mse: 0.0020
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.012028822675347328.
243/243 [==============================] - 0s 978us/step - loss: 0.0022 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0023 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0241
Epoch 11/30
243/243 [==============================] - 0s 910us/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0120
Epoch 12/30
243/243 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0120
Epoch 13/30
231/243 [===========================>..] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.006014411337673664.
243/243 [==============================] - 0s 958us/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0120
Epoch 14/30
243/243 [==============================] - 0s 923us/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0060
Epoch 15/30
243/243 [==============================] - 0s 950us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0060
Epoch 16/30
223/243 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.003007205668836832.
243/243 [==============================] - 0s 984us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0060
Epoch 17/30
243/243 [==============================] - 0s 889us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0030
Epoch 18/30
243/243 [==============================] - 0s 930us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0030
Epoch 19/30
168/243 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.001503602834418416.
243/243 [==============================] - 0s 884us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0030
Epoch 20/30
243/243 [==============================] - 0s 912us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0015
Epoch 21/30
243/243 [==============================] - 0s 924us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0015
Epoch 22/30
239/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.000751801417209208.
243/243 [==============================] - 0s 932us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0015
Epoch 23/30
243/243 [==============================] - 0s 898us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.5180e-04
Epoch 24/30
243/243 [==============================] - 0s 923us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.5180e-04
Epoch 25/30
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.000375900708604604.
243/243 [==============================] - 0s 963us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 7.5180e-04
Epoch 26/30
243/243 [==============================] - 0s 891us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.7590e-04
Epoch 27/30
243/243 [==============================] - 0s 906us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.7590e-04
Epoch 28/30
166/243 [===================>..........] - ETA: 0s - loss: 0.0019 - mae: 0.0382 - mse: 0.0019
Epoch 28: ReduceLROnPlateau reducing learning rate to 0.000187950354302302.
243/243 [==============================] - 0s 891us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.7590e-04
Epoch 29/30
243/243 [==============================] - 0s 906us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.8795e-04
Epoch 30/30
243/243 [==============================] - 0s 903us/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.8795e-04
>Saved ../trained_models/models_segments_overlap-new-network-sigmoid-adam-8IN-20HN_rmsprop_0.0962305780563334_30_16_30epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
157/243 [==================>...........] - ETA: 0s - loss: 0.0150 - mae: 0.0460 - mse: 0.0037
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0012s). Check your callbacks.
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0007s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0022s). Check your callbacks.
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
236/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019