Epoch 1/30
241/243 [============================>.] - ETA: 0s - loss: 0.0323 - mae: 0.0492 - mse: 0.0060
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0034s). Check your callbacks.
243/243 [==============================] - 2s 8ms/step - loss: 0.0321 - mae: 0.0492 - mse: 0.0060 - val_loss: 0.0023 - val_mae: 0.0367 - val_mse: 0.0018 - lr: 0.0277
Epoch 2/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0377 - mse: 0.0020 - val_loss: 0.0026 - val_mae: 0.0380 - val_mse: 0.0021 - lr: 0.0277
Epoch 3/30
207/243 [========================>.....] - ETA: 0s - loss: 0.0022 - mae: 0.0361 - mse: 0.0019
243/243 [==============================] - 2s 7ms/step - loss: 0.0022 - mae: 0.0359 - mse: 0.0018 - val_loss: 0.0018 - val_mae: 0.0334 - val_mse: 0.0016 - lr: 0.0277
Epoch 4/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0343 - mse: 0.0017 - val_loss: 0.0036 - val_mae: 0.0483 - val_mse: 0.0034 - lr: 0.0277
Epoch 5/30
225/243 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0322 - mse: 0.0016
243/243 [==============================] - 2s 7ms/step - loss: 0.0019 - mae: 0.0318 - mse: 0.0015 - val_loss: 0.0016 - val_mae: 0.0284 - val_mse: 0.0012 - lr: 0.0277
Epoch 6/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0296 - mse: 0.0014 - val_loss: 0.0027 - val_mae: 0.0391 - val_mse: 0.0023 - lr: 0.0277
Epoch 7/30
223/243 [==========================>...] - ETA: 0s - loss: 0.0015 - mae: 0.0283 - mse: 0.0012
243/243 [==============================] - 2s 9ms/step - loss: 0.0015 - mae: 0.0280 - mse: 0.0012 - val_loss: 0.0015 - val_mae: 0.0290 - val_mse: 0.0013 - lr: 0.0277
Epoch 8/30
243/243 [==============================] - 1s 2ms/step - loss: 0.0015 - mae: 0.0284 - mse: 0.0013 - val_loss: 0.0021 - val_mae: 0.0359 - val_mse: 0.0019 - lr: 0.0277
Epoch 9/30
222/243 [==========================>...] - ETA: 0s - loss: 0.0014 - mae: 0.0266 - mse: 0.0011
243/243 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0253 - val_mse: 0.0010 - lr: 0.0277
Epoch 10/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0261 - mse: 0.0011 - val_loss: 0.0018 - val_mae: 0.0324 - val_mse: 0.0016 - lr: 0.0277
Epoch 11/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0258 - mse: 0.0011 - val_loss: 0.0021 - val_mae: 0.0363 - val_mse: 0.0020 - lr: 0.0277
Epoch 12/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0250 - mse: 0.0010 - val_loss: 0.0018 - val_mae: 0.0329 - val_mse: 0.0017 - lr: 0.0277
Epoch 13/30
243/243 [==============================] - ETA: 0s - loss: 0.0012 - mae: 0.0248 - mse: 0.0010
243/243 [==============================] - 2s 8ms/step - loss: 0.0012 - mae: 0.0248 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0238 - val_mse: 9.2560e-04 - lr: 0.0277
Epoch 14/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0236 - mse: 9.1660e-04 - val_loss: 0.0011 - val_mae: 0.0250 - val_mse: 0.0010 - lr: 0.0277
Epoch 15/30
228/243 [===========================>..] - ETA: 0s - loss: 0.0011 - mae: 0.0241 - mse: 9.6416e-04
243/243 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0242 - mse: 9.6651e-04 - val_loss: 0.0010 - val_mae: 0.0226 - val_mse: 8.3653e-04 - lr: 0.0277
Epoch 16/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0239 - mse: 9.4189e-04 - val_loss: 0.0011 - val_mae: 0.0241 - val_mse: 9.2999e-04 - lr: 0.0277
Epoch 17/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0241 - mse: 9.4501e-04 - val_loss: 0.0011 - val_mae: 0.0238 - val_mse: 9.0986e-04 - lr: 0.0277
Epoch 18/30
221/243 [==========================>...] - ETA: 0s - loss: 0.0011 - mae: 0.0236 - mse: 9.1195e-04
Epoch 18: ReduceLROnPlateau reducing learning rate to 0.013866949826478958.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_225818-p2pliy6l\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 9ms/step - loss: 0.0011 - mae: 0.0236 - mse: 9.1242e-04 - val_loss: 0.0010 - val_mae: 0.0235 - val_mse: 8.9200e-04 - lr: 0.0277
Epoch 19/30
233/243 [===========================>..] - ETA: 0s - loss: 9.6112e-04 - mae: 0.0225 - mse: 8.3553e-04
243/243 [==============================] - 2s 7ms/step - loss: 9.5954e-04 - mae: 0.0225 - mse: 8.3385e-04 - val_loss: 9.5355e-04 - val_mae: 0.0230 - val_mse: 8.4401e-04 - lr: 0.0139
Epoch 20/30
233/243 [===========================>..] - ETA: 0s - loss: 9.4837e-04 - mae: 0.0223 - mse: 8.2775e-04
243/243 [==============================] - 2s 7ms/step - loss: 9.4734e-04 - mae: 0.0223 - mse: 8.2595e-04 - val_loss: 9.4640e-04 - val_mae: 0.0223 - val_mse: 8.0899e-04 - lr: 0.0139
Epoch 21/30
243/243 [==============================] - 1s 3ms/step - loss: 9.2837e-04 - mae: 0.0222 - mse: 8.1220e-04 - val_loss: 0.0010 - val_mae: 0.0233 - val_mse: 8.7086e-04 - lr: 0.0139
Epoch 22/30
238/243 [============================>.] - ETA: 0s - loss: 9.8248e-04 - mae: 0.0227 - mse: 8.5447e-04
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_225818-p2pliy6l\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 8ms/step - loss: 9.8118e-04 - mae: 0.0227 - mse: 8.5333e-04 - val_loss: 9.2383e-04 - val_mae: 0.0228 - val_mse: 8.2361e-04 - lr: 0.0139
Epoch 23/30
243/243 [==============================] - 2s 8ms/step - loss: 9.6036e-04 - mae: 0.0226 - mse: 8.3526e-04 - val_loss: 9.1453e-04 - val_mae: 0.0225 - val_mse: 8.2190e-04 - lr: 0.0139
Epoch 24/30
243/243 [==============================] - 1s 3ms/step - loss: 9.6695e-04 - mae: 0.0225 - mse: 8.3672e-04 - val_loss: 0.0012 - val_mae: 0.0252 - val_mse: 0.0010 - lr: 0.0139
Epoch 25/30
228/243 [===========================>..] - ETA: 0s - loss: 9.7666e-04 - mae: 0.0227 - mse: 8.4832e-04
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.006933474913239479.
243/243 [==============================] - 1s 3ms/step - loss: 9.6810e-04 - mae: 0.0226 - mse: 8.4091e-04 - val_loss: 9.7130e-04 - val_mae: 0.0233 - val_mse: 8.5380e-04 - lr: 0.0139
Epoch 26/30
237/243 [============================>.] - ETA: 0s - loss: 8.8565e-04 - mae: 0.0216 - mse: 7.7650e-04
243/243 [==============================] - 2s 9ms/step - loss: 8.8641e-04 - mae: 0.0216 - mse: 7.7776e-04 - val_loss: 9.0722e-04 - val_mae: 0.0226 - val_mse: 8.1267e-04 - lr: 0.0069
Epoch 27/30
243/243 [==============================] - 1s 3ms/step - loss: 8.7293e-04 - mae: 0.0214 - mse: 7.7051e-04 - val_loss: 0.0010 - val_mae: 0.0238 - val_mse: 9.1017e-04 - lr: 0.0069
Epoch 28/30
243/243 [==============================] - 1s 3ms/step - loss: 8.6223e-04 - mae: 0.0214 - mse: 7.6716e-04 - val_loss: 9.1636e-04 - val_mae: 0.0227 - val_mse: 8.1242e-04 - lr: 0.0069
Epoch 29/30
230/243 [===========================>..] - ETA: 0s - loss: 8.8605e-04 - mae: 0.0217 - mse: 7.8285e-04
243/243 [==============================] - 2s 7ms/step - loss: 8.8051e-04 - mae: 0.0217 - mse: 7.7843e-04 - val_loss: 8.9221e-04 - val_mae: 0.0222 - val_mse: 8.0755e-04 - lr: 0.0069
Epoch 30/30
217/243 [=========================>....] - ETA: 0s - loss: 8.6261e-04 - mae: 0.0214 - mse: 7.6441e-04
Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0034667374566197395.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_225818-p2pliy6l\files\model-best)... Done. 0.0s
243/243 [==============================] - 2s 7ms/step - loss: 8.6858e-04 - mae: 0.0215 - mse: 7.6958e-04 - val_loss: 8.6941e-04 - val_mae: 0.0216 - val_mse: 7.6003e-04 - lr: 0.0069
>Saved ../trained_models/models_segments_overlap_adam_0.027733900232875353LR_[33]HN_16BS_5P_val_mseM_30epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/30
323/323 [==============================] - 2s 3ms/step - loss: 0.0220 - mae: 0.0552 - mse: 0.0047 - val_loss: 0.0038 - val_mae: 0.0497 - val_mse: 0.0034 - lr: 0.0277
Epoch 2/30
261/323 [=======================>......] - ETA: 0s - loss: 0.0037 - mae: 0.0500 - mse: 0.0034
323/323 [==============================] - 1s 3ms/step - loss: 0.0037 - mae: 0.0501 - mse: 0.0034 - val_loss: 0.0033 - val_mae: 0.0476 - val_mse: 0.0031 - lr: 0.0277
Epoch 3/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0032 - mae: 0.0456 - mse: 0.0029 - val_loss: 0.0038 - val_mae: 0.0473 - val_mse: 0.0032 - lr: 0.0277
Epoch 4/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0028 - mae: 0.0401 - mse: 0.0024 - val_loss: 0.0039 - val_mae: 0.0480 - val_mse: 0.0033 - lr: 0.0277
Epoch 5/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0024 - mae: 0.0357 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0318 - val_mse: 0.0017 - lr: 0.0277
Epoch 6/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0022 - mae: 0.0345 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0307 - val_mse: 0.0016 - lr: 0.0277
Epoch 7/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0331 - mse: 0.0018 - val_loss: 0.0020 - val_mae: 0.0323 - val_mse: 0.0017 - lr: 0.0277
Epoch 8/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0021 - mae: 0.0328 - mse: 0.0018 - val_loss: 0.0018 - val_mae: 0.0304 - val_mse: 0.0016 - lr: 0.0277
Epoch 9/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0329 - mse: 0.0017 - val_loss: 0.0018 - val_mae: 0.0290 - val_mse: 0.0014 - lr: 0.0277
Epoch 10/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0320 - mse: 0.0016 - val_loss: 0.0017 - val_mae: 0.0294 - val_mse: 0.0015 - lr: 0.0277
Epoch 11/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0308 - mse: 0.0015 - val_loss: 0.0017 - val_mae: 0.0290 - val_mse: 0.0014 - lr: 0.0277
Epoch 12/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0303 - mse: 0.0015 - val_loss: 0.0028 - val_mae: 0.0412 - val_mse: 0.0026 - lr: 0.0277
Epoch 13/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0304 - mse: 0.0015 - val_loss: 0.0015 - val_mae: 0.0277 - val_mse: 0.0013 - lr: 0.0277
Epoch 14/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0298 - mse: 0.0015 - val_loss: 0.0027 - val_mae: 0.0403 - val_mse: 0.0025 - lr: 0.0277
Epoch 15/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0017 - mae: 0.0302 - mse: 0.0015 - val_loss: 0.0015 - val_mae: 0.0267 - val_mse: 0.0012 - lr: 0.0277
Epoch 16/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0293 - mse: 0.0014 - val_loss: 0.0019 - val_mae: 0.0335 - val_mse: 0.0018 - lr: 0.0277
Epoch 17/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0295 - mse: 0.0014 - val_loss: 0.0023 - val_mae: 0.0368 - val_mse: 0.0021 - lr: 0.0277
Epoch 18/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0295 - mse: 0.0014 - val_loss: 0.0023 - val_mae: 0.0368 - val_mse: 0.0021 - lr: 0.0277
Epoch 19/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0295 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0281 - val_mse: 0.0013 - lr: 0.0277
Epoch 20/30
302/323 [===========================>..] - ETA: 0s - loss: 0.0017 - mae: 0.0295 - mse: 0.0014
Epoch 20: ReduceLROnPlateau reducing learning rate to 0.013866949826478958.
323/323 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0295 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0281 - val_mse: 0.0013 - lr: 0.0277
Epoch 21/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0284 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0275 - val_mse: 0.0013 - lr: 0.0139
Epoch 22/30
323/323 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0284 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0266 - val_mse: 0.0012 - lr: 0.0139
Epoch 23/30
301/323 [==========================>...] - ETA: 0s - loss: 0.0015 - mae: 0.0283 - mse: 0.0013
323/323 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0282 - mse: 0.0013 - val_loss: 0.0028 - val_mae: 0.0424 - val_mse: 0.0027 - lr: 0.0139
Epoch 25/30
268/323 [=======================>......] - ETA: 0s - loss: 0.0015 - mae: 0.0286 - mse: 0.0013
323/323 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0276 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0284 - val_mse: 0.0013 - lr: 0.0069
Epoch 27/30
310/323 [===========================>..] - ETA: 0s - loss: 0.0014 - mae: 0.0275 - mse: 0.0012
320/323 [============================>.] - ETA: 0s - loss: 0.0014 - mae: 0.0278 - mse: 0.00130013 - val_loss: 0.0015 - val_mae: 0.0284 - val_mse: 0.0013 - lr: 0.0069
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.0278 - mse: 0.0013 - val_loss: 0.0013 - val_mae: 0.0266 - val_mse: 0.0012 - lr: 0.0069
Epoch 1/30
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.0278 - mse: 0.0013 - val_loss: 0.0013 - val_mae: 0.0266 - val_mse: 0.0012 - lr: 0.0069
 45/243 [====>.........................] - ETA: 0s - loss: 0.0020 - mae: 0.0387 - mse: 0.00200013 - val_loss: 0.0013 - val_mae: 0.0266 - val_mse: 0.0012 - lr: 0.0069
 47/243 [====>.........................] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0277
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0139
Epoch 9/30
  1/243 [..............................] - ETA: 0s - loss: 0.0023 - mae: 0.0443 - mse: 0.0023
233/243 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0139
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0069
Epoch 14/30
223/243 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
227/243 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0069
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0035
Epoch 19/30
240/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
225/243 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0035
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0017333687283098698.
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0035
Epoch 22/30
210/243 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0017
Epoch 24/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0017
Epoch 25/30
196/243 [=======================>......] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
146/243 [=================>............] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0017
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0008666843641549349.
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0017
Epoch 27/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.6668e-04
Epoch 28/30
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.6668e-04
Epoch 29/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 8.6668e-04
Epoch 30/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.6668e-04
>Saved ../trained_models/models_segments_overlap_adam_0.027733900232875353LR_[33]HN_16BS_5P_val_mseM_30epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.6668e-04
Epoch 1/30
241/243 [============================>.] - ETA: 0s - loss: 0.0252 - mae: 0.0382 - mse: 0.0020
243/243 [==============================] - 1s 4ms/step - loss: 0.0251 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0277
Epoch 2/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0277
Epoch 3/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0386 - val_mse: 0.0020 - lr: 0.0277
Epoch 4/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0277
Epoch 5/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0382 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0277
Epoch 6/30
233/243 [===========================>..] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0019
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.013866949826478958.
243/243 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0277
Epoch 7/30
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0139
Epoch 8/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0139
Epoch 9/30
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0139
Epoch 10/30
 66/243 [=======>......................] - ETA: 0s - loss: 0.0020 - mae: 0.0388 - mse: 0.0020
234/243 [===========================>..] - ETA: 0s - loss: 0.0020 - mae: 0.0382 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0139
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.006933474913239479.
243/243 [==============================] - 1s 2ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0139
Epoch 12/30
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0069
Epoch 13/30
210/243 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
  1/243 [..............................] - ETA: 0s - loss: 0.0012 - mae: 0.0289 - mse: 0.00120019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0069
Epoch 15/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0069
Epoch 16/30
227/243 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0034667374566197395.
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0069
Epoch 17/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0035
Epoch 18/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0035
Epoch 19/30
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0035
Epoch 20/30
106/243 [============>.................] - ETA: 0s - loss: 0.0019 - mae: 0.0373 - mse: 0.0019
228/243 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.00190019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0035
Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0017333687283098698.
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0035
Epoch 22/30
243/243 [==============================] - 1s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0017
Epoch 23/30
240/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0017
Epoch 25/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0017
Epoch 26/30
143/243 [================>.............] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.6668e-04
Epoch 28/30
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.6668e-04
Epoch 29/30
204/243 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.6668e-04
Epoch 1/30
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.6668e-04
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.6668e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0277e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0139e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0139e-04
236/243 [============================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0139e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0069e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0035e-04
242/243 [============================>.] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0035e-04
231/243 [===========================>..] - ETA: 0s - loss: 0.0018 - mae: 0.0357 - mse: 0.00170019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0035e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0018 - mae: 0.0356 - mse: 0.0017 - val_loss: 0.0018 - val_mae: 0.0350 - val_mse: 0.0017 - lr: 0.0017e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0318 - mse: 0.0015 - val_loss: 0.0016 - val_mae: 0.0313 - val_mse: 0.0014 - lr: 0.0017e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0318 - mse: 0.0015 - val_loss: 0.0016 - val_mae: 0.0313 - val_mse: 0.0014 - lr: 0.0017e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0318 - mse: 0.0015 - val_loss: 0.0016 - val_mae: 0.0313 - val_mse: 0.0014 - lr: 0.0017e-04
243/243 [==============================] - 1s 4ms/step - loss: 0.0274 - mae: 0.0388 - mse: 0.0021 - val_loss: 0.0021 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0277e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0277e-04
231/243 [===========================>..] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0277e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0021 - val_mae: 0.0388 - val_mse: 0.0020 - lr: 0.0139e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0139e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0382 - val_mse: 0.0019 - lr: 0.0069e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0376 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0035e-04
175/243 [====================>.........] - ETA: 0s - loss: 0.0013 - mae: 0.0259 - mse: 0.00110019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0035e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0257 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0253 - val_mse: 0.0011 - lr: 0.0035e-04
243/243 [==============================] - 1s 3ms/step - loss: 0.0011 - mae: 0.0239 - mse: 9.2322e-04 - val_loss: 0.0011 - val_mae: 0.0233 - val_mse: 8.9997e-04 - lr: 0.0035
243/243 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0232 - mse: 8.7709e-04 - val_loss: 0.0011 - val_mae: 0.0238 - val_mse: 9.2914e-04 - lr: 0.0035
243/243 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0232 - mse: 8.7709e-04 - val_loss: 0.0011 - val_mae: 0.0238 - val_mse: 9.2914e-04 - lr: 0.0035
243/243 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0232 - mse: 8.7709e-04 - val_loss: 0.0011 - val_mae: 0.0238 - val_mse: 9.2914e-04 - lr: 0.0035
243/243 [==============================] - 1s 3ms/step - loss: 0.0020 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0277: 0.0035
242/243 [============================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0380 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0277: 0.0035
224/243 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0385 - val_mse: 0.0020 - lr: 0.0277: 0.0035
217/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0139: 0.0035
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0069: 0.0035
218/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0069: 0.0035
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0035: 0.0035
243/243 [==============================] - 0s 2ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0017: 0.0035
216/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.00190019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0017: 0.0035
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.6668e-040035
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 8.6668e-040035
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_train_batch_end` time: 0.0034s). Check your callbacks.
243/243 [==============================] - 1s 3ms/step - loss: 0.0023 - mae: 0.0375 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0367 - val_mse: 0.0019 - lr: 0.0277e-040035
243/243 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0272 - mse: 0.0012 - val_loss: 0.0014 - val_mae: 0.0274 - val_mse: 0.0011 - lr: 0.0277e-040035
224/243 [==========================>...] - ETA: 0s - loss: 0.0012 - mae: 0.0257 - mse: 0.0011     - val_loss: 0.0014 - val_mae: 0.0274 - val_mse: 0.0011 - lr: 0.0277e-040035
243/243 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0256 - mse: 0.0010 - val_loss: 0.0014 - val_mae: 0.0271 - val_mse: 0.0011 - lr: 0.0277e-040035
243/243 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0253 - mse: 0.0010 - val_loss: 0.0010 - val_mae: 0.0238 - val_mse: 9.1575e-04 - lr: 0.02770035
243/243 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0236 - mse: 8.9806e-04 - val_loss: 0.0012 - val_mae: 0.0261 - val_mse: 0.0010 - lr: 0.01390035
243/243 [==============================] - 1s 2ms/step - loss: 9.8096e-04 - mae: 0.0232 - mse: 8.7496e-04 - val_loss: 9.7481e-04 - val_mae: 0.0234 - val_mse: 8.8036e-04 - lr: 0.0139
243/243 [==============================] - 1s 2ms/step - loss: 9.3985e-04 - mae: 0.0226 - mse: 8.4142e-04 - val_loss: 8.8329e-04 - val_mae: 0.0219 - val_mse: 7.9130e-04 - lr: 0.0069
234/243 [===========================>..] - ETA: 0s - loss: 8.8856e-04 - mae: 0.0220 - mse: 7.9607e-04e-04 - val_loss: 8.8329e-04 - val_mae: 0.0219 - val_mse: 7.9130e-04 - lr: 0.0069
234/243 [===========================>..] - ETA: 0s - loss: 8.8856e-04 - mae: 0.0220 - mse: 7.9607e-04e-04 - val_loss: 8.8329e-04 - val_mae: 0.0219 - val_mse: 7.9130e-04 - lr: 0.0069
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230420_225818-p2pliy6l\files\model-best)... Done. 0.0s
234/243 [===========================>..] - ETA: 0s - loss: 8.8856e-04 - mae: 0.0220 - mse: 7.9607e-04e-04 - val_loss: 8.8329e-04 - val_mae: 0.0219 - val_mse: 7.9130e-04 - lr: 0.0069
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])ae: 0.0220 - mse: 7.9607e-04e-04 - val_loss: 8.8329e-04 - val_mae: 0.0219 - val_mse: 7.9130e-04 - lr: 0.0069
243/243 [==============================] - 1s 3ms/step - loss: 0.0019 - mae: 0.0331 - mse: 0.0016 - val_loss: 0.0025 - val_mae: 0.0355 - val_mse: 0.0020 - lr: 0.0277-04 - lr: 0.0069
243/243 [==============================] - 1s 3ms/step - loss: 0.0016 - mae: 0.0308 - mse: 0.0014 - val_loss: 0.0020 - val_mae: 0.0341 - val_mse: 0.0018 - lr: 0.0277-04 - lr: 0.0069
240/243 [============================>.] - ETA: 0s - loss: 0.0015 - mae: 0.0297 - mse: 0.00130014 - val_loss: 0.0020 - val_mae: 0.0341 - val_mse: 0.0018 - lr: 0.0277-04 - lr: 0.0069
243/243 [==============================] - 1s 3ms/step - loss: 0.0015 - mae: 0.0297 - mse: 0.0013 - val_loss: 0.0013 - val_mae: 0.0275 - val_mse: 0.0011 - lr: 0.0277-04 - lr: 0.0069
243/243 [==============================] - 1s 3ms/step - loss: 0.0014 - mae: 0.0280 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0277 - val_mse: 0.0011 - lr: 0.0277-04 - lr: 0.0069
243/243 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0252 - val_mse: 0.0010 - lr: 0.0139-04 - lr: 0.0069
Epoch 23/30============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0264 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0252 - val_mse: 0.0010 - lr: 0.0139-04 - lr: 0.0069
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.006933474913239479.: 0.0264 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0252 - val_mse: 0.0010 - lr: 0.0139-04 - lr: 0.0069
Epoch 29/30educeLROnPlateau reducing learning rate to 0.006933474913239479.: 0.0264 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0252 - val_mse: 0.0010 - lr: 0.0139-04 - lr: 0.0069
>Saved ../trained_models/models_segments_overlap_adam_0.027733900232875353LR_[33]HN_16BS_5P_val_mseM_30epochs/model_9.h5al_mae: 0.0252 - val_mse: 0.0010 - lr: 0.0139-04 - lr: 0.0069
>Saved ../trained_models/models_segments_overlap_adam_0.027733900232875353LR_[33]HN_16BS_5P_val_mseM_30epochs/model_9.h5al_mae: 0.0252 - val_mse: 0.0010 - lr: 0.0139-04 - lr: 0.0069