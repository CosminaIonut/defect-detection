Epoch 1/150
54/54 [==============================] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
54/54 [==============================] - 3s 40ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0203
Epoch 2/150
54/54 [==============================] - 0s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0203
Epoch 3/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0203
Epoch 4/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0203
Epoch 5/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0203
Epoch 6/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0203
Epoch 7/150
54/54 [==============================] - 0s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0203
Epoch 8/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0203
Epoch 9/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0203
Epoch 10/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0203
Epoch 11/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0203
Epoch 12/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0203
Epoch 13/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0203
Epoch 14/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0203
Epoch 15/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0203
Epoch 16/150
48/54 [=========================>....] - ETA: 0s - loss: 0.8577 - mae: 0.9251 - mse: 0.8577 - root_mean_squared_error: 0.9261
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.010161164216697216.
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0203
Epoch 17/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0102
Epoch 18/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0102
Epoch 19/150
54/54 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0102
Epoch 20/150
54/54 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0102
Epoch 21/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0102
Epoch 22/150
54/54 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0102
Epoch 23/150
54/54 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0102
Epoch 24/150
54/54 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0102
Epoch 25/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0102
Epoch 26/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0102
Epoch 27/150
54/54 [==============================] - 0s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0102
Epoch 28/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0102
Epoch 29/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0102
Epoch 30/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0102
Epoch 31/150
47/54 [=========================>....] - ETA: 0s - loss: 0.8583 - mae: 0.9254 - mse: 0.8583 - root_mean_squared_error: 0.9264
Epoch 31: ReduceLROnPlateau reducing learning rate to 0.005080582108348608.
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0102
Epoch 32/150
54/54 [==============================] - 0s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0051
Epoch 33/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0051
Epoch 34/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0051
Epoch 35/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0051
Epoch 36/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0051
Epoch 37/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0051
Epoch 38/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0051
Epoch 39/150
54/54 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0051
Epoch 40/150
54/54 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0051
Epoch 41/150
54/54 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0051
Epoch 42/150
54/54 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0051
Epoch 43/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0051
Epoch 44/150
54/54 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0051
Epoch 45/150
54/54 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0051
Epoch 46/150
51/54 [===========================>..] - ETA: 0s - loss: 0.8578 - mae: 0.9251 - mse: 0.8578 - root_mean_squared_error: 0.9262
Epoch 46: ReduceLROnPlateau reducing learning rate to 0.002540291054174304.
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0051
Epoch 47/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0025
Epoch 48/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0025
Epoch 49/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0025
Epoch 50/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0025
Epoch 51/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0025
Epoch 52/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0025
Epoch 53/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0025
Epoch 54/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0025
Epoch 55/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0025
Epoch 56/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0025
Epoch 57/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0025
Epoch 58/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0025
Epoch 59/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0025
Epoch 60/150
54/54 [==============================] - 0s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0025
Epoch 61/150
25/54 [============>.................] - ETA: 0s - loss: 0.8558 - mae: 0.9241 - mse: 0.8558 - root_mean_squared_error: 0.9251
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0025
Epoch 62/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0013
Epoch 63/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0013
Epoch 64/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0013
Epoch 65/150
47/54 [=========================>....] - ETA: 0s - loss: 0.8580 - mae: 0.9252 - mse: 0.8580 - root_mean_squared_error: 0.9263
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0013
Epoch 69/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0013
Epoch 70/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0013
Epoch 71/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0013
Epoch 72/150
 1/54 [..............................] - ETA: 0s - loss: 0.8612 - mae: 0.9269 - mse: 0.8612 - root_mean_squared_error: 0.9280
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0013
Epoch 76/150
52/54 [===========================>..] - ETA: 0s - loss: 0.8578 - mae: 0.9251 - mse: 0.8578 - root_mean_squared_error: 0.9262
Epoch 76: ReduceLROnPlateau reducing learning rate to 0.000635072763543576.
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0013
Epoch 77/150
54/54 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 6.3507e-04
Epoch 78/150
40/54 [=====================>........] - ETA: 0s - loss: 0.8577 - mae: 0.9251 - mse: 0.8577 - root_mean_squared_error: 0.9261
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 6.3507e-04
Epoch 82/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 6.3507e-04
Epoch 83/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 6.3507e-04
Epoch 84/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 6.3507e-04
Epoch 85/150
14/54 [======>.......................] - ETA: 0s - loss: 0.8568 - mae: 0.9246 - mse: 0.8568 - root_mean_squared_error: 0.9257
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 6.3507e-04
Epoch 89/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 6.3507e-04
Epoch 90/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 6.3507e-04
Epoch 91/150
14/54 [======>.......................] - ETA: 0s - loss: 0.8609 - mae: 0.9268 - mse: 0.8609 - root_mean_squared_error: 0.9278
54/54 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.1754e-04
Epoch 95/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.1754e-04
Epoch 96/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.1754e-04
Epoch 97/150
47/54 [=========================>....] - ETA: 0s - loss: 0.8582 - mae: 0.9254 - mse: 0.8582 - root_mean_squared_error: 0.9264
54/54 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.1754e-04
Epoch 102/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.1754e-04
Epoch 103/150
54/54 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.1754e-04
Epoch 104/150
40/54 [=====================>........] - ETA: 0s - loss: 0.8575 - mae: 0.9249 - mse: 0.8575 - root_mean_squared_error: 0.9260
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.5877e-04
Epoch 108/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.5877e-04
Epoch 109/150
54/54 [==============================] - 0s 7ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.5877e-04
Epoch 110/150
47/54 [=========================>....] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.5877e-04
Epoch 115/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.5877e-04
Epoch 116/150
45/54 [========================>.....] - ETA: 0s - loss: 0.8572 - mae: 0.9248 - mse: 0.8572 - root_mean_squared_error: 0.9259
54/54 [==============================] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.92629262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.5877e-04
Epoch 121: ReduceLROnPlateau reducing learning rate to 7.9384095442947e-05.
54/54 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.5877e-04
Epoch 122/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 7.9384e-05
Epoch 123/150
39/54 [====================>.........] - ETA: 0s - loss: 0.8569 - mae: 0.9246 - mse: 0.8569 - root_mean_squared_error: 0.9257
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 7.9384e-05
Epoch 128/150
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 7.9384e-05
Epoch 129/150
46/54 [========================>.....] - ETA: 0s - loss: 0.8581 - mae: 0.9253 - mse: 0.8581 - root_mean_squared_error: 0.9263
54/54 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 7.9384e-05
Epoch 135/150
54/54 [==============================] - 0s 5ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 7.9384e-05
Epoch 136/150
14/54 [======>.......................] - ETA: 0s - loss: 0.8580 - mae: 0.9252 - mse: 0.8580 - root_mean_squared_error: 0.9263
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.9692e-05
Epoch 141/150
 1/54 [..............................] - ETA: 0s - loss: 0.8518 - mae: 0.9217 - mse: 0.8518 - root_mean_squared_error: 0.92299262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.9692e-05
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.9692e-05
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.9692e-05
54/54 [==============================] - 0s 6ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.9692e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
72/72 [==============================] - 0s 6ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0203e-05
72/72 [==============================] - 0s 6ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0203e-05
72/72 [==============================] - 0s 6ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0203e-05
72/72 [==============================] - ETA: 0s - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.80198019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0203e-05
72/72 [==============================] - 0s 6ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0102e-05
72/72 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0102e-05
72/72 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0051e-05
52/72 [====================>.........] - ETA: 0s - loss: 0.6430 - mae: 0.7998 - mse: 0.6430 - root_mean_squared_error: 0.80198019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0051e-05
72/72 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0051e-05
72/72 [==============================] - 0s 6ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0025e-05
72/72 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0025e-05
72/72 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0013e-05
 1/72 [..............................] - ETA: 0s - loss: 0.6355 - mae: 0.7946 - mse: 0.6355 - root_mean_squared_error: 0.79728019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0013e-05
72/72 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0013e-05
65/72 [==========================>...] - ETA: 0s - loss: 0.6427 - mae: 0.7996 - mse: 0.6427 - root_mean_squared_error: 0.80178019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 0.0013e-05
72/72 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 6.3507e-04
15/72 [=====>........................] - ETA: 0s - loss: 0.6398 - mae: 0.7977 - mse: 0.6398 - root_mean_squared_error: 0.79998019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 6.3507e-04
72/72 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 6.3507e-04
72/72 [==============================] - 0s 6ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 3.1754e-04
72/72 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 3.1754e-04
72/72 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
40/72 [===============>..............] - ETA: 0s - loss: 0.6432 - mae: 0.7999 - mse: 0.6432 - root_mean_squared_error: 0.80208019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
72/72 [==============================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 121/150========================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 126/150========================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 131/150========================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 136/150========================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 140/150========================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 145/150========================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 149/150========================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 149/150========================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230430_001845-btgu3w5g\files\model-best)... Done. 0.0s
Epoch 9/15050========================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 16/1500========================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 22/1500========================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 29/1500========================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 35/1500========================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 42/1500========================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 48/1500========================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 55/1500========================] - 0s 5ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 68/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 75/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 81/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 88/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 94/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 101/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 107/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 107/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 114/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 124/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 124/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 137/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 137/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 143/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 149/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 149/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230430_001845-btgu3w5g\files\model-best)... Done. 0.0s
Epoch 9/15050uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 16/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 22/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 29/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 35/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 42/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 48/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 55/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 68/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 75/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 81/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 88/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 94/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 101/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 107/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 114/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 121/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 127/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 134/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 140/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 147/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 147/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 147/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230430_001845-btgu3w5g\files\model-best)... Done. 0.0s
Epoch 9/15050uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 16/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 22/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 29/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 35/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 42/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 48/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 55/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 68/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 75/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 75/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 81/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 87/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 93/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 99/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 112/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 112/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 119/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 125/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 137/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 137/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 142/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 148/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 148/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230430_001845-btgu3w5g\files\model-best)... Done. 0.0s
Epoch 9/15050uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 22/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 22/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 29/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 35/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 42/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 48/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 55/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 68/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 75/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 81/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 81/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 99/150duceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 106/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 112/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 119/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 125/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 132/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 138/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 145/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 1/15050uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 1/15050uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230430_001845-btgu3w5g\files\model-best)... Done. 0.0s
Epoch 15/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 21/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 28/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 34/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 34/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 41/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 47/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 54/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 61/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 67/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 74/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 80/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 87/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 93/1500uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 100/150uceLROnPlateau reducing learning rate to 0.001270145527087152.0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 106: ReduceLROnPlateau reducing learning rate to 0.000158768190885894..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 113/150duceLROnPlateau reducing learning rate to 0.000158768190885894..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 120/150duceLROnPlateau reducing learning rate to 0.000158768190885894..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 126/150duceLROnPlateau reducing learning rate to 0.000158768190885894..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 133/150duceLROnPlateau reducing learning rate to 0.000158768190885894..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 139/150duceLROnPlateau reducing learning rate to 0.000158768190885894..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 146/150duceLROnPlateau reducing learning rate to 0.000158768190885894..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 146/150duceLROnPlateau reducing learning rate to 0.000158768190885894..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 146/150duceLROnPlateau reducing learning rate to 0.000158768190885894..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230430_001845-btgu3w5g\files\model-best)... Done. 0.0s
Epoch 9/15050duceLROnPlateau reducing learning rate to 0.000158768190885894..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 16/1500duceLROnPlateau reducing learning rate to 0.000158768190885894..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 22/1500duceLROnPlateau reducing learning rate to 0.000158768190885894..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 29/1500duceLROnPlateau reducing learning rate to 0.000158768190885894..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 35/1500duceLROnPlateau reducing learning rate to 0.000158768190885894..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 42/1500duceLROnPlateau reducing learning rate to 0.000158768190885894..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 48/1500duceLROnPlateau reducing learning rate to 0.000158768190885894..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 55/1500duceLROnPlateau reducing learning rate to 0.000158768190885894..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 68/150duceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 75/150duceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 81/150duceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 81/150duceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 87/150duceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 93/150duceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 99/150duceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 106/150uceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 112/150uceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 124/150uceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 124/150uceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 131/150uceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 136: ReduceLROnPlateau reducing learning rate to 3.96920477214735e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 143/150duceLROnPlateau reducing learning rate to 3.96920477214735e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 149/150duceLROnPlateau reducing learning rate to 3.96920477214735e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 149/150duceLROnPlateau reducing learning rate to 3.96920477214735e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 149/150duceLROnPlateau reducing learning rate to 3.96920477214735e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 9/15050duceLROnPlateau reducing learning rate to 3.96920477214735e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 16/1500duceLROnPlateau reducing learning rate to 3.96920477214735e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 22/1500duceLROnPlateau reducing learning rate to 3.96920477214735e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 29/1500duceLROnPlateau reducing learning rate to 3.96920477214735e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 35/1500duceLROnPlateau reducing learning rate to 3.96920477214735e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 42/1500duceLROnPlateau reducing learning rate to 3.96920477214735e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 48/1500duceLROnPlateau reducing learning rate to 3.96920477214735e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 55/1500duceLROnPlateau reducing learning rate to 3.96920477214735e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 61: ReduceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 68/150duceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 75/150duceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 94/150duceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 101/150uceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 107/150uceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 107/150uceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 114/150uceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 121/150uceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 127/150uceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 134/150uceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 140/150uceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 147/150uceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 147/150uceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04
Epoch 147/150uceLROnPlateau reducing learning rate to 0.001270145527087152...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.5877e-04