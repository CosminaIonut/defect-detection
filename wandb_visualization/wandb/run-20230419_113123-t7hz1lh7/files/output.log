Epoch 1/20
201/243 [=======================>......] - ETA: 0s - loss: 0.0144 - mae: 0.0463 - mse: 0.0040
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0007s vs `on_train_batch_end` time: 0.0018s). Check your callbacks.
243/243 [==============================] - 1s 4ms/step - loss: 0.0131 - mae: 0.0450 - mse: 0.0036 - val_loss: 0.0062 - val_mae: 0.0387 - val_mse: 0.0020 - lr: 0.0803
Epoch 2/20
207/243 [========================>.....] - ETA: 0s - loss: 0.0063 - mae: 0.0377 - mse: 0.0019
243/243 [==============================] - 1s 4ms/step - loss: 0.0064 - mae: 0.0379 - mse: 0.0020 - val_loss: 0.0060 - val_mae: 0.0373 - val_mse: 0.0019 - lr: 0.0803
Epoch 3/20
210/243 [========================>.....] - ETA: 0s - loss: 0.0063 - mae: 0.0373 - mse: 0.0019
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.04013668745756149.
243/243 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0373 - mse: 0.0019 - val_loss: 0.0088 - val_mae: 0.0395 - val_mse: 0.0021 - lr: 0.0803
Epoch 4/20
240/243 [============================>.] - ETA: 0s - loss: 0.0020 - mae: 0.0338 - mse: 0.0016
243/243 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0338 - mse: 0.0016 - val_loss: 0.0019 - val_mae: 0.0346 - val_mse: 0.0017 - lr: 0.0401
Epoch 5/20
243/243 [==============================] - 0s 1ms/step - loss: 0.0018 - mae: 0.0304 - mse: 0.0014 - val_loss: 0.0020 - val_mae: 0.0321 - val_mse: 0.0016 - lr: 0.0401
Epoch 6/20
222/243 [==========================>...] - ETA: 0s - loss: 0.0017 - mae: 0.0282 - mse: 0.0013
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_113123-t7hz1lh7\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0281 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0250 - val_mse: 9.8572e-04 - lr: 0.0401
Epoch 7/20
197/243 [=======================>......] - ETA: 0s - loss: 0.0017 - mae: 0.0278 - mse: 0.0012
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.020068343728780746.
243/243 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0276 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0254 - val_mse: 0.0010 - lr: 0.0401
Epoch 8/20
207/243 [========================>.....] - ETA: 0s - loss: 0.0012 - mae: 0.0244 - mse: 9.6183e-04
243/243 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0244 - mse: 9.7269e-04 - val_loss: 0.0011 - val_mae: 0.0230 - val_mse: 8.5419e-04 - lr: 0.0201
Epoch 9/20
204/243 [========================>.....] - ETA: 0s - loss: 0.0012 - mae: 0.0242 - mse: 9.5892e-04
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.010034171864390373.
243/243 [==============================] - 0s 1ms/step - loss: 0.0012 - mae: 0.0243 - mse: 9.6510e-04 - val_loss: 0.0014 - val_mae: 0.0258 - val_mse: 0.0011 - lr: 0.0201
Epoch 10/20
219/243 [==========================>...] - ETA: 0s - loss: 0.0010 - mae: 0.0230 - mse: 8.6471e-04
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.005017085932195187.
243/243 [==============================] - 0s 1ms/step - loss: 0.0010 - mae: 0.0230 - mse: 8.6342e-04 - val_loss: 0.0012 - val_mae: 0.0255 - val_mse: 0.0010 - lr: 0.0100
Epoch 11/20
216/243 [=========================>....] - ETA: 0s - loss: 9.4210e-04 - mae: 0.0224 - mse: 8.2652e-04
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0025085429660975933.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_113123-t7hz1lh7\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 4ms/step - loss: 9.4552e-04 - mae: 0.0224 - mse: 8.2856e-04 - val_loss: 9.9459e-04 - val_mae: 0.0230 - val_mse: 8.6630e-04 - lr: 0.0050
Epoch 12/20
207/243 [========================>.....] - ETA: 0s - loss: 9.2406e-04 - mae: 0.0222 - mse: 8.1566e-04
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0012542714830487967.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_113123-t7hz1lh7\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 4ms/step - loss: 9.2167e-04 - mae: 0.0221 - mse: 8.1291e-04 - val_loss: 9.6509e-04 - val_mae: 0.0227 - val_mse: 8.4407e-04 - lr: 0.0025
Epoch 13/20
206/243 [========================>.....] - ETA: 0s - loss: 8.9093e-04 - mae: 0.0217 - mse: 7.8828e-04
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0006271357415243983.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_113123-t7hz1lh7\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 4ms/step - loss: 9.1077e-04 - mae: 0.0220 - mse: 8.0749e-04 - val_loss: 9.2866e-04 - val_mae: 0.0226 - val_mse: 8.1963e-04 - lr: 0.0013
Epoch 14/20
197/243 [=======================>......] - ETA: 0s - loss: 9.1531e-04 - mae: 0.0220 - mse: 8.0631e-04
Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00031356787076219916.
243/243 [==============================] - 0s 1ms/step - loss: 9.0531e-04 - mae: 0.0219 - mse: 7.9837e-04 - val_loss: 9.3461e-04 - val_mae: 0.0230 - val_mse: 8.4196e-04 - lr: 6.2714e-04
Epoch 15/20
206/243 [========================>.....] - ETA: 0s - loss: 8.9454e-04 - mae: 0.0219 - mse: 7.9713e-04
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00015678393538109958.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_113123-t7hz1lh7\files\model-best)... Done. 0.0s
243/243 [==============================] - 0s 1ms/step - loss: 9.0250e-04 - mae: 0.0220 - mse: 8.0413e-04 - val_loss: 9.3392e-04 - val_mae: 0.0226 - val_mse: 8.3238e-04 - lr: 3.1357e-04
Epoch 16/20
212/243 [=========================>....] - ETA: 0s - loss: 9.0040e-04 - mae: 0.0219 - mse: 8.0013e-04
Epoch 16: ReduceLROnPlateau reducing learning rate to 7.839196769054979e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Disertatie\segments\wandb_visualization\wandb\run-20230419_113123-t7hz1lh7\files\model-best)... Done. 0.0s
243/243 [==============================] - 1s 4ms/step - loss: 9.0221e-04 - mae: 0.0219 - mse: 8.0209e-04 - val_loss: 9.2795e-04 - val_mae: 0.0226 - val_mse: 8.2911e-04 - lr: 1.5678e-04
Epoch 17/20
203/243 [========================>.....] - ETA: 0s - loss: 8.8977e-04 - mae: 0.0218 - mse: 7.9116e-04
Epoch 17: ReduceLROnPlateau reducing learning rate to 3.9195983845274895e-05.
243/243 [==============================] - 0s 1ms/step - loss: 9.0136e-04 - mae: 0.0219 - mse: 8.0272e-04 - val_loss: 9.2927e-04 - val_mae: 0.0226 - val_mse: 8.2949e-04 - lr: 7.8392e-05
Epoch 18/20
197/243 [=======================>......] - ETA: 0s - loss: 9.0670e-04 - mae: 0.0220 - mse: 8.0670e-04
Epoch 18: ReduceLROnPlateau reducing learning rate to 1.9597991922637448e-05.
243/243 [==============================] - 1s 4ms/step - loss: 9.0070e-04 - mae: 0.0219 - mse: 8.0087e-04 - val_loss: 9.2770e-04 - val_mae: 0.0226 - val_mse: 8.2890e-04 - lr: 3.9196e-05
Epoch 19/20
210/243 [========================>.....] - ETA: 0s - loss: 9.0026e-04 - mae: 0.0219 - mse: 8.0136e-04
Epoch 19: ReduceLROnPlateau reducing learning rate to 1e-05.
243/243 [==============================] - 0s 1ms/step - loss: 9.0059e-04 - mae: 0.0219 - mse: 8.0168e-04 - val_loss: 9.2805e-04 - val_mae: 0.0226 - val_mse: 8.2892e-04 - lr: 1.9598e-05
Epoch 20/20
243/243 [==============================] - 0s 1ms/step - loss: 9.0043e-04 - mae: 0.0219 - mse: 8.0135e-04 - val_loss: 9.2810e-04 - val_mae: 0.0226 - val_mse: 8.2890e-04 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.08027337664994234LR_[30]HN_16BS_1P_val_mseM_20epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
323/323 [==============================] - 1s 1ms/step - loss: 0.0119 - mae: 0.0542 - mse: 0.0043 - val_loss: 0.0093 - val_mae: 0.0516 - val_mse: 0.0037 - lr: 0.0803
Epoch 2/20
291/323 [==========================>...] - ETA: 0s - loss: 0.0080 - mae: 0.0522 - mse: 0.0037
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.04013668745756149.
323/323 [==============================] - 0s 1ms/step - loss: 0.0080 - mae: 0.0520 - mse: 0.0037 - val_loss: 0.0102 - val_mae: 0.0529 - val_mse: 0.0039 - lr: 0.0803
Epoch 3/20
323/323 [==============================] - 0s 1ms/step - loss: 0.0036 - mae: 0.0509 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0507 - val_mse: 0.0035 - lr: 0.0401
Epoch 4/20
293/323 [==========================>...] - ETA: 0s - loss: 0.0036 - mae: 0.0508 - mse: 0.0035
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.020068343728780746.
323/323 [==============================] - 0s 989us/step - loss: 0.0036 - mae: 0.0509 - mse: 0.0035 - val_loss: 0.0035 - val_mae: 0.0505 - val_mse: 0.0035 - lr: 0.0401
Epoch 5/20
298/323 [==========================>...] - ETA: 0s - loss: 0.0035 - mae: 0.0509 - mse: 0.0034
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.010034171864390373.
323/323 [==============================] - 0s 974us/step - loss: 0.0035 - mae: 0.0508 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0201
Epoch 6/20
289/323 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0509 - mse: 0.0034
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.005017085932195187.
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0507 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0100
Epoch 7/20
286/323 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0025085429660975933.
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0050
Epoch 8/20
286/323 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0012542714830487967.
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0504 - val_mse: 0.0034 - lr: 0.0025
Epoch 9/20
264/323 [=======================>......] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0006271357415243983.
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 0.0013
Epoch 10/20
295/323 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00031356787076219916.
323/323 [==============================] - 0s 987us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 6.2714e-04
Epoch 11/20
289/323 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00015678393538109958.
323/323 [==============================] - 0s 992us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.1357e-04
Epoch 12/20
291/323 [==========================>...] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034
Epoch 12: ReduceLROnPlateau reducing learning rate to 7.839196769054979e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.5678e-04
Epoch 13/20
281/323 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0506 - mse: 0.0034
Epoch 13: ReduceLROnPlateau reducing learning rate to 3.9195983845274895e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 7.8392e-05
Epoch 14/20
289/323 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0505 - mse: 0.0034
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.9597991922637448e-05.
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 3.9196e-05
Epoch 15/20
290/323 [=========================>....] - ETA: 0s - loss: 0.0034 - mae: 0.0507 - mse: 0.0034
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.
323/323 [==============================] - 0s 999us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.9598e-05
Epoch 16/20
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 17/20
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 18/20
323/323 [==============================] - 0s 993us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 19/20
323/323 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
Epoch 20/20
323/323 [==============================] - 0s 998us/step - loss: 0.0034 - mae: 0.0506 - mse: 0.0034 - val_loss: 0.0034 - val_mae: 0.0503 - val_mse: 0.0034 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.08027337664994234LR_[30]HN_16BS_1P_val_mseM_20epochs/model_2.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
243/243 [==============================] - 1s 2ms/step - loss: 0.0111 - mae: 0.0431 - mse: 0.0029 - val_loss: 0.0170 - val_mae: 0.0804 - val_mse: 0.0084 - lr: 0.0803
Epoch 2/20
243/243 [==============================] - 0s 1ms/step - loss: 0.0069 - mae: 0.0410 - mse: 0.0025 - val_loss: 0.0066 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0803
Epoch 3/20
212/243 [=========================>....] - ETA: 0s - loss: 0.0070 - mae: 0.0417 - mse: 0.0026
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.04013668745756149.
243/243 [==============================] - 0s 1ms/step - loss: 0.0070 - mae: 0.0415 - mse: 0.0026 - val_loss: 0.0060 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0803
Epoch 4/20
213/243 [=========================>....] - ETA: 0s - loss: 0.0021 - mae: 0.0384 - mse: 0.0020
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.020068343728780746.
243/243 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0384 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0401
Epoch 5/20
215/243 [=========================>....] - ETA: 0s - loss: 0.0020 - mae: 0.0382 - mse: 0.0020
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.010034171864390373.
243/243 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0020 - val_loss: 0.0020 - val_mae: 0.0384 - val_mse: 0.0020 - lr: 0.0201
Epoch 6/20
221/243 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.005017085932195187.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0100
Epoch 7/20
217/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0025085429660975933.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0050
Epoch 8/20
216/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0012542714830487967.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0025
Epoch 9/20
206/243 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0006271357415243983.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0013
Epoch 10/20
185/243 [=====================>........] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00031356787076219916.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 6.2714e-04
Epoch 11/20
178/243 [====================>.........] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00015678393538109958.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.1357e-04
Epoch 12/20
213/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 7.839196769054979e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.5678e-04
Epoch 13/20
222/243 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 13: ReduceLROnPlateau reducing learning rate to 3.9195983845274895e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 7.8392e-05
Epoch 14/20
218/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0378 - mse: 0.0019
Epoch 14: ReduceLROnPlateau reducing learning rate to 1.9597991922637448e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 3.9196e-05
Epoch 15/20
214/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 15: ReduceLROnPlateau reducing learning rate to 1e-05.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.9598e-05
Epoch 16/20
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 17/20
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 18/20
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 19/20
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
Epoch 20/20
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 1.0000e-05
>Saved ../trained_models/models_segments_overlap_rmsprop_0.08027337664994234LR_[30]HN_16BS_1P_val_mseM_20epochs/model_3.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
Epoch 1/20
243/243 [==============================] - 1s 1ms/step - loss: 0.0108 - mae: 0.0422 - mse: 0.0027 - val_loss: 0.0082 - val_mae: 0.0437 - val_mse: 0.0028 - lr: 0.0803
Epoch 2/20
210/243 [========================>.....] - ETA: 0s - loss: 0.0071 - mae: 0.0427 - mse: 0.0026
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.04013668745756149.
243/243 [==============================] - 0s 1ms/step - loss: 0.0070 - mae: 0.0423 - mse: 0.0026 - val_loss: 0.0092 - val_mae: 0.0480 - val_mse: 0.0034 - lr: 0.0803
Epoch 3/20
243/243 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0387 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0392 - val_mse: 0.0021 - lr: 0.0401
Epoch 4/20
218/243 [=========================>....] - ETA: 0s - loss: 0.0022 - mae: 0.0385 - mse: 0.0020
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.020068343728780746.
243/243 [==============================] - 0s 1ms/step - loss: 0.0022 - mae: 0.0385 - mse: 0.0020 - val_loss: 0.0033 - val_mae: 0.0453 - val_mse: 0.0030 - lr: 0.0401
Epoch 5/20
146/243 [=================>............] - ETA: 0s - loss: 0.0020 - mae: 0.0382 - mse: 0.0020
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0008s vs `on_train_batch_end` time: 0.0008s). Check your callbacks.
219/243 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.010034171864390373.
243/243 [==============================] - 0s 1ms/step - loss: 0.0020 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0390 - val_mse: 0.0021 - lr: 0.0201
Epoch 6/20
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0380 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0100
Epoch 7/20
220/243 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.005017085932195187.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0381 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0100
Epoch 8/20
219/243 [==========================>...] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0025085429660975933.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 0.0050
Epoch 9/20
206/243 [========================>.....] - ETA: 0s - loss: 0.0019 - mae: 0.0380 - mse: 0.0019
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0012542714830487967.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0025
Epoch 10/20
217/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0006271357415243983.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 0.0013
Epoch 11/20
214/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0377 - mse: 0.0019
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00031356787076219916.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0020 - val_mae: 0.0383 - val_mse: 0.0020 - lr: 6.2714e-04
Epoch 12/20
218/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0379 - mse: 0.0019
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00015678393538109958.
243/243 [==============================] - 0s 1ms/step - loss: 0.0019 - mae: 0.0379 - mse: 0.0019 - val_loss: 0.0019 - val_mae: 0.0383 - val_mse: 0.0019 - lr: 3.1357e-04
Epoch 13/20
217/243 [=========================>....] - ETA: 0s - loss: 0.0019 - mae: 0.0381 - mse: 0.0019
219/243 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020
219/243 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0009s vs `on_train_batch_end` time: 0.0018s). Check your callbacks.
219/243 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020
219/243 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020
219/243 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020
219/243 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0019s). Check your callbacks.
219/243 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020
219/243 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020
219/243 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0006s vs `on_train_batch_end` time: 0.0017s). Check your callbacks.
219/243 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020
219/243 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020
219/243 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0022s). Check your callbacks.
219/243 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020
219/243 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020
219/243 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020
219/243 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020
219/243 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020
219/243 [==========================>...] - ETA: 0s - loss: 0.0020 - mae: 0.0381 - mse: 0.0020