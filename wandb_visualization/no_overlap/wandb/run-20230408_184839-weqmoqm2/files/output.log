
Epoch 1/50

85/87 [============================>.] - ETA: 0s - loss: 2.6383 - mae: 0.1931 - mse: 0.2994
87/87 [==============================] - 8s 66ms/step - loss: 2.5829 - mae: 0.1909 - mse: 0.2932 - val_loss: 0.0935 - val_mae: 0.2052 - val_mse: 0.0430 - lr: 0.0100
Epoch 2/50
87/87 [==============================] - 1s 15ms/step - loss: 0.0624 - mae: 0.1317 - mse: 0.0257 - val_loss: 0.2757 - val_mae: 0.4588 - val_mse: 0.2114 - lr: 0.0100
Epoch 3/50
87/87 [==============================] - ETA: 0s - loss: 0.0647 - mae: 0.1067 - mse: 0.0259
87/87 [==============================] - 5s 60ms/step - loss: 0.0647 - mae: 0.1067 - mse: 0.0259 - val_loss: 0.0457 - val_mae: 0.0748 - val_mse: 0.0065 - lr: 0.0100
Epoch 4/50
87/87 [==============================] - 1s 16ms/step - loss: 0.0470 - mae: 0.0855 - mse: 0.0111 - val_loss: 0.0464 - val_mae: 0.0884 - val_mse: 0.0087 - lr: 0.0100
Epoch 5/50
86/87 [============================>.] - ETA: 0s - loss: 0.0526 - mae: 0.0894 - mse: 0.0155
87/87 [==============================] - 5s 60ms/step - loss: 0.0524 - mae: 0.0890 - mse: 0.0153 - val_loss: 0.0351 - val_mae: 0.0305 - val_mse: 0.0014 - lr: 0.0100
Epoch 6/50
87/87 [==============================] - 1s 16ms/step - loss: 0.0448 - mae: 0.0708 - mse: 0.0089 - val_loss: 0.0427 - val_mae: 0.0927 - val_mse: 0.0095 - lr: 0.0100
Epoch 7/50
87/87 [==============================] - 1s 14ms/step - loss: 0.0418 - mae: 0.0602 - mse: 0.0065 - val_loss: 0.0363 - val_mae: 0.0350 - val_mse: 0.0019 - lr: 0.0100
Epoch 8/50
86/87 [============================>.] - ETA: 0s - loss: 0.0366 - mae: 0.0363 - mse: 0.0020
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.
87/87 [==============================] - 1s 15ms/step - loss: 0.0366 - mae: 0.0362 - mse: 0.0020 - val_loss: 0.0355 - val_mae: 0.0300 - val_mse: 0.0013 - lr: 0.0100
Epoch 9/50

87/87 [==============================] - ETA: 0s - loss: 0.0067 - mae: 0.0269 - mse: 0.0010
87/87 [==============================] - 5s 59ms/step - loss: 0.0067 - mae: 0.0269 - mse: 0.0010 - val_loss: 0.0100 - val_mae: 0.0280 - val_mse: 0.0011 - lr: 0.0050
Epoch 10/50
83/87 [===========================>..] - ETA: 0s - loss: 0.0087 - mae: 0.0264 - mse: 9.7015e-04
87/87 [==============================] - 5s 60ms/step - loss: 0.0087 - mae: 0.0264 - mse: 9.7214e-04 - val_loss: 0.0088 - val_mae: 0.0263 - val_mse: 9.1307e-04 - lr: 0.0050
Epoch 11/50
87/87 [==============================] - ETA: 0s - loss: 0.0086 - mae: 0.0255 - mse: 8.8295e-04
87/87 [==============================] - 5s 56ms/step - loss: 0.0086 - mae: 0.0255 - mse: 8.8295e-04 - val_loss: 0.0087 - val_mae: 0.0266 - val_mse: 9.4653e-04 - lr: 0.0050
Epoch 12/50
86/87 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0254 - mse: 8.7530e-04
87/87 [==============================] - 6s 67ms/step - loss: 0.0086 - mae: 0.0254 - mse: 8.7377e-04 - val_loss: 0.0086 - val_mae: 0.0263 - val_mse: 9.1127e-04 - lr: 0.0050
Epoch 13/50
84/87 [===========================>..] - ETA: 0s - loss: 0.0086 - mae: 0.0255 - mse: 8.8467e-04
Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\no_overlap\wandb\run-20230408_184839-weqmoqm2\files\model-best)... Done. 0.1s
87/87 [==============================] - 5s 58ms/step - loss: 0.0086 - mae: 0.0255 - mse: 8.8194e-04 - val_loss: 0.0085 - val_mae: 0.0263 - val_mse: 9.1046e-04 - lr: 0.0050
Epoch 14/50
84/87 [===========================>..] - ETA: 0s - loss: 0.0023 - mae: 0.0253 - mse: 8.5815e-04
87/87 [==============================] - 5s 55ms/step - loss: 0.0023 - mae: 0.0253 - mse: 8.5895e-04 - val_loss: 0.0027 - val_mae: 0.0263 - val_mse: 9.1005e-04 - lr: 0.0025
Epoch 15/50
87/87 [==============================] - 1s 17ms/step - loss: 0.0028 - mae: 0.0253 - mse: 8.6059e-04 - val_loss: 0.0028 - val_mae: 0.0263 - val_mse: 9.1867e-04 - lr: 0.0025
Epoch 16/50
86/87 [============================>.] - ETA: 0s - loss: 0.0028 - mae: 0.0252 - mse: 8.5803e-04
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.
87/87 [==============================] - 1s 16ms/step - loss: 0.0028 - mae: 0.0253 - mse: 8.5868e-04 - val_loss: 0.0028 - val_mae: 0.0263 - val_mse: 9.1915e-04 - lr: 0.0025
Epoch 17/50
85/87 [============================>.] - ETA: 0s - loss: 0.0012 - mae: 0.0252 - mse: 8.5475e-04

87/87 [==============================] - 5s 57ms/step - loss: 0.0012 - mae: 0.0252 - mse: 8.5134e-04 - val_loss: 0.0014 - val_mae: 0.0263 - val_mse: 9.1183e-04 - lr: 0.0012
Epoch 18/50
83/87 [===========================>..] - ETA: 0s - loss: 0.0013 - mae: 0.0252 - mse: 8.5107e-04
87/87 [==============================] - 5s 59ms/step - loss: 0.0013 - mae: 0.0252 - mse: 8.5267e-04 - val_loss: 0.0014 - val_mae: 0.0263 - val_mse: 9.1450e-04 - lr: 0.0012
Epoch 19/50
84/87 [===========================>..] - ETA: 0s - loss: 0.0013 - mae: 0.0252 - mse: 8.5094e-04
Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.
87/87 [==============================] - 2s 17ms/step - loss: 0.0013 - mae: 0.0252 - mse: 8.5171e-04 - val_loss: 0.0014 - val_mae: 0.0264 - val_mse: 9.1901e-04 - lr: 0.0012
Epoch 20/50
83/87 [===========================>..] - ETA: 0s - loss: 9.2925e-04 - mae: 0.0252 - mse: 8.4979e-04
87/87 [==============================] - 5s 62ms/step - loss: 9.3298e-04 - mae: 0.0252 - mse: 8.5116e-04 - val_loss: 0.0010 - val_mae: 0.0263 - val_mse: 9.1007e-04 - lr: 6.2500e-04
Epoch 21/50
85/87 [============================>.] - ETA: 0s - loss: 9.6896e-04 - mae: 0.0252 - mse: 8.4969e-04
87/87 [==============================] - 5s 58ms/step - loss: 9.7020e-04 - mae: 0.0252 - mse: 8.5094e-04 - val_loss: 0.0010 - val_mae: 0.0263 - val_mse: 9.0998e-04 - lr: 6.2500e-04
Epoch 22/50
87/87 [==============================] - ETA: 0s - loss: 9.7047e-04 - mae: 0.0252 - mse: 8.5119e-04
Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.
87/87 [==============================] - 1s 16ms/step - loss: 9.7047e-04 - mae: 0.0252 - mse: 8.5119e-04 - val_loss: 0.0010 - val_mae: 0.0263 - val_mse: 9.1169e-04 - lr: 6.2500e-04
Epoch 23/50
83/87 [===========================>..] - ETA: 0s - loss: 8.6914e-04 - mae: 0.0252 - mse: 8.5050e-04
87/87 [==============================] - 5s 58ms/step - loss: 8.6853e-04 - mae: 0.0252 - mse: 8.4944e-04 - val_loss: 9.4334e-04 - val_mae: 0.0263 - val_mse: 9.1025e-04 - lr: 3.1250e-04
Epoch 24/50
86/87 [============================>.] - ETA: 0s - loss: 8.7794e-04 - mae: 0.0252 - mse: 8.4815e-04
87/87 [==============================] - 5s 62ms/step - loss: 8.7873e-04 - mae: 0.0252 - mse: 8.4894e-04 - val_loss: 9.4082e-04 - val_mae: 0.0263 - val_mse: 9.1101e-04 - lr: 3.1250e-04
Epoch 25/50
87/87 [==============================] - ETA: 0s - loss: 8.7961e-04 - mae: 0.0252 - mse: 8.4976e-04
Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\no_overlap\wandb\run-20230408_184839-weqmoqm2\files\model-best)... Done. 0.1s
87/87 [==============================] - 5s 54ms/step - loss: 8.7961e-04 - mae: 0.0252 - mse: 8.4976e-04 - val_loss: 9.3980e-04 - val_mae: 0.0263 - val_mse: 9.1001e-04 - lr: 3.1250e-04
Epoch 26/50
85/87 [============================>.] - ETA: 0s - loss: 8.5072e-04 - mae: 0.0251 - mse: 8.4644e-04
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\no_overlap\wandb\run-20230408_184839-weqmoqm2\files\model-best)... Done. 0.1s
87/87 [==============================] - 5s 60ms/step - loss: 8.5307e-04 - mae: 0.0252 - mse: 8.4873e-04 - val_loss: 9.1785e-04 - val_mae: 0.0263 - val_mse: 9.0996e-04 - lr: 1.5625e-04
Epoch 27/50
87/87 [==============================] - 5s 53ms/step - loss: 8.5634e-04 - mae: 0.0252 - mse: 8.4887e-04 - val_loss: 9.1733e-04 - val_mae: 0.0263 - val_mse: 9.0996e-04 - lr: 1.5625e-04
Epoch 28/50
85/87 [============================>.] - ETA: 0s - loss: 8.5623e-04 - mae: 0.0251 - mse: 8.4883e-04
Epoch 28: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.
87/87 [==============================] - 1s 16ms/step - loss: 8.5624e-04 - mae: 0.0252 - mse: 8.4885e-04 - val_loss: 9.1755e-04 - val_mae: 0.0263 - val_mse: 9.1011e-04 - lr: 1.5625e-04
Epoch 29/50
86/87 [============================>.] - ETA: 0s - loss: 8.5073e-04 - mae: 0.0252 - mse: 8.4965e-04
87/87 [==============================] - 6s 68ms/step - loss: 8.4964e-04 - mae: 0.0252 - mse: 8.4856e-04 - val_loss: 9.1202e-04 - val_mae: 0.0263 - val_mse: 9.0996e-04 - lr: 7.8125e-05
Epoch 30/50
87/87 [==============================] - ETA: 0s - loss: 8.5041e-04 - mae: 0.0252 - mse: 8.4858e-04
87/87 [==============================] - 5s 60ms/step - loss: 8.5041e-04 - mae: 0.0252 - mse: 8.4858e-04 - val_loss: 9.1180e-04 - val_mae: 0.0263 - val_mse: 9.0996e-04 - lr: 7.8125e-05
Epoch 31/50
84/87 [===========================>..] - ETA: 0s - loss: 8.5194e-04 - mae: 0.0252 - mse: 8.5008e-04
Epoch 31: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.
87/87 [==============================] - 1s 17ms/step - loss: 8.5036e-04 - mae: 0.0252 - mse: 8.4849e-04 - val_loss: 9.1185e-04 - val_mae: 0.0263 - val_mse: 9.0999e-04 - lr: 7.8125e-05
Epoch 32/50
85/87 [============================>.] - ETA: 0s - loss: 8.4351e-04 - mae: 0.0251 - mse: 8.4323e-04
87/87 [==============================] - 5s 57ms/step - loss: 8.4865e-04 - mae: 0.0252 - mse: 8.4836e-04 - val_loss: 9.1045e-04 - val_mae: 0.0263 - val_mse: 9.1000e-04 - lr: 3.9062e-05
Epoch 33/50
87/87 [==============================] - 2s 18ms/step - loss: 8.4874e-04 - mae: 0.0252 - mse: 8.4828e-04 - val_loss: 9.1048e-04 - val_mae: 0.0263 - val_mse: 9.1003e-04 - lr: 3.9062e-05
Epoch 34/50
85/87 [============================>.] - ETA: 0s - loss: 8.4649e-04 - mae: 0.0251 - mse: 8.4603e-04
Epoch 34: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.
87/87 [==============================] - 2s 17ms/step - loss: 8.4883e-04 - mae: 0.0252 - mse: 8.4837e-04 - val_loss: 9.1053e-04 - val_mae: 0.0263 - val_mse: 9.1008e-04 - lr: 3.9062e-05
Epoch 35/50
83/87 [===========================>..] - ETA: 0s - loss: 8.5078e-04 - mae: 0.0252 - mse: 8.5071e-04
87/87 [==============================] - 5s 57ms/step - loss: 8.4825e-04 - mae: 0.0252 - mse: 8.4817e-04 - val_loss: 9.1014e-04 - val_mae: 0.0263 - val_mse: 9.1001e-04 - lr: 1.9531e-05
Epoch 36/50
87/87 [==============================] - 1s 16ms/step - loss: 8.4834e-04 - mae: 0.0252 - mse: 8.4822e-04 - val_loss: 9.1015e-04 - val_mae: 0.0263 - val_mse: 9.1003e-04 - lr: 1.9531e-05
Epoch 37/50
87/87 [==============================] - ETA: 0s - loss: 8.4831e-04 - mae: 0.0252 - mse: 8.4820e-04
Epoch 37: ReduceLROnPlateau reducing learning rate to 1e-05.
87/87 [==============================] - 1s 16ms/step - loss: 8.4831e-04 - mae: 0.0252 - mse: 8.4820e-04 - val_loss: 9.1017e-04 - val_mae: 0.0263 - val_mse: 9.1005e-04 - lr: 1.9531e-05
Epoch 38/50

83/87 [===========================>..] - ETA: 0s - loss: 8.4726e-04 - mae: 0.0251 - mse: 8.4724e-04
87/87 [==============================] - 5s 59ms/step - loss: 8.4819e-04 - mae: 0.0252 - mse: 8.4817e-04 - val_loss: 9.1005e-04 - val_mae: 0.0263 - val_mse: 9.1002e-04 - lr: 1.0000e-05
Epoch 39/50
87/87 [==============================] - 1s 17ms/step - loss: 8.4819e-04 - mae: 0.0252 - mse: 8.4816e-04 - val_loss: 9.1005e-04 - val_mae: 0.0263 - val_mse: 9.1002e-04 - lr: 1.0000e-05
Epoch 40/50
85/87 [============================>.] - ETA: 0s - loss: 8.5085e-04 - mae: 0.0252 - mse: 8.5082e-04
87/87 [==============================] - 5s 58ms/step - loss: 8.4822e-04 - mae: 0.0252 - mse: 8.4819e-04 - val_loss: 9.1005e-04 - val_mae: 0.0263 - val_mse: 9.1002e-04 - lr: 1.0000e-05
Epoch 41/50
87/87 [==============================] - ETA: 0s - loss: 8.4820e-04 - mae: 0.0252 - mse: 8.4817e-04
85/87 [============================>.] - ETA: 0s - loss: 8.4748e-04 - mae: 0.0251 - mse: 8.4745e-047e-04 - val_loss: 9.1004e-04 - val_mae: 0.0263 - val_mse: 9.1001e-04 - lr: 1.0000e-05
Epoch 42/50
85/87 [============================>.] - ETA: 0s - loss: 8.4748e-04 - mae: 0.0251 - mse: 8.4745e-047e-04 - val_loss: 9.1004e-04 - val_mae: 0.0263 - val_mse: 9.1001e-04 - lr: 1.0000e-05
87/87 [==============================] - 2s 18ms/step - loss: 8.4819e-04 - mae: 0.0252 - mse: 8.4816e-04 - val_loss: 9.1003e-04 - val_mae: 0.0263 - val_mse: 9.1001e-04 - lr: 1.0000e-05
Epoch 43/50
87/87 [==============================] - 2s 18ms/step - loss: 8.4819e-04 - mae: 0.0252 - mse: 8.4816e-04 - val_loss: 9.1003e-04 - val_mae: 0.0263 - val_mse: 9.1001e-04 - lr: 1.0000e-05
Epoch 44/50
84/87 [===========================>..] - ETA: 0s - loss: 8.4996e-04 - mae: 0.0252 - mse: 8.4993e-04
86/87 [============================>.] - ETA: 0s - loss: 8.5076e-04 - mae: 0.0252 - mse: 8.5073e-047e-04 - val_loss: 9.1003e-04 - val_mae: 0.0263 - val_mse: 9.1000e-04 - lr: 1.0000e-05
Epoch 45/50
87/87 [==============================] - 1s 17ms/step - loss: 8.4819e-04 - mae: 0.0252 - mse: 8.4816e-04 - val_loss: 9.1003e-04 - val_mae: 0.0263 - val_mse: 9.1000e-04 - lr: 1.0000e-05
Epoch 46/50
86/87 [============================>.] - ETA: 0s - loss: 8.5076e-04 - mae: 0.0252 - mse: 8.5073e-047e-04 - val_loss: 9.1003e-04 - val_mae: 0.0263 - val_mse: 9.1000e-04 - lr: 1.0000e-05
87/87 [==============================] - 6s 66ms/step - loss: 8.4819e-04 - mae: 0.0252 - mse: 8.4816e-04 - val_loss: 9.1002e-04 - val_mae: 0.0263 - val_mse: 9.1000e-04 - lr: 1.0000e-05
Epoch 47/50
84/87 [===========================>..] - ETA: 0s - loss: 8.4911e-04 - mae: 0.0252 - mse: 8.4908e-04
87/87 [==============================] - 6s 66ms/step - loss: 8.4819e-04 - mae: 0.0252 - mse: 8.4816e-04 - val_loss: 9.1002e-04 - val_mae: 0.0263 - val_mse: 9.1000e-04 - lr: 1.0000e-05
84/87 [===========================>..] - ETA: 0s - loss: 8.4220e-04 - mae: 0.0251 - mse: 8.4218e-046e-04 - val_loss: 9.1002e-04 - val_mae: 0.0263 - val_mse: 9.1000e-04 - lr: 1.0000e-05
84/87 [===========================>..] - ETA: 0s - loss: 8.4220e-04 - mae: 0.0251 - mse: 8.4218e-046e-04 - val_loss: 9.1002e-04 - val_mae: 0.0263 - val_mse: 9.1000e-04 - lr: 1.0000e-05

87/87 [==============================] - 2s 18ms/step - loss: 8.4817e-04 - mae: 0.0252 - mse: 8.4813e-04 - val_loss: 9.1004e-04 - val_mae: 0.0263 - val_mse: 9.1001e-04 - lr: 1.0000e-05
>Saved ../../trained_models/models_segments_no_overlap-dropout-hiddenlayer30.0_50epochs/model_10.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])
87/87 [==============================] - 2s 18ms/step - loss: 8.4817e-04 - mae: 0.0252 - mse: 8.4813e-04 - val_loss: 9.1004e-04 - val_mae: 0.0263 - val_mse: 9.1001e-04 - lr: 1.0000e-05