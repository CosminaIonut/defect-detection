Epoch 1/150
45/45 [==============================] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
45/45 [==============================] - 8s 155ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0764
Epoch 2/150
44/45 [============================>.] - ETA: 0s - loss: 0.8580 - mae: 0.9252 - mse: 0.8580 - root_mean_squared_error: 0.9263
Epoch 2: ReduceLROnPlateau reducing learning rate to 0.03818824514746666.
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0764
Epoch 3/150
45/45 [==============================] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262
Epoch 3: ReduceLROnPlateau reducing learning rate to 0.01909412257373333.
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0382
Epoch 4/150
45/45 [==============================] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262
Epoch 4: ReduceLROnPlateau reducing learning rate to 0.009547061286866665.
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0191
Epoch 5/150
44/45 [============================>.] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262
Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0047735306434333324.
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0095
Epoch 6/150
45/45 [==============================] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262
Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0023867653217166662.
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0048
Epoch 7/150
36/45 [=======================>......] - ETA: 0s - loss: 0.8586 - mae: 0.9256 - mse: 0.8586 - root_mean_squared_error: 0.9266
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0011933826608583331.
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0024
Epoch 8/150
39/45 [=========================>....] - ETA: 0s - loss: 0.8572 - mae: 0.9248 - mse: 0.8572 - root_mean_squared_error: 0.9258
Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005966913304291666.
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 0.0012
Epoch 9/150
44/45 [============================>.] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002983456652145833.
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 5.9669e-04
Epoch 10/150
45/45 [==============================] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262
Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00014917283260729164.
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 2.9835e-04
Epoch 11/150
37/45 [=======================>......] - ETA: 0s - loss: 0.8593 - mae: 0.9259 - mse: 0.8593 - root_mean_squared_error: 0.9270
Epoch 11: ReduceLROnPlateau reducing learning rate to 7.458641630364582e-05.
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.4917e-04
Epoch 12/150
38/45 [========================>.....] - ETA: 0s - loss: 0.8584 - mae: 0.9254 - mse: 0.8584 - root_mean_squared_error: 0.9265
Epoch 12: ReduceLROnPlateau reducing learning rate to 3.729320815182291e-05.
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 7.4586e-05
Epoch 13/150
39/45 [=========================>....] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262
Epoch 13: ReduceLROnPlateau reducing learning rate to 1.8646604075911455e-05.
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 3.7293e-05
Epoch 14/150
37/45 [=======================>......] - ETA: 0s - loss: 0.8581 - mae: 0.9253 - mse: 0.8581 - root_mean_squared_error: 0.9263
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.8647e-05
Epoch 15/150
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 16/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 17/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 18/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 19/150
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 20/150
45/45 [==============================] - 0s 10ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 21/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 22/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 23/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 24/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 25/150
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 26/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 27/150
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 28/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 29/150
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 30/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 31/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 32/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 33/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 34/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 35/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 36/150
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 37/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 38/150
45/45 [==============================] - 0s 10ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 39/150
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 40/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 41/150
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 42/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 43/150
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 44/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 45/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 46/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 47/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 48/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 49/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 50/150
38/45 [========================>.....] - ETA: 0s - loss: 0.8587 - mae: 0.9256 - mse: 0.8587 - root_mean_squared_error: 0.9267
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 52/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 53/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 54/150
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 55/150
45/45 [==============================] - ETA: 0s - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 58/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 59/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 60/150
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 61/150
11/45 [======>.......................] - ETA: 0s - loss: 0.8594 - mae: 0.9259 - mse: 0.8594 - root_mean_squared_error: 0.9270
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 64/150
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 65/150
19/45 [===========>..................] - ETA: 0s - loss: 0.8580 - mae: 0.9252 - mse: 0.8580 - root_mean_squared_error: 0.9263
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 70/150
39/45 [=========================>....] - ETA: 0s - loss: 0.8581 - mae: 0.9253 - mse: 0.8581 - root_mean_squared_error: 0.9263
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
Epoch 76/150
11/45 [======>.......................] - ETA: 0s - loss: 0.8573 - mae: 0.9249 - mse: 0.8573 - root_mean_squared_error: 0.9259
40/45 [=========================>....] - ETA: 0s - loss: 0.8578 - mae: 0.9252 - mse: 0.8578 - root_mean_squared_error: 0.92629262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
36/45 [=======================>......] - ETA: 0s - loss: 0.8576 - mae: 0.9250 - mse: 0.8576 - root_mean_squared_error: 0.92619262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
45/45 [==============================] - 0s 8ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
45/45 [==============================] - 0s 9ms/step - loss: 0.8579 - mae: 0.9252 - mse: 0.8579 - root_mean_squared_error: 0.9262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
29/59 [=============>................] - ETA: 0s - loss: 0.6436 - mae: 0.8001 - mse: 0.6436 - root_mean_squared_error: 0.80229262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
53/59 [=========================>....] - ETA: 0s - loss: 0.6437 - mae: 0.8002 - mse: 0.6437 - root_mean_squared_error: 0.80239262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
52/59 [=========================>....] - ETA: 0s - loss: 0.6430 - mae: 0.7997 - mse: 0.6430 - root_mean_squared_error: 0.80189262 - val_loss: 0.8568 - val_mae: 0.9246 - val_mse: 0.8568 - val_root_mean_squared_error: 0.9256 - lr: 1.0000e-05
59/59 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
59/59 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
59/59 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
59/59 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
59/59 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
59/59 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
59/59 [==============================] - 1s 9ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
19/59 [========>.....................] - ETA: 0s - loss: 0.6424 - mae: 0.7994 - mse: 0.6424 - root_mean_squared_error: 0.80158019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
59/59 [==============================] - 1s 9ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
59/59 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
59/59 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
59/59 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
59/59 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
18/59 [========>.....................] - ETA: 0s - loss: 0.6485 - mae: 0.8032 - mse: 0.6485 - root_mean_squared_error: 0.80538019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
59/59 [==============================] - 1s 9ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
59/59 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
54/59 [==========================>...] - ETA: 0s - loss: 0.6420 - mae: 0.7991 - mse: 0.6420 - root_mean_squared_error: 0.80138019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
59/59 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
59/59 [==============================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 96/150=========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 100/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 104/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 108/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 112/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 117/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 120/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 124/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 127/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 130/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 134/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 137/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 141/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 145/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 149/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 149/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 149/150========================] - 0s 8ms/step - loss: 0.6431 - mae: 0.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 11: ReduceLROnPlateau reducing learning rate to 7.458641630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 20/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 26/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 32/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 38/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 44/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 50/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 56/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 56/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 62/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 68/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 74/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 80/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 80/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 86/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 92/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 98/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 104/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 116/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 122/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 127/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 133/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 138/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 143/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 148/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 148/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 148/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 38/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
44/45 [============================>.] - ETA: 0s - loss: 0.3328 - mae: 0.5752 - mse: 0.3328 - root_mean_squared_error: 0.5769
Epoch 38/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 44/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 50/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 56/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 62/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 68/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 74/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 80/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 80/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 86/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 92/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 98/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 104/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 116/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 116/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 122/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 128/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 134/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 140/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 146/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 1/15050uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 1/15050uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 1/15050uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0011933826608583331...7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 13: ReduceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 18/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 24/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 30/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 36/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 42/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 48/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 48/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 54/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 60/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 66/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 72/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 78/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 78/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 84/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 90/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 96/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 102/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 108/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 114/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 120/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 126/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 126/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 132/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 138/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 144/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 150/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 150/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 150/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 12: ReduceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 16/150duceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 22/150duceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 28/150duceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 34/150duceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 40/150duceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 40/150duceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 46/150duceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 52/150duceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 58/150duceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 64/150duceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 70/150duceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 76/150duceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 82/150duceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 82/150duceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 88/150duceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 94/150duceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 100/150uceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 106/150uceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 112/150uceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 118/150uceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 124/150uceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 130/150uceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 136/150uceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 136/150uceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 142/150uceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 148/150uceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 148/150uceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 148/150uceLROnPlateau reducing learning rate to 3.729320815182291e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 11: ReduceLROnPlateau reducing learning rate to 7.458641630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 14: ReduceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 20/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 26/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 32/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 38/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 44/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 44/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 50/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 56/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 62/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 68/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 74/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 80/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 86/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 92/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 92/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 98/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 104/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 116/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 116/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 122/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 128/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 128/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 134/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 140/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 146/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05..7998 - mse: 0.6431 - root_mean_squared_error: 0.8019 - val_loss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn_sgd_0.07637649241437211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
>Saved ../trained_models/CNN/models_segments_overlap-cnn_sgd_0.07637649241437211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
>Saved ../trained_models/CNN/models_segments_overlap-cnn_sgd_0.07637649241437211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 26/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 32/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 38/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 44/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 50/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 56/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 62/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 68/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 74/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 80/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 80/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 86/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 92/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 98/150duceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 104/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 104/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 110/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 116/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 122/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 128/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 134/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 140/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 140/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 146/150uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 1/15050uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 1/15050uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.
Epoch 1/15050uceLROnPlateau reducing learning rate to 1e-05.41630364582e-05.7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0011933826608583331..7211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 13: ReduceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 18/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 24/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 30/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 30/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 36/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 42/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 48/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 54/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 54/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 60/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 66/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 72/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 72/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 78/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 84/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 90/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 96/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 96/150duceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 102/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 108/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 113/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 119/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 123/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 128/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 133/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 138/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 143/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 148/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05
Epoch 148/150uceLROnPlateau reducing learning rate to 1.8646604075911455e-05.211LR_[37]CHN_8CNNI_88BS_1DU_1P_val_mseM_150epochs/model_7.h5ss: 0.6442 - val_mae: 0.8005 - val_mse: 0.6442 - val_root_mean_squared_error: 0.8026 - lr: 1.0000e-05