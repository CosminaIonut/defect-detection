wandb: WARNING The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0032s). Check your callbacks.
Epoch 1/50
79/86 [==========================>...] - ETA: 0s - loss: 0.1731 - mae: 0.4145 - mse: 0.1731
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\no_overlap\wandb\run-20230408_170545-5rkjzh0h\files\model-best)... Done. 0.0s
86/86 [==============================] - 2s 18ms/step - loss: 0.1709 - mae: 0.4118 - mse: 0.1709 - val_loss: 0.1396 - val_mae: 0.3724 - val_mse: 0.1396 - lr: 0.0010
Epoch 2/50
68/86 [======================>.......] - ETA: 0s - loss: 0.1149 - mae: 0.3370 - mse: 0.1149
86/86 [==============================] - 1s 14ms/step - loss: 0.1088 - mae: 0.3274 - mse: 0.1088 - val_loss: 0.0777 - val_mae: 0.2770 - val_mse: 0.0777 - lr: 0.0010
Epoch 3/50
57/86 [==================>...........] - ETA: 0s - loss: 0.0600 - mae: 0.2422 - mse: 0.0600
86/86 [==============================] - 1s 12ms/step - loss: 0.0528 - mae: 0.2258 - mse: 0.0528 - val_loss: 0.0308 - val_mae: 0.1723 - val_mse: 0.0308 - lr: 0.0010
Epoch 4/50
61/86 [====================>.........] - ETA: 0s - loss: 0.0206 - mae: 0.1389 - mse: 0.0206
86/86 [==============================] - 1s 15ms/step - loss: 0.0174 - mae: 0.1257 - mse: 0.0174 - val_loss: 0.0076 - val_mae: 0.0808 - val_mse: 0.0076 - lr: 0.0010
Epoch 5/50
30/86 [=========>....................] - ETA: 0s - loss: 0.0056 - mae: 0.0681 - mse: 0.0056
86/86 [==============================] - 1s 13ms/step - loss: 0.0036 - mae: 0.0502 - mse: 0.0036 - val_loss: 0.0014 - val_mae: 0.0306 - val_mse: 0.0014 - lr: 0.0010
Epoch 6/50
56/86 [==================>...........] - ETA: 0s - loss: 0.0010 - mae: 0.0264 - mse: 0.0010
86/86 [==============================] - 1s 14ms/step - loss: 9.7278e-04 - mae: 0.0262 - mse: 9.7278e-04 - val_loss: 9.4330e-04 - val_mae: 0.0268 - val_mse: 9.4330e-04 - lr: 0.0010
Epoch 7/50
85/86 [============================>.] - ETA: 0s - loss: 8.7933e-04 - mae: 0.0255 - mse: 8.7933e-04
86/86 [==============================] - 1s 12ms/step - loss: 8.7975e-04 - mae: 0.0255 - mse: 8.7975e-04 - val_loss: 9.3108e-04 - val_mae: 0.0266 - val_mse: 9.3108e-04 - lr: 0.0010
Epoch 8/50
72/86 [========================>.....] - ETA: 0s - loss: 8.7589e-04 - mae: 0.0256 - mse: 8.7589e-04
86/86 [==============================] - 1s 13ms/step - loss: 8.6920e-04 - mae: 0.0254 - mse: 8.6920e-04 - val_loss: 9.1838e-04 - val_mae: 0.0265 - val_mse: 9.1838e-04 - lr: 0.0010
Epoch 9/50
64/86 [=====================>........] - ETA: 0s - loss: 8.5608e-04 - mae: 0.0252 - mse: 8.5608e-04
Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\no_overlap\wandb\run-20230408_170545-5rkjzh0h\files\model-best)... Done. 0.0s
86/86 [==============================] - 1s 12ms/step - loss: 8.5957e-04 - mae: 0.0253 - mse: 8.5957e-04 - val_loss: 9.0944e-04 - val_mae: 0.0263 - val_mse: 9.0944e-04 - lr: 0.0010
Epoch 10/50
44/86 [==============>...............] - ETA: 0s - loss: 8.5662e-04 - mae: 0.0253 - mse: 8.5662e-04
86/86 [==============================] - 1s 13ms/step - loss: 8.5230e-04 - mae: 0.0252 - mse: 8.5230e-04 - val_loss: 9.0243e-04 - val_mae: 0.0263 - val_mse: 9.0243e-04 - lr: 5.0000e-04
Epoch 11/50
54/86 [=================>............] - ETA: 0s - loss: 8.4559e-04 - mae: 0.0251 - mse: 8.4559e-04
86/86 [==============================] - 1s 15ms/step - loss: 8.4773e-04 - mae: 0.0252 - mse: 8.4773e-04 - val_loss: 8.9692e-04 - val_mae: 0.0262 - val_mse: 8.9692e-04 - lr: 5.0000e-04
Epoch 12/50
60/86 [===================>..........] - ETA: 0s - loss: 8.4845e-04 - mae: 0.0252 - mse: 8.4845e-04
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\no_overlap\wandb\run-20230408_170545-5rkjzh0h\files\model-best)... Done. 0.0s
86/86 [==============================] - 1s 13ms/step - loss: 8.4387e-04 - mae: 0.0251 - mse: 8.4387e-04 - val_loss: 8.9246e-04 - val_mae: 0.0261 - val_mse: 8.9246e-04 - lr: 5.0000e-04
Epoch 13/50
75/86 [=========================>....] - ETA: 0s - loss: 8.4014e-04 - mae: 0.0250 - mse: 8.4014e-04
86/86 [==============================] - 1s 15ms/step - loss: 8.4053e-04 - mae: 0.0251 - mse: 8.4053e-04 - val_loss: 8.9010e-04 - val_mae: 0.0261 - val_mse: 8.9010e-04 - lr: 2.5000e-04
Epoch 14/50
60/86 [===================>..........] - ETA: 0s - loss: 8.2511e-04 - mae: 0.0248 - mse: 8.2511e-04
86/86 [==============================] - 1s 15ms/step - loss: 8.3865e-04 - mae: 0.0250 - mse: 8.3865e-04 - val_loss: 8.8835e-04 - val_mae: 0.0261 - val_mse: 8.8835e-04 - lr: 2.5000e-04
Epoch 15/50
42/86 [=============>................] - ETA: 0s - loss: 8.6446e-04 - mae: 0.0255 - mse: 8.6446e-04
Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\no_overlap\wandb\run-20230408_170545-5rkjzh0h\files\model-best)... Done. 0.0s
86/86 [==============================] - 1s 14ms/step - loss: 8.3680e-04 - mae: 0.0250 - mse: 8.3680e-04 - val_loss: 8.8610e-04 - val_mae: 0.0260 - val_mse: 8.8610e-04 - lr: 2.5000e-04
Epoch 16/50
55/86 [==================>...........] - ETA: 0s - loss: 8.4493e-04 - mae: 0.0251 - mse: 8.4493e-04
86/86 [==============================] - 1s 14ms/step - loss: 8.3542e-04 - mae: 0.0250 - mse: 8.3542e-04 - val_loss: 8.8492e-04 - val_mae: 0.0260 - val_mse: 8.8492e-04 - lr: 1.2500e-04
Epoch 17/50
57/86 [==================>...........] - ETA: 0s - loss: 8.3838e-04 - mae: 0.0251 - mse: 8.3838e-04
86/86 [==============================] - 1s 14ms/step - loss: 8.3468e-04 - mae: 0.0250 - mse: 8.3468e-04 - val_loss: 8.8393e-04 - val_mae: 0.0260 - val_mse: 8.8393e-04 - lr: 1.2500e-04
Epoch 18/50
79/86 [==========================>...] - ETA: 0s - loss: 8.4683e-04 - mae: 0.0252 - mse: 8.4683e-04
Epoch 18: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\no_overlap\wandb\run-20230408_170545-5rkjzh0h\files\model-best)... Done. 0.0s
86/86 [==============================] - 1s 14ms/step - loss: 8.3380e-04 - mae: 0.0250 - mse: 8.3380e-04 - val_loss: 8.8297e-04 - val_mae: 0.0260 - val_mse: 8.8297e-04 - lr: 1.2500e-04
Epoch 19/50
84/86 [============================>.] - ETA: 0s - loss: 8.3430e-04 - mae: 0.0250 - mse: 8.3430e-04
86/86 [==============================] - 1s 14ms/step - loss: 8.3302e-04 - mae: 0.0250 - mse: 8.3302e-04 - val_loss: 8.8250e-04 - val_mae: 0.0260 - val_mse: 8.8250e-04 - lr: 6.2500e-05
Epoch 20/50
72/86 [========================>.....] - ETA: 0s - loss: 8.3132e-04 - mae: 0.0249 - mse: 8.3132e-04
86/86 [==============================] - 1s 14ms/step - loss: 8.3266e-04 - mae: 0.0250 - mse: 8.3266e-04 - val_loss: 8.8206e-04 - val_mae: 0.0260 - val_mse: 8.8206e-04 - lr: 6.2500e-05
Epoch 21/50
82/86 [===========================>..] - ETA: 0s - loss: 8.3043e-04 - mae: 0.0249 - mse: 8.3043e-04
Epoch 21: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\no_overlap\wandb\run-20230408_170545-5rkjzh0h\files\model-best)... Done. 0.0s
86/86 [==============================] - 1s 13ms/step - loss: 8.3231e-04 - mae: 0.0249 - mse: 8.3231e-04 - val_loss: 8.8156e-04 - val_mae: 0.0260 - val_mse: 8.8156e-04 - lr: 6.2500e-05
Epoch 22/50
69/86 [=======================>......] - ETA: 0s - loss: 8.3803e-04 - mae: 0.0250 - mse: 8.3803e-04
86/86 [==============================] - 1s 13ms/step - loss: 8.3191e-04 - mae: 0.0249 - mse: 8.3191e-04 - val_loss: 8.8132e-04 - val_mae: 0.0260 - val_mse: 8.8132e-04 - lr: 3.1250e-05
Epoch 23/50
65/86 [=====================>........] - ETA: 0s - loss: 8.1742e-04 - mae: 0.0246 - mse: 8.1742e-04
86/86 [==============================] - 1s 13ms/step - loss: 8.3173e-04 - mae: 0.0249 - mse: 8.3173e-04 - val_loss: 8.8108e-04 - val_mae: 0.0260 - val_mse: 8.8108e-04 - lr: 3.1250e-05
Epoch 24/50
47/86 [===============>..............] - ETA: 0s - loss: 8.1416e-04 - mae: 0.0246 - mse: 8.1416e-04
Epoch 24: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\no_overlap\wandb\run-20230408_170545-5rkjzh0h\files\model-best)... Done. 0.0s
86/86 [==============================] - 1s 17ms/step - loss: 8.3154e-04 - mae: 0.0249 - mse: 8.3154e-04 - val_loss: 8.8085e-04 - val_mae: 0.0260 - val_mse: 8.8085e-04 - lr: 3.1250e-05
Epoch 25/50
68/86 [======================>.......] - ETA: 0s - loss: 8.3192e-04 - mae: 0.0249 - mse: 8.3192e-04
86/86 [==============================] - 1s 13ms/step - loss: 8.3136e-04 - mae: 0.0249 - mse: 8.3136e-04 - val_loss: 8.8072e-04 - val_mae: 0.0259 - val_mse: 8.8072e-04 - lr: 1.5625e-05
Epoch 26/50
68/86 [======================>.......] - ETA: 0s - loss: 8.3353e-04 - mae: 0.0250 - mse: 8.3353e-04
86/86 [==============================] - 1s 14ms/step - loss: 8.3126e-04 - mae: 0.0249 - mse: 8.3126e-04 - val_loss: 8.8061e-04 - val_mae: 0.0259 - val_mse: 8.8061e-04 - lr: 1.5625e-05
Epoch 27/50
75/86 [=========================>....] - ETA: 0s - loss: 8.3903e-04 - mae: 0.0250 - mse: 8.3903e-04
Epoch 27: ReduceLROnPlateau reducing learning rate to 1e-05.
wandb: Adding directory to artifact (C:\MyDocuments\Dizertatie\segments\wandb_visualization\no_overlap\wandb\run-20230408_170545-5rkjzh0h\files\model-best)... Done. 0.0s
86/86 [==============================] - 1s 14ms/step - loss: 8.3116e-04 - mae: 0.0249 - mse: 8.3116e-04 - val_loss: 8.8049e-04 - val_mae: 0.0259 - val_mse: 8.8049e-04 - lr: 1.5625e-05
Epoch 28/50
66/86 [======================>.......] - ETA: 0s - loss: 8.2676e-04 - mae: 0.0248 - mse: 8.2676e-04
86/86 [==============================] - 1s 14ms/step - loss: 8.3107e-04 - mae: 0.0249 - mse: 8.3107e-04 - val_loss: 8.8041e-04 - val_mae: 0.0259 - val_mse: 8.8041e-04 - lr: 1.0000e-05
Epoch 29/50
70/86 [=======================>......] - ETA: 0s - loss: 8.1652e-04 - mae: 0.0247 - mse: 8.1652e-04
86/86 [==============================] - 1s 15ms/step - loss: 8.3101e-04 - mae: 0.0249 - mse: 8.3101e-04 - val_loss: 8.8034e-04 - val_mae: 0.0259 - val_mse: 8.8034e-04 - lr: 1.0000e-05
Epoch 30/50
43/86 [==============>...............] - ETA: 0s - loss: 8.5853e-04 - mae: 0.0256 - mse: 8.5853e-04
86/86 [==============================] - 1s 12ms/step - loss: 8.3094e-04 - mae: 0.0249 - mse: 8.3094e-04 - val_loss: 8.8026e-04 - val_mae: 0.0259 - val_mse: 8.8026e-04 - lr: 1.0000e-05
Epoch 31/50
59/86 [===================>..........] - ETA: 0s - loss: 8.2596e-04 - mae: 0.0248 - mse: 8.2596e-04
86/86 [==============================] - 1s 13ms/step - loss: 8.3088e-04 - mae: 0.0249 - mse: 8.3088e-04 - val_loss: 8.8018e-04 - val_mae: 0.0259 - val_mse: 8.8018e-04 - lr: 1.0000e-05
Epoch 32/50
61/86 [====================>.........] - ETA: 0s - loss: 8.2679e-04 - mae: 0.0249 - mse: 8.2679e-04
86/86 [==============================] - 1s 14ms/step - loss: 8.3082e-04 - mae: 0.0249 - mse: 8.3082e-04 - val_loss: 8.8011e-04 - val_mae: 0.0259 - val_mse: 8.8011e-04 - lr: 1.0000e-05
Epoch 33/50
56/86 [==================>...........] - ETA: 0s - loss: 8.2622e-04 - mae: 0.0249 - mse: 8.2622e-04
86/86 [==============================] - 1s 12ms/step - loss: 8.3076e-04 - mae: 0.0249 - mse: 8.3076e-04 - val_loss: 8.8004e-04 - val_mae: 0.0259 - val_mse: 8.8004e-04 - lr: 1.0000e-05
Epoch 34/50
76/86 [=========================>....] - ETA: 0s - loss: 8.3590e-04 - mae: 0.0250 - mse: 8.3590e-04
86/86 [==============================] - 1s 15ms/step - loss: 8.3069e-04 - mae: 0.0249 - mse: 8.3069e-04 - val_loss: 8.7996e-04 - val_mae: 0.0259 - val_mse: 8.7996e-04 - lr: 1.0000e-05
Epoch 35/50
70/86 [=======================>......] - ETA: 0s - loss: 8.2981e-04 - mae: 0.0249 - mse: 8.2981e-04
86/86 [==============================] - 1s 17ms/step - loss: 8.3063e-04 - mae: 0.0249 - mse: 8.3063e-04 - val_loss: 8.7989e-04 - val_mae: 0.0259 - val_mse: 8.7989e-04 - lr: 1.0000e-05
Epoch 36/50
69/86 [=======================>......] - ETA: 0s - loss: 8.2082e-04 - mae: 0.0247 - mse: 8.2082e-04
86/86 [==============================] - 1s 13ms/step - loss: 8.3058e-04 - mae: 0.0249 - mse: 8.3058e-04 - val_loss: 8.7981e-04 - val_mae: 0.0259 - val_mse: 8.7981e-04 - lr: 1.0000e-05
Epoch 37/50
86/86 [==============================] - ETA: 0s - loss: 8.3052e-04 - mae: 0.0249 - mse: 8.3052e-04
86/86 [==============================] - 1s 13ms/step - loss: 8.3052e-04 - mae: 0.0249 - mse: 8.3052e-04 - val_loss: 8.7974e-04 - val_mae: 0.0259 - val_mse: 8.7974e-04 - lr: 1.0000e-05
Epoch 38/50
78/86 [==========================>...] - ETA: 0s - loss: 8.4363e-04 - mae: 0.0252 - mse: 8.4363e-04
86/86 [==============================] - 1s 13ms/step - loss: 8.3046e-04 - mae: 0.0249 - mse: 8.3046e-04 - val_loss: 8.7967e-04 - val_mae: 0.0259 - val_mse: 8.7967e-04 - lr: 1.0000e-05
Epoch 39/50
75/86 [=========================>....] - ETA: 0s - loss: 8.4065e-04 - mae: 0.0251 - mse: 8.4065e-04
86/86 [==============================] - 1s 13ms/step - loss: 8.3039e-04 - mae: 0.0249 - mse: 8.3039e-04 - val_loss: 8.7959e-04 - val_mae: 0.0259 - val_mse: 8.7959e-04 - lr: 1.0000e-05
Epoch 40/50
74/86 [========================>.....] - ETA: 0s - loss: 8.3010e-04 - mae: 0.0250 - mse: 8.3010e-04
86/86 [==============================] - 1s 14ms/step - loss: 8.3034e-04 - mae: 0.0249 - mse: 8.3034e-04 - val_loss: 8.7952e-04 - val_mae: 0.0259 - val_mse: 8.7952e-04 - lr: 1.0000e-05
Epoch 41/50
74/86 [========================>.....] - ETA: 0s - loss: 8.4448e-04 - mae: 0.0252 - mse: 8.4448e-04
86/86 [==============================] - 1s 14ms/step - loss: 8.3027e-04 - mae: 0.0249 - mse: 8.3027e-04 - val_loss: 8.7944e-04 - val_mae: 0.0259 - val_mse: 8.7944e-04 - lr: 1.0000e-05
Epoch 42/50
81/86 [===========================>..] - ETA: 0s - loss: 8.3015e-04 - mae: 0.0249 - mse: 8.3015e-04
86/86 [==============================] - 1s 16ms/step - loss: 8.3021e-04 - mae: 0.0249 - mse: 8.3021e-04 - val_loss: 8.7935e-04 - val_mae: 0.0259 - val_mse: 8.7935e-04 - lr: 1.0000e-05
Epoch 43/50
73/86 [========================>.....] - ETA: 0s - loss: 8.2812e-04 - mae: 0.0249 - mse: 8.2812e-04
86/86 [==============================] - 1s 15ms/step - loss: 8.3015e-04 - mae: 0.0249 - mse: 8.3015e-04 - val_loss: 8.7928e-04 - val_mae: 0.0259 - val_mse: 8.7928e-04 - lr: 1.0000e-05
Epoch 44/50
63/86 [====================>.........] - ETA: 0s - loss: 8.3444e-04 - mae: 0.0250 - mse: 8.3444e-04
79/86 [==========================>...] - ETA: 0s - loss: 8.2925e-04 - mae: 0.0249 - mse: 8.2925e-048e-04 - val_loss: 8.7920e-04 - val_mae: 0.0259 - val_mse: 8.7920e-04 - lr: 1.0000e-05
Epoch 45/50
79/86 [==========================>...] - ETA: 0s - loss: 8.2925e-04 - mae: 0.0249 - mse: 8.2925e-048e-04 - val_loss: 8.7920e-04 - val_mae: 0.0259 - val_mse: 8.7920e-04 - lr: 1.0000e-05
57/86 [==================>...........] - ETA: 0s - loss: 8.1866e-04 - mae: 0.0246 - mse: 8.1866e-042e-04 - val_loss: 8.7913e-04 - val_mae: 0.0259 - val_mse: 8.7913e-04 - lr: 1.0000e-05
Epoch 46/50
57/86 [==================>...........] - ETA: 0s - loss: 8.1866e-04 - mae: 0.0246 - mse: 8.1866e-042e-04 - val_loss: 8.7913e-04 - val_mae: 0.0259 - val_mse: 8.7913e-04 - lr: 1.0000e-05
76/86 [=========================>....] - ETA: 0s - loss: 8.2807e-04 - mae: 0.0249 - mse: 8.2807e-046e-04 - val_loss: 8.7906e-04 - val_mae: 0.0259 - val_mse: 8.7906e-04 - lr: 1.0000e-05
Epoch 47/50
76/86 [=========================>....] - ETA: 0s - loss: 8.2807e-04 - mae: 0.0249 - mse: 8.2807e-046e-04 - val_loss: 8.7906e-04 - val_mae: 0.0259 - val_mse: 8.7906e-04 - lr: 1.0000e-05
81/86 [===========================>..] - ETA: 0s - loss: 8.3256e-04 - mae: 0.0250 - mse: 8.3256e-041e-04 - val_loss: 8.7899e-04 - val_mae: 0.0259 - val_mse: 8.7899e-04 - lr: 1.0000e-05
Epoch 48/50
81/86 [===========================>..] - ETA: 0s - loss: 8.3256e-04 - mae: 0.0250 - mse: 8.3256e-041e-04 - val_loss: 8.7899e-04 - val_mae: 0.0259 - val_mse: 8.7899e-04 - lr: 1.0000e-05
64/86 [=====================>........] - ETA: 0s - loss: 8.2525e-04 - mae: 0.0248 - mse: 8.2525e-046e-04 - val_loss: 8.7892e-04 - val_mae: 0.0259 - val_mse: 8.7892e-04 - lr: 1.0000e-05
Epoch 49/50
64/86 [=====================>........] - ETA: 0s - loss: 8.2525e-04 - mae: 0.0248 - mse: 8.2525e-046e-04 - val_loss: 8.7892e-04 - val_mae: 0.0259 - val_mse: 8.7892e-04 - lr: 1.0000e-05
84/86 [============================>.] - ETA: 0s - loss: 8.2892e-04 - mae: 0.0249 - mse: 8.2892e-049e-04 - val_loss: 8.7885e-04 - val_mae: 0.0259 - val_mse: 8.7885e-04 - lr: 1.0000e-05
Epoch 50/50
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])- mae: 0.0249 - mse: 8.2974e-04 - val_loss: 8.7877e-04 - val_mae: 0.0259 - val_mse: 8.7877e-04 - lr: 1.0000e-05
>Saved ../../trained_models/models_segments_no_overlap-baseline-RMSprop30.0_50epochs/model_1.h5
dict_keys(['loss', 'mae', 'mse', 'val_loss', 'val_mae', 'val_mse', 'lr'])- mae: 0.0249 - mse: 8.2974e-04 - val_loss: 8.7877e-04 - val_mae: 0.0259 - val_mse: 8.7877e-04 - lr: 1.0000e-05